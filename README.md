# ğŸ” KURE: Korea University Retrieval Embedding model

## Update Logs
- 2024.12.21: [ğŸ¤— KURE-v1](https://huggingface.co/nlpai-lab/KURE-v1), [MTEB-ko-retrieval Leaderboard](https://github.com/nlpai-lab/KURE?tab=readme-ov-file#mteb-ko-retrieval-leaderboard) ê³µê°œ
- 2024.10.02: [ğŸ¤— KoE5](https://huggingface.co/nlpai-lab/KoE5), [ğŸ¤— ko-triplet-v1.0](https://huggingface.co/datasets/nlpai-lab/ko-triplet-v1.0) ê³µê°œ

---

<br>

KUREëŠ” ê³ ë ¤ëŒ€í•™êµ [NLP & AI ì—°êµ¬ì‹¤](http://nlp.korea.ac.kr/)ê³¼ [HIAI ì—°êµ¬ì†Œ](http://hiai.korea.ac.kr)ê°€ ê°œë°œí•œ í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ì…ë‹ˆë‹¤.

KUREë¥¼ ê³µê°œí•©ë‹ˆë‹¤.  
<br/>

## KURE ëª¨ë¸ ì‹¤í–‰ ì½”ë“œ
### sentence-transformersë¡œ ì‹¤í–‰
```bash
pip install sentence-transformers
```

ì•„ë˜ ì˜ˆì œ ì½”ë“œë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from sentence_transformers import SentenceTransformer

# Download from the ğŸ¤— Hub

model = SentenceTransformer("nlpai-lab/KURE-v1")
# model = SentenceTransformer("nlpai-lab/KoE5")

# Run inference
sentences = [
    'í—Œë²•ê³¼ ë²•ì›ì¡°ì§ë²•ì€ ì–´ë–¤ ë°©ì‹ì„ í†µí•´ ê¸°ë³¸ê¶Œ ë³´ì¥ ë“±ì˜ ë‹¤ì–‘í•œ ë²•ì  ëª¨ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆì–´',
    '4. ì‹œì‚¬ì ê³¼ ê°œì„ ë°©í–¥ ì•ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´ ìš°ë¦¬ í—Œë²•ê³¼ ï½¢ë²•ì›ì¡°ì§ ë²•ï½£ì€ ëŒ€ë²•ì› êµ¬ì„±ì„ ë‹¤ì–‘í™”í•˜ì—¬ ê¸°ë³¸ê¶Œ ë³´ì¥ê³¼ ë¯¼ì£¼ì£¼ì˜ í™•ë¦½ì— ìˆì–´ ë‹¤ê°ì ì¸ ë²•ì  ëª¨ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ê·¼ë³¸ ê·œë²”ìœ¼ë¡œ í•˜ê³  ìˆë‹¤. ë”ìš±ì´ í•©ì˜ì²´ë¡œì„œì˜ ëŒ€ë²•ì› ì›ë¦¬ë¥¼ ì±„íƒí•˜ê³  ìˆëŠ” ê²ƒ ì—­ì‹œ ê·¸ êµ¬ì„±ì˜ ë‹¤ì–‘ì„±ì„ ìš”ì²­í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì„ëœë‹¤. ì´ì™€ ê°™ì€ ê´€ì ì—ì„œ ë³¼ ë•Œ í˜„ì§ ë²•ì›ì¥ê¸‰ ê³ ìœ„ë²•ê´€ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ë²•ì›ì„ êµ¬ì„±í•˜ëŠ” ê´€í–‰ì€ ê°œì„ í•  í•„ìš”ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.',
    'ì—°ë°©í—Œë²•ì¬íŒì†ŒëŠ” 2001ë…„ 1ì›” 24ì¼ 5:3ì˜ ë‹¤ìˆ˜ê²¬í•´ë¡œ ã€Œë²•ì›ì¡°ì§ë²•ã€ ì œ169ì¡° ì œ2ë¬¸ì´ í—Œë²•ì— í•©ì¹˜ëœë‹¤ëŠ” íŒê²°ì„ ë‚´ë ¸ìŒ â—‹ 5ì¸ì˜ ë‹¤ìˆ˜ ì¬íŒê´€ì€ ì†Œì†¡ê´€ê³„ì¸ì˜ ì¸ê²©ê¶Œ ë³´í˜¸, ê³µì •í•œ ì ˆì°¨ì˜ ë³´ì¥ê³¼ ë°©í•´ë°›ì§€ ì•ŠëŠ” ë²•ê³¼ ì§„ì‹¤ ë°œê²¬ ë“±ì„ ê·¼ê±°ë¡œ í•˜ì—¬ í…”ë ˆë¹„ì „ ì´¬ì˜ì— ëŒ€í•œ ì ˆëŒ€ì ì¸ ê¸ˆì§€ë¥¼ í—Œë²•ì— í•©ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•˜ìŒ â—‹ ê·¸ëŸ¬ë‚˜ ë‚˜ë¨¸ì§€ 3ì¸ì˜ ì¬íŒê´€ì€ í–‰ì •ë²•ì›ì˜ ì†Œì†¡ì ˆì°¨ëŠ” íŠ¹ë³„í•œ ì¸ê²©ê¶Œ ë³´í˜¸ì˜ ì´ìµë„ ì—†ìœ¼ë©°, í…”ë ˆë¹„ì „ ê³µê°œì£¼ì˜ë¡œ ì¸í•´ ë²•ê³¼ ì§„ì‹¤ ë°œê²¬ì˜ ê³¼ì •ì´ ì–¸ì œë‚˜ ìœ„íƒœë¡­ê²Œ ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë¼ë©´ì„œ ë°˜ëŒ€ì˜ê²¬ì„ ì œì‹œí•¨ â—‹ ì™œëƒí•˜ë©´ í–‰ì •ë²•ì›ì˜ ì†Œì†¡ì ˆì°¨ì—ì„œëŠ” ì†Œì†¡ë‹¹ì‚¬ìê°€ ê°œì¸ì ìœ¼ë¡œ ì§ì ‘ ì‹¬ë¦¬ì— ì°¸ì„í•˜ê¸°ë³´ë‹¤ëŠ” ë³€í˜¸ì‚¬ê°€ ì°¸ì„í•˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©°, ì‹¬ë¦¬ëŒ€ìƒë„ ì‚¬ì‹¤ë¬¸ì œê°€ ì•„ë‹Œ ë²•ë¥ ë¬¸ì œê°€ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì´ë¼ëŠ” ê²ƒì„ â–¡ í•œí¸, ì—°ë°©í—Œë²•ì¬íŒì†ŒëŠ” ã€Œì—°ë°©í—Œë²•ì¬íŒì†Œë²•ã€(Bundesverfassungsgerichtsgesetz: BVerfGG) ì œ17aì¡°ì— ë”°ë¼ ì œí•œì ì´ë‚˜ë§ˆ ì¬íŒì— ëŒ€í•œ ë°©ì†¡ì„ í—ˆìš©í•˜ê³  ìˆìŒ â—‹ ã€Œì—°ë°©í—Œë²•ì¬íŒì†Œë²•ã€ ì œ17ì¡°ì—ì„œ ã€Œë²•ì›ì¡°ì§ë²•ã€ ì œ14ì ˆ ë‚´ì§€ ì œ16ì ˆì˜ ê·œì •ì„ ì¤€ìš©í•˜ë„ë¡ í•˜ê³  ìˆì§€ë§Œ, ë…¹ìŒì´ë‚˜ ì´¬ì˜ì„ í†µí•œ ì¬íŒê³µê°œì™€ ê´€ë ¨í•˜ì—¬ì„œëŠ” ã€Œë²•ì›ì¡°ì§ë²•ã€ê³¼ ë‹¤ë¥¸ ë‚´ìš©ì„ ê·œì •í•˜ê³  ìˆìŒ',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 1024]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities)
# Results for KURE-v1
# tensor([[1.0000, 0.6967, 0.5306],
#         [0.6967, 1.0000, 0.4427],
#         [0.5306, 0.4427, 1.0000]])

# Results for KoE5
# tensor([[1.0000, 0.6721, 0.3897],
#        [0.6721, 1.0000, 0.3740],
#        [0.3897, 0.3740, 1.0000]])
```

<br/>

## MTEB-ko-retrieval leaderboard
MTEBì— ë“±ë¡ëœ ëª¨ë“  Korean Retrieval Benchmarkì— ëŒ€í•œ í‰ê°€ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.
### Korean Retrieval Benchmark
- [Ko-StrategyQA](https://huggingface.co/datasets/taeminlee/Ko-StrategyQA): í•œêµ­ì–´ ODQA multi-hop ê²€ìƒ‰ ë°ì´í„°ì…‹ (StrategyQA ë²ˆì—­)
- [AutoRAGRetrieval](https://huggingface.co/datasets/yjoonjang/markers_bm): ê¸ˆìœµ, ê³µê³µ, ì˜ë£Œ, ë²•ë¥ , ì»¤ë¨¸ìŠ¤ 5ê°œ ë¶„ì•¼ì— ëŒ€í•´, pdfë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì„±í•œ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [MIRACLRetrieval]([url](https://huggingface.co/datasets/miracl/miracl)): Wikipedia ê¸°ë°˜ì˜ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [PublicHealthQA]([url](https://huggingface.co/datasets/xhluca/publichealth-qa)): ì˜ë£Œ ë° ê³µì¤‘ë³´ê±´ ë„ë©”ì¸ì— ëŒ€í•œ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [BelebeleRetrieval]([url](https://huggingface.co/datasets/facebook/belebele)): FLORES-200 ê¸°ë°˜ì˜ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [MrTidyRetrieval](https://huggingface.co/datasets/mteb/mrtidy): Wikipedia ê¸°ë°˜ì˜ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [MultiLongDocRetrieval](https://huggingface.co/datasets/Shitao/MLDR): ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ í•œêµ­ì–´ ì¥ë¬¸ ê²€ìƒ‰ ë°ì´í„°ì…‹
- [XPQARetrieval](https://huggingface.co/datasets/jinaai/xpqa): ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ ë°ì´í„°ì…‹

### Evaluation code
`evaluate.py`ì— ëª¨ë¸ì„ ì¶”ê°€í•˜ì—¬ mtebë¥¼ í™œìš©í•œ í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```bash
cd eval
pip install -r requirements.txt
python evaluate.py
```

### Leaderboard
streamlitì„ í†µí•´ ëª¨ë“  ëª¨ë¸ì˜ ëª¨ë“  íƒœìŠ¤í¬ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
```bash
streamlit run leaderboard.py
```

ì•„ë˜ëŠ” ëª¨ë“  ëª¨ë¸ì˜, ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê·  ê²°ê³¼ì…ë‹ˆë‹¤.
ìì„¸í•œ ê²°ê³¼ëŠ” `eval/results`í´ë”ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
### Top-k 1
| Model                                   | Average Recall_top1 | Average Precision_top1 | Average NDCG_top1 | Average F1_top1 |
|-----------------------------------------|----------------------|------------------------|-------------------|-----------------|
| **nlpai-lab/KURE-v1**                   | **0.52640**          | **0.60551**            | **0.60551**       | **0.55784**     |
| dragonkue/BGE-m3-ko                     | 0.52361              | 0.60394                | 0.60394           | 0.55535         |
| BAAI/bge-m3                             | 0.51778              | 0.59846                | 0.59846           | 0.54998         |
| Snowflake/snowflake-arctic-embed-l-v2.0 | 0.51246              | 0.59384                | 0.59384           | 0.54489         |
| nlpai-lab/KoE5                          | 0.50157              | 0.57790                | 0.57790           | 0.53178         |
| intfloat/multilingual-e5-large          | 0.50052              | 0.57727                | 0.57727           | 0.53122         |
| jinaai/jina-embeddings-v3               | 0.48287              | 0.56068                | 0.56068           | 0.51361         |
| BAAI/bge-multilingual-gemma2            | 0.47904              | 0.55472                | 0.55472           | 0.50916         |
| intfloat/multilingual-e5-large-instruct | 0.47842              | 0.55435                | 0.55435           | 0.50826         |
| intfloat/multilingual-e5-base           | 0.46950              | 0.54490                | 0.54490           | 0.49947         |
| intfloat/e5-mistral-7b-instruct         | 0.46772              | 0.54394                | 0.54394           | 0.49781         |
| Alibaba-NLP/gte-multilingual-base       | 0.46469              | 0.53744                | 0.53744           | 0.49353         |
| Alibaba-NLP/gte-Qwen2-7B-instruct       | 0.46633              | 0.53625                | 0.53625           | 0.49429         |
| openai/text-embedding-3-large           | 0.44884              | 0.51688                | 0.51688           | 0.47572         |
| Salesforce/SFR-Embedding-2_R            | 0.43748              | 0.50815                | 0.50815           | 0.46504         |
| upskyy/bge-m3-korean                    | 0.43125              | 0.50245                | 0.50245           | 0.45945         |
| jhgan/ko-sroberta-multitask             | 0.33788              | 0.38497                | 0.38497           | 0.35678         |

### Top-k 3
| Model                                   | Average Recall_top1 | Average Precision_top1 | Average NDCG_top1 | Average F1_top1 |
|-----------------------------------------|----------------------|------------------------|-------------------|-----------------|
| **nlpai-lab/KURE-v1**                   | **0.68678**          | **0.28711**            | **0.65538**       | **0.39835**     |
| dragonkue/BGE-m3-ko                     | 0.67834              | 0.28385                | 0.64950           | 0.39378         |
| BAAI/bge-m3                             | 0.67526              | 0.28374                | 0.64556           | 0.39291         |
| Snowflake/snowflake-arctic-embed-l-v2.0 | 0.67128              | 0.28193                | 0.64042           | 0.39072         |
| intfloat/multilingual-e5-large          | 0.65807              | 0.27777                | 0.62822           | 0.38423         |
| nlpai-lab/KoE5                          | 0.65174              | 0.27329                | 0.62369           | 0.37882         |
| BAAI/bge-multilingual-gemma2            | 0.64415              | 0.27416                | 0.61105           | 0.37782         |
| jinaai/jina-embeddings-v3               | 0.64116              | 0.27165                | 0.60954           | 0.37511         |
| intfloat/multilingual-e5-large-instruct | 0.64353              | 0.27040                | 0.60790           | 0.37453         |
| Alibaba-NLP/gte-multilingual-base       | 0.63744              | 0.26404                | 0.59695           | 0.36764         |
| Alibaba-NLP/gte-Qwen2-7B-instruct       | 0.63163              | 0.25937                | 0.59237           | 0.36263         |
| intfloat/multilingual-e5-base           | 0.62099              | 0.26144                | 0.59179           | 0.36203         |
| intfloat/e5-mistral-7b-instruct         | 0.62087              | 0.26144                | 0.58917           | 0.36188         |
| openai/text-embedding-3-large           | 0.61035              | 0.25356                | 0.57329           | 0.35270         |
| Salesforce/SFR-Embedding-2_R            | 0.60001              | 0.25253                | 0.56346           | 0.34952         |
| upskyy/bge-m3-korean                    | 0.59215              | 0.25076                | 0.55722           | 0.34623         |
| jhgan/ko-sroberta-multitask             | 0.46930              | 0.18994                | 0.43293           | 0.26696         |

### Top-k 5
| Model                                   | Average Recall_top1 | Average Precision_top1 | Average NDCG_top1 | Average F1_top1 |
|-----------------------------------------|----------------------|------------------------|-------------------|-----------------|
| **nlpai-lab/KURE-v1**                   | **0.73851**          | **0.19130**            | **0.67479**       | **0.29903**     |
| dragonkue/BGE-m3-ko                     | 0.72517              | 0.18799                | 0.66692           | 0.29401         |
| BAAI/bge-m3                             | 0.72954              | 0.18975                | 0.66615           | 0.29632         |
| Snowflake/snowflake-arctic-embed-l-v2.0 | 0.72962              | 0.18875                | 0.66236           | 0.29542         |
| nlpai-lab/KoE5                          | 0.70820              | 0.18287                | 0.64499           | 0.28628         |
| intfloat/multilingual-e5-large          | 0.70124              | 0.18316                | 0.64402           | 0.28588         |
| BAAI/bge-multilingual-gemma2            | 0.70258              | 0.18556                | 0.63338           | 0.28851         |
| jinaai/jina-embeddings-v3               | 0.69933              | 0.18256                | 0.63133           | 0.28505         |
| intfloat/multilingual-e5-large-instruct | 0.69018              | 0.17838                | 0.62486           | 0.27933         |
| Alibaba-NLP/gte-multilingual-base       | 0.69365              | 0.17789                | 0.61896           | 0.27879         |
| intfloat/multilingual-e5-base           | 0.67250              | 0.17406                | 0.61119           | 0.27247         |
| Alibaba-NLP/gte-Qwen2-7B-instruct       | 0.67447              | 0.17114                | 0.60952           | 0.26943         |
| intfloat/e5-mistral-7b-instruct         | 0.67449              | 0.17484                | 0.60935           | 0.27349         |
| openai/text-embedding-3-large           | 0.66365              | 0.17004                | 0.59389           | 0.26677         |
| Salesforce/SFR-Embedding-2_R            | 0.65622              | 0.17018                | 0.58494           | 0.26612         |
| upskyy/bge-m3-korean                    | 0.65477              | 0.17015                | 0.58073           | 0.26589         |
| jhgan/ko-sroberta-multitask             | 0.53136              | 0.13264                | 0.45879           | 0.20976         |

### Top-k 10
| Model                                   | Average Recall_top1 | Average Precision_top1 | Average NDCG_top1 | Average F1_top1 |
|-----------------------------------------|----------------------|------------------------|-------------------|-----------------|
| **nlpai-lab/KURE-v1**                   | **0.79682**          | **0.10624**            | **0.69473**       | **0.18524**     |
| dragonkue/BGE-m3-ko                     | 0.78450              | 0.10492                | 0.68748           | 0.18288         |
| BAAI/bge-m3                             | 0.79195              | 0.10592                | 0.68723           | 0.18456         |
| Snowflake/snowflake-arctic-embed-l-v2.0 | 0.78669              | 0.10462                | 0.68189           | 0.18260         |
| intfloat/multilingual-e5-large          | 0.75902              | 0.10147                | 0.66370           | 0.17693         |
| nlpai-lab/KoE5                          | 0.75296              | 0.09937                | 0.66012           | 0.17369         |
| BAAI/bge-multilingual-gemma2            | 0.76153              | 0.10364                | 0.65330           | 0.18003         |
| jinaai/jina-embeddings-v3               | 0.76277              | 0.10240                | 0.65290           | 0.17843         |
| intfloat/multilingual-e5-large-instruct | 0.74851              | 0.09888                | 0.64451           | 0.17283         |
| Alibaba-NLP/gte-multilingual-base       | 0.75631              | 0.09938                | 0.64025           | 0.17363         |
| Alibaba-NLP/gte-Qwen2-7B-instruct       | 0.74092              | 0.09607                | 0.63258           | 0.16847         |
| intfloat/multilingual-e5-base           | 0.73512              | 0.09717                | 0.63216           | 0.16977         |
| intfloat/e5-mistral-7b-instruct         | 0.73795              | 0.09777                | 0.63076           | 0.17078         |
| openai/text-embedding-3-large           | 0.72946              | 0.09571                | 0.61670           | 0.16739         |
| Salesforce/SFR-Embedding-2_R            | 0.71662              | 0.09546                | 0.60589           | 0.16651         |
| upskyy/bge-m3-korean                    | 0.71895              | 0.09583                | 0.60258           | 0.16712         |
| jhgan/ko-sroberta-multitask             | 0.61225              | 0.07826                | 0.48687           | 0.13757         |
<br/>

## Training Details
- KURE-v1ì€ [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ fine-tuningëœ ëª¨ë¸ì…ë‹ˆë‹¤.
- KoE5ëŠ” [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ fine-tuningëœ ëª¨ë¸ì…ë‹ˆë‹¤.

### Training Data
**KURE-v1**
- í•œêµ­ì–´ query-document-hard_negative(5ê°œ) ë°ì´í„° ìŒ 
- ì•½ 2,000,000 examples

**KoE5**
- [ko-triplet-v1.0](https://huggingface.co/datasets/nlpai-lab/ko-triplet-v1.0)
- í•œêµ­ì–´ query-document-hard_negative(1ê°œ) ë°ì´í„° ìŒ (open data)
- ì•½ 700,000+ examples

### Training Procedure
**KURE-v1**
- loss: [CachedGISTEmbedLoss](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cachedgistembedloss)
- batch size: 4096
- learning rate: 2e-05
- epochs: 1

**KoE5**
- loss: [CachedMultipleNegativesRankingLoss](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cachedmultiplenegativesrankingloss)
- batch size: 512
- learning rate: 1e-05
- epochs: 1

<br/>

## ì£¼ì˜ì‚¬í•­
- KoE5 ì‚¬ìš© ì‹œ, prefixë¥¼ ë¶™ì—¬ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. (query: {query}, passage: {document})
  
## License
- ```MIT```

## Citation
If you find our paper or models helpful, please consider cite as follows:
```text
@misc{KURE,
  publisher = {Youngjoon Jang, Junyoung Son, Taemin Lee},
  year = {2024},
  url = {https://github.com/nlpai-lab/KURE}
},

@misc{KoE5,
  author = {NLP & AI Lab and Human-Inspired AI research},
  title = {KoE5: í•œêµ­ì–´ ì„ë² ë”© ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë° ëª¨ë¸},
  year = {2024},
  publisher = {Youngjoon Jang, Junyoung Son, Taemin Lee},
  journal = {GitHub repository},
  howpublished = {\url{https://drive.google.com/file/d/1wB02XGFH5v18iJYSYB0oJkWFYxH0ftoJ/view}},
}
```
