taeminlee/Ko-StrategyQA loading



==================================================
Running model: nlpai-lab/KURE-v1
--------------------------------------------------
INFO:mteb.models.overview:Model not found in model registry, assuming it is on HF Hub model.
INFO:mteb.models.overview:Attempting to extract metadata by loading the model (nlpai-lab/KURE-v1) using HuggingFace.
WARNING:mteb.model_meta:Loader not specified for model nlpai-lab/KURE-v1, loading using sentence transformers.
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: nlpai-lab/KURE-v1
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / nlpai-lab/KURE-v1 on GPU 0 in process Process-1
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  10%|█         | 1/10 [00:00<00:03,  2.92it/s]Batches:  30%|███       | 3/10 [00:00<00:00,  7.79it/s]Batches:  50%|█████     | 5/10 [00:00<00:00, 11.02it/s]Batches:  80%|████████  | 8/10 [00:00<00:00, 14.54it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 12.66it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/145 [00:00<?, ?it/s]Batches:   1%|          | 1/145 [00:00<00:28,  5.02it/s]Batches:   1%|▏         | 2/145 [00:13<19:29,  8.18s/it]Batches:   2%|▏         | 3/145 [00:16<13:04,  5.52s/it]Batches:   3%|▎         | 4/145 [00:17<09:22,  3.99s/it]Batches:   3%|▎         | 5/145 [00:19<07:06,  3.05s/it]Batches:   4%|▍         | 6/145 [00:20<05:39,  2.44s/it]Batches:   5%|▍         | 7/145 [00:21<04:42,  2.05s/it]Batches:   6%|▌         | 8/145 [00:22<03:59,  1.75s/it]Batches:   6%|▌         | 9/145 [00:24<03:32,  1.56s/it]Batches:   7%|▋         | 10/145 [00:25<03:10,  1.41s/it]Batches:   8%|▊         | 11/145 [00:26<02:55,  1.31s/it]Batches:   8%|▊         | 12/145 [00:27<02:45,  1.25s/it]Batches:   9%|▉         | 13/145 [00:28<02:30,  1.14s/it]Batches:  10%|▉         | 14/145 [00:29<02:22,  1.09s/it]Batches:  10%|█         | 15/145 [00:30<02:14,  1.03s/it]Batches:  11%|█         | 16/145 [00:30<02:06,  1.02it/s]Batches:  12%|█▏        | 17/145 [00:31<02:01,  1.05it/s]Batches:  12%|█▏        | 18/145 [00:32<01:58,  1.08it/s]Batches:  13%|█▎        | 19/145 [00:33<01:52,  1.12it/s]Batches:  14%|█▍        | 20/145 [00:34<01:48,  1.15it/s]Batches:  14%|█▍        | 21/145 [00:35<01:45,  1.17it/s]Batches:  15%|█▌        | 22/145 [00:35<01:43,  1.19it/s]Batches:  16%|█▌        | 23/145 [00:36<01:43,  1.18it/s]Batches:  17%|█▋        | 24/145 [00:37<01:39,  1.22it/s]Batches:  17%|█▋        | 25/145 [00:38<01:35,  1.26it/s]Batches:  18%|█▊        | 26/145 [00:39<01:33,  1.27it/s]Batches:  19%|█▊        | 27/145 [00:39<01:31,  1.28it/s]Batches:  19%|█▉        | 28/145 [00:40<01:29,  1.31it/s]Batches:  20%|██        | 29/145 [00:41<01:28,  1.32it/s]Batches:  21%|██        | 30/145 [00:42<01:25,  1.34it/s]Batches:  21%|██▏       | 31/145 [00:42<01:23,  1.36it/s]Batches:  22%|██▏       | 32/145 [00:43<01:22,  1.37it/s]Batches:  23%|██▎       | 33/145 [00:44<01:20,  1.40it/s]Batches:  23%|██▎       | 34/145 [00:44<01:19,  1.40it/s]Batches:  24%|██▍       | 35/145 [00:45<01:15,  1.45it/s]Batches:  25%|██▍       | 36/145 [00:46<01:13,  1.48it/s]Batches:  26%|██▌       | 37/145 [00:46<01:11,  1.51it/s]Batches:  26%|██▌       | 38/145 [00:47<01:11,  1.49it/s]Batches:  27%|██▋       | 39/145 [00:48<01:09,  1.53it/s]Batches:  28%|██▊       | 40/145 [00:48<01:07,  1.56it/s]Batches:  28%|██▊       | 41/145 [00:49<01:05,  1.58it/s]Batches:  29%|██▉       | 42/145 [00:49<01:04,  1.59it/s]Batches:  30%|██▉       | 43/145 [00:50<01:04,  1.59it/s]Batches:  30%|███       | 44/145 [00:51<01:03,  1.59it/s]Batches:  31%|███       | 45/145 [00:51<01:01,  1.62it/s]Batches:  32%|███▏      | 46/145 [00:52<01:00,  1.65it/s]Batches:  32%|███▏      | 47/145 [00:52<00:59,  1.66it/s]Batches:  33%|███▎      | 48/145 [00:53<00:58,  1.66it/s]Batches:  34%|███▍      | 49/145 [00:54<00:57,  1.67it/s]Batches:  34%|███▍      | 50/145 [00:54<00:55,  1.70it/s]Batches:  35%|███▌      | 51/145 [00:55<00:55,  1.70it/s]Batches:  36%|███▌      | 52/145 [00:55<00:54,  1.70it/s]Batches:  37%|███▋      | 53/145 [00:56<00:53,  1.71it/s]Batches:  37%|███▋      | 54/145 [00:57<00:52,  1.73it/s]Batches:  38%|███▊      | 55/145 [00:57<00:50,  1.77it/s]Batches:  39%|███▊      | 56/145 [00:58<00:50,  1.75it/s]Batches:  39%|███▉      | 57/145 [00:58<00:49,  1.79it/s]Batches:  40%|████      | 58/145 [00:59<00:47,  1.82it/s]Batches:  41%|████      | 59/145 [00:59<00:46,  1.83it/s]Batches:  41%|████▏     | 60/145 [01:00<00:46,  1.82it/s]Batches:  42%|████▏     | 61/145 [01:00<00:45,  1.87it/s]Batches:  43%|████▎     | 62/145 [01:01<00:44,  1.88it/s]Batches:  43%|████▎     | 63/145 [01:01<00:43,  1.89it/s]Batches:  44%|████▍     | 64/145 [01:02<00:42,  1.92it/s]Batches:  45%|████▍     | 65/145 [01:02<00:41,  1.91it/s]Batches:  46%|████▌     | 66/145 [01:03<00:40,  1.93it/s]Batches:  46%|████▌     | 67/145 [01:03<00:40,  1.91it/s]Batches:  47%|████▋     | 68/145 [01:04<00:39,  1.96it/s]Batches:  48%|████▊     | 69/145 [01:04<00:38,  1.96it/s]Batches:  48%|████▊     | 70/145 [01:05<00:37,  1.99it/s]Batches:  49%|████▉     | 71/145 [01:05<00:36,  2.01it/s]Batches:  50%|████▉     | 72/145 [01:06<00:35,  2.06it/s]Batches:  50%|█████     | 73/145 [01:06<00:34,  2.11it/s]Batches:  51%|█████     | 74/145 [01:07<00:33,  2.15it/s]Batches:  52%|█████▏    | 75/145 [01:07<00:32,  2.18it/s]Batches:  52%|█████▏    | 76/145 [01:08<00:31,  2.20it/s]Batches:  53%|█████▎    | 77/145 [01:08<00:30,  2.21it/s]Batches:  54%|█████▍    | 78/145 [01:09<00:30,  2.22it/s]Batches:  54%|█████▍    | 79/145 [01:09<00:29,  2.22it/s]Batches:  55%|█████▌    | 80/145 [01:09<00:29,  2.21it/s]Batches:  56%|█████▌    | 81/145 [01:10<00:28,  2.26it/s]Batches:  57%|█████▋    | 82/145 [01:10<00:27,  2.26it/s]Batches:  57%|█████▋    | 83/145 [01:11<00:27,  2.26it/s]Batches:  58%|█████▊    | 84/145 [01:11<00:27,  2.24it/s]Batches:  59%|█████▊    | 85/145 [01:12<00:26,  2.24it/s]Batches:  59%|█████▉    | 86/145 [01:12<00:25,  2.28it/s]Batches:  60%|██████    | 87/145 [01:12<00:25,  2.31it/s]Batches:  61%|██████    | 88/145 [01:13<00:24,  2.37it/s]Batches:  61%|██████▏   | 89/145 [01:13<00:23,  2.39it/s]Batches:  62%|██████▏   | 90/145 [01:14<00:22,  2.43it/s]Batches:  63%|██████▎   | 91/145 [01:14<00:22,  2.42it/s]Batches:  63%|██████▎   | 92/145 [01:14<00:21,  2.46it/s]Batches:  64%|██████▍   | 93/145 [01:15<00:20,  2.49it/s]Batches:  65%|██████▍   | 94/145 [01:15<00:20,  2.47it/s]Batches:  66%|██████▌   | 95/145 [01:16<00:20,  2.49it/s]Batches:  66%|██████▌   | 96/145 [01:16<00:19,  2.46it/s]Batches:  67%|██████▋   | 97/145 [01:16<00:19,  2.48it/s]Batches:  68%|██████▊   | 98/145 [01:17<00:18,  2.50it/s]Batches:  68%|██████▊   | 99/145 [01:17<00:18,  2.56it/s]Batches:  69%|██████▉   | 100/145 [01:18<00:17,  2.62it/s]Batches:  70%|██████▉   | 101/145 [01:18<00:16,  2.67it/s]Batches:  70%|███████   | 102/145 [01:18<00:16,  2.67it/s]Batches:  71%|███████   | 103/145 [01:19<00:15,  2.72it/s]Batches:  72%|███████▏  | 104/145 [01:19<00:14,  2.74it/s]Batches:  72%|███████▏  | 105/145 [01:19<00:14,  2.77it/s]Batches:  73%|███████▎  | 106/145 [01:20<00:13,  2.81it/s]Batches:  74%|███████▍  | 107/145 [01:20<00:13,  2.81it/s]Batches:  74%|███████▍  | 108/145 [01:20<00:12,  2.85it/s]Batches:  75%|███████▌  | 109/145 [01:21<00:12,  2.86it/s]Batches:  76%|███████▌  | 110/145 [01:21<00:11,  2.94it/s]Batches:  77%|███████▋  | 111/145 [01:21<00:11,  2.98it/s]Batches:  77%|███████▋  | 112/145 [01:22<00:10,  3.02it/s]Batches:  78%|███████▊  | 113/145 [01:22<00:10,  3.09it/s]Batches:  79%|███████▊  | 114/145 [01:22<00:09,  3.15it/s]Batches:  79%|███████▉  | 115/145 [01:23<00:09,  3.19it/s]Batches:  80%|████████  | 116/145 [01:23<00:09,  3.18it/s]Batches:  81%|████████  | 117/145 [01:23<00:08,  3.23it/s]Batches:  81%|████████▏ | 118/145 [01:24<00:08,  3.29it/s]Batches:  82%|████████▏ | 119/145 [01:24<00:07,  3.37it/s]Batches:  83%|████████▎ | 120/145 [01:24<00:07,  3.43it/s]Batches:  83%|████████▎ | 121/145 [01:24<00:06,  3.44it/s]Batches:  84%|████████▍ | 122/145 [01:25<00:06,  3.55it/s]Batches:  85%|████████▍ | 123/145 [01:25<00:06,  3.57it/s]Batches:  86%|████████▌ | 124/145 [01:25<00:05,  3.56it/s]Batches:  86%|████████▌ | 125/145 [01:26<00:05,  3.67it/s]Batches:  87%|████████▋ | 126/145 [01:26<00:05,  3.78it/s]Batches:  88%|████████▊ | 127/145 [01:26<00:04,  3.81it/s]Batches:  88%|████████▊ | 128/145 [01:26<00:04,  3.89it/s]Batches:  89%|████████▉ | 129/145 [01:26<00:04,  3.97it/s]Batches:  90%|████████▉ | 130/145 [01:27<00:03,  4.06it/s]Batches:  90%|█████████ | 131/145 [01:27<00:03,  4.11it/s]Batches:  91%|█████████ | 132/145 [01:27<00:03,  4.21it/s]Batches:  92%|█████████▏| 133/145 [01:27<00:02,  4.26it/s]Batches:  92%|█████████▏| 134/145 [01:28<00:02,  4.40it/s]Batches:  93%|█████████▎| 135/145 [01:28<00:02,  4.50it/s]Batches:  94%|█████████▍| 136/145 [01:28<00:01,  4.62it/s]Batches:  94%|█████████▍| 137/145 [01:28<00:01,  4.82it/s]Batches:  95%|█████████▌| 138/145 [01:28<00:01,  4.98it/s]Batches:  96%|█████████▌| 139/145 [01:29<00:01,  5.02it/s]Batches:  97%|█████████▋| 140/145 [01:29<00:00,  5.21it/s]Batches:  97%|█████████▋| 141/145 [01:29<00:00,  5.37it/s]Batches:  98%|█████████▊| 142/145 [01:29<00:00,  5.66it/s]Batches:  99%|█████████▊| 143/145 [01:29<00:00,  5.92it/s]Batches:  99%|█████████▉| 144/145 [01:29<00:00,  6.36it/s]Batches: 100%|██████████| 145/145 [01:30<00:00,  6.92it/s]Batches: 100%|██████████| 145/145 [01:30<00:00,  1.61it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 91.53 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 92.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.76182, 'ndcg_at_3': 0.7545, 'ndcg_at_5': 0.78417, 'ndcg_at_10': 0.7999, 'ndcg_at_20': 0.80687, 'ndcg_at_100': 0.8145, 'ndcg_at_1000': 0.82292, 'map_at_1': 0.49595, 'map_at_3': 0.71511, 'map_at_5': 0.74568, 'map_at_10': 0.7559, 'map_at_20': 0.75907, 'map_at_100': 0.76054, 'map_at_1000': 0.76093, 'recall_at_1': 0.49595, 'recall_at_3': 0.76143, 'recall_at_5': 0.82177, 'recall_at_10': 0.85963, 'recall_at_20': 0.88024, 'recall_at_100': 0.91352, 'recall_at_1000': 0.96824, 'precision_at_1': 0.76182, 'precision_at_3': 0.4482, 'precision_at_5': 0.3, 'precision_at_10': 0.15912, 'precision_at_20': 0.08226, 'precision_at_100': 0.01718, 'precision_at_1000': 0.00184, 'mrr_at_1': 0.7618243243243243, 'mrr_at_3': 0.8082770270270268, 'mrr_at_5': 0.8126689189189186, 'mrr_at_10': 0.8154976404976402, 'mrr_at_20': 0.8160744027931525, 'mrr_at_100': 0.8167956168366535, 'mrr_at_1000': 0.8169514667693805, 'nauc_ndcg_at_1_max': np.float64(0.6140254993577773), 'nauc_ndcg_at_1_std': np.float64(0.26164220377831593), 'nauc_ndcg_at_1_diff1': np.float64(0.701575251206495), 'nauc_ndcg_at_3_max': np.float64(0.6209796742675765), 'nauc_ndcg_at_3_std': np.float64(0.2303169238935898), 'nauc_ndcg_at_3_diff1': np.float64(0.6250836894696198), 'nauc_ndcg_at_5_max': np.float64(0.6687344221366953), 'nauc_ndcg_at_5_std': np.float64(0.30008730063783606), 'nauc_ndcg_at_5_diff1': np.float64(0.630877111145664), 'nauc_ndcg_at_10_max': np.float64(0.6851107272437286), 'nauc_ndcg_at_10_std': np.float64(0.3449680619360948), 'nauc_ndcg_at_10_diff1': np.float64(0.6400367271749046), 'nauc_ndcg_at_20_max': np.float64(0.6897953927170336), 'nauc_ndcg_at_20_std': np.float64(0.35735119233384965), 'nauc_ndcg_at_20_diff1': np.float64(0.6417254471545015), 'nauc_ndcg_at_100_max': np.float64(0.6887717706103195), 'nauc_ndcg_at_100_std': np.float64(0.3616623541875642), 'nauc_ndcg_at_100_diff1': np.float64(0.643658512326843), 'nauc_ndcg_at_1000_max': np.float64(0.6775852880388933), 'nauc_ndcg_at_1000_std': np.float64(0.3451241051969923), 'nauc_ndcg_at_1000_diff1': np.float64(0.6429093132500182), 'nauc_map_at_1_max': np.float64(0.27290509162716314), 'nauc_map_at_1_std': np.float64(0.0028759235987818013), 'nauc_map_at_1_diff1': np.float64(0.6464672979634157), 'nauc_map_at_3_max': np.float64(0.5670920829398617), 'nauc_map_at_3_std': np.float64(0.1756383920546387), 'nauc_map_at_3_diff1': np.float64(0.6155392083766899), 'nauc_map_at_5_max': np.float64(0.6092391800145269), 'nauc_map_at_5_std': np.float64(0.22355516017145907), 'nauc_map_at_5_diff1': np.float64(0.6163142507523922), 'nauc_map_at_10_max': np.float64(0.6197264129478576), 'nauc_map_at_10_std': np.float64(0.2508306296919132), 'nauc_map_at_10_diff1': np.float64(0.6203539417206237), 'nauc_map_at_20_max': np.float64(0.6214155949462463), 'nauc_map_at_20_std': np.float64(0.25570274919757285), 'nauc_map_at_20_diff1': np.float64(0.6205461070939835), 'nauc_map_at_100_max': np.float64(0.6219353404394223), 'nauc_map_at_100_std': np.float64(0.2575084800827703), 'nauc_map_at_100_diff1': np.float64(0.6213641559783811), 'nauc_map_at_1000_max': np.float64(0.6214711417382313), 'nauc_map_at_1000_std': np.float64(0.2567865270036656), 'nauc_map_at_1000_diff1': np.float64(0.6212996512566442), 'nauc_recall_at_1_max': np.float64(0.27290509162716314), 'nauc_recall_at_1_std': np.float64(0.0028759235987818013), 'nauc_recall_at_1_diff1': np.float64(0.6464672979634157), 'nauc_recall_at_3_max': np.float64(0.6388778017999005), 'nauc_recall_at_3_std': np.float64(0.23458948836332089), 'nauc_recall_at_3_diff1': np.float64(0.5941800831540573), 'nauc_recall_at_5_max': np.float64(0.7473056788506388), 'nauc_recall_at_5_std': np.float64(0.39120501589322754), 'nauc_recall_at_5_diff1': np.float64(0.597476512024073), 'nauc_recall_at_10_max': np.float64(0.8118647384703), 'nauc_recall_at_10_std': np.float64(0.5478022958777538), 'nauc_recall_at_10_diff1': np.float64(0.6227966796357309), 'nauc_recall_at_20_max': np.float64(0.8594554667361674), 'nauc_recall_at_20_std': np.float64(0.635509907206941), 'nauc_recall_at_20_diff1': np.float64(0.6363284533068185), 'nauc_recall_at_100_max': np.float64(0.9013941354506494), 'nauc_recall_at_100_std': np.float64(0.7504325366536387), 'nauc_recall_at_100_diff1': np.float64(0.6460768742930085), 'nauc_recall_at_1000_max': np.float64(0.9160749921103895), 'nauc_recall_at_1000_std': np.float64(0.8794977109606553), 'nauc_recall_at_1000_diff1': np.float64(0.6627744451830913), 'nauc_precision_at_1_max': np.float64(0.6140254993577773), 'nauc_precision_at_1_std': np.float64(0.26164220377831593), 'nauc_precision_at_1_diff1': np.float64(0.701575251206495), 'nauc_precision_at_3_max': np.float64(0.4041172186373468), 'nauc_precision_at_3_std': np.float64(0.27905238612252137), 'nauc_precision_at_3_diff1': np.float64(0.01418361972025458), 'nauc_precision_at_5_max': np.float64(0.33037080164485005), 'nauc_precision_at_5_std': np.float64(0.30521777024468577), 'nauc_precision_at_5_diff1': np.float64(-0.08321768669571969), 'nauc_precision_at_10_max': np.float64(0.2789771063289397), 'nauc_precision_at_10_std': np.float64(0.3350573686132287), 'nauc_precision_at_10_diff1': np.float64(-0.1334293497523394), 'nauc_precision_at_20_max': np.float64(0.23906940344922564), 'nauc_precision_at_20_std': np.float64(0.33096326658624614), 'nauc_precision_at_20_diff1': np.float64(-0.16744008430127263), 'nauc_precision_at_100_max': np.float64(0.1768423855007564), 'nauc_precision_at_100_std': np.float64(0.3117360527077333), 'nauc_precision_at_100_diff1': np.float64(-0.22576801387905987), 'nauc_precision_at_1000_max': np.float64(0.02509741507921252), 'nauc_precision_at_1000_std': np.float64(0.20165796299973043), 'nauc_precision_at_1000_diff1': np.float64(-0.3521367477122964), 'nauc_mrr_at_1_max': np.float64(0.6140254993577773), 'nauc_mrr_at_1_std': np.float64(0.26164220377831593), 'nauc_mrr_at_1_diff1': np.float64(0.701575251206495), 'nauc_mrr_at_3_max': np.float64(0.7012771158473596), 'nauc_mrr_at_3_std': np.float64(0.3518000153505748), 'nauc_mrr_at_3_diff1': np.float64(0.6959255554798751), 'nauc_mrr_at_5_max': np.float64(0.702634941552595), 'nauc_mrr_at_5_std': np.float64(0.36767658523370134), 'nauc_mrr_at_5_diff1': np.float64(0.6957431236608096), 'nauc_mrr_at_10_max': np.float64(0.7025143673498627), 'nauc_mrr_at_10_std': np.float64(0.3705204114687801), 'nauc_mrr_at_10_diff1': np.float64(0.6991264660710457), 'nauc_mrr_at_20_max': np.float64(0.701730164451804), 'nauc_mrr_at_20_std': np.float64(0.36943703981843395), 'nauc_mrr_at_20_diff1': np.float64(0.6989540668156641), 'nauc_mrr_at_100_max': np.float64(0.7008009901376224), 'nauc_mrr_at_100_std': np.float64(0.36844196918362865), 'nauc_mrr_at_100_diff1': np.float64(0.6988489101194866), 'nauc_mrr_at_1000_max': np.float64(0.7005914667680472), 'nauc_mrr_at_1000_std': np.float64(0.3681330218438171), 'nauc_mrr_at_1000_diff1': np.float64(0.6988541315818936), 'main_score': 0.7999}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  9.10it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  9.06it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/12 [00:00<?, ?it/s]Batches:   8%|▊         | 1/12 [00:00<00:01,  9.47it/s]Batches:  17%|█▋        | 2/12 [00:04<00:25,  2.59s/it]Batches:  25%|██▌       | 3/12 [00:06<00:22,  2.46s/it]Batches:  33%|███▎      | 4/12 [00:08<00:17,  2.24s/it]Batches:  42%|████▏     | 5/12 [00:10<00:14,  2.07s/it]Batches:  50%|█████     | 6/12 [00:12<00:11,  1.94s/it]Batches:  58%|█████▊    | 7/12 [00:13<00:08,  1.80s/it]Batches:  67%|██████▋   | 8/12 [00:14<00:06,  1.66s/it]Batches:  75%|███████▌  | 9/12 [00:16<00:04,  1.52s/it]Batches:  83%|████████▎ | 10/12 [00:17<00:02,  1.36s/it]Batches:  92%|█████████▏| 11/12 [00:17<00:01,  1.16s/it]Batches: 100%|██████████| 12/12 [00:18<00:00,  1.08it/s]Batches: 100%|██████████| 12/12 [00:18<00:00,  1.53s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 18.71 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 18.84 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.73684, 'ndcg_at_3': 0.84847, 'ndcg_at_5': 0.86243, 'ndcg_at_10': 0.87076, 'ndcg_at_20': 0.8751, 'ndcg_at_100': 0.8751, 'ndcg_at_1000': 0.8751, 'map_at_1': 0.73684, 'map_at_3': 0.8231, 'map_at_5': 0.83056, 'map_at_10': 0.83388, 'map_at_20': 0.83501, 'map_at_100': 0.83501, 'map_at_1000': 0.83501, 'recall_at_1': 0.73684, 'recall_at_3': 0.92105, 'recall_at_5': 0.95614, 'recall_at_10': 0.98246, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.73684, 'precision_at_3': 0.30702, 'precision_at_5': 0.19123, 'precision_at_10': 0.09825, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7368421052631579, 'mrr_at_3': 0.8230994152046783, 'mrr_at_5': 0.8305555555555556, 'mrr_at_10': 0.8338798384851017, 'mrr_at_20': 0.8350128794207742, 'mrr_at_100': 0.8350128794207742, 'mrr_at_1000': 0.8350128794207742, 'nauc_ndcg_at_1_max': np.float64(0.07149425237817773), 'nauc_ndcg_at_1_std': np.float64(-0.5740489410911888), 'nauc_ndcg_at_1_diff1': np.float64(0.855920358194514), 'nauc_ndcg_at_3_max': np.float64(0.22596241107106488), 'nauc_ndcg_at_3_std': np.float64(-0.6287197205166997), 'nauc_ndcg_at_3_diff1': np.float64(0.8137408571767901), 'nauc_ndcg_at_5_max': np.float64(0.2106235946341074), 'nauc_ndcg_at_5_std': np.float64(-0.666076696942193), 'nauc_ndcg_at_5_diff1': np.float64(0.8367016854385332), 'nauc_ndcg_at_10_max': np.float64(0.16414878963712487), 'nauc_ndcg_at_10_std': np.float64(-0.6413227310670958), 'nauc_ndcg_at_10_diff1': np.float64(0.8350980422990169), 'nauc_ndcg_at_20_max': np.float64(0.1498253866834618), 'nauc_ndcg_at_20_std': np.float64(-0.6286718895071159), 'nauc_ndcg_at_20_diff1': np.float64(0.8398691466479165), 'nauc_ndcg_at_100_max': np.float64(0.1498253866834618), 'nauc_ndcg_at_100_std': np.float64(-0.6286718895071159), 'nauc_ndcg_at_100_diff1': np.float64(0.8398691466479165), 'nauc_ndcg_at_1000_max': np.float64(0.1498253866834618), 'nauc_ndcg_at_1000_std': np.float64(-0.6286718895071159), 'nauc_ndcg_at_1000_diff1': np.float64(0.8398691466479165), 'nauc_map_at_1_max': np.float64(0.07149425237817773), 'nauc_map_at_1_std': np.float64(-0.5740489410911888), 'nauc_map_at_1_diff1': np.float64(0.855920358194514), 'nauc_map_at_3_max': np.float64(0.16850617051774516), 'nauc_map_at_3_std': np.float64(-0.6167591068556976), 'nauc_map_at_3_diff1': np.float64(0.8296416937237968), 'nauc_map_at_5_max': np.float64(0.15870821400135557), 'nauc_map_at_5_std': np.float64(-0.6335419991197105), 'nauc_map_at_5_diff1': np.float64(0.8408510417136918), 'nauc_map_at_10_max': np.float64(0.14297700181558054), 'nauc_map_at_10_std': np.float64(-0.6253694992666116), 'nauc_map_at_10_diff1': np.float64(0.8405955325090816), 'nauc_map_at_20_max': np.float64(0.14000751576930393), 'nauc_map_at_20_std': np.float64(-0.6226121734182121), 'nauc_map_at_20_diff1': np.float64(0.8416083980756537), 'nauc_map_at_100_max': np.float64(0.14000751576930393), 'nauc_map_at_100_std': np.float64(-0.6226121734182121), 'nauc_map_at_100_diff1': np.float64(0.8416083980756537), 'nauc_map_at_1000_max': np.float64(0.14000751576930393), 'nauc_map_at_1000_std': np.float64(-0.6226121734182121), 'nauc_map_at_1000_diff1': np.float64(0.8416083980756537), 'nauc_recall_at_1_max': np.float64(0.07149425237817773), 'nauc_recall_at_1_std': np.float64(-0.5740489410911888), 'nauc_recall_at_1_diff1': np.float64(0.855920358194514), 'nauc_recall_at_3_max': np.float64(0.5675458441336484), 'nauc_recall_at_3_std': np.float64(-0.6932252091560408), 'nauc_recall_at_3_diff1': np.float64(0.7190418415751849), 'nauc_recall_at_5_max': np.float64(0.7344259573530263), 'nauc_recall_at_5_std': np.float64(-0.9997270410753551), 'nauc_recall_at_5_diff1': np.float64(0.8033487300820272), 'nauc_recall_at_10_max': np.float64(0.5399672160741448), 'nauc_recall_at_10_std': np.float64(-0.9629312206778983), 'nauc_recall_at_10_diff1': np.float64(0.7122741478966538), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.07149425237817773), 'nauc_precision_at_1_std': np.float64(-0.5740489410911888), 'nauc_precision_at_1_diff1': np.float64(0.855920358194514), 'nauc_precision_at_3_max': np.float64(0.5675458441336447), 'nauc_precision_at_3_std': np.float64(-0.6932252091560439), 'nauc_precision_at_3_diff1': np.float64(0.7190418415751814), 'nauc_precision_at_5_max': np.float64(0.7344259573530225), 'nauc_precision_at_5_std': np.float64(-0.9997270410753618), 'nauc_precision_at_5_diff1': np.float64(0.8033487300820259), 'nauc_precision_at_10_max': np.float64(0.539967216074137), 'nauc_precision_at_10_std': np.float64(-0.9629312206779349), 'nauc_precision_at_10_diff1': np.float64(0.7122741478966378), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.07149425237817773), 'nauc_mrr_at_1_std': np.float64(-0.5740489410911888), 'nauc_mrr_at_1_diff1': np.float64(0.855920358194514), 'nauc_mrr_at_3_max': np.float64(0.16850617051774516), 'nauc_mrr_at_3_std': np.float64(-0.6167591068556976), 'nauc_mrr_at_3_diff1': np.float64(0.8296416937237968), 'nauc_mrr_at_5_max': np.float64(0.15870821400135557), 'nauc_mrr_at_5_std': np.float64(-0.6335419991197105), 'nauc_mrr_at_5_diff1': np.float64(0.8408510417136918), 'nauc_mrr_at_10_max': np.float64(0.14297700181558054), 'nauc_mrr_at_10_std': np.float64(-0.6253694992666116), 'nauc_mrr_at_10_diff1': np.float64(0.8405955325090816), 'nauc_mrr_at_20_max': np.float64(0.14000751576930393), 'nauc_mrr_at_20_std': np.float64(-0.6226121734182121), 'nauc_mrr_at_20_diff1': np.float64(0.8416083980756537), 'nauc_mrr_at_100_max': np.float64(0.14000751576930393), 'nauc_mrr_at_100_std': np.float64(-0.6226121734182121), 'nauc_mrr_at_100_diff1': np.float64(0.8416083980756537), 'nauc_mrr_at_1000_max': np.float64(0.14000751576930393), 'nauc_mrr_at_1000_std': np.float64(-0.6226121734182121), 'nauc_mrr_at_1000_diff1': np.float64(0.8416083980756537), 'main_score': 0.87076}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 12.85it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 12.76it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.17 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 2.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.68831, 'ndcg_at_3': 0.78154, 'ndcg_at_5': 0.80277, 'ndcg_at_10': 0.81925, 'ndcg_at_20': 0.82266, 'ndcg_at_100': 0.83027, 'ndcg_at_1000': 0.83027, 'map_at_1': 0.68831, 'map_at_3': 0.75974, 'map_at_5': 0.77143, 'map_at_10': 0.77803, 'map_at_20': 0.77902, 'map_at_100': 0.7802, 'map_at_1000': 0.7802, 'recall_at_1': 0.68831, 'recall_at_3': 0.84416, 'recall_at_5': 0.8961, 'recall_at_10': 0.94805, 'recall_at_20': 0.96104, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.68831, 'precision_at_3': 0.28139, 'precision_at_5': 0.17922, 'precision_at_10': 0.09481, 'precision_at_20': 0.04805, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6883116883116883, 'mrr_at_3': 0.7597402597402597, 'mrr_at_5': 0.7714285714285715, 'mrr_at_10': 0.778025149453721, 'mrr_at_20': 0.7790241504527221, 'mrr_at_100': 0.780204129893571, 'mrr_at_1000': 0.780204129893571, 'nauc_ndcg_at_1_max': np.float64(0.3086258756612234), 'nauc_ndcg_at_1_std': np.float64(-0.22857924276595137), 'nauc_ndcg_at_1_diff1': np.float64(0.6557373727917203), 'nauc_ndcg_at_3_max': np.float64(0.31818235058958816), 'nauc_ndcg_at_3_std': np.float64(-0.19089663973512322), 'nauc_ndcg_at_3_diff1': np.float64(0.6257453957423033), 'nauc_ndcg_at_5_max': np.float64(0.2981689346532907), 'nauc_ndcg_at_5_std': np.float64(-0.21999997460016935), 'nauc_ndcg_at_5_diff1': np.float64(0.611828075715884), 'nauc_ndcg_at_10_max': np.float64(0.2834765024263417), 'nauc_ndcg_at_10_std': np.float64(-0.21694632470850087), 'nauc_ndcg_at_10_diff1': np.float64(0.5957814447956384), 'nauc_ndcg_at_20_max': np.float64(0.28186924385631246), 'nauc_ndcg_at_20_std': np.float64(-0.1964900690754987), 'nauc_ndcg_at_20_diff1': np.float64(0.5930431772351377), 'nauc_ndcg_at_100_max': np.float64(0.306940606296968), 'nauc_ndcg_at_100_std': np.float64(-0.20629584114969146), 'nauc_ndcg_at_100_diff1': np.float64(0.6247531082029524), 'nauc_ndcg_at_1000_max': np.float64(0.306940606296968), 'nauc_ndcg_at_1000_std': np.float64(-0.20629584114969146), 'nauc_ndcg_at_1000_diff1': np.float64(0.6247531082029524), 'nauc_map_at_1_max': np.float64(0.3086258756612234), 'nauc_map_at_1_std': np.float64(-0.22857924276595137), 'nauc_map_at_1_diff1': np.float64(0.6557373727917203), 'nauc_map_at_3_max': np.float64(0.3214124041997709), 'nauc_map_at_3_std': np.float64(-0.197379816730269), 'nauc_map_at_3_diff1': np.float64(0.6376961611862957), 'nauc_map_at_5_max': np.float64(0.31043885449421843), 'nauc_map_at_5_std': np.float64(-0.2150032443531132), 'nauc_map_at_5_diff1': np.float64(0.6319381261267509), 'nauc_map_at_10_max': np.float64(0.3062753843027218), 'nauc_map_at_10_std': np.float64(-0.2144310663182138), 'nauc_map_at_10_diff1': np.float64(0.6275610998508999), 'nauc_map_at_20_max': np.float64(0.30601079865389114), 'nauc_map_at_20_std': np.float64(-0.20956395913424966), 'nauc_map_at_20_diff1': np.float64(0.6270741426196489), 'nauc_map_at_100_max': np.float64(0.3106764089031353), 'nauc_map_at_100_std': np.float64(-0.20968711965751216), 'nauc_map_at_100_diff1': np.float64(0.632278611841524), 'nauc_map_at_1000_max': np.float64(0.3106764089031353), 'nauc_map_at_1000_std': np.float64(-0.20968711965751216), 'nauc_map_at_1000_diff1': np.float64(0.632278611841524), 'nauc_recall_at_1_max': np.float64(0.3086258756612234), 'nauc_recall_at_1_std': np.float64(-0.22857924276595137), 'nauc_recall_at_1_diff1': np.float64(0.6557373727917203), 'nauc_recall_at_3_max': np.float64(0.3012785654766077), 'nauc_recall_at_3_std': np.float64(-0.1670454698150862), 'nauc_recall_at_3_diff1': np.float64(0.5747846082563047), 'nauc_recall_at_5_max': np.float64(0.2219334620273603), 'nauc_recall_at_5_std': np.float64(-0.2524622560301858), 'nauc_recall_at_5_diff1': np.float64(0.49137845809737585), 'nauc_recall_at_10_max': np.float64(-0.0036776120344924994), 'nauc_recall_at_10_std': np.float64(-0.2427037697518675), 'nauc_recall_at_10_diff1': np.float64(0.20892163796627083), 'nauc_recall_at_20_max': np.float64(-0.12420871870243454), 'nauc_recall_at_20_std': np.float64(0.06451677149364604), 'nauc_recall_at_20_diff1': np.float64(0.03769463543960132), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.3086258756612234), 'nauc_precision_at_1_std': np.float64(-0.22857924276595137), 'nauc_precision_at_1_diff1': np.float64(0.6557373727917203), 'nauc_precision_at_3_max': np.float64(0.3012785654766092), 'nauc_precision_at_3_std': np.float64(-0.16704546981508386), 'nauc_precision_at_3_diff1': np.float64(0.5747846082563061), 'nauc_precision_at_5_max': np.float64(0.22193346202736167), 'nauc_precision_at_5_std': np.float64(-0.252462256030184), 'nauc_precision_at_5_diff1': np.float64(0.4913784580973776), 'nauc_precision_at_10_max': np.float64(-0.0036776120344830495), 'nauc_precision_at_10_std': np.float64(-0.2427037697518592), 'nauc_precision_at_10_diff1': np.float64(0.20892163796627847), 'nauc_precision_at_20_max': np.float64(-0.12420871870242951), 'nauc_precision_at_20_std': np.float64(0.06451677149364855), 'nauc_precision_at_20_diff1': np.float64(0.037694635439603), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.3086258756612234), 'nauc_mrr_at_1_std': np.float64(-0.22857924276595137), 'nauc_mrr_at_1_diff1': np.float64(0.6557373727917203), 'nauc_mrr_at_3_max': np.float64(0.3214124041997709), 'nauc_mrr_at_3_std': np.float64(-0.197379816730269), 'nauc_mrr_at_3_diff1': np.float64(0.6376961611862957), 'nauc_mrr_at_5_max': np.float64(0.31043885449421843), 'nauc_mrr_at_5_std': np.float64(-0.2150032443531132), 'nauc_mrr_at_5_diff1': np.float64(0.6319381261267509), 'nauc_mrr_at_10_max': np.float64(0.3062753843027218), 'nauc_mrr_at_10_std': np.float64(-0.2144310663182138), 'nauc_mrr_at_10_diff1': np.float64(0.6275610998508999), 'nauc_mrr_at_20_max': np.float64(0.30601079865389114), 'nauc_mrr_at_20_std': np.float64(-0.20956395913424966), 'nauc_mrr_at_20_diff1': np.float64(0.6270741426196489), 'nauc_mrr_at_100_max': np.float64(0.3106764089031353), 'nauc_mrr_at_100_std': np.float64(-0.20968711965751216), 'nauc_mrr_at_100_diff1': np.float64(0.632278611841524), 'nauc_mrr_at_1000_max': np.float64(0.3106764089031353), 'nauc_mrr_at_1000_std': np.float64(-0.20968711965751216), 'nauc_mrr_at_1000_diff1': np.float64(0.632278611841524), 'main_score': 0.81925}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  13%|█▎        | 2/15 [00:00<00:00, 15.30it/s]Batches:  27%|██▋       | 4/15 [00:00<00:00, 12.69it/s]Batches:  40%|████      | 6/15 [00:00<00:00, 12.75it/s]Batches:  53%|█████▎    | 8/15 [00:00<00:00, 13.11it/s]Batches:  67%|██████▋   | 10/15 [00:00<00:00, 13.66it/s]Batches:  80%|████████  | 12/15 [00:00<00:00, 14.40it/s]Batches:  93%|█████████▎| 14/15 [00:00<00:00, 15.34it/s]Batches: 100%|██████████| 15/15 [00:01<00:00, 14.55it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:02,  2.05it/s]Batches:  38%|███▊      | 3/8 [00:01<00:02,  2.03it/s]Batches:  50%|█████     | 4/8 [00:01<00:01,  2.11it/s]Batches:  62%|██████▎   | 5/8 [00:02<00:01,  2.24it/s]Batches:  75%|███████▌  | 6/8 [00:02<00:00,  2.39it/s]Batches:  88%|████████▊ | 7/8 [00:02<00:00,  2.61it/s]Batches: 100%|██████████| 8/8 [00:03<00:00,  2.85it/s]Batches: 100%|██████████| 8/8 [00:03<00:00,  2.45it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.72 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  13%|█▎        | 2/15 [00:00<00:00, 17.58it/s]Batches:  27%|██▋       | 4/15 [00:00<00:00, 13.90it/s]Batches:  40%|████      | 6/15 [00:00<00:00, 14.15it/s]Batches:  53%|█████▎    | 8/15 [00:00<00:00, 14.37it/s]Batches:  67%|██████▋   | 10/15 [00:00<00:00, 14.79it/s]Batches:  80%|████████  | 12/15 [00:00<00:00, 15.76it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 17.50it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 15.98it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:02,  2.06it/s]Batches:  38%|███▊      | 3/8 [00:01<00:02,  2.03it/s]Batches:  50%|█████     | 4/8 [00:01<00:01,  2.10it/s]Batches:  62%|██████▎   | 5/8 [00:02<00:01,  2.23it/s]Batches:  75%|███████▌  | 6/8 [00:02<00:00,  2.39it/s]Batches:  88%|████████▊ | 7/8 [00:02<00:00,  2.61it/s]Batches: 100%|██████████| 8/8 [00:03<00:00,  2.85it/s]Batches: 100%|██████████| 8/8 [00:03<00:00,  2.45it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.66 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  13%|█▎        | 2/15 [00:00<00:00, 16.07it/s]Batches:  27%|██▋       | 4/15 [00:00<00:00, 12.81it/s]Batches:  40%|████      | 6/15 [00:00<00:00, 12.81it/s]Batches:  53%|█████▎    | 8/15 [00:00<00:00, 13.11it/s]Batches:  67%|██████▋   | 10/15 [00:00<00:00, 13.64it/s]Batches:  80%|████████  | 12/15 [00:00<00:00, 14.34it/s]Batches:  93%|█████████▎| 14/15 [00:00<00:00, 15.27it/s]Batches: 100%|██████████| 15/15 [00:01<00:00, 14.55it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:02,  2.29it/s]Batches:  38%|███▊      | 3/8 [00:01<00:02,  2.24it/s]Batches:  50%|█████     | 4/8 [00:01<00:01,  2.36it/s]Batches:  62%|██████▎   | 5/8 [00:02<00:01,  2.52it/s]Batches:  75%|███████▌  | 6/8 [00:02<00:00,  2.73it/s]Batches:  88%|████████▊ | 7/8 [00:02<00:00,  2.93it/s]Batches: 100%|██████████| 8/8 [00:02<00:00,  3.20it/s]Batches: 100%|██████████| 8/8 [00:02<00:00,  2.75it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.51 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 15.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.90778, 'ndcg_at_3': 0.94389, 'ndcg_at_5': 0.948, 'ndcg_at_10': 0.95019, 'ndcg_at_20': 0.95047, 'ndcg_at_100': 0.95212, 'ndcg_at_1000': 0.95285, 'map_at_1': 0.90778, 'map_at_3': 0.93556, 'map_at_5': 0.93783, 'map_at_10': 0.93876, 'map_at_20': 0.93883, 'map_at_100': 0.93907, 'map_at_1000': 0.9391, 'recall_at_1': 0.90778, 'recall_at_3': 0.96778, 'recall_at_5': 0.97778, 'recall_at_10': 0.98444, 'recall_at_20': 0.98556, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.90778, 'precision_at_3': 0.32259, 'precision_at_5': 0.19556, 'precision_at_10': 0.09844, 'precision_at_20': 0.04928, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.9077777777777778, 'mrr_at_3': 0.9355555555555556, 'mrr_at_5': 0.9378333333333334, 'mrr_at_10': 0.9387557319223988, 'mrr_at_20': 0.9388298059964728, 'mrr_at_100': 0.9390678008460436, 'mrr_at_1000': 0.9390968480352451, 'nauc_ndcg_at_1_max': np.float64(0.8035447110571144), 'nauc_ndcg_at_1_std': np.float64(-0.058581665597967306), 'nauc_ndcg_at_1_diff1': np.float64(0.9248815992260353), 'nauc_ndcg_at_3_max': np.float64(0.8410697495136905), 'nauc_ndcg_at_3_std': np.float64(-0.04214062390066272), 'nauc_ndcg_at_3_diff1': np.float64(0.930107278622579), 'nauc_ndcg_at_5_max': np.float64(0.8386962198735806), 'nauc_ndcg_at_5_std': np.float64(-0.006393147566806968), 'nauc_ndcg_at_5_diff1': np.float64(0.9280794678139023), 'nauc_ndcg_at_10_max': np.float64(0.8353970205645103), 'nauc_ndcg_at_10_std': np.float64(-0.03470509418686251), 'nauc_ndcg_at_10_diff1': np.float64(0.9288337891215238), 'nauc_ndcg_at_20_max': np.float64(0.8344739644893199), 'nauc_ndcg_at_20_std': np.float64(-0.035588248498667714), 'nauc_ndcg_at_20_diff1': np.float64(0.9291677473630476), 'nauc_ndcg_at_100_max': np.float64(0.8320277171092116), 'nauc_ndcg_at_100_std': np.float64(-0.023947007735861857), 'nauc_ndcg_at_100_diff1': np.float64(0.928054136021157), 'nauc_ndcg_at_1000_max': np.float64(0.8298178001223949), 'nauc_ndcg_at_1000_std': np.float64(-0.034696633407776956), 'nauc_ndcg_at_1000_diff1': np.float64(0.9277511087968355), 'nauc_map_at_1_max': np.float64(0.8035447110571144), 'nauc_map_at_1_std': np.float64(-0.058581665597967306), 'nauc_map_at_1_diff1': np.float64(0.9248815992260353), 'nauc_map_at_3_max': np.float64(0.8285843072861339), 'nauc_map_at_3_std': np.float64(-0.05097556263884969), 'nauc_map_at_3_diff1': np.float64(0.9278523670004413), 'nauc_map_at_5_max': np.float64(0.8270577221058213), 'nauc_map_at_5_std': np.float64(-0.034058604079103515), 'nauc_map_at_5_diff1': np.float64(0.926785926365382), 'nauc_map_at_10_max': np.float64(0.8256736328796452), 'nauc_map_at_10_std': np.float64(-0.044253886298678116), 'nauc_map_at_10_diff1': np.float64(0.9268873724202777), 'nauc_map_at_20_max': np.float64(0.8254625322865969), 'nauc_map_at_20_std': np.float64(-0.04445615902114404), 'nauc_map_at_20_diff1': np.float64(0.9269571308275951), 'nauc_map_at_100_max': np.float64(0.8252106538103274), 'nauc_map_at_100_std': np.float64(-0.04284582476861592), 'nauc_map_at_100_diff1': np.float64(0.9268838209190285), 'nauc_map_at_1000_max': np.float64(0.8251376135773191), 'nauc_map_at_1000_std': np.float64(-0.04320433301481756), 'nauc_map_at_1000_diff1': np.float64(0.9268742816703098), 'nauc_recall_at_1_max': np.float64(0.8035447110571144), 'nauc_recall_at_1_std': np.float64(-0.058581665597967306), 'nauc_recall_at_1_diff1': np.float64(0.9248815992260353), 'nauc_recall_at_3_max': np.float64(0.9127467078785526), 'nauc_recall_at_3_std': np.float64(0.011462056086799444), 'nauc_recall_at_3_diff1': np.float64(0.9434946392350054), 'nauc_recall_at_5_max': np.float64(0.931139122315592), 'nauc_recall_at_5_std': np.float64(0.23116246498599574), 'nauc_recall_at_5_diff1': np.float64(0.9384920634920638), 'nauc_recall_at_10_max': np.float64(0.9401427237561681), 'nauc_recall_at_10_std': np.float64(0.05802320928372045), 'nauc_recall_at_10_diff1': np.float64(0.9533146591970086), 'nauc_recall_at_20_max': np.float64(0.9355383178912666), 'nauc_recall_at_20_std': np.float64(0.05304172951232186), 'nauc_recall_at_20_diff1': np.float64(0.9597787833082027), 'nauc_recall_at_100_max': np.float64(0.9738562091503434), 'nauc_recall_at_100_std': np.float64(0.6611577964519149), 'nauc_recall_at_100_diff1': np.float64(0.9477124183006633), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8035447110571144), 'nauc_precision_at_1_std': np.float64(-0.058581665597967306), 'nauc_precision_at_1_diff1': np.float64(0.9248815992260353), 'nauc_precision_at_3_max': np.float64(0.9127467078785482), 'nauc_precision_at_3_std': np.float64(0.011462056086805571), 'nauc_precision_at_3_diff1': np.float64(0.9434946392350031), 'nauc_precision_at_5_max': np.float64(0.9311391223155887), 'nauc_precision_at_5_std': np.float64(0.23116246498598536), 'nauc_precision_at_5_diff1': np.float64(0.9384920634920635), 'nauc_precision_at_10_max': np.float64(0.9401427237561738), 'nauc_precision_at_10_std': np.float64(0.05802320928370427), 'nauc_precision_at_10_diff1': np.float64(0.9533146591970207), 'nauc_precision_at_20_max': np.float64(0.9355383178912531), 'nauc_precision_at_20_std': np.float64(0.05304172951230378), 'nauc_precision_at_20_diff1': np.float64(0.9597787833081913), 'nauc_precision_at_100_max': np.float64(0.9738562091503018), 'nauc_precision_at_100_std': np.float64(0.6611577964519374), 'nauc_precision_at_100_diff1': np.float64(0.9477124183006403), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8035447110571144), 'nauc_mrr_at_1_std': np.float64(-0.058581665597967306), 'nauc_mrr_at_1_diff1': np.float64(0.9248815992260353), 'nauc_mrr_at_3_max': np.float64(0.8285843072861339), 'nauc_mrr_at_3_std': np.float64(-0.05097556263884969), 'nauc_mrr_at_3_diff1': np.float64(0.9278523670004413), 'nauc_mrr_at_5_max': np.float64(0.8270577221058213), 'nauc_mrr_at_5_std': np.float64(-0.034058604079103515), 'nauc_mrr_at_5_diff1': np.float64(0.926785926365382), 'nauc_mrr_at_10_max': np.float64(0.8256736328796452), 'nauc_mrr_at_10_std': np.float64(-0.044253886298678116), 'nauc_mrr_at_10_diff1': np.float64(0.9268873724202777), 'nauc_mrr_at_20_max': np.float64(0.8254625322865969), 'nauc_mrr_at_20_std': np.float64(-0.04445615902114404), 'nauc_mrr_at_20_diff1': np.float64(0.9269571308275951), 'nauc_mrr_at_100_max': np.float64(0.8252106538103274), 'nauc_mrr_at_100_std': np.float64(-0.04284582476861592), 'nauc_mrr_at_100_diff1': np.float64(0.9268838209190285), 'nauc_mrr_at_1000_max': np.float64(0.8251376135773191), 'nauc_mrr_at_1000_std': np.float64(-0.04320433301481756), 'nauc_mrr_at_1000_diff1': np.float64(0.9268742816703098), 'main_score': 0.95019}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.85556, 'ndcg_at_3': 0.91315, 'ndcg_at_5': 0.91587, 'ndcg_at_10': 0.92367, 'ndcg_at_20': 0.92533, 'ndcg_at_100': 0.92614, 'ndcg_at_1000': 0.92671, 'map_at_1': 0.85556, 'map_at_3': 0.89889, 'map_at_5': 0.90039, 'map_at_10': 0.90376, 'map_at_20': 0.9042, 'map_at_100': 0.90431, 'map_at_1000': 0.90433, 'recall_at_1': 0.85556, 'recall_at_3': 0.95444, 'recall_at_5': 0.96111, 'recall_at_10': 0.98444, 'recall_at_20': 0.99111, 'recall_at_100': 0.99556, 'recall_at_1000': 1.0, 'precision_at_1': 0.85556, 'precision_at_3': 0.31815, 'precision_at_5': 0.19222, 'precision_at_10': 0.09844, 'precision_at_20': 0.04956, 'precision_at_100': 0.00996, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8555555555555555, 'mrr_at_3': 0.8988888888888893, 'mrr_at_5': 0.9003888888888892, 'mrr_at_10': 0.9037614638447976, 'mrr_at_20': 0.9042035226459895, 'mrr_at_100': 0.904305094607937, 'mrr_at_1000': 0.9043277360586081, 'nauc_ndcg_at_1_max': np.float64(0.7409675970964595), 'nauc_ndcg_at_1_std': np.float64(-0.0850183342063909), 'nauc_ndcg_at_1_diff1': np.float64(0.906555414203397), 'nauc_ndcg_at_3_max': np.float64(0.7718002301108531), 'nauc_ndcg_at_3_std': np.float64(-0.02083363686317385), 'nauc_ndcg_at_3_diff1': np.float64(0.8872384600033298), 'nauc_ndcg_at_5_max': np.float64(0.7668173443808738), 'nauc_ndcg_at_5_std': np.float64(-0.02487259039215843), 'nauc_ndcg_at_5_diff1': np.float64(0.8857096934246813), 'nauc_ndcg_at_10_max': np.float64(0.7641962275761153), 'nauc_ndcg_at_10_std': np.float64(-0.011096139527735268), 'nauc_ndcg_at_10_diff1': np.float64(0.8861062884316846), 'nauc_ndcg_at_20_max': np.float64(0.7604488277139023), 'nauc_ndcg_at_20_std': np.float64(-0.02766497514935716), 'nauc_ndcg_at_20_diff1': np.float64(0.8871461253383455), 'nauc_ndcg_at_100_max': np.float64(0.7614834475942092), 'nauc_ndcg_at_100_std': np.float64(-0.027939756007766273), 'nauc_ndcg_at_100_diff1': np.float64(0.8900898024185966), 'nauc_ndcg_at_1000_max': np.float64(0.7595547666303061), 'nauc_ndcg_at_1000_std': np.float64(-0.03429462716746115), 'nauc_ndcg_at_1000_diff1': np.float64(0.8902837152247524), 'nauc_map_at_1_max': np.float64(0.7409675970964595), 'nauc_map_at_1_std': np.float64(-0.0850183342063909), 'nauc_map_at_1_diff1': np.float64(0.906555414203397), 'nauc_map_at_3_max': np.float64(0.760930231739225), 'nauc_map_at_3_std': np.float64(-0.04362849184634293), 'nauc_map_at_3_diff1': np.float64(0.8926749136391964), 'nauc_map_at_5_max': np.float64(0.7585026861692188), 'nauc_map_at_5_std': np.float64(-0.045672475629407745), 'nauc_map_at_5_diff1': np.float64(0.8920239896626241), 'nauc_map_at_10_max': np.float64(0.7572999163129488), 'nauc_map_at_10_std': np.float64(-0.041865466257857954), 'nauc_map_at_10_diff1': np.float64(0.8924014077555502), 'nauc_map_at_20_max': np.float64(0.7565244112208233), 'nauc_map_at_20_std': np.float64(-0.045332413896560037), 'nauc_map_at_20_diff1': np.float64(0.8926013468146251), 'nauc_map_at_100_max': np.float64(0.7566017007965883), 'nauc_map_at_100_std': np.float64(-0.04524760207311181), 'nauc_map_at_100_diff1': np.float64(0.8928449264837649), 'nauc_map_at_1000_max': np.float64(0.7565422953299448), 'nauc_map_at_1000_std': np.float64(-0.045419981896821525), 'nauc_map_at_1000_diff1': np.float64(0.8928500920610803), 'nauc_recall_at_1_max': np.float64(0.7409675970964595), 'nauc_recall_at_1_std': np.float64(-0.0850183342063909), 'nauc_recall_at_1_diff1': np.float64(0.906555414203397), 'nauc_recall_at_3_max': np.float64(0.8397554143608675), 'nauc_recall_at_3_std': np.float64(0.12181457949033453), 'nauc_recall_at_3_diff1': np.float64(0.8544328300425864), 'nauc_recall_at_5_max': np.float64(0.8250233426704008), 'nauc_recall_at_5_std': np.float64(0.12343604108310226), 'nauc_recall_at_5_diff1': np.float64(0.8411497932506334), 'nauc_recall_at_10_max': np.float64(0.8744497799119666), 'nauc_recall_at_10_std': np.float64(0.5465519541149856), 'nauc_recall_at_10_diff1': np.float64(0.779445111377877), 'nauc_recall_at_20_max': np.float64(0.8313492063492053), 'nauc_recall_at_20_std': np.float64(0.41188141923436017), 'nauc_recall_at_20_diff1': np.float64(0.7371615312791687), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.7806956115779841), 'nauc_recall_at_100_diff1': np.float64(0.8651960784313707), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7409675970964595), 'nauc_precision_at_1_std': np.float64(-0.0850183342063909), 'nauc_precision_at_1_diff1': np.float64(0.906555414203397), 'nauc_precision_at_3_max': np.float64(0.8397554143608684), 'nauc_precision_at_3_std': np.float64(0.12181457949033488), 'nauc_precision_at_3_diff1': np.float64(0.8544328300425831), 'nauc_precision_at_5_max': np.float64(0.8250233426703982), 'nauc_precision_at_5_std': np.float64(0.12343604108309754), 'nauc_precision_at_5_diff1': np.float64(0.8411497932506291), 'nauc_precision_at_10_max': np.float64(0.8744497799119568), 'nauc_precision_at_10_std': np.float64(0.546551954114966), 'nauc_precision_at_10_diff1': np.float64(0.7794451113778831), 'nauc_precision_at_20_max': np.float64(0.831349206349182), 'nauc_precision_at_20_std': np.float64(0.4118814192343615), 'nauc_precision_at_20_diff1': np.float64(0.7371615312791836), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.7806956115779151), 'nauc_precision_at_100_diff1': np.float64(0.8651960784313598), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7409675970964595), 'nauc_mrr_at_1_std': np.float64(-0.0850183342063909), 'nauc_mrr_at_1_diff1': np.float64(0.906555414203397), 'nauc_mrr_at_3_max': np.float64(0.760930231739225), 'nauc_mrr_at_3_std': np.float64(-0.04362849184634293), 'nauc_mrr_at_3_diff1': np.float64(0.8926749136391964), 'nauc_mrr_at_5_max': np.float64(0.7585026861692188), 'nauc_mrr_at_5_std': np.float64(-0.045672475629407745), 'nauc_mrr_at_5_diff1': np.float64(0.8920239896626241), 'nauc_mrr_at_10_max': np.float64(0.7572999163129488), 'nauc_mrr_at_10_std': np.float64(-0.041865466257857954), 'nauc_mrr_at_10_diff1': np.float64(0.8924014077555502), 'nauc_mrr_at_20_max': np.float64(0.7565244112208233), 'nauc_mrr_at_20_std': np.float64(-0.045332413896560037), 'nauc_mrr_at_20_diff1': np.float64(0.8926013468146251), 'nauc_mrr_at_100_max': np.float64(0.7566017007965883), 'nauc_mrr_at_100_std': np.float64(-0.04524760207311181), 'nauc_mrr_at_100_diff1': np.float64(0.8928449264837649), 'nauc_mrr_at_1000_max': np.float64(0.7565422953299448), 'nauc_mrr_at_1000_std': np.float64(-0.045419981896821525), 'nauc_mrr_at_1000_diff1': np.float64(0.8928500920610803), 'main_score': 0.92367}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.84, 'ndcg_at_3': 0.8923, 'ndcg_at_5': 0.90148, 'ndcg_at_10': 0.90577, 'ndcg_at_20': 0.91004, 'ndcg_at_100': 0.91226, 'ndcg_at_1000': 0.91319, 'map_at_1': 0.84, 'map_at_3': 0.87963, 'map_at_5': 0.88474, 'map_at_10': 0.88649, 'map_at_20': 0.88769, 'map_at_100': 0.88798, 'map_at_1000': 0.88803, 'recall_at_1': 0.84, 'recall_at_3': 0.92889, 'recall_at_5': 0.95111, 'recall_at_10': 0.96444, 'recall_at_20': 0.98111, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.84, 'precision_at_3': 0.30963, 'precision_at_5': 0.19022, 'precision_at_10': 0.09644, 'precision_at_20': 0.04906, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.84, 'mrr_at_3': 0.87962962962963, 'mrr_at_5': 0.884740740740741, 'mrr_at_10': 0.8864929453262789, 'mrr_at_20': 0.8876929709485182, 'mrr_at_100': 0.8879781128339055, 'mrr_at_1000': 0.8880272704078894, 'nauc_ndcg_at_1_max': np.float64(0.6698712703867343), 'nauc_ndcg_at_1_std': np.float64(-0.013885479735995902), 'nauc_ndcg_at_1_diff1': np.float64(0.8844024436807941), 'nauc_ndcg_at_3_max': np.float64(0.7272947072297444), 'nauc_ndcg_at_3_std': np.float64(0.0715074092955055), 'nauc_ndcg_at_3_diff1': np.float64(0.8731619343589773), 'nauc_ndcg_at_5_max': np.float64(0.7187898178065163), 'nauc_ndcg_at_5_std': np.float64(0.04481082433729226), 'nauc_ndcg_at_5_diff1': np.float64(0.876589189299396), 'nauc_ndcg_at_10_max': np.float64(0.7184488802401127), 'nauc_ndcg_at_10_std': np.float64(0.06030277417740266), 'nauc_ndcg_at_10_diff1': np.float64(0.8779571776757665), 'nauc_ndcg_at_20_max': np.float64(0.7194462894729402), 'nauc_ndcg_at_20_std': np.float64(0.06976194757924663), 'nauc_ndcg_at_20_diff1': np.float64(0.8806944035339188), 'nauc_ndcg_at_100_max': np.float64(0.7147883694681721), 'nauc_ndcg_at_100_std': np.float64(0.05684059861037063), 'nauc_ndcg_at_100_diff1': np.float64(0.8793948642914982), 'nauc_ndcg_at_1000_max': np.float64(0.7123955474730314), 'nauc_ndcg_at_1000_std': np.float64(0.0501975438990718), 'nauc_ndcg_at_1000_diff1': np.float64(0.8785245861096637), 'nauc_map_at_1_max': np.float64(0.6698712703867343), 'nauc_map_at_1_std': np.float64(-0.013885479735995902), 'nauc_map_at_1_diff1': np.float64(0.8844024436807941), 'nauc_map_at_3_max': np.float64(0.711326413945684), 'nauc_map_at_3_std': np.float64(0.04492033795120766), 'nauc_map_at_3_diff1': np.float64(0.8754770071421153), 'nauc_map_at_5_max': np.float64(0.7066144606454553), 'nauc_map_at_5_std': np.float64(0.030795588951507427), 'nauc_map_at_5_diff1': np.float64(0.8771859407768526), 'nauc_map_at_10_max': np.float64(0.7064799249896533), 'nauc_map_at_10_std': np.float64(0.036855845584850486), 'nauc_map_at_10_diff1': np.float64(0.8776408458178071), 'nauc_map_at_20_max': np.float64(0.706929800547732), 'nauc_map_at_20_std': np.float64(0.039629808880621335), 'nauc_map_at_20_diff1': np.float64(0.8783542965578791), 'nauc_map_at_100_max': np.float64(0.7064065801220124), 'nauc_map_at_100_std': np.float64(0.038139850738070864), 'nauc_map_at_100_diff1': np.float64(0.8781916205186626), 'nauc_map_at_1000_max': np.float64(0.7062984812316708), 'nauc_map_at_1000_std': np.float64(0.03784310349076912), 'nauc_map_at_1000_diff1': np.float64(0.8781540759034451), 'nauc_recall_at_1_max': np.float64(0.6698712703867343), 'nauc_recall_at_1_std': np.float64(-0.013885479735995902), 'nauc_recall_at_1_diff1': np.float64(0.8844024436807941), 'nauc_recall_at_3_max': np.float64(0.8013174019607853), 'nauc_recall_at_3_std': np.float64(0.19693189775910358), 'nauc_recall_at_3_diff1': np.float64(0.8630514705882346), 'nauc_recall_at_5_max': np.float64(0.7938736100500814), 'nauc_recall_at_5_std': np.float64(0.12887276122570276), 'nauc_recall_at_5_diff1': np.float64(0.8750212206094554), 'nauc_recall_at_10_max': np.float64(0.8162785947712434), 'nauc_recall_at_10_std': np.float64(0.26741946778711256), 'nauc_recall_at_10_diff1': np.float64(0.8856355042016815), 'nauc_recall_at_20_max': np.float64(0.9059427692645661), 'nauc_recall_at_20_std': np.float64(0.5835118361069919), 'nauc_recall_at_20_diff1': np.float64(0.9375240292195298), 'nauc_recall_at_100_max': np.float64(0.9256924992219061), 'nauc_recall_at_100_std': np.float64(0.643323996265173), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6698712703867343), 'nauc_precision_at_1_std': np.float64(-0.013885479735995902), 'nauc_precision_at_1_diff1': np.float64(0.8844024436807941), 'nauc_precision_at_3_max': np.float64(0.8013174019607885), 'nauc_precision_at_3_std': np.float64(0.19693189775910763), 'nauc_precision_at_3_diff1': np.float64(0.8630514705882362), 'nauc_precision_at_5_max': np.float64(0.7938736100500778), 'nauc_precision_at_5_std': np.float64(0.12887276122570093), 'nauc_precision_at_5_diff1': np.float64(0.8750212206094533), 'nauc_precision_at_10_max': np.float64(0.8162785947712319), 'nauc_precision_at_10_std': np.float64(0.2674194677871078), 'nauc_precision_at_10_diff1': np.float64(0.8856355042016738), 'nauc_precision_at_20_max': np.float64(0.9059427692645702), 'nauc_precision_at_20_std': np.float64(0.5835118361069921), 'nauc_precision_at_20_diff1': np.float64(0.9375240292195359), 'nauc_precision_at_100_max': np.float64(0.9256924992219204), 'nauc_precision_at_100_std': np.float64(0.6433239962651692), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505334), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6698712703867343), 'nauc_mrr_at_1_std': np.float64(-0.013885479735995902), 'nauc_mrr_at_1_diff1': np.float64(0.8844024436807941), 'nauc_mrr_at_3_max': np.float64(0.711326413945684), 'nauc_mrr_at_3_std': np.float64(0.04492033795120766), 'nauc_mrr_at_3_diff1': np.float64(0.8754770071421153), 'nauc_mrr_at_5_max': np.float64(0.7066144606454553), 'nauc_mrr_at_5_std': np.float64(0.030795588951507427), 'nauc_mrr_at_5_diff1': np.float64(0.8771859407768526), 'nauc_mrr_at_10_max': np.float64(0.7064799249896533), 'nauc_mrr_at_10_std': np.float64(0.036855845584850486), 'nauc_mrr_at_10_diff1': np.float64(0.8776408458178071), 'nauc_mrr_at_20_max': np.float64(0.706929800547732), 'nauc_mrr_at_20_std': np.float64(0.039629808880621335), 'nauc_mrr_at_20_diff1': np.float64(0.8783542965578791), 'nauc_mrr_at_100_max': np.float64(0.7064065801220124), 'nauc_mrr_at_100_std': np.float64(0.038139850738070864), 'nauc_mrr_at_100_diff1': np.float64(0.8781916205186626), 'nauc_mrr_at_1000_max': np.float64(0.7062984812316708), 'nauc_mrr_at_1000_std': np.float64(0.03784310349076912), 'nauc_mrr_at_1000_diff1': np.float64(0.8781540759034451), 'main_score': 0.90577}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:  18%|█▊        | 2/11 [00:00<00:00, 10.81it/s]Batches:  36%|███▋      | 4/11 [00:00<00:00, 13.14it/s]Batches:  64%|██████▎   | 7/11 [00:00<00:00, 16.52it/s]Batches:  91%|█████████ | 10/11 [00:00<00:00, 19.81it/s]Batches: 100%|██████████| 11/11 [00:00<00:00, 18.14it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:  14%|█▍        | 2/14 [00:00<00:01,  6.85it/s]Batches:  29%|██▊       | 4/14 [00:00<00:01,  9.63it/s]Batches:  43%|████▎     | 6/14 [00:00<00:00, 11.22it/s]Batches:  57%|█████▋    | 8/14 [00:00<00:00, 12.90it/s]Batches:  71%|███████▏  | 10/14 [00:00<00:00, 14.38it/s]Batches:  93%|█████████▎| 13/14 [00:00<00:00, 17.28it/s]Batches: 100%|██████████| 14/14 [00:00<00:00, 14.38it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.02 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:  18%|█▊        | 2/11 [00:00<00:00, 11.09it/s]Batches:  36%|███▋      | 4/11 [00:00<00:00, 13.25it/s]Batches:  64%|██████▎   | 7/11 [00:00<00:00, 16.63it/s]Batches:  91%|█████████ | 10/11 [00:00<00:00, 19.89it/s]Batches: 100%|██████████| 11/11 [00:00<00:00, 18.21it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:  11%|█         | 2/19 [00:04<00:36,  2.14s/it]Batches:  16%|█▌        | 3/19 [00:04<00:21,  1.36s/it]Batches:  21%|██        | 4/19 [00:04<00:14,  1.06it/s]Batches:  26%|██▋       | 5/19 [00:04<00:09,  1.46it/s]Batches:  32%|███▏      | 6/19 [00:05<00:06,  1.88it/s]Batches:  37%|███▋      | 7/19 [00:05<00:04,  2.46it/s]Batches:  42%|████▏     | 8/19 [00:05<00:03,  3.01it/s]Batches:  47%|████▋     | 9/19 [00:05<00:02,  3.70it/s]Batches:  53%|█████▎    | 10/19 [00:05<00:02,  4.32it/s]Batches:  58%|█████▊    | 11/19 [00:05<00:01,  5.03it/s]Batches:  63%|██████▎   | 12/19 [00:06<00:01,  5.88it/s]Batches:  68%|██████▊   | 13/19 [00:06<00:00,  6.66it/s]Batches:  79%|███████▉  | 15/19 [00:06<00:00,  8.12it/s]Batches:  89%|████████▉ | 17/19 [00:06<00:00,  9.74it/s]Batches: 100%|██████████| 19/19 [00:06<00:00, 11.46it/s]Batches: 100%|██████████| 19/19 [00:06<00:00,  2.89it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 7.58 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  20%|██        | 2/10 [00:00<00:00,  9.26it/s]Batches:  40%|████      | 4/10 [00:00<00:00, 12.45it/s]Batches:  70%|███████   | 7/10 [00:00<00:00, 16.45it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 19.33it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 16.79it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:  14%|█▍        | 2/14 [00:00<00:01,  6.83it/s]Batches:  29%|██▊       | 4/14 [00:00<00:01,  9.61it/s]Batches:  43%|████▎     | 6/14 [00:00<00:00, 11.21it/s]Batches:  57%|█████▋    | 8/14 [00:00<00:00, 12.89it/s]Batches:  71%|███████▏  | 10/14 [00:00<00:00, 14.34it/s]Batches:  93%|█████████▎| 13/14 [00:00<00:00, 17.18it/s]Batches: 100%|██████████| 14/14 [00:00<00:00, 14.33it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.96 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 13.37 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.29817, 'ndcg_at_3': 0.32562, 'ndcg_at_5': 0.34814, 'ndcg_at_10': 0.38136, 'ndcg_at_20': 0.40338, 'ndcg_at_100': 0.45402, 'ndcg_at_1000': 0.47931, 'map_at_1': 0.20831, 'map_at_3': 0.29414, 'map_at_5': 0.3122, 'map_at_10': 0.32908, 'map_at_20': 0.33605, 'map_at_100': 0.34389, 'map_at_1000': 0.34504, 'recall_at_1': 0.20831, 'recall_at_3': 0.34778, 'recall_at_5': 0.40398, 'recall_at_10': 0.49478, 'recall_at_20': 0.57146, 'recall_at_100': 0.81863, 'recall_at_1000': 1.0, 'precision_at_1': 0.29817, 'precision_at_3': 0.18145, 'precision_at_5': 0.12813, 'precision_at_10': 0.07859, 'precision_at_20': 0.04557, 'precision_at_100': 0.01306, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.2966360856269113, 'mrr_at_3': 0.3488786952089705, 'mrr_at_5': 0.36080530071355765, 'mrr_at_10': 0.37183753215863297, 'mrr_at_20': 0.3772811917655272, 'mrr_at_100': 0.3829008286371145, 'mrr_at_1000': 0.3836966269839772, 'nauc_ndcg_at_1_max': np.float64(0.17921127296001094), 'nauc_ndcg_at_1_std': np.float64(-0.30209841901980133), 'nauc_ndcg_at_1_diff1': np.float64(0.5348018188303136), 'nauc_ndcg_at_3_max': np.float64(0.18190095075864193), 'nauc_ndcg_at_3_std': np.float64(-0.29325503717718704), 'nauc_ndcg_at_3_diff1': np.float64(0.47956477922271434), 'nauc_ndcg_at_5_max': np.float64(0.1723425293963438), 'nauc_ndcg_at_5_std': np.float64(-0.3089086169711066), 'nauc_ndcg_at_5_diff1': np.float64(0.4754360431359368), 'nauc_ndcg_at_10_max': np.float64(0.18013884433387334), 'nauc_ndcg_at_10_std': np.float64(-0.3070527412905117), 'nauc_ndcg_at_10_diff1': np.float64(0.48366943212475033), 'nauc_ndcg_at_20_max': np.float64(0.18848447114362457), 'nauc_ndcg_at_20_std': np.float64(-0.29600603373128404), 'nauc_ndcg_at_20_diff1': np.float64(0.47734068226312065), 'nauc_ndcg_at_100_max': np.float64(0.21161875281233428), 'nauc_ndcg_at_100_std': np.float64(-0.24796200153063172), 'nauc_ndcg_at_100_diff1': np.float64(0.4769617530545894), 'nauc_ndcg_at_1000_max': np.float64(0.19641653494506675), 'nauc_ndcg_at_1000_std': np.float64(-0.27753510742838244), 'nauc_ndcg_at_1000_diff1': np.float64(0.48197084861228895), 'nauc_map_at_1_max': np.float64(0.14031554390030418), 'nauc_map_at_1_std': np.float64(-0.27108694948652934), 'nauc_map_at_1_diff1': np.float64(0.5456119893123789), 'nauc_map_at_3_max': np.float64(0.18359053188779517), 'nauc_map_at_3_std': np.float64(-0.2876209558059667), 'nauc_map_at_3_diff1': np.float64(0.48134743166975946), 'nauc_map_at_5_max': np.float64(0.17891580665842385), 'nauc_map_at_5_std': np.float64(-0.30222239266697265), 'nauc_map_at_5_diff1': np.float64(0.47929986564046945), 'nauc_map_at_10_max': np.float64(0.18064060627508502), 'nauc_map_at_10_std': np.float64(-0.30386335046213536), 'nauc_map_at_10_diff1': np.float64(0.4820374106404779), 'nauc_map_at_20_max': np.float64(0.18287062366464865), 'nauc_map_at_20_std': np.float64(-0.3019944470269644), 'nauc_map_at_20_diff1': np.float64(0.4810957669014283), 'nauc_map_at_100_max': np.float64(0.18571419612298687), 'nauc_map_at_100_std': np.float64(-0.2949244620326775), 'nauc_map_at_100_diff1': np.float64(0.4812608576168362), 'nauc_map_at_1000_max': np.float64(0.18521674219481413), 'nauc_map_at_1000_std': np.float64(-0.2960425549816837), 'nauc_map_at_1000_diff1': np.float64(0.48133604414825215), 'nauc_recall_at_1_max': np.float64(0.14031554390030418), 'nauc_recall_at_1_std': np.float64(-0.27108694948652934), 'nauc_recall_at_1_diff1': np.float64(0.5456119893123789), 'nauc_recall_at_3_max': np.float64(0.1764088433100612), 'nauc_recall_at_3_std': np.float64(-0.2737743742105919), 'nauc_recall_at_3_diff1': np.float64(0.43799152653326956), 'nauc_recall_at_5_max': np.float64(0.15119844812264505), 'nauc_recall_at_5_std': np.float64(-0.31337762808461), 'nauc_recall_at_5_diff1': np.float64(0.4277166494237209), 'nauc_recall_at_10_max': np.float64(0.170510123243143), 'nauc_recall_at_10_std': np.float64(-0.30151715099932846), 'nauc_recall_at_10_diff1': np.float64(0.4449286527602635), 'nauc_recall_at_20_max': np.float64(0.2008384506734435), 'nauc_recall_at_20_std': np.float64(-0.25920459179394156), 'nauc_recall_at_20_diff1': np.float64(0.41603250813833426), 'nauc_recall_at_100_max': np.float64(0.39132323058198576), 'nauc_recall_at_100_std': np.float64(0.13851370488998885), 'nauc_recall_at_100_diff1': np.float64(0.3657287302918947), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.17921127296001094), 'nauc_precision_at_1_std': np.float64(-0.30209841901980133), 'nauc_precision_at_1_diff1': np.float64(0.5348018188303136), 'nauc_precision_at_3_max': np.float64(0.19321982362263856), 'nauc_precision_at_3_std': np.float64(-0.26553455036982765), 'nauc_precision_at_3_diff1': np.float64(0.33808932274585224), 'nauc_precision_at_5_max': np.float64(0.1683945728070259), 'nauc_precision_at_5_std': np.float64(-0.2804091965029408), 'nauc_precision_at_5_diff1': np.float64(0.3121834704092435), 'nauc_precision_at_10_max': np.float64(0.1646200459731871), 'nauc_precision_at_10_std': np.float64(-0.25644518362135166), 'nauc_precision_at_10_diff1': np.float64(0.29471205149151025), 'nauc_precision_at_20_max': np.float64(0.16723077639227812), 'nauc_precision_at_20_std': np.float64(-0.2112208451299249), 'nauc_precision_at_20_diff1': np.float64(0.25220629460345056), 'nauc_precision_at_100_max': np.float64(0.2125217418258856), 'nauc_precision_at_100_std': np.float64(0.06125951206669296), 'nauc_precision_at_100_diff1': np.float64(0.11684819918873653), 'nauc_precision_at_1000_max': np.float64(0.13382872144346714), 'nauc_precision_at_1000_std': np.float64(0.04122449989207637), 'nauc_precision_at_1000_diff1': np.float64(0.011563968467457964), 'nauc_mrr_at_1_max': np.float64(0.18160868422719123), 'nauc_mrr_at_1_std': np.float64(-0.30797690086780494), 'nauc_mrr_at_1_diff1': np.float64(0.5405924761468841), 'nauc_mrr_at_3_max': np.float64(0.18325360402514465), 'nauc_mrr_at_3_std': np.float64(-0.29809729527087636), 'nauc_mrr_at_3_diff1': np.float64(0.5074309411382669), 'nauc_mrr_at_5_max': np.float64(0.17499978850136277), 'nauc_mrr_at_5_std': np.float64(-0.30613844007932), 'nauc_mrr_at_5_diff1': np.float64(0.5040973124023358), 'nauc_mrr_at_10_max': np.float64(0.18020656145161706), 'nauc_mrr_at_10_std': np.float64(-0.30351865123540833), 'nauc_mrr_at_10_diff1': np.float64(0.5082858235855772), 'nauc_mrr_at_20_max': np.float64(0.18363919497044315), 'nauc_mrr_at_20_std': np.float64(-0.2981878607029016), 'nauc_mrr_at_20_diff1': np.float64(0.5063474793547407), 'nauc_mrr_at_100_max': np.float64(0.18545091331376476), 'nauc_mrr_at_100_std': np.float64(-0.29376162189552335), 'nauc_mrr_at_100_diff1': np.float64(0.5061732074305647), 'nauc_mrr_at_1000_max': np.float64(0.1848178730121744), 'nauc_mrr_at_1000_std': np.float64(-0.2949369363625658), 'nauc_mrr_at_1000_diff1': np.float64(0.5063529245855974), 'main_score': 0.38136}, 'eng-kor': {'ndcg_at_1': 0.28135, 'ndcg_at_3': 0.30684, 'ndcg_at_5': 0.3301, 'ndcg_at_10': 0.36466, 'ndcg_at_20': 0.38747, 'ndcg_at_100': 0.44394, 'ndcg_at_1000': 0.47299, 'map_at_1': 0.16195, 'map_at_3': 0.25461, 'map_at_5': 0.28316, 'map_at_10': 0.30247, 'map_at_20': 0.31045, 'map_at_100': 0.32029, 'map_at_1000': 0.32204, 'recall_at_1': 0.16195, 'recall_at_3': 0.31007, 'recall_at_5': 0.38512, 'recall_at_10': 0.47031, 'recall_at_20': 0.54559, 'recall_at_100': 0.80691, 'recall_at_1000': 0.99949, 'precision_at_1': 0.28135, 'precision_at_3': 0.20133, 'precision_at_5': 0.15535, 'precision_at_10': 0.09694, 'precision_at_20': 0.05604, 'precision_at_100': 0.01609, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.28134556574923547, 'mrr_at_3': 0.3460754332313967, 'mrr_at_5': 0.3609836901121305, 'mrr_at_10': 0.37137274889568456, 'mrr_at_20': 0.376339975809719, 'mrr_at_100': 0.382117780728189, 'mrr_at_1000': 0.3828201876395578, 'nauc_ndcg_at_1_max': np.float64(0.09410463653050855), 'nauc_ndcg_at_1_std': np.float64(-0.3164744056590057), 'nauc_ndcg_at_1_diff1': np.float64(0.5166741775760436), 'nauc_ndcg_at_3_max': np.float64(0.04586386939210757), 'nauc_ndcg_at_3_std': np.float64(-0.3427489136849516), 'nauc_ndcg_at_3_diff1': np.float64(0.4296823580628194), 'nauc_ndcg_at_5_max': np.float64(0.03440645713150041), 'nauc_ndcg_at_5_std': np.float64(-0.3484468296393965), 'nauc_ndcg_at_5_diff1': np.float64(0.4071745202531586), 'nauc_ndcg_at_10_max': np.float64(0.03466501214903401), 'nauc_ndcg_at_10_std': np.float64(-0.3467392563825769), 'nauc_ndcg_at_10_diff1': np.float64(0.4026679939253098), 'nauc_ndcg_at_20_max': np.float64(0.03885261952490511), 'nauc_ndcg_at_20_std': np.float64(-0.34417067833566617), 'nauc_ndcg_at_20_diff1': np.float64(0.40184863073072746), 'nauc_ndcg_at_100_max': np.float64(0.04867269810602465), 'nauc_ndcg_at_100_std': np.float64(-0.3205533316797824), 'nauc_ndcg_at_100_diff1': np.float64(0.39999391764192366), 'nauc_ndcg_at_1000_max': np.float64(0.05549815947986959), 'nauc_ndcg_at_1000_std': np.float64(-0.3250375899627975), 'nauc_ndcg_at_1000_diff1': np.float64(0.4116961025596255), 'nauc_map_at_1_max': np.float64(0.06852898908911594), 'nauc_map_at_1_std': np.float64(-0.26801606329609107), 'nauc_map_at_1_diff1': np.float64(0.5347867339770137), 'nauc_map_at_3_max': np.float64(0.046531320512400685), 'nauc_map_at_3_std': np.float64(-0.327301522006749), 'nauc_map_at_3_diff1': np.float64(0.45370008142470125), 'nauc_map_at_5_max': np.float64(0.042114916596199745), 'nauc_map_at_5_std': np.float64(-0.3388846457657111), 'nauc_map_at_5_diff1': np.float64(0.4285264136511262), 'nauc_map_at_10_max': np.float64(0.043826915864737095), 'nauc_map_at_10_std': np.float64(-0.34096339413992105), 'nauc_map_at_10_diff1': np.float64(0.42642245236739607), 'nauc_map_at_20_max': np.float64(0.04409714490385517), 'nauc_map_at_20_std': np.float64(-0.3422271490399481), 'nauc_map_at_20_diff1': np.float64(0.4264320601135709), 'nauc_map_at_100_max': np.float64(0.04467394001247778), 'nauc_map_at_100_std': np.float64(-0.3400128364169017), 'nauc_map_at_100_diff1': np.float64(0.4258615414976782), 'nauc_map_at_1000_max': np.float64(0.04593631651918141), 'nauc_map_at_1000_std': np.float64(-0.33906835090023435), 'nauc_map_at_1000_diff1': np.float64(0.4264480961534915), 'nauc_recall_at_1_max': np.float64(0.06852898908911594), 'nauc_recall_at_1_std': np.float64(-0.26801606329609107), 'nauc_recall_at_1_diff1': np.float64(0.5347867339770137), 'nauc_recall_at_3_max': np.float64(0.02446814988308303), 'nauc_recall_at_3_std': np.float64(-0.3190482508474083), 'nauc_recall_at_3_diff1': np.float64(0.3816865054005904), 'nauc_recall_at_5_max': np.float64(0.009923653988699249), 'nauc_recall_at_5_std': np.float64(-0.33192783597342224), 'nauc_recall_at_5_diff1': np.float64(0.32694981256741423), 'nauc_recall_at_10_max': np.float64(0.0014732026701540697), 'nauc_recall_at_10_std': np.float64(-0.3273621591273574), 'nauc_recall_at_10_diff1': np.float64(0.3129484445006831), 'nauc_recall_at_20_max': np.float64(0.012056931114468188), 'nauc_recall_at_20_std': np.float64(-0.31514501177949855), 'nauc_recall_at_20_diff1': np.float64(0.300354390788173), 'nauc_recall_at_100_max': np.float64(0.04471442847930234), 'nauc_recall_at_100_std': np.float64(-0.1469415932749167), 'nauc_recall_at_100_diff1': np.float64(0.2406610558506222), 'nauc_recall_at_1000_max': np.float64(1.0), 'nauc_recall_at_1000_std': np.float64(1.0), 'nauc_recall_at_1000_diff1': np.float64(1.0), 'nauc_precision_at_1_max': np.float64(0.09410463653050855), 'nauc_precision_at_1_std': np.float64(-0.3164744056590057), 'nauc_precision_at_1_diff1': np.float64(0.5166741775760436), 'nauc_precision_at_3_max': np.float64(0.028082917422987488), 'nauc_precision_at_3_std': np.float64(-0.3544347772193157), 'nauc_precision_at_3_diff1': np.float64(0.28314476815765904), 'nauc_precision_at_5_max': np.float64(0.017424097214046527), 'nauc_precision_at_5_std': np.float64(-0.33222837661919), 'nauc_precision_at_5_diff1': np.float64(0.2051545833299847), 'nauc_precision_at_10_max': np.float64(0.027621943464164772), 'nauc_precision_at_10_std': np.float64(-0.2928941233286181), 'nauc_precision_at_10_diff1': np.float64(0.18355004569248826), 'nauc_precision_at_20_max': np.float64(0.03770338605989291), 'nauc_precision_at_20_std': np.float64(-0.2620809639869071), 'nauc_precision_at_20_diff1': np.float64(0.16569771821092633), 'nauc_precision_at_100_max': np.float64(0.08511372467683319), 'nauc_precision_at_100_std': np.float64(-0.09204186750756403), 'nauc_precision_at_100_diff1': np.float64(0.054652038933834135), 'nauc_precision_at_1000_max': np.float64(0.11801114888802201), 'nauc_precision_at_1000_std': np.float64(-0.000622007292001318), 'nauc_precision_at_1000_diff1': np.float64(-0.004350817932090188), 'nauc_mrr_at_1_max': np.float64(0.09410463653050855), 'nauc_mrr_at_1_std': np.float64(-0.3164744056590057), 'nauc_mrr_at_1_diff1': np.float64(0.5166741775760436), 'nauc_mrr_at_3_max': np.float64(0.05769408330326005), 'nauc_mrr_at_3_std': np.float64(-0.3379753707269689), 'nauc_mrr_at_3_diff1': np.float64(0.4487253942588003), 'nauc_mrr_at_5_max': np.float64(0.05396346830372321), 'nauc_mrr_at_5_std': np.float64(-0.3419412016617669), 'nauc_mrr_at_5_diff1': np.float64(0.4383203353791776), 'nauc_mrr_at_10_max': np.float64(0.05530460109467874), 'nauc_mrr_at_10_std': np.float64(-0.33766782095912956), 'nauc_mrr_at_10_diff1': np.float64(0.4365804099650248), 'nauc_mrr_at_20_max': np.float64(0.05719074084124191), 'nauc_mrr_at_20_std': np.float64(-0.33505772021560115), 'nauc_mrr_at_20_diff1': np.float64(0.436022324599732), 'nauc_mrr_at_100_max': np.float64(0.058166211672347375), 'nauc_mrr_at_100_std': np.float64(-0.3325160383077923), 'nauc_mrr_at_100_diff1': np.float64(0.4369614451082152), 'nauc_mrr_at_1000_max': np.float64(0.05804950031013807), 'nauc_mrr_at_1000_std': np.float64(-0.3330461830157836), 'nauc_mrr_at_1000_diff1': np.float64(0.43745525286589537), 'main_score': 0.36466}, 'kor-eng': {'ndcg_at_1': 0.2671, 'ndcg_at_3': 0.29495, 'ndcg_at_5': 0.3154, 'ndcg_at_10': 0.34959, 'ndcg_at_20': 0.37236, 'ndcg_at_100': 0.42687, 'ndcg_at_1000': 0.45518, 'map_at_1': 0.18673, 'map_at_3': 0.26357, 'map_at_5': 0.27997, 'map_at_10': 0.29701, 'map_at_20': 0.30461, 'map_at_100': 0.31346, 'map_at_1000': 0.31472, 'recall_at_1': 0.18673, 'recall_at_3': 0.31788, 'recall_at_5': 0.3662, 'recall_at_10': 0.45766, 'recall_at_20': 0.53428, 'recall_at_100': 0.79612, 'recall_at_1000': 1.0, 'precision_at_1': 0.2671, 'precision_at_3': 0.16667, 'precision_at_5': 0.12052, 'precision_at_10': 0.07704, 'precision_at_20': 0.04577, 'precision_at_100': 0.01358, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.2687296416938111, 'mrr_at_3': 0.3170466883821934, 'mrr_at_5': 0.3297502714440826, 'mrr_at_10': 0.3418347034796545, 'mrr_at_20': 0.3472891307095276, 'mrr_at_100': 0.3531289154138696, 'mrr_at_1000': 0.3538781217892554, 'nauc_ndcg_at_1_max': np.float64(0.18996964027841132), 'nauc_ndcg_at_1_std': np.float64(-0.19997224616582124), 'nauc_ndcg_at_1_diff1': np.float64(0.4689714941309702), 'nauc_ndcg_at_3_max': np.float64(0.14877800750145417), 'nauc_ndcg_at_3_std': np.float64(-0.23055872236324135), 'nauc_ndcg_at_3_diff1': np.float64(0.40643640765191125), 'nauc_ndcg_at_5_max': np.float64(0.14913135770716596), 'nauc_ndcg_at_5_std': np.float64(-0.23816684421001302), 'nauc_ndcg_at_5_diff1': np.float64(0.39599687759814983), 'nauc_ndcg_at_10_max': np.float64(0.15296553539200014), 'nauc_ndcg_at_10_std': np.float64(-0.24042172969904993), 'nauc_ndcg_at_10_diff1': np.float64(0.39457157140549987), 'nauc_ndcg_at_20_max': np.float64(0.15577799187602123), 'nauc_ndcg_at_20_std': np.float64(-0.23056036740615085), 'nauc_ndcg_at_20_diff1': np.float64(0.39635285965850037), 'nauc_ndcg_at_100_max': np.float64(0.17395123869340684), 'nauc_ndcg_at_100_std': np.float64(-0.18221581110950394), 'nauc_ndcg_at_100_diff1': np.float64(0.39792642157696606), 'nauc_ndcg_at_1000_max': np.float64(0.17185273917463043), 'nauc_ndcg_at_1000_std': np.float64(-0.202730946562446), 'nauc_ndcg_at_1000_diff1': np.float64(0.40727257322303795), 'nauc_map_at_1_max': np.float64(0.15020218455097), 'nauc_map_at_1_std': np.float64(-0.17634504812640114), 'nauc_map_at_1_diff1': np.float64(0.4926009965257486), 'nauc_map_at_3_max': np.float64(0.1547445251297351), 'nauc_map_at_3_std': np.float64(-0.2219555779183466), 'nauc_map_at_3_diff1': np.float64(0.41083869494830844), 'nauc_map_at_5_max': np.float64(0.15344254275769037), 'nauc_map_at_5_std': np.float64(-0.23044339088779464), 'nauc_map_at_5_diff1': np.float64(0.40025849027627447), 'nauc_map_at_10_max': np.float64(0.15670449588022742), 'nauc_map_at_10_std': np.float64(-0.23297286938371808), 'nauc_map_at_10_diff1': np.float64(0.4011910814803658), 'nauc_map_at_20_max': np.float64(0.1559260704824353), 'nauc_map_at_20_std': np.float64(-0.23163069978796522), 'nauc_map_at_20_diff1': np.float64(0.4009783654182684), 'nauc_map_at_100_max': np.float64(0.1585455417526513), 'nauc_map_at_100_std': np.float64(-0.22372189087419364), 'nauc_map_at_100_diff1': np.float64(0.4020132419508975), 'nauc_map_at_1000_max': np.float64(0.15883662766294382), 'nauc_map_at_1000_std': np.float64(-0.22412141392470475), 'nauc_map_at_1000_diff1': np.float64(0.40245440644825425), 'nauc_recall_at_1_max': np.float64(0.15020218455097), 'nauc_recall_at_1_std': np.float64(-0.17634504812640114), 'nauc_recall_at_1_diff1': np.float64(0.4926009965257486), 'nauc_recall_at_3_max': np.float64(0.12036860033464729), 'nauc_recall_at_3_std': np.float64(-0.23357099358664996), 'nauc_recall_at_3_diff1': np.float64(0.3648539759847008), 'nauc_recall_at_5_max': np.float64(0.12350607961827925), 'nauc_recall_at_5_std': np.float64(-0.25044076947010224), 'nauc_recall_at_5_diff1': np.float64(0.34668306087213346), 'nauc_recall_at_10_max': np.float64(0.12899550396149898), 'nauc_recall_at_10_std': np.float64(-0.2538865426117726), 'nauc_recall_at_10_diff1': np.float64(0.331843612524452), 'nauc_recall_at_20_max': np.float64(0.13975604106934852), 'nauc_recall_at_20_std': np.float64(-0.2225211196225209), 'nauc_recall_at_20_diff1': np.float64(0.33189492642587626), 'nauc_recall_at_100_max': np.float64(0.21162150897481632), 'nauc_recall_at_100_std': np.float64(0.08591648067936566), 'nauc_recall_at_100_diff1': np.float64(0.2756837976348629), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.18996964027841132), 'nauc_precision_at_1_std': np.float64(-0.19997224616582124), 'nauc_precision_at_1_diff1': np.float64(0.4689714941309702), 'nauc_precision_at_3_max': np.float64(0.14827702362286377), 'nauc_precision_at_3_std': np.float64(-0.22809924837457654), 'nauc_precision_at_3_diff1': np.float64(0.2778664435367793), 'nauc_precision_at_5_max': np.float64(0.13674940258101684), 'nauc_precision_at_5_std': np.float64(-0.23758104215581138), 'nauc_precision_at_5_diff1': np.float64(0.2401499628183716), 'nauc_precision_at_10_max': np.float64(0.13153183505893853), 'nauc_precision_at_10_std': np.float64(-0.2110845698023772), 'nauc_precision_at_10_diff1': np.float64(0.2191611913174667), 'nauc_precision_at_20_max': np.float64(0.1281119428499148), 'nauc_precision_at_20_std': np.float64(-0.15782713885062405), 'nauc_precision_at_20_diff1': np.float64(0.20043707396935223), 'nauc_precision_at_100_max': np.float64(0.20232212664954746), 'nauc_precision_at_100_std': np.float64(0.110301848631096), 'nauc_precision_at_100_diff1': np.float64(0.10724857697666676), 'nauc_precision_at_1000_max': np.float64(0.1827251330010961), 'nauc_precision_at_1000_std': np.float64(0.11546928731175385), 'nauc_precision_at_1000_diff1': np.float64(0.04945592286120255), 'nauc_mrr_at_1_max': np.float64(0.18585061593342325), 'nauc_mrr_at_1_std': np.float64(-0.2037305358284754), 'nauc_mrr_at_1_diff1': np.float64(0.46269205360487015), 'nauc_mrr_at_3_max': np.float64(0.160970868575251), 'nauc_mrr_at_3_std': np.float64(-0.22409113997782748), 'nauc_mrr_at_3_diff1': np.float64(0.43203460840446883), 'nauc_mrr_at_5_max': np.float64(0.16441669038410864), 'nauc_mrr_at_5_std': np.float64(-0.2284707714837824), 'nauc_mrr_at_5_diff1': np.float64(0.4298683149143761), 'nauc_mrr_at_10_max': np.float64(0.16520289084384704), 'nauc_mrr_at_10_std': np.float64(-0.22515060936251266), 'nauc_mrr_at_10_diff1': np.float64(0.42608519846944043), 'nauc_mrr_at_20_max': np.float64(0.167682860083439), 'nauc_mrr_at_20_std': np.float64(-0.21997621282363297), 'nauc_mrr_at_20_diff1': np.float64(0.4282671840596742), 'nauc_mrr_at_100_max': np.float64(0.1689665298798761), 'nauc_mrr_at_100_std': np.float64(-0.21617548092035688), 'nauc_mrr_at_100_diff1': np.float64(0.42818213060128935), 'nauc_mrr_at_1000_max': np.float64(0.1688794335552809), 'nauc_mrr_at_1000_std': np.float64(-0.21680100724045004), 'nauc_mrr_at_1000_diff1': np.float64(0.4283794686153868), 'main_score': 0.34959}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  50%|█████     | 2/4 [00:00<00:00,  2.06it/s]Batches:  75%|███████▌  | 3/4 [00:01<00:00,  3.08it/s]Batches: 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/97 [00:00<?, ?it/s]Batches:   1%|          | 1/97 [00:01<02:37,  1.64s/it]Batches:   2%|▏         | 2/97 [01:17<1:12:09, 45.57s/it]Batches:   3%|▎         | 3/97 [02:34<1:33:44, 59.83s/it]Batches:   4%|▍         | 4/97 [03:51<1:43:11, 66.58s/it]Batches:   5%|▌         | 5/97 [05:08<1:47:50, 70.33s/it]Batches:   6%|▌         | 6/97 [06:25<1:50:04, 72.58s/it]Batches:   7%|▋         | 7/97 [07:42<1:51:01, 74.02s/it]Batches:   8%|▊         | 8/97 [08:59<1:51:11, 74.96s/it]Batches:   9%|▉         | 9/97 [10:16<1:50:52, 75.59s/it]Batches:  10%|█         | 10/97 [11:33<1:50:14, 76.02s/it]Batches:  10%|█         | 10/97 [12:51<1:51:51, 77.15s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating MultiLongDocRetrieval: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 44.34 GiB of which 1.85 GiB is free. Process 2144007 has 42.48 GiB memory in use. Of the allocated memory 42.14 GiB is allocated by PyTorch, and 33.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/workspace/KURE/eval/evaluate.py", line 241, in evaluate_model
    evaluation.run(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 630, in run
    raise e
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 583, in run
    results, tick, tock = self._run_eval(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 304, in _run_eval
    results = task.evaluate(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py", line 339, in evaluate
    scores[hf_subset] = self._evaluate_subset(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py", line 348, in _evaluate_subset
    results = retriever(corpus, queries)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/evaluators/RetrievalEvaluator.py", line 484, in __call__
    return self.retriever.search(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/evaluators/RetrievalEvaluator.py", line 159, in search
    sub_corpus_embeddings = self.model.encode(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/evaluators/RetrievalEvaluator.py", line 419, in encode
    return self.encode_corpus(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/evaluators/RetrievalEvaluator.py", line 399, in encode_corpus
    corpus_embeddings = self.model.encode(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/models/sentence_transformer_wrapper.py", line 108, in encode
    embeddings = self.model.encode(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py", line 623, in encode
    out_features = self.forward(features, **kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py", line 690, in forward
    input = module(input, **module_kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py", line 442, in forward
    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py", line 943, in forward
    extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 451, in _prepare_4d_attention_mask_for_sdpa
    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 192, in _expand_mask
    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 44.34 GiB of which 1.85 GiB is free. Process 2144007 has 42.48 GiB memory in use. Of the allocated memory 42.14 GiB is allocated by PyTorch, and 33.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 44.34 GiB of which 1.85 GiB is free. Process 2144007 has 42.48 GiB memory in use. Of the allocated memory 42.14 GiB is allocated by PyTorch, and 33.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)



==================================================
Running model: elastic/multilingual-e5-small-optimized
--------------------------------------------------
INFO:mteb.models.overview:Model not found in model registry, assuming it is on HF Hub model.
INFO:mteb.models.overview:Attempting to extract metadata by loading the model (elastic/multilingual-e5-small-optimized) using HuggingFace.
WARNING:mteb.model_meta:Loader not specified for model elastic/multilingual-e5-small-optimized, loading using sentence transformers.
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: elastic/multilingual-e5-small-optimized
WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name elastic/multilingual-e5-small-optimized. Creating a new one with mean pooling.
/workspace/KURE/.venv/lib/python3.10/site-packages/torch/_utils.py:392: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  device=storage.device,
Some weights of the model checkpoint at elastic/multilingual-e5-small-optimized were not used when initializing BertModel: ['model.embeddings.LayerNorm.bias', 'model.embeddings.LayerNorm.weight', 'model.embeddings.position_embeddings.weight', 'model.embeddings.token_type_embeddings.weight', 'model.embeddings.word_embeddings.weight', 'model.encoder.layer.0.attention.output.LayerNorm.bias', 'model.encoder.layer.0.attention.output.LayerNorm.weight', 'model.encoder.layer.0.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.0.attention.output.dense._packed_params.dtype', 'model.encoder.layer.0.attention.output.dense.scale', 'model.encoder.layer.0.attention.output.dense.zero_point', 'model.encoder.layer.0.attention.self.key._packed_params._packed_params', 'model.encoder.layer.0.attention.self.key._packed_params.dtype', 'model.encoder.layer.0.attention.self.key.scale', 'model.encoder.layer.0.attention.self.key.zero_point', 'model.encoder.layer.0.attention.self.query._packed_params._packed_params', 'model.encoder.layer.0.attention.self.query._packed_params.dtype', 'model.encoder.layer.0.attention.self.query.scale', 'model.encoder.layer.0.attention.self.query.zero_point', 'model.encoder.layer.0.attention.self.value._packed_params._packed_params', 'model.encoder.layer.0.attention.self.value._packed_params.dtype', 'model.encoder.layer.0.attention.self.value.scale', 'model.encoder.layer.0.attention.self.value.zero_point', 'model.encoder.layer.0.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.0.intermediate.dense._packed_params.dtype', 'model.encoder.layer.0.intermediate.dense.scale', 'model.encoder.layer.0.intermediate.dense.zero_point', 'model.encoder.layer.0.output.LayerNorm.bias', 'model.encoder.layer.0.output.LayerNorm.weight', 'model.encoder.layer.0.output.dense.bias', 'model.encoder.layer.0.output.dense.weight', 'model.encoder.layer.1.attention.output.LayerNorm.bias', 'model.encoder.layer.1.attention.output.LayerNorm.weight', 'model.encoder.layer.1.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.1.attention.output.dense._packed_params.dtype', 'model.encoder.layer.1.attention.output.dense.scale', 'model.encoder.layer.1.attention.output.dense.zero_point', 'model.encoder.layer.1.attention.self.key._packed_params._packed_params', 'model.encoder.layer.1.attention.self.key._packed_params.dtype', 'model.encoder.layer.1.attention.self.key.scale', 'model.encoder.layer.1.attention.self.key.zero_point', 'model.encoder.layer.1.attention.self.query._packed_params._packed_params', 'model.encoder.layer.1.attention.self.query._packed_params.dtype', 'model.encoder.layer.1.attention.self.query.scale', 'model.encoder.layer.1.attention.self.query.zero_point', 'model.encoder.layer.1.attention.self.value._packed_params._packed_params', 'model.encoder.layer.1.attention.self.value._packed_params.dtype', 'model.encoder.layer.1.attention.self.value.scale', 'model.encoder.layer.1.attention.self.value.zero_point', 'model.encoder.layer.1.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.1.intermediate.dense._packed_params.dtype', 'model.encoder.layer.1.intermediate.dense.scale', 'model.encoder.layer.1.intermediate.dense.zero_point', 'model.encoder.layer.1.output.LayerNorm.bias', 'model.encoder.layer.1.output.LayerNorm.weight', 'model.encoder.layer.1.output.dense._packed_params._packed_params', 'model.encoder.layer.1.output.dense._packed_params.dtype', 'model.encoder.layer.1.output.dense.scale', 'model.encoder.layer.1.output.dense.zero_point', 'model.encoder.layer.10.attention.output.LayerNorm.bias', 'model.encoder.layer.10.attention.output.LayerNorm.weight', 'model.encoder.layer.10.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.10.attention.output.dense._packed_params.dtype', 'model.encoder.layer.10.attention.output.dense.scale', 'model.encoder.layer.10.attention.output.dense.zero_point', 'model.encoder.layer.10.attention.self.key._packed_params._packed_params', 'model.encoder.layer.10.attention.self.key._packed_params.dtype', 'model.encoder.layer.10.attention.self.key.scale', 'model.encoder.layer.10.attention.self.key.zero_point', 'model.encoder.layer.10.attention.self.query._packed_params._packed_params', 'model.encoder.layer.10.attention.self.query._packed_params.dtype', 'model.encoder.layer.10.attention.self.query.scale', 'model.encoder.layer.10.attention.self.query.zero_point', 'model.encoder.layer.10.attention.self.value._packed_params._packed_params', 'model.encoder.layer.10.attention.self.value._packed_params.dtype', 'model.encoder.layer.10.attention.self.value.scale', 'model.encoder.layer.10.attention.self.value.zero_point', 'model.encoder.layer.10.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.10.intermediate.dense._packed_params.dtype', 'model.encoder.layer.10.intermediate.dense.scale', 'model.encoder.layer.10.intermediate.dense.zero_point', 'model.encoder.layer.10.output.LayerNorm.bias', 'model.encoder.layer.10.output.LayerNorm.weight', 'model.encoder.layer.10.output.dense._packed_params._packed_params', 'model.encoder.layer.10.output.dense._packed_params.dtype', 'model.encoder.layer.10.output.dense.scale', 'model.encoder.layer.10.output.dense.zero_point', 'model.encoder.layer.11.attention.output.LayerNorm.bias', 'model.encoder.layer.11.attention.output.LayerNorm.weight', 'model.encoder.layer.11.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.11.attention.output.dense._packed_params.dtype', 'model.encoder.layer.11.attention.output.dense.scale', 'model.encoder.layer.11.attention.output.dense.zero_point', 'model.encoder.layer.11.attention.self.key._packed_params._packed_params', 'model.encoder.layer.11.attention.self.key._packed_params.dtype', 'model.encoder.layer.11.attention.self.key.scale', 'model.encoder.layer.11.attention.self.key.zero_point', 'model.encoder.layer.11.attention.self.query._packed_params._packed_params', 'model.encoder.layer.11.attention.self.query._packed_params.dtype', 'model.encoder.layer.11.attention.self.query.scale', 'model.encoder.layer.11.attention.self.query.zero_point', 'model.encoder.layer.11.attention.self.value._packed_params._packed_params', 'model.encoder.layer.11.attention.self.value._packed_params.dtype', 'model.encoder.layer.11.attention.self.value.scale', 'model.encoder.layer.11.attention.self.value.zero_point', 'model.encoder.layer.11.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.11.intermediate.dense._packed_params.dtype', 'model.encoder.layer.11.intermediate.dense.scale', 'model.encoder.layer.11.intermediate.dense.zero_point', 'model.encoder.layer.11.output.LayerNorm.bias', 'model.encoder.layer.11.output.LayerNorm.weight', 'model.encoder.layer.11.output.dense._packed_params._packed_params', 'model.encoder.layer.11.output.dense._packed_params.dtype', 'model.encoder.layer.11.output.dense.scale', 'model.encoder.layer.11.output.dense.zero_point', 'model.encoder.layer.2.attention.output.LayerNorm.bias', 'model.encoder.layer.2.attention.output.LayerNorm.weight', 'model.encoder.layer.2.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.2.attention.output.dense._packed_params.dtype', 'model.encoder.layer.2.attention.output.dense.scale', 'model.encoder.layer.2.attention.output.dense.zero_point', 'model.encoder.layer.2.attention.self.key._packed_params._packed_params', 'model.encoder.layer.2.attention.self.key._packed_params.dtype', 'model.encoder.layer.2.attention.self.key.scale', 'model.encoder.layer.2.attention.self.key.zero_point', 'model.encoder.layer.2.attention.self.query._packed_params._packed_params', 'model.encoder.layer.2.attention.self.query._packed_params.dtype', 'model.encoder.layer.2.attention.self.query.scale', 'model.encoder.layer.2.attention.self.query.zero_point', 'model.encoder.layer.2.attention.self.value._packed_params._packed_params', 'model.encoder.layer.2.attention.self.value._packed_params.dtype', 'model.encoder.layer.2.attention.self.value.scale', 'model.encoder.layer.2.attention.self.value.zero_point', 'model.encoder.layer.2.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.2.intermediate.dense._packed_params.dtype', 'model.encoder.layer.2.intermediate.dense.scale', 'model.encoder.layer.2.intermediate.dense.zero_point', 'model.encoder.layer.2.output.LayerNorm.bias', 'model.encoder.layer.2.output.LayerNorm.weight', 'model.encoder.layer.2.output.dense._packed_params._packed_params', 'model.encoder.layer.2.output.dense._packed_params.dtype', 'model.encoder.layer.2.output.dense.scale', 'model.encoder.layer.2.output.dense.zero_point', 'model.encoder.layer.3.attention.output.LayerNorm.bias', 'model.encoder.layer.3.attention.output.LayerNorm.weight', 'model.encoder.layer.3.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.3.attention.output.dense._packed_params.dtype', 'model.encoder.layer.3.attention.output.dense.scale', 'model.encoder.layer.3.attention.output.dense.zero_point', 'model.encoder.layer.3.attention.self.key._packed_params._packed_params', 'model.encoder.layer.3.attention.self.key._packed_params.dtype', 'model.encoder.layer.3.attention.self.key.scale', 'model.encoder.layer.3.attention.self.key.zero_point', 'model.encoder.layer.3.attention.self.query._packed_params._packed_params', 'model.encoder.layer.3.attention.self.query._packed_params.dtype', 'model.encoder.layer.3.attention.self.query.scale', 'model.encoder.layer.3.attention.self.query.zero_point', 'model.encoder.layer.3.attention.self.value._packed_params._packed_params', 'model.encoder.layer.3.attention.self.value._packed_params.dtype', 'model.encoder.layer.3.attention.self.value.scale', 'model.encoder.layer.3.attention.self.value.zero_point', 'model.encoder.layer.3.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.3.intermediate.dense._packed_params.dtype', 'model.encoder.layer.3.intermediate.dense.scale', 'model.encoder.layer.3.intermediate.dense.zero_point', 'model.encoder.layer.3.output.LayerNorm.bias', 'model.encoder.layer.3.output.LayerNorm.weight', 'model.encoder.layer.3.output.dense._packed_params._packed_params', 'model.encoder.layer.3.output.dense._packed_params.dtype', 'model.encoder.layer.3.output.dense.scale', 'model.encoder.layer.3.output.dense.zero_point', 'model.encoder.layer.4.attention.output.LayerNorm.bias', 'model.encoder.layer.4.attention.output.LayerNorm.weight', 'model.encoder.layer.4.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.4.attention.output.dense._packed_params.dtype', 'model.encoder.layer.4.attention.output.dense.scale', 'model.encoder.layer.4.attention.output.dense.zero_point', 'model.encoder.layer.4.attention.self.key._packed_params._packed_params', 'model.encoder.layer.4.attention.self.key._packed_params.dtype', 'model.encoder.layer.4.attention.self.key.scale', 'model.encoder.layer.4.attention.self.key.zero_point', 'model.encoder.layer.4.attention.self.query._packed_params._packed_params', 'model.encoder.layer.4.attention.self.query._packed_params.dtype', 'model.encoder.layer.4.attention.self.query.scale', 'model.encoder.layer.4.attention.self.query.zero_point', 'model.encoder.layer.4.attention.self.value._packed_params._packed_params', 'model.encoder.layer.4.attention.self.value._packed_params.dtype', 'model.encoder.layer.4.attention.self.value.scale', 'model.encoder.layer.4.attention.self.value.zero_point', 'model.encoder.layer.4.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.4.intermediate.dense._packed_params.dtype', 'model.encoder.layer.4.intermediate.dense.scale', 'model.encoder.layer.4.intermediate.dense.zero_point', 'model.encoder.layer.4.output.LayerNorm.bias', 'model.encoder.layer.4.output.LayerNorm.weight', 'model.encoder.layer.4.output.dense.bias', 'model.encoder.layer.4.output.dense.weight', 'model.encoder.layer.5.attention.output.LayerNorm.bias', 'model.encoder.layer.5.attention.output.LayerNorm.weight', 'model.encoder.layer.5.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.5.attention.output.dense._packed_params.dtype', 'model.encoder.layer.5.attention.output.dense.scale', 'model.encoder.layer.5.attention.output.dense.zero_point', 'model.encoder.layer.5.attention.self.key._packed_params._packed_params', 'model.encoder.layer.5.attention.self.key._packed_params.dtype', 'model.encoder.layer.5.attention.self.key.scale', 'model.encoder.layer.5.attention.self.key.zero_point', 'model.encoder.layer.5.attention.self.query._packed_params._packed_params', 'model.encoder.layer.5.attention.self.query._packed_params.dtype', 'model.encoder.layer.5.attention.self.query.scale', 'model.encoder.layer.5.attention.self.query.zero_point', 'model.encoder.layer.5.attention.self.value._packed_params._packed_params', 'model.encoder.layer.5.attention.self.value._packed_params.dtype', 'model.encoder.layer.5.attention.self.value.scale', 'model.encoder.layer.5.attention.self.value.zero_point', 'model.encoder.layer.5.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.5.intermediate.dense._packed_params.dtype', 'model.encoder.layer.5.intermediate.dense.scale', 'model.encoder.layer.5.intermediate.dense.zero_point', 'model.encoder.layer.5.output.LayerNorm.bias', 'model.encoder.layer.5.output.LayerNorm.weight', 'model.encoder.layer.5.output.dense.bias', 'model.encoder.layer.5.output.dense.weight', 'model.encoder.layer.6.attention.output.LayerNorm.bias', 'model.encoder.layer.6.attention.output.LayerNorm.weight', 'model.encoder.layer.6.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.6.attention.output.dense._packed_params.dtype', 'model.encoder.layer.6.attention.output.dense.scale', 'model.encoder.layer.6.attention.output.dense.zero_point', 'model.encoder.layer.6.attention.self.key._packed_params._packed_params', 'model.encoder.layer.6.attention.self.key._packed_params.dtype', 'model.encoder.layer.6.attention.self.key.scale', 'model.encoder.layer.6.attention.self.key.zero_point', 'model.encoder.layer.6.attention.self.query._packed_params._packed_params', 'model.encoder.layer.6.attention.self.query._packed_params.dtype', 'model.encoder.layer.6.attention.self.query.scale', 'model.encoder.layer.6.attention.self.query.zero_point', 'model.encoder.layer.6.attention.self.value._packed_params._packed_params', 'model.encoder.layer.6.attention.self.value._packed_params.dtype', 'model.encoder.layer.6.attention.self.value.scale', 'model.encoder.layer.6.attention.self.value.zero_point', 'model.encoder.layer.6.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.6.intermediate.dense._packed_params.dtype', 'model.encoder.layer.6.intermediate.dense.scale', 'model.encoder.layer.6.intermediate.dense.zero_point', 'model.encoder.layer.6.output.LayerNorm.bias', 'model.encoder.layer.6.output.LayerNorm.weight', 'model.encoder.layer.6.output.dense._packed_params._packed_params', 'model.encoder.layer.6.output.dense._packed_params.dtype', 'model.encoder.layer.6.output.dense.scale', 'model.encoder.layer.6.output.dense.zero_point', 'model.encoder.layer.7.attention.output.LayerNorm.bias', 'model.encoder.layer.7.attention.output.LayerNorm.weight', 'model.encoder.layer.7.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.7.attention.output.dense._packed_params.dtype', 'model.encoder.layer.7.attention.output.dense.scale', 'model.encoder.layer.7.attention.output.dense.zero_point', 'model.encoder.layer.7.attention.self.key._packed_params._packed_params', 'model.encoder.layer.7.attention.self.key._packed_params.dtype', 'model.encoder.layer.7.attention.self.key.scale', 'model.encoder.layer.7.attention.self.key.zero_point', 'model.encoder.layer.7.attention.self.query._packed_params._packed_params', 'model.encoder.layer.7.attention.self.query._packed_params.dtype', 'model.encoder.layer.7.attention.self.query.scale', 'model.encoder.layer.7.attention.self.query.zero_point', 'model.encoder.layer.7.attention.self.value._packed_params._packed_params', 'model.encoder.layer.7.attention.self.value._packed_params.dtype', 'model.encoder.layer.7.attention.self.value.scale', 'model.encoder.layer.7.attention.self.value.zero_point', 'model.encoder.layer.7.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.7.intermediate.dense._packed_params.dtype', 'model.encoder.layer.7.intermediate.dense.scale', 'model.encoder.layer.7.intermediate.dense.zero_point', 'model.encoder.layer.7.output.LayerNorm.bias', 'model.encoder.layer.7.output.LayerNorm.weight', 'model.encoder.layer.7.output.dense._packed_params._packed_params', 'model.encoder.layer.7.output.dense._packed_params.dtype', 'model.encoder.layer.7.output.dense.scale', 'model.encoder.layer.7.output.dense.zero_point', 'model.encoder.layer.8.attention.output.LayerNorm.bias', 'model.encoder.layer.8.attention.output.LayerNorm.weight', 'model.encoder.layer.8.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.8.attention.output.dense._packed_params.dtype', 'model.encoder.layer.8.attention.output.dense.scale', 'model.encoder.layer.8.attention.output.dense.zero_point', 'model.encoder.layer.8.attention.self.key._packed_params._packed_params', 'model.encoder.layer.8.attention.self.key._packed_params.dtype', 'model.encoder.layer.8.attention.self.key.scale', 'model.encoder.layer.8.attention.self.key.zero_point', 'model.encoder.layer.8.attention.self.query._packed_params._packed_params', 'model.encoder.layer.8.attention.self.query._packed_params.dtype', 'model.encoder.layer.8.attention.self.query.scale', 'model.encoder.layer.8.attention.self.query.zero_point', 'model.encoder.layer.8.attention.self.value._packed_params._packed_params', 'model.encoder.layer.8.attention.self.value._packed_params.dtype', 'model.encoder.layer.8.attention.self.value.scale', 'model.encoder.layer.8.attention.self.value.zero_point', 'model.encoder.layer.8.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.8.intermediate.dense._packed_params.dtype', 'model.encoder.layer.8.intermediate.dense.scale', 'model.encoder.layer.8.intermediate.dense.zero_point', 'model.encoder.layer.8.output.LayerNorm.bias', 'model.encoder.layer.8.output.LayerNorm.weight', 'model.encoder.layer.8.output.dense._packed_params._packed_params', 'model.encoder.layer.8.output.dense._packed_params.dtype', 'model.encoder.layer.8.output.dense.scale', 'model.encoder.layer.8.output.dense.zero_point', 'model.encoder.layer.9.attention.output.LayerNorm.bias', 'model.encoder.layer.9.attention.output.LayerNorm.weight', 'model.encoder.layer.9.attention.output.dense._packed_params._packed_params', 'model.encoder.layer.9.attention.output.dense._packed_params.dtype', 'model.encoder.layer.9.attention.output.dense.scale', 'model.encoder.layer.9.attention.output.dense.zero_point', 'model.encoder.layer.9.attention.self.key._packed_params._packed_params', 'model.encoder.layer.9.attention.self.key._packed_params.dtype', 'model.encoder.layer.9.attention.self.key.scale', 'model.encoder.layer.9.attention.self.key.zero_point', 'model.encoder.layer.9.attention.self.query._packed_params._packed_params', 'model.encoder.layer.9.attention.self.query._packed_params.dtype', 'model.encoder.layer.9.attention.self.query.scale', 'model.encoder.layer.9.attention.self.query.zero_point', 'model.encoder.layer.9.attention.self.value._packed_params._packed_params', 'model.encoder.layer.9.attention.self.value._packed_params.dtype', 'model.encoder.layer.9.attention.self.value.scale', 'model.encoder.layer.9.attention.self.value.zero_point', 'model.encoder.layer.9.intermediate.dense._packed_params._packed_params', 'model.encoder.layer.9.intermediate.dense._packed_params.dtype', 'model.encoder.layer.9.intermediate.dense.scale', 'model.encoder.layer.9.intermediate.dense.zero_point', 'model.encoder.layer.9.output.LayerNorm.bias', 'model.encoder.layer.9.output.LayerNorm.weight', 'model.encoder.layer.9.output.dense._packed_params._packed_params', 'model.encoder.layer.9.output.dense._packed_params.dtype', 'model.encoder.layer.9.output.dense.scale', 'model.encoder.layer.9.output.dense.zero_point', 'model.pooler.dense._packed_params._packed_params', 'model.pooler.dense._packed_params.dtype', 'model.pooler.dense.scale', 'model.pooler.dense.zero_point']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertModel were not initialized from the model checkpoint at elastic/multilingual-e5-small-optimized and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / elastic/multilingual-e5-small-optimized on GPU 0 in process Process-2
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  2.64it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.98it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:04,  3.66it/s]Batches:  11%|█         | 2/19 [00:01<00:14,  1.15it/s]Batches:  16%|█▌        | 3/19 [00:02<00:15,  1.05it/s]Batches:  21%|██        | 4/19 [00:03<00:13,  1.13it/s]Batches:  26%|██▋       | 5/19 [00:04<00:11,  1.25it/s]Batches:  32%|███▏      | 6/19 [00:04<00:09,  1.36it/s]Batches:  37%|███▋      | 7/19 [00:05<00:07,  1.51it/s]Batches:  42%|████▏     | 8/19 [00:05<00:06,  1.65it/s]Batches:  47%|████▋     | 9/19 [00:06<00:05,  1.79it/s]Batches:  53%|█████▎    | 10/19 [00:06<00:04,  1.92it/s]Batches:  58%|█████▊    | 11/19 [00:06<00:03,  2.12it/s]Batches:  63%|██████▎   | 12/19 [00:07<00:03,  2.29it/s]Batches:  68%|██████▊   | 13/19 [00:07<00:02,  2.47it/s]Batches:  74%|███████▎  | 14/19 [00:07<00:01,  2.66it/s]Batches:  79%|███████▉  | 15/19 [00:08<00:01,  2.90it/s]Batches:  84%|████████▍ | 16/19 [00:08<00:00,  3.21it/s]Batches:  89%|████████▉ | 17/19 [00:08<00:00,  3.49it/s]Batches:  95%|█████████▍| 18/19 [00:08<00:00,  3.95it/s]Batches: 100%|██████████| 19/19 [00:08<00:00,  4.51it/s]Batches: 100%|██████████| 19/19 [00:08<00:00,  2.12it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 9.97 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 10.58 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.04223, 'ndcg_at_3': 0.0435, 'ndcg_at_5': 0.05094, 'ndcg_at_10': 0.05747, 'ndcg_at_20': 0.06534, 'ndcg_at_100': 0.0908, 'ndcg_at_1000': 0.13319, 'map_at_1': 0.02252, 'map_at_3': 0.03435, 'map_at_5': 0.03818, 'map_at_10': 0.0406, 'map_at_20': 0.04265, 'map_at_100': 0.04591, 'map_at_1000': 0.04723, 'recall_at_1': 0.02252, 'recall_at_3': 0.04842, 'recall_at_5': 0.06475, 'recall_at_10': 0.08226, 'recall_at_20': 0.10831, 'recall_at_100': 0.23007, 'recall_at_1000': 0.53297, 'precision_at_1': 0.04223, 'precision_at_3': 0.02928, 'precision_at_5': 0.02264, 'precision_at_10': 0.01453, 'precision_at_20': 0.0098, 'precision_at_100': 0.0041, 'precision_at_1000': 0.00097, 'mrr_at_1': 0.04222972972972973, 'mrr_at_3': 0.05743243243243242, 'mrr_at_5': 0.0626689189189189, 'mrr_at_10': 0.06633285070785072, 'mrr_at_20': 0.06920823414631469, 'mrr_at_100': 0.07298338041929164, 'mrr_at_1000': 0.07419450768654146, 'nauc_ndcg_at_1_max': np.float64(0.17859825441414645), 'nauc_ndcg_at_1_std': np.float64(-0.10204154986659444), 'nauc_ndcg_at_1_diff1': np.float64(0.34298588244287764), 'nauc_ndcg_at_3_max': np.float64(0.08709659970452799), 'nauc_ndcg_at_3_std': np.float64(-0.0702390629780754), 'nauc_ndcg_at_3_diff1': np.float64(0.2260111377503708), 'nauc_ndcg_at_5_max': np.float64(0.07073798044636168), 'nauc_ndcg_at_5_std': np.float64(-0.06911021665219046), 'nauc_ndcg_at_5_diff1': np.float64(0.20179204907356324), 'nauc_ndcg_at_10_max': np.float64(0.05642487220956016), 'nauc_ndcg_at_10_std': np.float64(-0.06904780113974508), 'nauc_ndcg_at_10_diff1': np.float64(0.19322248270186151), 'nauc_ndcg_at_20_max': np.float64(0.061472546849634956), 'nauc_ndcg_at_20_std': np.float64(-0.08102423242514505), 'nauc_ndcg_at_20_diff1': np.float64(0.17306607367361918), 'nauc_ndcg_at_100_max': np.float64(0.05635959538173708), 'nauc_ndcg_at_100_std': np.float64(-0.08545394275269326), 'nauc_ndcg_at_100_diff1': np.float64(0.1247778863460825), 'nauc_ndcg_at_1000_max': np.float64(0.06894212975489013), 'nauc_ndcg_at_1000_std': np.float64(-0.0575292826159381), 'nauc_ndcg_at_1000_diff1': np.float64(0.10730212654049792), 'nauc_map_at_1_max': np.float64(0.17655243151879366), 'nauc_map_at_1_std': np.float64(-0.05777131676385387), 'nauc_map_at_1_diff1': np.float64(0.35535926946614765), 'nauc_map_at_3_max': np.float64(0.09135540199105666), 'nauc_map_at_3_std': np.float64(-0.06175089887454224), 'nauc_map_at_3_diff1': np.float64(0.26748406688783616), 'nauc_map_at_5_max': np.float64(0.0795631705626116), 'nauc_map_at_5_std': np.float64(-0.05876144460016381), 'nauc_map_at_5_diff1': np.float64(0.2498134251010857), 'nauc_map_at_10_max': np.float64(0.07417217403278889), 'nauc_map_at_10_std': np.float64(-0.05935839734295752), 'nauc_map_at_10_diff1': np.float64(0.24258060765008055), 'nauc_map_at_20_max': np.float64(0.076040233171815), 'nauc_map_at_20_std': np.float64(-0.0641264620618799), 'nauc_map_at_20_diff1': np.float64(0.23467455989174482), 'nauc_map_at_100_max': np.float64(0.07521974575222902), 'nauc_map_at_100_std': np.float64(-0.06729985602839476), 'nauc_map_at_100_diff1': np.float64(0.22162926407111985), 'nauc_map_at_1000_max': np.float64(0.07593137264484194), 'nauc_map_at_1000_std': np.float64(-0.06501388396451492), 'nauc_map_at_1000_diff1': np.float64(0.21911121649684312), 'nauc_recall_at_1_max': np.float64(0.17655243151879366), 'nauc_recall_at_1_std': np.float64(-0.05777131676385387), 'nauc_recall_at_1_diff1': np.float64(0.35535926946614765), 'nauc_recall_at_3_max': np.float64(0.05335421513773448), 'nauc_recall_at_3_std': np.float64(-0.06653774299225668), 'nauc_recall_at_3_diff1': np.float64(0.16756847767255034), 'nauc_recall_at_5_max': np.float64(0.028990392841908276), 'nauc_recall_at_5_std': np.float64(-0.06367882470075559), 'nauc_recall_at_5_diff1': np.float64(0.14322414815235351), 'nauc_recall_at_10_max': np.float64(0.004367438769360211), 'nauc_recall_at_10_std': np.float64(-0.0590875597249949), 'nauc_recall_at_10_diff1': np.float64(0.13848898082791203), 'nauc_recall_at_20_max': np.float64(0.02218821264070726), 'nauc_recall_at_20_std': np.float64(-0.08640729234246083), 'nauc_recall_at_20_diff1': np.float64(0.10493123052596652), 'nauc_recall_at_100_max': np.float64(0.015595720097276708), 'nauc_recall_at_100_std': np.float64(-0.08455198289479307), 'nauc_recall_at_100_diff1': np.float64(0.007070963645781479), 'nauc_recall_at_1000_max': np.float64(0.040361186070753445), 'nauc_recall_at_1000_std': np.float64(0.002567608529126118), 'nauc_recall_at_1000_diff1': np.float64(-0.035679148917279295), 'nauc_precision_at_1_max': np.float64(0.17859825441414645), 'nauc_precision_at_1_std': np.float64(-0.10204154986659444), 'nauc_precision_at_1_diff1': np.float64(0.34298588244287764), 'nauc_precision_at_3_max': np.float64(0.06806045805324822), 'nauc_precision_at_3_std': np.float64(-0.08514246409934081), 'nauc_precision_at_3_diff1': np.float64(0.18711987012477882), 'nauc_precision_at_5_max': np.float64(0.05647722174530148), 'nauc_precision_at_5_std': np.float64(-0.08848064063786044), 'nauc_precision_at_5_diff1': np.float64(0.15082898020224195), 'nauc_precision_at_10_max': np.float64(0.04265835420150357), 'nauc_precision_at_10_std': np.float64(-0.09721504731759395), 'nauc_precision_at_10_diff1': np.float64(0.14023777007513455), 'nauc_precision_at_20_max': np.float64(0.0602121745971497), 'nauc_precision_at_20_std': np.float64(-0.11663665847917616), 'nauc_precision_at_20_diff1': np.float64(0.10847304269085038), 'nauc_precision_at_100_max': np.float64(0.05270033915730794), 'nauc_precision_at_100_std': np.float64(-0.1122097812636336), 'nauc_precision_at_100_diff1': np.float64(0.04173121349276761), 'nauc_precision_at_1000_max': np.float64(0.1003465250515663), 'nauc_precision_at_1000_std': np.float64(-0.03978734845273682), 'nauc_precision_at_1000_diff1': np.float64(0.005258894893722139), 'nauc_mrr_at_1_max': np.float64(0.17859825441414645), 'nauc_mrr_at_1_std': np.float64(-0.10204154986659444), 'nauc_mrr_at_1_diff1': np.float64(0.34298588244287764), 'nauc_mrr_at_3_max': np.float64(0.12271802600516472), 'nauc_mrr_at_3_std': np.float64(-0.08905260359340003), 'nauc_mrr_at_3_diff1': np.float64(0.23334879238792702), 'nauc_mrr_at_5_max': np.float64(0.11153107968592617), 'nauc_mrr_at_5_std': np.float64(-0.09098308852844693), 'nauc_mrr_at_5_diff1': np.float64(0.21367761499055363), 'nauc_mrr_at_10_max': np.float64(0.0995710373537792), 'nauc_mrr_at_10_std': np.float64(-0.0898774010354607), 'nauc_mrr_at_10_diff1': np.float64(0.208147019006056), 'nauc_mrr_at_20_max': np.float64(0.09907748073135705), 'nauc_mrr_at_20_std': np.float64(-0.09306536608208546), 'nauc_mrr_at_20_diff1': np.float64(0.19952595239012358), 'nauc_mrr_at_100_max': np.float64(0.0989724881772174), 'nauc_mrr_at_100_std': np.float64(-0.09197711383509988), 'nauc_mrr_at_100_diff1': np.float64(0.1928848563858916), 'nauc_mrr_at_1000_max': np.float64(0.09957671060317173), 'nauc_mrr_at_1000_std': np.float64(-0.09104509682950397), 'nauc_mrr_at_1000_diff1': np.float64(0.1926068397532791), 'main_score': 0.05747}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 48.30it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.66it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.09 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 2.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.08772, 'ndcg_at_3': 0.12302, 'ndcg_at_5': 0.15208, 'ndcg_at_10': 0.18328, 'ndcg_at_20': 0.2141, 'ndcg_at_100': 0.2732, 'ndcg_at_1000': 0.30416, 'map_at_1': 0.08772, 'map_at_3': 0.11404, 'map_at_5': 0.13026, 'map_at_10': 0.14312, 'map_at_20': 0.15147, 'map_at_100': 0.15922, 'map_at_1000': 0.1605, 'recall_at_1': 0.08772, 'recall_at_3': 0.14912, 'recall_at_5': 0.2193, 'recall_at_10': 0.31579, 'recall_at_20': 0.4386, 'recall_at_100': 0.76316, 'recall_at_1000': 1.0, 'precision_at_1': 0.08772, 'precision_at_3': 0.04971, 'precision_at_5': 0.04386, 'precision_at_10': 0.03158, 'precision_at_20': 0.02193, 'precision_at_100': 0.00763, 'precision_at_1000': 0.001, 'mrr_at_1': 0.08771929824561403, 'mrr_at_3': 0.11403508771929824, 'mrr_at_5': 0.13026315789473683, 'mrr_at_10': 0.1431216931216931, 'mrr_at_20': 0.15146766002029158, 'mrr_at_100': 0.15922416215745547, 'mrr_at_1000': 0.1605022571493838, 'nauc_ndcg_at_1_max': np.float64(-0.032809471768709506), 'nauc_ndcg_at_1_std': np.float64(0.13197028873589112), 'nauc_ndcg_at_1_diff1': np.float64(0.22009807944589663), 'nauc_ndcg_at_3_max': np.float64(-0.03617263530082942), 'nauc_ndcg_at_3_std': np.float64(0.15043597496352099), 'nauc_ndcg_at_3_diff1': np.float64(0.14363379678373606), 'nauc_ndcg_at_5_max': np.float64(-0.003612139861348012), 'nauc_ndcg_at_5_std': np.float64(0.17438544986102325), 'nauc_ndcg_at_5_diff1': np.float64(0.07558635032373784), 'nauc_ndcg_at_10_max': np.float64(0.0503293147435786), 'nauc_ndcg_at_10_std': np.float64(0.21286066614662263), 'nauc_ndcg_at_10_diff1': np.float64(0.01693938571157342), 'nauc_ndcg_at_20_max': np.float64(0.03435421455814953), 'nauc_ndcg_at_20_std': np.float64(0.1687950697136731), 'nauc_ndcg_at_20_diff1': np.float64(0.015541782575847658), 'nauc_ndcg_at_100_max': np.float64(0.04678556941927005), 'nauc_ndcg_at_100_std': np.float64(0.18833134468918), 'nauc_ndcg_at_100_diff1': np.float64(0.00905692488790609), 'nauc_ndcg_at_1000_max': np.float64(0.01982959391068451), 'nauc_ndcg_at_1000_std': np.float64(0.1780312131950111), 'nauc_ndcg_at_1000_diff1': np.float64(0.03468999837363311), 'nauc_map_at_1_max': np.float64(-0.032809471768709506), 'nauc_map_at_1_std': np.float64(0.13197028873589112), 'nauc_map_at_1_diff1': np.float64(0.22009807944589663), 'nauc_map_at_3_max': np.float64(-0.03563060999784739), 'nauc_map_at_3_std': np.float64(0.15344061618168295), 'nauc_map_at_3_diff1': np.float64(0.1609844010775931), 'nauc_map_at_5_max': np.float64(-0.013802962792312115), 'nauc_map_at_5_std': np.float64(0.17118297027863863), 'nauc_map_at_5_diff1': np.float64(0.11562083373487374), 'nauc_map_at_10_max': np.float64(0.01014506746304342), 'nauc_map_at_10_std': np.float64(0.18716107630221537), 'nauc_map_at_10_diff1': np.float64(0.08523941746249758), 'nauc_map_at_20_max': np.float64(0.006567884342914243), 'nauc_map_at_20_std': np.float64(0.17489551874125048), 'nauc_map_at_20_diff1': np.float64(0.08175641557138585), 'nauc_map_at_100_max': np.float64(0.006913870976782461), 'nauc_map_at_100_std': np.float64(0.17707356471483013), 'nauc_map_at_100_diff1': np.float64(0.08044482724565385), 'nauc_map_at_1000_max': np.float64(0.0049974872393325764), 'nauc_map_at_1000_std': np.float64(0.17617834757571374), 'nauc_map_at_1000_diff1': np.float64(0.08096699357746838), 'nauc_recall_at_1_max': np.float64(-0.032809471768709506), 'nauc_recall_at_1_std': np.float64(0.13197028873589112), 'nauc_recall_at_1_diff1': np.float64(0.22009807944589663), 'nauc_recall_at_3_max': np.float64(-0.03740227504308547), 'nauc_recall_at_3_std': np.float64(0.14114197958535288), 'nauc_recall_at_3_diff1': np.float64(0.10218951490138047), 'nauc_recall_at_5_max': np.float64(0.018019414115933354), 'nauc_recall_at_5_std': np.float64(0.17853454983399572), 'nauc_recall_at_5_diff1': np.float64(-0.008270728591581138), 'nauc_recall_at_10_max': np.float64(0.13823991543760364), 'nauc_recall_at_10_std': np.float64(0.2688817366739239), 'nauc_recall_at_10_diff1': np.float64(-0.11964676224941552), 'nauc_recall_at_20_max': np.float64(0.08604278474282522), 'nauc_recall_at_20_std': np.float64(0.13997425509410538), 'nauc_recall_at_20_diff1': np.float64(-0.10695022976993884), 'nauc_recall_at_100_max': np.float64(0.2036432770255055), 'nauc_recall_at_100_std': np.float64(0.23989521355270807), 'nauc_recall_at_100_diff1': np.float64(-0.20600933381874464), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(-0.032809471768709506), 'nauc_precision_at_1_std': np.float64(0.13197028873589112), 'nauc_precision_at_1_diff1': np.float64(0.22009807944589663), 'nauc_precision_at_3_max': np.float64(-0.037402275043085305), 'nauc_precision_at_3_std': np.float64(0.14114197958535296), 'nauc_precision_at_3_diff1': np.float64(0.10218951490138048), 'nauc_precision_at_5_max': np.float64(0.01801941411593332), 'nauc_precision_at_5_std': np.float64(0.1785345498339956), 'nauc_precision_at_5_diff1': np.float64(-0.008270728591581051), 'nauc_precision_at_10_max': np.float64(0.13823991543760344), 'nauc_precision_at_10_std': np.float64(0.26888173667392373), 'nauc_precision_at_10_diff1': np.float64(-0.11964676224941573), 'nauc_precision_at_20_max': np.float64(0.08604278474282584), 'nauc_precision_at_20_std': np.float64(0.13997425509410577), 'nauc_precision_at_20_diff1': np.float64(-0.10695022976993826), 'nauc_precision_at_100_max': np.float64(0.20364327702550597), 'nauc_precision_at_100_std': np.float64(0.2398952135527093), 'nauc_precision_at_100_diff1': np.float64(-0.20600933381874412), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(-0.032809471768709506), 'nauc_mrr_at_1_std': np.float64(0.13197028873589112), 'nauc_mrr_at_1_diff1': np.float64(0.22009807944589663), 'nauc_mrr_at_3_max': np.float64(-0.03563060999784739), 'nauc_mrr_at_3_std': np.float64(0.15344061618168295), 'nauc_mrr_at_3_diff1': np.float64(0.1609844010775931), 'nauc_mrr_at_5_max': np.float64(-0.013802962792312115), 'nauc_mrr_at_5_std': np.float64(0.17118297027863863), 'nauc_mrr_at_5_diff1': np.float64(0.11562083373487374), 'nauc_mrr_at_10_max': np.float64(0.01014506746304342), 'nauc_mrr_at_10_std': np.float64(0.18716107630221537), 'nauc_mrr_at_10_diff1': np.float64(0.08523941746249758), 'nauc_mrr_at_20_max': np.float64(0.006567884342914243), 'nauc_mrr_at_20_std': np.float64(0.17489551874125048), 'nauc_mrr_at_20_diff1': np.float64(0.08175641557138585), 'nauc_mrr_at_100_max': np.float64(0.006913870976782461), 'nauc_mrr_at_100_std': np.float64(0.17707356471483013), 'nauc_mrr_at_100_diff1': np.float64(0.08044482724565385), 'nauc_mrr_at_1000_max': np.float64(0.004998495968313456), 'nauc_mrr_at_1000_std': np.float64(0.17617831616425766), 'nauc_mrr_at_1000_diff1': np.float64(0.0809663510341503), 'main_score': 0.18328}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 32.05it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.32 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.15584, 'ndcg_at_3': 0.2064, 'ndcg_at_5': 0.24384, 'ndcg_at_10': 0.29936, 'ndcg_at_20': 0.35024, 'ndcg_at_100': 0.40591, 'ndcg_at_1000': 0.40591, 'map_at_1': 0.15584, 'map_at_3': 0.19264, 'map_at_5': 0.21342, 'map_at_10': 0.23684, 'map_at_20': 0.25169, 'map_at_100': 0.25938, 'map_at_1000': 0.25938, 'recall_at_1': 0.15584, 'recall_at_3': 0.24675, 'recall_at_5': 0.33766, 'recall_at_10': 0.50649, 'recall_at_20': 0.7013, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.15584, 'precision_at_3': 0.08225, 'precision_at_5': 0.06753, 'precision_at_10': 0.05065, 'precision_at_20': 0.03506, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.15584415584415584, 'mrr_at_3': 0.19264069264069264, 'mrr_at_5': 0.21341991341991343, 'mrr_at_10': 0.2368429189857761, 'mrr_at_20': 0.25168955560274764, 'mrr_at_100': 0.25938384710324747, 'mrr_at_1000': 0.25938384710324747, 'nauc_ndcg_at_1_max': np.float64(-0.026240791050421344), 'nauc_ndcg_at_1_std': np.float64(0.25614468155760095), 'nauc_ndcg_at_1_diff1': np.float64(0.5808027083243883), 'nauc_ndcg_at_3_max': np.float64(-0.033748541543781284), 'nauc_ndcg_at_3_std': np.float64(0.2615047638819212), 'nauc_ndcg_at_3_diff1': np.float64(0.49583335096601355), 'nauc_ndcg_at_5_max': np.float64(-0.0225914778504786), 'nauc_ndcg_at_5_std': np.float64(0.20335602928986118), 'nauc_ndcg_at_5_diff1': np.float64(0.443204459586375), 'nauc_ndcg_at_10_max': np.float64(-0.01546571037812267), 'nauc_ndcg_at_10_std': np.float64(0.21573039881203915), 'nauc_ndcg_at_10_diff1': np.float64(0.43967319592850634), 'nauc_ndcg_at_20_max': np.float64(0.06113451368141311), 'nauc_ndcg_at_20_std': np.float64(0.21498225638815668), 'nauc_ndcg_at_20_diff1': np.float64(0.4586721548375412), 'nauc_ndcg_at_100_max': np.float64(0.012389143916950434), 'nauc_ndcg_at_100_std': np.float64(0.2223798218888861), 'nauc_ndcg_at_100_diff1': np.float64(0.48558635790415006), 'nauc_ndcg_at_1000_max': np.float64(0.012389143916950434), 'nauc_ndcg_at_1000_std': np.float64(0.2223798218888861), 'nauc_ndcg_at_1000_diff1': np.float64(0.48558635790415006), 'nauc_map_at_1_max': np.float64(-0.026240791050421344), 'nauc_map_at_1_std': np.float64(0.25614468155760095), 'nauc_map_at_1_diff1': np.float64(0.5808027083243883), 'nauc_map_at_3_max': np.float64(-0.027261085375413382), 'nauc_map_at_3_std': np.float64(0.2615515556728077), 'nauc_map_at_3_diff1': np.float64(0.5179228360833111), 'nauc_map_at_5_max': np.float64(-0.02129395367651818), 'nauc_map_at_5_std': np.float64(0.22748783731645733), 'nauc_map_at_5_diff1': np.float64(0.48835829636629313), 'nauc_map_at_10_max': np.float64(-0.020772898453846556), 'nauc_map_at_10_std': np.float64(0.2354011358573723), 'nauc_map_at_10_diff1': np.float64(0.487732741005292), 'nauc_map_at_20_max': np.float64(0.0022063720338431716), 'nauc_map_at_20_std': np.float64(0.23428555529980008), 'nauc_map_at_20_diff1': np.float64(0.4943852004442868), 'nauc_map_at_100_max': np.float64(-0.0029881455947029082), 'nauc_map_at_100_std': np.float64(0.23375230015959428), 'nauc_map_at_100_diff1': np.float64(0.49989752213372024), 'nauc_map_at_1000_max': np.float64(-0.0029881455947029082), 'nauc_map_at_1000_std': np.float64(0.23375230015959428), 'nauc_map_at_1000_diff1': np.float64(0.49989752213372024), 'nauc_recall_at_1_max': np.float64(-0.026240791050421344), 'nauc_recall_at_1_std': np.float64(0.25614468155760095), 'nauc_recall_at_1_diff1': np.float64(0.5808027083243883), 'nauc_recall_at_3_max': np.float64(-0.051716698556389946), 'nauc_recall_at_3_std': np.float64(0.2609635032229946), 'nauc_recall_at_3_diff1': np.float64(0.43916944185020657), 'nauc_recall_at_5_max': np.float64(-0.025460823594098302), 'nauc_recall_at_5_std': np.float64(0.1401173126734485), 'nauc_recall_at_5_diff1': np.float64(0.3290581734956122), 'nauc_recall_at_10_max': np.float64(0.0038666253129315854), 'nauc_recall_at_10_std': np.float64(0.16231547894893505), 'nauc_recall_at_10_diff1': np.float64(0.3149249207251562), 'nauc_recall_at_20_max': np.float64(0.3170715858340734), 'nauc_recall_at_20_std': np.float64(0.15134201886014043), 'nauc_recall_at_20_diff1': np.float64(0.34948038079089583), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(-0.026240791050421344), 'nauc_precision_at_1_std': np.float64(0.25614468155760095), 'nauc_precision_at_1_diff1': np.float64(0.5808027083243883), 'nauc_precision_at_3_max': np.float64(-0.05171669855638981), 'nauc_precision_at_3_std': np.float64(0.2609635032229948), 'nauc_precision_at_3_diff1': np.float64(0.43916944185020673), 'nauc_precision_at_5_max': np.float64(-0.025460823594098382), 'nauc_precision_at_5_std': np.float64(0.1401173126734485), 'nauc_precision_at_5_diff1': np.float64(0.3290581734956119), 'nauc_precision_at_10_max': np.float64(0.003866625312931396), 'nauc_precision_at_10_std': np.float64(0.1623154789489347), 'nauc_precision_at_10_diff1': np.float64(0.31492492072515615), 'nauc_precision_at_20_max': np.float64(0.31707158583407413), 'nauc_precision_at_20_std': np.float64(0.1513420188601414), 'nauc_precision_at_20_diff1': np.float64(0.349480380790897), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(-0.026240791050421344), 'nauc_mrr_at_1_std': np.float64(0.25614468155760095), 'nauc_mrr_at_1_diff1': np.float64(0.5808027083243883), 'nauc_mrr_at_3_max': np.float64(-0.027261085375413382), 'nauc_mrr_at_3_std': np.float64(0.2615515556728077), 'nauc_mrr_at_3_diff1': np.float64(0.5179228360833111), 'nauc_mrr_at_5_max': np.float64(-0.02129395367651818), 'nauc_mrr_at_5_std': np.float64(0.22748783731645733), 'nauc_mrr_at_5_diff1': np.float64(0.48835829636629313), 'nauc_mrr_at_10_max': np.float64(-0.020772898453846556), 'nauc_mrr_at_10_std': np.float64(0.2354011358573723), 'nauc_mrr_at_10_diff1': np.float64(0.487732741005292), 'nauc_mrr_at_20_max': np.float64(0.0022063720338431716), 'nauc_mrr_at_20_std': np.float64(0.23428555529980008), 'nauc_mrr_at_20_diff1': np.float64(0.4943852004442868), 'nauc_mrr_at_100_max': np.float64(-0.0029881455947029082), 'nauc_mrr_at_100_std': np.float64(0.23375230015959428), 'nauc_mrr_at_100_diff1': np.float64(0.49989752213372024), 'nauc_mrr_at_1000_max': np.float64(-0.0029881455947029082), 'nauc_mrr_at_1000_std': np.float64(0.23375230015959428), 'nauc_mrr_at_1000_diff1': np.float64(0.49989752213372024), 'main_score': 0.29936}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 17.44it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 17.32it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.33 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 18.06it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 17.90it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.30 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 18.01it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 17.88it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.29 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 5.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.12, 'ndcg_at_3': 0.15898, 'ndcg_at_5': 0.17548, 'ndcg_at_10': 0.20243, 'ndcg_at_20': 0.2235, 'ndcg_at_100': 0.27266, 'ndcg_at_1000': 0.31594, 'map_at_1': 0.12, 'map_at_3': 0.14907, 'map_at_5': 0.15824, 'map_at_10': 0.16957, 'map_at_20': 0.17536, 'map_at_100': 0.18185, 'map_at_1000': 0.1835, 'recall_at_1': 0.12, 'recall_at_3': 0.18778, 'recall_at_5': 0.22778, 'recall_at_10': 0.31, 'recall_at_20': 0.39333, 'recall_at_100': 0.66333, 'recall_at_1000': 1.0, 'precision_at_1': 0.12, 'precision_at_3': 0.06259, 'precision_at_5': 0.04556, 'precision_at_10': 0.031, 'precision_at_20': 0.01967, 'precision_at_100': 0.00663, 'precision_at_1000': 0.001, 'mrr_at_1': 0.12, 'mrr_at_3': 0.14907407407407403, 'mrr_at_5': 0.15824074074074074, 'mrr_at_10': 0.1695727513227513, 'mrr_at_20': 0.17536215334086858, 'mrr_at_100': 0.1818492251994634, 'mrr_at_1000': 0.18350349514700048, 'nauc_ndcg_at_1_max': np.float64(0.21581156077886252), 'nauc_ndcg_at_1_std': np.float64(-0.02633504986362536), 'nauc_ndcg_at_1_diff1': np.float64(0.3766283343337651), 'nauc_ndcg_at_3_max': np.float64(0.2080974538020496), 'nauc_ndcg_at_3_std': np.float64(-0.0036909785785852003), 'nauc_ndcg_at_3_diff1': np.float64(0.2853369976582991), 'nauc_ndcg_at_5_max': np.float64(0.20815704908639035), 'nauc_ndcg_at_5_std': np.float64(0.0025343236556675725), 'nauc_ndcg_at_5_diff1': np.float64(0.26077085281658463), 'nauc_ndcg_at_10_max': np.float64(0.21139990184622282), 'nauc_ndcg_at_10_std': np.float64(3.942564042621245e-06), 'nauc_ndcg_at_10_diff1': np.float64(0.2432039793212003), 'nauc_ndcg_at_20_max': np.float64(0.19603381464025948), 'nauc_ndcg_at_20_std': np.float64(-0.00760298408440502), 'nauc_ndcg_at_20_diff1': np.float64(0.23211597117861324), 'nauc_ndcg_at_100_max': np.float64(0.1732842253815971), 'nauc_ndcg_at_100_std': np.float64(0.004664344609429712), 'nauc_ndcg_at_100_diff1': np.float64(0.22530702268952885), 'nauc_ndcg_at_1000_max': np.float64(0.19246965934821064), 'nauc_ndcg_at_1000_std': np.float64(-0.0020938641908639236), 'nauc_ndcg_at_1000_diff1': np.float64(0.24911813824646917), 'nauc_map_at_1_max': np.float64(0.21581156077886252), 'nauc_map_at_1_std': np.float64(-0.02633504986362536), 'nauc_map_at_1_diff1': np.float64(0.3766283343337651), 'nauc_map_at_3_max': np.float64(0.2097050820695825), 'nauc_map_at_3_std': np.float64(-0.009529560239054633), 'nauc_map_at_3_diff1': np.float64(0.30418720828403023), 'nauc_map_at_5_max': np.float64(0.21010640650645668), 'nauc_map_at_5_std': np.float64(-0.005870059811680362), 'nauc_map_at_5_diff1': np.float64(0.2886165588743412), 'nauc_map_at_10_max': np.float64(0.21089940562218382), 'nauc_map_at_10_std': np.float64(-0.007482193853241788), 'nauc_map_at_10_diff1': np.float64(0.2797666687712872), 'nauc_map_at_20_max': np.float64(0.2060383304058084), 'nauc_map_at_20_std': np.float64(-0.00986210236655964), 'nauc_map_at_20_diff1': np.float64(0.275868203930548), 'nauc_map_at_100_max': np.float64(0.202165388951675), 'nauc_map_at_100_std': np.float64(-0.00797566856136865), 'nauc_map_at_100_diff1': np.float64(0.2749098014831328), 'nauc_map_at_1000_max': np.float64(0.20298865795344886), 'nauc_map_at_1000_std': np.float64(-0.008073881289863775), 'nauc_map_at_1000_diff1': np.float64(0.27594735818708194), 'nauc_recall_at_1_max': np.float64(0.21581156077886252), 'nauc_recall_at_1_std': np.float64(-0.02633504986362536), 'nauc_recall_at_1_diff1': np.float64(0.3766283343337651), 'nauc_recall_at_3_max': np.float64(0.2042038531234739), 'nauc_recall_at_3_std': np.float64(0.010833020630823191), 'nauc_recall_at_3_diff1': np.float64(0.23974257197971824), 'nauc_recall_at_5_max': np.float64(0.2033711402486238), 'nauc_recall_at_5_std': np.float64(0.02270797348694352), 'nauc_recall_at_5_diff1': np.float64(0.19578139491350924), 'nauc_recall_at_10_max': np.float64(0.2141163711003848), 'nauc_recall_at_10_std': np.float64(0.01661355885107835), 'nauc_recall_at_10_diff1': np.float64(0.16238144109663522), 'nauc_recall_at_20_max': np.float64(0.16909736870047873), 'nauc_recall_at_20_std': np.float64(-0.006175762428291362), 'nauc_recall_at_20_diff1': np.float64(0.13449501950014206), 'nauc_recall_at_100_max': np.float64(0.05531952015828918), 'nauc_recall_at_100_std': np.float64(0.055029966905548004), 'nauc_recall_at_100_diff1': np.float64(0.07645876371897764), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.21581156077886252), 'nauc_precision_at_1_std': np.float64(-0.02633504986362536), 'nauc_precision_at_1_diff1': np.float64(0.3766283343337651), 'nauc_precision_at_3_max': np.float64(0.20420385312347386), 'nauc_precision_at_3_std': np.float64(0.01083302063082313), 'nauc_precision_at_3_diff1': np.float64(0.23974257197971804), 'nauc_precision_at_5_max': np.float64(0.2033711402486237), 'nauc_precision_at_5_std': np.float64(0.02270797348694353), 'nauc_precision_at_5_diff1': np.float64(0.19578139491350932), 'nauc_precision_at_10_max': np.float64(0.2141163711003849), 'nauc_precision_at_10_std': np.float64(0.016613558851078652), 'nauc_precision_at_10_diff1': np.float64(0.16238144109663535), 'nauc_precision_at_20_max': np.float64(0.16909736870047817), 'nauc_precision_at_20_std': np.float64(-0.00617576242829159), 'nauc_precision_at_20_diff1': np.float64(0.13449501950014184), 'nauc_precision_at_100_max': np.float64(0.05531952015828994), 'nauc_precision_at_100_std': np.float64(0.055029966905549114), 'nauc_precision_at_100_diff1': np.float64(0.076458763718978), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.21581156077886252), 'nauc_mrr_at_1_std': np.float64(-0.02633504986362536), 'nauc_mrr_at_1_diff1': np.float64(0.3766283343337651), 'nauc_mrr_at_3_max': np.float64(0.2097050820695825), 'nauc_mrr_at_3_std': np.float64(-0.009529560239054633), 'nauc_mrr_at_3_diff1': np.float64(0.30418720828403023), 'nauc_mrr_at_5_max': np.float64(0.21010640650645668), 'nauc_mrr_at_5_std': np.float64(-0.005870059811680362), 'nauc_mrr_at_5_diff1': np.float64(0.2886165588743412), 'nauc_mrr_at_10_max': np.float64(0.21089940562218382), 'nauc_mrr_at_10_std': np.float64(-0.007482193853241788), 'nauc_mrr_at_10_diff1': np.float64(0.2797666687712872), 'nauc_mrr_at_20_max': np.float64(0.2060383304058084), 'nauc_mrr_at_20_std': np.float64(-0.00986210236655964), 'nauc_mrr_at_20_diff1': np.float64(0.275868203930548), 'nauc_mrr_at_100_max': np.float64(0.202165388951675), 'nauc_mrr_at_100_std': np.float64(-0.00797566856136865), 'nauc_mrr_at_100_diff1': np.float64(0.2749098014831328), 'nauc_mrr_at_1000_max': np.float64(0.20298865795344886), 'nauc_mrr_at_1000_std': np.float64(-0.008073881289863775), 'nauc_mrr_at_1000_diff1': np.float64(0.27594735818708194), 'main_score': 0.20243}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.00111, 'ndcg_at_3': 0.00433, 'ndcg_at_5': 0.00614, 'ndcg_at_10': 0.00927, 'ndcg_at_20': 0.01511, 'ndcg_at_100': 0.04417, 'ndcg_at_1000': 0.14268, 'map_at_1': 0.00111, 'map_at_3': 0.00352, 'map_at_5': 0.00452, 'map_at_10': 0.00575, 'map_at_20': 0.00731, 'map_at_100': 0.01082, 'map_at_1000': 0.01407, 'recall_at_1': 0.00111, 'recall_at_3': 0.00667, 'recall_at_5': 0.01111, 'recall_at_10': 0.02111, 'recall_at_20': 0.04444, 'recall_at_100': 0.20889, 'recall_at_1000': 1.0, 'precision_at_1': 0.00111, 'precision_at_3': 0.00222, 'precision_at_5': 0.00222, 'precision_at_10': 0.00211, 'precision_at_20': 0.00222, 'precision_at_100': 0.00209, 'precision_at_1000': 0.001, 'mrr_at_1': 0.0011111111111111111, 'mrr_at_3': 0.0035185185185185185, 'mrr_at_5': 0.004518518518518518, 'mrr_at_10': 0.005746031746031746, 'mrr_at_20': 0.007313670147648473, 'mrr_at_100': 0.010824783573544643, 'mrr_at_1000': 0.014074218111914909, 'nauc_ndcg_at_1_max': np.float64(1.0), 'nauc_ndcg_at_1_std': np.float64(0.3238529648510867), 'nauc_ndcg_at_1_diff1': np.float64(-0.07056613898577946), 'nauc_ndcg_at_3_max': np.float64(0.3557350542838024), 'nauc_ndcg_at_3_std': np.float64(0.06090833669948216), 'nauc_ndcg_at_3_diff1': np.float64(-0.052017274937506124), 'nauc_ndcg_at_5_max': np.float64(0.2508617451175651), 'nauc_ndcg_at_5_std': np.float64(0.02054018473078683), 'nauc_ndcg_at_5_diff1': np.float64(0.012155930069203926), 'nauc_ndcg_at_10_max': np.float64(0.21224622685299369), 'nauc_ndcg_at_10_std': np.float64(0.00870617720321037), 'nauc_ndcg_at_10_diff1': np.float64(0.014740857598014611), 'nauc_ndcg_at_20_max': np.float64(0.13117084426492462), 'nauc_ndcg_at_20_std': np.float64(0.022873258804591956), 'nauc_ndcg_at_20_diff1': np.float64(-0.009338403314547944), 'nauc_ndcg_at_100_max': np.float64(0.036151435950626754), 'nauc_ndcg_at_100_std': np.float64(-0.003502963574510636), 'nauc_ndcg_at_100_diff1': np.float64(0.0021121416694797426), 'nauc_ndcg_at_1000_max': np.float64(0.07974561181144546), 'nauc_ndcg_at_1000_std': np.float64(-0.009199621965092492), 'nauc_ndcg_at_1000_diff1': np.float64(-0.0033616500124682377), 'nauc_map_at_1_max': np.float64(1.0), 'nauc_map_at_1_std': np.float64(0.3238529648510867), 'nauc_map_at_1_diff1': np.float64(-0.07056613898577946), 'nauc_map_at_3_max': np.float64(0.40364057447078916), 'nauc_map_at_3_std': np.float64(0.0823718808693319), 'nauc_map_at_3_diff1': np.float64(-0.057644782737632905), 'nauc_map_at_5_max': np.float64(0.31564634677387443), 'nauc_map_at_5_std': np.float64(0.04293326940755767), 'nauc_map_at_5_diff1': np.float64(-0.008942277663659418), 'nauc_map_at_10_max': np.float64(0.27655896620203674), 'nauc_map_at_10_std': np.float64(0.03361723543442143), 'nauc_map_at_10_diff1': np.float64(-0.009469497633366629), 'nauc_map_at_20_max': np.float64(0.22156837923014455), 'nauc_map_at_20_std': np.float64(0.0385282573880931), 'nauc_map_at_20_diff1': np.float64(-0.022068909030274673), 'nauc_map_at_100_max': np.float64(0.15868136929578366), 'nauc_map_at_100_std': np.float64(0.025836643299620446), 'nauc_map_at_100_diff1': np.float64(-0.014024344541365941), 'nauc_map_at_1000_max': np.float64(0.1616170625873096), 'nauc_map_at_1000_std': np.float64(0.020390058624775092), 'nauc_map_at_1000_diff1': np.float64(-0.013920194217552459), 'nauc_recall_at_1_max': np.float64(1.0), 'nauc_recall_at_1_std': np.float64(0.3238529648510867), 'nauc_recall_at_1_diff1': np.float64(-0.07056613898577946), 'nauc_recall_at_3_max': np.float64(0.28302477417046773), 'nauc_recall_at_3_std': np.float64(0.027904480815669475), 'nauc_recall_at_3_diff1': np.float64(-0.04252750201234235), 'nauc_recall_at_5_max': np.float64(0.16847330292460433), 'nauc_recall_at_5_std': np.float64(-0.005929702173329711), 'nauc_recall_at_5_diff1': np.float64(0.041400590287094266), 'nauc_recall_at_10_max': np.float64(0.15422309462951722), 'nauc_recall_at_10_std': np.float64(-0.014517108440540615), 'nauc_recall_at_10_diff1': np.float64(0.04130597489161603), 'nauc_recall_at_20_max': np.float64(0.06975449423128524), 'nauc_recall_at_20_std': np.float64(0.013952240407834845), 'nauc_recall_at_20_diff1': np.float64(0.0001341561577675402), 'nauc_recall_at_100_max': np.float64(-0.009079271260200864), 'nauc_recall_at_100_std': np.float64(-0.015448338611501118), 'nauc_recall_at_100_diff1': np.float64(0.0074570281917632035), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(1.0), 'nauc_precision_at_1_std': np.float64(0.3238529648510867), 'nauc_precision_at_1_diff1': np.float64(-0.07056613898577946), 'nauc_precision_at_3_max': np.float64(0.2830247741704679), 'nauc_precision_at_3_std': np.float64(0.02790448081566961), 'nauc_precision_at_3_diff1': np.float64(-0.04252750201234225), 'nauc_precision_at_5_max': np.float64(0.16847330292460416), 'nauc_precision_at_5_std': np.float64(-0.005929702173329658), 'nauc_precision_at_5_diff1': np.float64(0.04140059028709426), 'nauc_precision_at_10_max': np.float64(0.15422309462951714), 'nauc_precision_at_10_std': np.float64(-0.014517108440540624), 'nauc_precision_at_10_diff1': np.float64(0.04130597489161599), 'nauc_precision_at_20_max': np.float64(0.0697544942312852), 'nauc_precision_at_20_std': np.float64(0.013952240407834738), 'nauc_precision_at_20_diff1': np.float64(0.00013415615776767216), 'nauc_precision_at_100_max': np.float64(-0.009079271260200668), 'nauc_precision_at_100_std': np.float64(-0.01544833861150086), 'nauc_precision_at_100_diff1': np.float64(0.00745702819176332), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(1.0), 'nauc_mrr_at_1_std': np.float64(0.3238529648510867), 'nauc_mrr_at_1_diff1': np.float64(-0.07056613898577946), 'nauc_mrr_at_3_max': np.float64(0.40364057447078916), 'nauc_mrr_at_3_std': np.float64(0.0823718808693319), 'nauc_mrr_at_3_diff1': np.float64(-0.057644782737632905), 'nauc_mrr_at_5_max': np.float64(0.31564634677387443), 'nauc_mrr_at_5_std': np.float64(0.04293326940755767), 'nauc_mrr_at_5_diff1': np.float64(-0.008942277663659418), 'nauc_mrr_at_10_max': np.float64(0.27655896620203674), 'nauc_mrr_at_10_std': np.float64(0.03361723543442143), 'nauc_mrr_at_10_diff1': np.float64(-0.009469497633366629), 'nauc_mrr_at_20_max': np.float64(0.22156837923014455), 'nauc_mrr_at_20_std': np.float64(0.0385282573880931), 'nauc_mrr_at_20_diff1': np.float64(-0.022068909030274673), 'nauc_mrr_at_100_max': np.float64(0.15868136929578366), 'nauc_mrr_at_100_std': np.float64(0.025836643299620446), 'nauc_mrr_at_100_diff1': np.float64(-0.014024344541365941), 'nauc_mrr_at_1000_max': np.float64(0.1616170625873096), 'nauc_mrr_at_1000_std': np.float64(0.020390058624775092), 'nauc_mrr_at_1000_diff1': np.float64(-0.013920194217552459), 'main_score': 0.00927}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.00556, 'ndcg_at_3': 0.00807, 'ndcg_at_5': 0.01032, 'ndcg_at_10': 0.01494, 'ndcg_at_20': 0.02074, 'ndcg_at_100': 0.05036, 'ndcg_at_1000': 0.14672, 'map_at_1': 0.00556, 'map_at_3': 0.00741, 'map_at_5': 0.00863, 'map_at_10': 0.01051, 'map_at_20': 0.01205, 'map_at_100': 0.01545, 'map_at_1000': 0.01856, 'recall_at_1': 0.00556, 'recall_at_3': 0.01, 'recall_at_5': 0.01556, 'recall_at_10': 0.03, 'recall_at_20': 0.05333, 'recall_at_100': 0.22333, 'recall_at_1000': 1.0, 'precision_at_1': 0.00556, 'precision_at_3': 0.00333, 'precision_at_5': 0.00311, 'precision_at_10': 0.003, 'precision_at_20': 0.00267, 'precision_at_100': 0.00223, 'precision_at_1000': 0.001, 'mrr_at_1': 0.005555555555555556, 'mrr_at_3': 0.007407407407407407, 'mrr_at_5': 0.008629629629629631, 'mrr_at_10': 0.010508818342151673, 'mrr_at_20': 0.012050270554656519, 'mrr_at_100': 0.015453258219061754, 'mrr_at_1000': 0.01856481536571736, 'nauc_ndcg_at_1_max': np.float64(-0.36120203917359817), 'nauc_ndcg_at_1_std': np.float64(-0.035792862892406754), 'nauc_ndcg_at_1_diff1': np.float64(-0.10957874966460951), 'nauc_ndcg_at_3_max': np.float64(-0.2459041384306037), 'nauc_ndcg_at_3_std': np.float64(0.0352874162483711), 'nauc_ndcg_at_3_diff1': np.float64(-0.14775094152481344), 'nauc_ndcg_at_5_max': np.float64(-0.16830715404944702), 'nauc_ndcg_at_5_std': np.float64(0.07532603565386704), 'nauc_ndcg_at_5_diff1': np.float64(-0.16667524263377206), 'nauc_ndcg_at_10_max': np.float64(-0.14087981632884666), 'nauc_ndcg_at_10_std': np.float64(0.08558467294718798), 'nauc_ndcg_at_10_diff1': np.float64(-0.10528917900303014), 'nauc_ndcg_at_20_max': np.float64(-0.10004718944487799), 'nauc_ndcg_at_20_std': np.float64(0.10811205517057201), 'nauc_ndcg_at_20_diff1': np.float64(-0.06911988696655741), 'nauc_ndcg_at_100_max': np.float64(-0.05645668308921501), 'nauc_ndcg_at_100_std': np.float64(0.01449745244458282), 'nauc_ndcg_at_100_diff1': np.float64(-0.04763699720172144), 'nauc_ndcg_at_1000_max': np.float64(-0.078187585897887), 'nauc_ndcg_at_1000_std': np.float64(0.02962892872260407), 'nauc_ndcg_at_1000_diff1': np.float64(-0.05829625802109176), 'nauc_map_at_1_max': np.float64(-0.36120203917359817), 'nauc_map_at_1_std': np.float64(-0.035792862892406754), 'nauc_map_at_1_diff1': np.float64(-0.10957874966460951), 'nauc_map_at_3_max': np.float64(-0.26854038100348804), 'nauc_map_at_3_std': np.float64(0.017715320633217013), 'nauc_map_at_3_diff1': np.float64(-0.13596726589750466), 'nauc_map_at_5_max': np.float64(-0.21416274466225463), 'nauc_map_at_5_std': np.float64(0.04437747512353308), 'nauc_map_at_5_diff1': np.float64(-0.15087328173599218), 'nauc_map_at_10_max': np.float64(-0.19130150250618838), 'nauc_map_at_10_std': np.float64(0.053499588953277756), 'nauc_map_at_10_diff1': np.float64(-0.11806337407656343), 'nauc_map_at_20_max': np.float64(-0.16788309437798737), 'nauc_map_at_20_std': np.float64(0.07170762246168892), 'nauc_map_at_20_diff1': np.float64(-0.10309182866075349), 'nauc_map_at_100_max': np.float64(-0.1432441865504517), 'nauc_map_at_100_std': np.float64(0.046197355958896305), 'nauc_map_at_100_diff1': np.float64(-0.0891705145529695), 'nauc_map_at_1000_max': np.float64(-0.14278711344476366), 'nauc_map_at_1000_std': np.float64(0.04503188044002803), 'nauc_map_at_1000_diff1': np.float64(-0.08888875342589705), 'nauc_recall_at_1_max': np.float64(-0.36120203917359817), 'nauc_recall_at_1_std': np.float64(-0.035792862892406754), 'nauc_recall_at_1_diff1': np.float64(-0.10957874966460951), 'nauc_recall_at_3_max': np.float64(-0.19697105208240173), 'nauc_recall_at_3_std': np.float64(0.07429269892376955), 'nauc_recall_at_3_diff1': np.float64(-0.17443281757743798), 'nauc_recall_at_5_max': np.float64(-0.088830541607574), 'nauc_recall_at_5_std': np.float64(0.13030395952317073), 'nauc_recall_at_5_diff1': np.float64(-0.19379815247805585), 'nauc_recall_at_10_max': np.float64(-0.08235200588299588), 'nauc_recall_at_10_std': np.float64(0.1239205398046288), 'nauc_recall_at_10_diff1': np.float64(-0.08547237873773961), 'nauc_recall_at_20_max': np.float64(-0.04106296395671236), 'nauc_recall_at_20_std': np.float64(0.13590577765852785), 'nauc_recall_at_20_diff1': np.float64(-0.032275735622931706), 'nauc_recall_at_100_max': np.float64(-0.016863215438387178), 'nauc_recall_at_100_std': np.float64(-0.0124929865289883), 'nauc_recall_at_100_diff1': np.float64(-0.028769386778127255), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(-0.36120203917359817), 'nauc_precision_at_1_std': np.float64(-0.035792862892406754), 'nauc_precision_at_1_diff1': np.float64(-0.10957874966460951), 'nauc_precision_at_3_max': np.float64(-0.1969710520824017), 'nauc_precision_at_3_std': np.float64(0.07429269892376957), 'nauc_precision_at_3_diff1': np.float64(-0.1744328175774379), 'nauc_precision_at_5_max': np.float64(-0.08883054160757424), 'nauc_precision_at_5_std': np.float64(0.1303039595231705), 'nauc_precision_at_5_diff1': np.float64(-0.19379815247805593), 'nauc_precision_at_10_max': np.float64(-0.0823520058829961), 'nauc_precision_at_10_std': np.float64(0.12392053980462886), 'nauc_precision_at_10_diff1': np.float64(-0.08547237873773969), 'nauc_precision_at_20_max': np.float64(-0.04106296395671205), 'nauc_precision_at_20_std': np.float64(0.13590577765852802), 'nauc_precision_at_20_diff1': np.float64(-0.03227573562293161), 'nauc_precision_at_100_max': np.float64(-0.016863215438386914), 'nauc_precision_at_100_std': np.float64(-0.012492986528988198), 'nauc_precision_at_100_diff1': np.float64(-0.028769386778127213), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(-0.36120203917359817), 'nauc_mrr_at_1_std': np.float64(-0.035792862892406754), 'nauc_mrr_at_1_diff1': np.float64(-0.10957874966460951), 'nauc_mrr_at_3_max': np.float64(-0.26854038100348804), 'nauc_mrr_at_3_std': np.float64(0.017715320633217013), 'nauc_mrr_at_3_diff1': np.float64(-0.13596726589750466), 'nauc_mrr_at_5_max': np.float64(-0.21416274466225463), 'nauc_mrr_at_5_std': np.float64(0.04437747512353308), 'nauc_mrr_at_5_diff1': np.float64(-0.15087328173599218), 'nauc_mrr_at_10_max': np.float64(-0.19130150250618838), 'nauc_mrr_at_10_std': np.float64(0.053499588953277756), 'nauc_mrr_at_10_diff1': np.float64(-0.11806337407656343), 'nauc_mrr_at_20_max': np.float64(-0.16788309437798737), 'nauc_mrr_at_20_std': np.float64(0.07170762246168892), 'nauc_mrr_at_20_diff1': np.float64(-0.10309182866075349), 'nauc_mrr_at_100_max': np.float64(-0.1432441865504517), 'nauc_mrr_at_100_std': np.float64(0.046197355958896305), 'nauc_mrr_at_100_diff1': np.float64(-0.0891705145529695), 'nauc_mrr_at_1000_max': np.float64(-0.1427889241110975), 'nauc_mrr_at_1000_std': np.float64(0.04503689419144477), 'nauc_mrr_at_1000_diff1': np.float64(-0.08888527092098616), 'main_score': 0.01494}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 12.18it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 11.50it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.93it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.90it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.79 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 12.24it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 12.17it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  8.27it/s]Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.23it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.15 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 10.49it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 10.44it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  8.02it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  8.00it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.81 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 5.52 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.07645, 'ndcg_at_3': 0.07782, 'ndcg_at_5': 0.08476, 'ndcg_at_10': 0.09667, 'ndcg_at_20': 0.10591, 'ndcg_at_100': 0.13802, 'ndcg_at_1000': 0.2249, 'map_at_1': 0.04954, 'map_at_3': 0.06682, 'map_at_5': 0.07111, 'map_at_10': 0.07629, 'map_at_20': 0.07882, 'map_at_100': 0.08293, 'map_at_1000': 0.0855, 'recall_at_1': 0.04954, 'recall_at_3': 0.0829, 'recall_at_5': 0.1013, 'recall_at_10': 0.13486, 'recall_at_20': 0.16784, 'recall_at_100': 0.32979, 'recall_at_1000': 1.0, 'precision_at_1': 0.07645, 'precision_at_3': 0.04434, 'precision_at_5': 0.0315, 'precision_at_10': 0.02064, 'precision_at_20': 0.01292, 'precision_at_100': 0.00517, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.0779816513761468, 'mrr_at_3': 0.09276248725790012, 'mrr_at_5': 0.09742609582059125, 'mrr_at_10': 0.10281782437745741, 'mrr_at_20': 0.105432433865345, 'mrr_at_100': 0.10943750717160941, 'mrr_at_1000': 0.11134599877345515, 'nauc_ndcg_at_1_max': np.float64(0.2644898215650018), 'nauc_ndcg_at_1_std': np.float64(-0.07575476298846044), 'nauc_ndcg_at_1_diff1': np.float64(0.5401692511752626), 'nauc_ndcg_at_3_max': np.float64(0.2546131758245229), 'nauc_ndcg_at_3_std': np.float64(-0.04833185796621194), 'nauc_ndcg_at_3_diff1': np.float64(0.44810108224102696), 'nauc_ndcg_at_5_max': np.float64(0.2343164438822604), 'nauc_ndcg_at_5_std': np.float64(-0.04240960512131272), 'nauc_ndcg_at_5_diff1': np.float64(0.4139499709750631), 'nauc_ndcg_at_10_max': np.float64(0.21645675753067642), 'nauc_ndcg_at_10_std': np.float64(-0.04408018106002208), 'nauc_ndcg_at_10_diff1': np.float64(0.3774891605454227), 'nauc_ndcg_at_20_max': np.float64(0.190480264806404), 'nauc_ndcg_at_20_std': np.float64(-0.04300860866138035), 'nauc_ndcg_at_20_diff1': np.float64(0.3537512209231502), 'nauc_ndcg_at_100_max': np.float64(0.12865906961408272), 'nauc_ndcg_at_100_std': np.float64(-0.07791950231337748), 'nauc_ndcg_at_100_diff1': np.float64(0.3272255065022616), 'nauc_ndcg_at_1000_max': np.float64(0.15786184007244083), 'nauc_ndcg_at_1000_std': np.float64(-0.07813183852584815), 'nauc_ndcg_at_1000_diff1': np.float64(0.36127534031125585), 'nauc_map_at_1_max': np.float64(0.288620595784996), 'nauc_map_at_1_std': np.float64(-0.08216567732334136), 'nauc_map_at_1_diff1': np.float64(0.6054010079672169), 'nauc_map_at_3_max': np.float64(0.28001282799139043), 'nauc_map_at_3_std': np.float64(-0.048607585479639635), 'nauc_map_at_3_diff1': np.float64(0.48140291401474844), 'nauc_map_at_5_max': np.float64(0.26727119417830975), 'nauc_map_at_5_std': np.float64(-0.04504741367782564), 'nauc_map_at_5_diff1': np.float64(0.45639682997251496), 'nauc_map_at_10_max': np.float64(0.2596291720273004), 'nauc_map_at_10_std': np.float64(-0.04623135218770816), 'nauc_map_at_10_diff1': np.float64(0.4393911800520347), 'nauc_map_at_20_max': np.float64(0.2492874746923693), 'nauc_map_at_20_std': np.float64(-0.046022517622134655), 'nauc_map_at_20_diff1': np.float64(0.4304767232334016), 'nauc_map_at_100_max': np.float64(0.23583361730985825), 'nauc_map_at_100_std': np.float64(-0.05313614431894037), 'nauc_map_at_100_diff1': np.float64(0.42455415501257315), 'nauc_map_at_1000_max': np.float64(0.2353817558191942), 'nauc_map_at_1000_std': np.float64(-0.05445052170274775), 'nauc_map_at_1000_diff1': np.float64(0.4253469350305203), 'nauc_recall_at_1_max': np.float64(0.288620595784996), 'nauc_recall_at_1_std': np.float64(-0.08216567732334136), 'nauc_recall_at_1_diff1': np.float64(0.6054010079672169), 'nauc_recall_at_3_max': np.float64(0.22996915211711277), 'nauc_recall_at_3_std': np.float64(-0.038387278500926096), 'nauc_recall_at_3_diff1': np.float64(0.3910083390841778), 'nauc_recall_at_5_max': np.float64(0.1922802747056205), 'nauc_recall_at_5_std': np.float64(-0.021847838864223694), 'nauc_recall_at_5_diff1': np.float64(0.3139607813021583), 'nauc_recall_at_10_max': np.float64(0.16428101594281594), 'nauc_recall_at_10_std': np.float64(-0.02333985721048256), 'nauc_recall_at_10_diff1': np.float64(0.24879837236379138), 'nauc_recall_at_20_max': np.float64(0.10845708180770731), 'nauc_recall_at_20_std': np.float64(-0.023690623915561686), 'nauc_recall_at_20_diff1': np.float64(0.2099613225108133), 'nauc_recall_at_100_max': np.float64(-0.03368396316871295), 'nauc_recall_at_100_std': np.float64(-0.11050214356663036), 'nauc_recall_at_100_diff1': np.float64(0.1689472368651501), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2644898215650018), 'nauc_precision_at_1_std': np.float64(-0.07575476298846044), 'nauc_precision_at_1_diff1': np.float64(0.5401692511752626), 'nauc_precision_at_3_max': np.float64(0.25308198321219383), 'nauc_precision_at_3_std': np.float64(-0.03170951972562491), 'nauc_precision_at_3_diff1': np.float64(0.3839440177207396), 'nauc_precision_at_5_max': np.float64(0.21704695904088503), 'nauc_precision_at_5_std': np.float64(-0.026092308381792127), 'nauc_precision_at_5_diff1': np.float64(0.32808979668578275), 'nauc_precision_at_10_max': np.float64(0.1744317148161231), 'nauc_precision_at_10_std': np.float64(-0.03949845901799769), 'nauc_precision_at_10_diff1': np.float64(0.2764329469422914), 'nauc_precision_at_20_max': np.float64(0.11137934565464801), 'nauc_precision_at_20_std': np.float64(-0.043282268482723846), 'nauc_precision_at_20_diff1': np.float64(0.22718426545732012), 'nauc_precision_at_100_max': np.float64(-0.035007315543486954), 'nauc_precision_at_100_std': np.float64(-0.13303117457637567), 'nauc_precision_at_100_diff1': np.float64(0.16261577393295418), 'nauc_precision_at_1000_max': np.float64(-0.07313663332989635), 'nauc_precision_at_1000_std': np.float64(-0.11378646752391178), 'nauc_precision_at_1000_diff1': np.float64(0.0524453327726162), 'nauc_mrr_at_1_max': np.float64(0.25117749649703097), 'nauc_mrr_at_1_std': np.float64(-0.0840508501214062), 'nauc_mrr_at_1_diff1': np.float64(0.5183264731530405), 'nauc_mrr_at_3_max': np.float64(0.22531708245601614), 'nauc_mrr_at_3_std': np.float64(-0.06330317034200106), 'nauc_mrr_at_3_diff1': np.float64(0.45398245998782955), 'nauc_mrr_at_5_max': np.float64(0.21248889240794447), 'nauc_mrr_at_5_std': np.float64(-0.06219808799044615), 'nauc_mrr_at_5_diff1': np.float64(0.43567059524871754), 'nauc_mrr_at_10_max': np.float64(0.19929623349510558), 'nauc_mrr_at_10_std': np.float64(-0.06470176094449613), 'nauc_mrr_at_10_diff1': np.float64(0.4155657961493131), 'nauc_mrr_at_20_max': np.float64(0.19392209685254103), 'nauc_mrr_at_20_std': np.float64(-0.06249339781586345), 'nauc_mrr_at_20_diff1': np.float64(0.4074084996518699), 'nauc_mrr_at_100_max': np.float64(0.1850959291849321), 'nauc_mrr_at_100_std': np.float64(-0.06881497647788341), 'nauc_mrr_at_100_diff1': np.float64(0.4025727515983243), 'nauc_mrr_at_1000_max': np.float64(0.18588101785746844), 'nauc_mrr_at_1000_std': np.float64(-0.06914627300223536), 'nauc_mrr_at_1000_diff1': np.float64(0.404125420963527), 'main_score': 0.09667}, 'eng-kor': {'ndcg_at_1': 0.00765, 'ndcg_at_3': 0.01062, 'ndcg_at_5': 0.01461, 'ndcg_at_10': 0.01702, 'ndcg_at_20': 0.02069, 'ndcg_at_100': 0.03899, 'ndcg_at_1000': 0.13466, 'map_at_1': 0.00612, 'map_at_3': 0.00896, 'map_at_5': 0.01101, 'map_at_10': 0.01176, 'map_at_20': 0.01263, 'map_at_100': 0.01468, 'map_at_1000': 0.01736, 'recall_at_1': 0.00612, 'recall_at_3': 0.01198, 'recall_at_5': 0.02128, 'recall_at_10': 0.02661, 'recall_at_20': 0.03863, 'recall_at_100': 0.12635, 'recall_at_1000': 0.821, 'precision_at_1': 0.00765, 'precision_at_3': 0.00561, 'precision_at_5': 0.00612, 'precision_at_10': 0.00459, 'precision_at_20': 0.00367, 'precision_at_100': 0.00248, 'precision_at_1000': 0.00166, 'mrr_at_1': 0.00764525993883792, 'mrr_at_3': 0.011977573904179408, 'mrr_at_5': 0.014959225280326198, 'mrr_at_10': 0.01707198679675744, 'mrr_at_20': 0.018335836885237572, 'mrr_at_100': 0.021286705315100643, 'mrr_at_1000': 0.023375097355558535, 'nauc_ndcg_at_1_max': np.float64(0.15461780938885142), 'nauc_ndcg_at_1_std': np.float64(0.035116963007947956), 'nauc_ndcg_at_1_diff1': np.float64(0.7293458918092662), 'nauc_ndcg_at_3_max': np.float64(0.20238606455409852), 'nauc_ndcg_at_3_std': np.float64(0.0931967259201691), 'nauc_ndcg_at_3_diff1': np.float64(0.3016373302418107), 'nauc_ndcg_at_5_max': np.float64(0.19446747817674806), 'nauc_ndcg_at_5_std': np.float64(0.1151356824651165), 'nauc_ndcg_at_5_diff1': np.float64(0.22145273954723607), 'nauc_ndcg_at_10_max': np.float64(0.19132678690918647), 'nauc_ndcg_at_10_std': np.float64(0.09994188598414515), 'nauc_ndcg_at_10_diff1': np.float64(0.17088338616408152), 'nauc_ndcg_at_20_max': np.float64(0.14635384009458147), 'nauc_ndcg_at_20_std': np.float64(0.1493343707616514), 'nauc_ndcg_at_20_diff1': np.float64(0.1131441817609872), 'nauc_ndcg_at_100_max': np.float64(0.08401767783810002), 'nauc_ndcg_at_100_std': np.float64(0.0996493731925943), 'nauc_ndcg_at_100_diff1': np.float64(0.056180903249865646), 'nauc_ndcg_at_1000_max': np.float64(0.02409640827840784), 'nauc_ndcg_at_1000_std': np.float64(0.08932576751120176), 'nauc_ndcg_at_1000_diff1': np.float64(0.06963194517544356), 'nauc_map_at_1_max': np.float64(0.10802748754947965), 'nauc_map_at_1_std': np.float64(0.01227562111841019), 'nauc_map_at_1_diff1': np.float64(0.6616823647615828), 'nauc_map_at_3_max': np.float64(0.19453907496824518), 'nauc_map_at_3_std': np.float64(0.07964981292919329), 'nauc_map_at_3_diff1': np.float64(0.34912263142383543), 'nauc_map_at_5_max': np.float64(0.182121385411282), 'nauc_map_at_5_std': np.float64(0.09455872732456226), 'nauc_map_at_5_diff1': np.float64(0.29254050412479504), 'nauc_map_at_10_max': np.float64(0.179130919357446), 'nauc_map_at_10_std': np.float64(0.08943197879458817), 'nauc_map_at_10_diff1': np.float64(0.263473041041212), 'nauc_map_at_20_max': np.float64(0.16322570546489115), 'nauc_map_at_20_std': np.float64(0.10905596924810057), 'nauc_map_at_20_diff1': np.float64(0.2324030736665146), 'nauc_map_at_100_max': np.float64(0.1490344330374013), 'nauc_map_at_100_std': np.float64(0.10495111020915814), 'nauc_map_at_100_diff1': np.float64(0.20120419004023707), 'nauc_map_at_1000_max': np.float64(0.14057161948862434), 'nauc_map_at_1000_std': np.float64(0.10139600982865259), 'nauc_map_at_1000_diff1': np.float64(0.19755553235994328), 'nauc_recall_at_1_max': np.float64(0.10802748754947965), 'nauc_recall_at_1_std': np.float64(0.01227562111841019), 'nauc_recall_at_1_diff1': np.float64(0.6616823647615828), 'nauc_recall_at_3_max': np.float64(0.2330421007098768), 'nauc_recall_at_3_std': np.float64(0.10704530704773903), 'nauc_recall_at_3_diff1': np.float64(0.17642638377077446), 'nauc_recall_at_5_max': np.float64(0.19138087066183124), 'nauc_recall_at_5_std': np.float64(0.13079936383203397), 'nauc_recall_at_5_diff1': np.float64(0.10659837907074299), 'nauc_recall_at_10_max': np.float64(0.17929002788435736), 'nauc_recall_at_10_std': np.float64(0.10314589049833145), 'nauc_recall_at_10_diff1': np.float64(0.05370411983200672), 'nauc_recall_at_20_max': np.float64(0.10327060585904228), 'nauc_recall_at_20_std': np.float64(0.19044940417247508), 'nauc_recall_at_20_diff1': np.float64(-0.028190759332478638), 'nauc_recall_at_100_max': np.float64(0.023741764006824394), 'nauc_recall_at_100_std': np.float64(0.07892374596484182), 'nauc_recall_at_100_diff1': np.float64(-0.026555062230784666), 'nauc_recall_at_1000_max': np.float64(-0.056348108886798566), 'nauc_recall_at_1000_std': np.float64(0.12718687942003054), 'nauc_recall_at_1000_diff1': np.float64(-0.008997512349625), 'nauc_precision_at_1_max': np.float64(0.15461780938885142), 'nauc_precision_at_1_std': np.float64(0.035116963007947956), 'nauc_precision_at_1_diff1': np.float64(0.7293458918092662), 'nauc_precision_at_3_max': np.float64(0.1955164156491604), 'nauc_precision_at_3_std': np.float64(0.10283644936402331), 'nauc_precision_at_3_diff1': np.float64(0.1985386893649684), 'nauc_precision_at_5_max': np.float64(0.23177503569515473), 'nauc_precision_at_5_std': np.float64(0.16384403961597543), 'nauc_precision_at_5_diff1': np.float64(0.08637263875759575), 'nauc_precision_at_10_max': np.float64(0.23772987145307728), 'nauc_precision_at_10_std': np.float64(0.11517253286836107), 'nauc_precision_at_10_diff1': np.float64(0.02925328349301662), 'nauc_precision_at_20_max': np.float64(0.1303397733648339), 'nauc_precision_at_20_std': np.float64(0.21159933144814144), 'nauc_precision_at_20_diff1': np.float64(-0.007563348258507938), 'nauc_precision_at_100_max': np.float64(0.03142771217550743), 'nauc_precision_at_100_std': np.float64(0.08855083053723763), 'nauc_precision_at_100_diff1': np.float64(-0.021182716101241353), 'nauc_precision_at_1000_max': np.float64(-0.09530016441204182), 'nauc_precision_at_1000_std': np.float64(-0.0032820650657069375), 'nauc_precision_at_1000_diff1': np.float64(0.024618837489003353), 'nauc_mrr_at_1_max': np.float64(0.15461780938885142), 'nauc_mrr_at_1_std': np.float64(0.035116963007947956), 'nauc_mrr_at_1_diff1': np.float64(0.7293458918092662), 'nauc_mrr_at_3_max': np.float64(0.19099411945909225), 'nauc_mrr_at_3_std': np.float64(0.09222970278794672), 'nauc_mrr_at_3_diff1': np.float64(0.38437824583278746), 'nauc_mrr_at_5_max': np.float64(0.20581753515749654), 'nauc_mrr_at_5_std': np.float64(0.12036605873527434), 'nauc_mrr_at_5_diff1': np.float64(0.30111243007945904), 'nauc_mrr_at_10_max': np.float64(0.21194645491160763), 'nauc_mrr_at_10_std': np.float64(0.10802243979694379), 'nauc_mrr_at_10_diff1': np.float64(0.2543534954793093), 'nauc_mrr_at_20_max': np.float64(0.18916229102796947), 'nauc_mrr_at_20_std': np.float64(0.1284118552307213), 'nauc_mrr_at_20_diff1': np.float64(0.23608698220849667), 'nauc_mrr_at_100_max': np.float64(0.17031261729868352), 'nauc_mrr_at_100_std': np.float64(0.11608114097884326), 'nauc_mrr_at_100_diff1': np.float64(0.20799898416748433), 'nauc_mrr_at_1000_max': np.float64(0.16641410393762998), 'nauc_mrr_at_1000_std': np.float64(0.11419543643124197), 'nauc_mrr_at_1000_diff1': np.float64(0.20857735395872792), 'main_score': 0.01702}, 'kor-eng': {'ndcg_at_1': 0.0114, 'ndcg_at_3': 0.01248, 'ndcg_at_5': 0.01475, 'ndcg_at_10': 0.01828, 'ndcg_at_20': 0.02223, 'ndcg_at_100': 0.0423, 'ndcg_at_1000': 0.1534, 'map_at_1': 0.00733, 'map_at_3': 0.01031, 'map_at_5': 0.01156, 'map_at_10': 0.01298, 'map_at_20': 0.01398, 'map_at_100': 0.0163, 'map_at_1000': 0.01928, 'recall_at_1': 0.00733, 'recall_at_3': 0.01344, 'recall_at_5': 0.01846, 'recall_at_10': 0.02877, 'recall_at_20': 0.0424, 'recall_at_100': 0.1424, 'recall_at_1000': 1.0, 'precision_at_1': 0.0114, 'precision_at_3': 0.0076, 'precision_at_5': 0.00619, 'precision_at_10': 0.00456, 'precision_at_20': 0.00342, 'precision_at_100': 0.00243, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.011400651465798045, 'mrr_at_3': 0.015743756786102063, 'mrr_at_5': 0.01720955483170467, 'mrr_at_10': 0.01865208624166279, 'mrr_at_20': 0.020155288070597514, 'mrr_at_100': 0.022971866347441784, 'mrr_at_1000': 0.02532981659825926, 'nauc_ndcg_at_1_max': np.float64(0.026529250192224026), 'nauc_ndcg_at_1_std': np.float64(-0.1171414533742609), 'nauc_ndcg_at_1_diff1': np.float64(0.5603733489142458), 'nauc_ndcg_at_3_max': np.float64(0.048703680200580066), 'nauc_ndcg_at_3_std': np.float64(-0.08562430767760201), 'nauc_ndcg_at_3_diff1': np.float64(0.33204682863527807), 'nauc_ndcg_at_5_max': np.float64(0.06282603291523677), 'nauc_ndcg_at_5_std': np.float64(-0.07239942177927212), 'nauc_ndcg_at_5_diff1': np.float64(0.30342867102207355), 'nauc_ndcg_at_10_max': np.float64(0.05302567428087425), 'nauc_ndcg_at_10_std': np.float64(-0.05148920434094798), 'nauc_ndcg_at_10_diff1': np.float64(0.29545095712808983), 'nauc_ndcg_at_20_max': np.float64(0.035826858334737505), 'nauc_ndcg_at_20_std': np.float64(-0.058710943942782534), 'nauc_ndcg_at_20_diff1': np.float64(0.29727148957187366), 'nauc_ndcg_at_100_max': np.float64(0.01405491209887384), 'nauc_ndcg_at_100_std': np.float64(-0.024446140140222224), 'nauc_ndcg_at_100_diff1': np.float64(0.17344764601244103), 'nauc_ndcg_at_1000_max': np.float64(-0.0390295857328801), 'nauc_ndcg_at_1000_std': np.float64(-0.09532728402701628), 'nauc_ndcg_at_1000_diff1': np.float64(0.18615920019049131), 'nauc_map_at_1_max': np.float64(-0.0619601760121801), 'nauc_map_at_1_std': np.float64(-0.12918876287190464), 'nauc_map_at_1_diff1': np.float64(0.6717984342459743), 'nauc_map_at_3_max': np.float64(0.04694925023360188), 'nauc_map_at_3_std': np.float64(-0.06573326261756973), 'nauc_map_at_3_diff1': np.float64(0.39436110498864196), 'nauc_map_at_5_max': np.float64(0.05066672116783316), 'nauc_map_at_5_std': np.float64(-0.06316071814367974), 'nauc_map_at_5_diff1': np.float64(0.3610869658049584), 'nauc_map_at_10_max': np.float64(0.04213721753897287), 'nauc_map_at_10_std': np.float64(-0.05381437000532623), 'nauc_map_at_10_diff1': np.float64(0.3526269216051773), 'nauc_map_at_20_max': np.float64(0.03908903274216042), 'nauc_map_at_20_std': np.float64(-0.05384107474637129), 'nauc_map_at_20_diff1': np.float64(0.351344690296953), 'nauc_map_at_100_max': np.float64(0.038550836628746143), 'nauc_map_at_100_std': np.float64(-0.04020147733597665), 'nauc_map_at_100_diff1': np.float64(0.3055250048876811), 'nauc_map_at_1000_max': np.float64(0.030464376305831747), 'nauc_map_at_1000_std': np.float64(-0.047193042352017045), 'nauc_map_at_1000_diff1': np.float64(0.29958146842181), 'nauc_recall_at_1_max': np.float64(-0.0619601760121801), 'nauc_recall_at_1_std': np.float64(-0.12918876287190464), 'nauc_recall_at_1_diff1': np.float64(0.6717984342459743), 'nauc_recall_at_3_max': np.float64(0.060557464911615407), 'nauc_recall_at_3_std': np.float64(-0.07069539100357011), 'nauc_recall_at_3_diff1': np.float64(0.23827287643769848), 'nauc_recall_at_5_max': np.float64(0.08222061291741377), 'nauc_recall_at_5_std': np.float64(-0.06097917044336927), 'nauc_recall_at_5_diff1': np.float64(0.22169453552198462), 'nauc_recall_at_10_max': np.float64(0.0745658744967564), 'nauc_recall_at_10_std': np.float64(-0.011122181333433179), 'nauc_recall_at_10_diff1': np.float64(0.2324904000094258), 'nauc_recall_at_20_max': np.float64(0.03490876810738549), 'nauc_recall_at_20_std': np.float64(-0.03794090528251044), 'nauc_recall_at_20_diff1': np.float64(0.26382847457067515), 'nauc_recall_at_100_max': np.float64(-0.000255827309964051), 'nauc_recall_at_100_std': np.float64(0.0026711421000329104), 'nauc_recall_at_100_diff1': np.float64(0.0854222990806023), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.026529250192224026), 'nauc_precision_at_1_std': np.float64(-0.1171414533742609), 'nauc_precision_at_1_diff1': np.float64(0.5603733489142458), 'nauc_precision_at_3_max': np.float64(0.09946567105286076), 'nauc_precision_at_3_std': np.float64(-0.0913137563317581), 'nauc_precision_at_3_diff1': np.float64(0.16379605664615154), 'nauc_precision_at_5_max': np.float64(0.11761491425107666), 'nauc_precision_at_5_std': np.float64(-0.04250382590931625), 'nauc_precision_at_5_diff1': np.float64(0.1393299183152234), 'nauc_precision_at_10_max': np.float64(0.06437769304996158), 'nauc_precision_at_10_std': np.float64(-0.031511567857873325), 'nauc_precision_at_10_diff1': np.float64(0.1795253245893714), 'nauc_precision_at_20_max': np.float64(0.028029074599445942), 'nauc_precision_at_20_std': np.float64(-0.0508955338492189), 'nauc_precision_at_20_diff1': np.float64(0.19292480611247398), 'nauc_precision_at_100_max': np.float64(-0.02938271965143573), 'nauc_precision_at_100_std': np.float64(-0.02238956752523026), 'nauc_precision_at_100_diff1': np.float64(0.08135763163609314), 'nauc_precision_at_1000_max': np.float64(-0.17111858411998015), 'nauc_precision_at_1000_std': np.float64(-0.19149077742705287), 'nauc_precision_at_1000_diff1': np.float64(0.05814726120369953), 'nauc_mrr_at_1_max': np.float64(0.026529250192224026), 'nauc_mrr_at_1_std': np.float64(-0.1171414533742609), 'nauc_mrr_at_1_diff1': np.float64(0.5603733489142458), 'nauc_mrr_at_3_max': np.float64(0.03466295513178192), 'nauc_mrr_at_3_std': np.float64(-0.1359931509797941), 'nauc_mrr_at_3_diff1': np.float64(0.3615946098904525), 'nauc_mrr_at_5_max': np.float64(0.05023315789457687), 'nauc_mrr_at_5_std': np.float64(-0.11483257681831495), 'nauc_mrr_at_5_diff1': np.float64(0.3457519188859779), 'nauc_mrr_at_10_max': np.float64(0.04616377727675733), 'nauc_mrr_at_10_std': np.float64(-0.10883774912964826), 'nauc_mrr_at_10_diff1': np.float64(0.3389181824511175), 'nauc_mrr_at_20_max': np.float64(0.034078712646592596), 'nauc_mrr_at_20_std': np.float64(-0.11262709092724381), 'nauc_mrr_at_20_diff1': np.float64(0.3345241391880963), 'nauc_mrr_at_100_max': np.float64(0.02975318769888639), 'nauc_mrr_at_100_std': np.float64(-0.09995938341254154), 'nauc_mrr_at_100_diff1': np.float64(0.30426608717916637), 'nauc_mrr_at_1000_max': np.float64(0.02763652394596852), 'nauc_mrr_at_1000_std': np.float64(-0.10217872940011344), 'nauc_mrr_at_1000_diff1': np.float64(0.30193884496750695), 'main_score': 0.01828}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 22.96it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:02,  5.21s/it]Batches:  15%|█▌        | 2/13 [00:07<00:41,  3.73s/it]Batches:  23%|██▎       | 3/13 [00:10<00:30,  3.04s/it]Batches:  31%|███       | 4/13 [00:12<00:23,  2.60s/it]Batches:  38%|███▊      | 5/13 [00:13<00:18,  2.30s/it]Batches:  46%|████▌     | 6/13 [00:15<00:14,  2.05s/it]Batches:  54%|█████▍    | 7/13 [00:16<00:10,  1.83s/it]Batches:  62%|██████▏   | 8/13 [00:17<00:08,  1.63s/it]Batches:  69%|██████▉   | 9/13 [00:19<00:06,  1.50s/it]Batches:  77%|███████▋  | 10/13 [00:20<00:04,  1.42s/it]Batches:  85%|████████▍ | 11/13 [00:21<00:02,  1.36s/it]Batches:  92%|█████████▏| 12/13 [00:22<00:01,  1.31s/it]Batches: 100%|██████████| 13/13 [00:24<00:00,  1.28s/it]Batches: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 28.48 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 28.76 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.0, 'ndcg_at_3': 0.0, 'ndcg_at_5': 0.00431, 'ndcg_at_10': 0.00575, 'ndcg_at_20': 0.00946, 'ndcg_at_100': 0.0222, 'ndcg_at_1000': 0.05504, 'map_at_1': 0.0, 'map_at_3': 0.0, 'map_at_5': 0.0025, 'map_at_10': 0.003, 'map_at_20': 0.00397, 'map_at_100': 0.00566, 'map_at_1000': 0.00671, 'recall_at_1': 0.0, 'recall_at_3': 0.0, 'recall_at_5': 0.01, 'recall_at_10': 0.015, 'recall_at_20': 0.03, 'recall_at_100': 0.1, 'recall_at_1000': 0.37, 'precision_at_1': 0.0, 'precision_at_3': 0.0, 'precision_at_5': 0.002, 'precision_at_10': 0.0015, 'precision_at_20': 0.0015, 'precision_at_100': 0.001, 'precision_at_1000': 0.00037, 'mrr_at_1': 0.0, 'mrr_at_3': 0.0, 'mrr_at_5': 0.0025, 'mrr_at_10': 0.003, 'mrr_at_20': 0.003973942208462332, 'mrr_at_100': 0.005662190185786297, 'mrr_at_1000': 0.006711808742751704, 'nauc_ndcg_at_1_max': nan, 'nauc_ndcg_at_1_std': nan, 'nauc_ndcg_at_1_diff1': nan, 'nauc_ndcg_at_3_max': nan, 'nauc_ndcg_at_3_std': nan, 'nauc_ndcg_at_3_diff1': nan, 'nauc_ndcg_at_5_max': np.float64(0.5492353099007247), 'nauc_ndcg_at_5_std': np.float64(0.04360075127448352), 'nauc_ndcg_at_5_diff1': np.float64(-0.20056345586262403), 'nauc_ndcg_at_10_max': np.float64(0.6624986831880245), 'nauc_ndcg_at_10_std': np.float64(-0.11176558428538692), 'nauc_ndcg_at_10_diff1': np.float64(0.016153873561200273), 'nauc_ndcg_at_20_max': np.float64(0.278131208470478), 'nauc_ndcg_at_20_std': np.float64(0.0009706992760806801), 'nauc_ndcg_at_20_diff1': np.float64(-0.017046838712795987), 'nauc_ndcg_at_100_max': np.float64(0.13512329844497178), 'nauc_ndcg_at_100_std': np.float64(-0.10448340024593972), 'nauc_ndcg_at_100_diff1': np.float64(-0.025298217339818713), 'nauc_ndcg_at_1000_max': np.float64(0.0797896713544601), 'nauc_ndcg_at_1000_std': np.float64(-0.04712907501577812), 'nauc_ndcg_at_1000_diff1': np.float64(0.054292728220425746), 'nauc_map_at_1_max': nan, 'nauc_map_at_1_std': nan, 'nauc_map_at_1_diff1': nan, 'nauc_map_at_3_max': nan, 'nauc_map_at_3_std': nan, 'nauc_map_at_3_diff1': nan, 'nauc_map_at_5_max': np.float64(0.5492353099007243), 'nauc_map_at_5_std': np.float64(0.04360075127448346), 'nauc_map_at_5_diff1': np.float64(-0.2005634558626241), 'nauc_map_at_10_max': np.float64(0.6243627582506036), 'nauc_map_at_10_std': np.float64(-0.05945353725069318), 'nauc_map_at_10_diff1': np.float64(-0.05681513281459619), 'nauc_map_at_20_max': np.float64(0.39466787149109983), 'nauc_map_at_20_std': np.float64(-0.00595582617382368), 'nauc_map_at_20_diff1': np.float64(-0.06711577464768609), 'nauc_map_at_100_max': np.float64(0.27782986298570506), 'nauc_map_at_100_std': np.float64(-0.05365847050625711), 'nauc_map_at_100_diff1': np.float64(-0.058054380193831655), 'nauc_map_at_1000_max': np.float64(0.2537176441437752), 'nauc_map_at_1000_std': np.float64(-0.04371024492467261), 'nauc_map_at_1000_diff1': np.float64(-0.034256275853175415), 'nauc_recall_at_1_max': nan, 'nauc_recall_at_1_std': nan, 'nauc_recall_at_1_diff1': nan, 'nauc_recall_at_3_max': nan, 'nauc_recall_at_3_std': nan, 'nauc_recall_at_3_diff1': nan, 'nauc_recall_at_5_max': np.float64(0.5492353099007243), 'nauc_recall_at_5_std': np.float64(0.04360075127448346), 'nauc_recall_at_5_diff1': np.float64(-0.2005634558626241), 'nauc_recall_at_10_max': np.float64(0.6994902066004831), 'nauc_recall_at_10_std': np.float64(-0.16250782577586975), 'nauc_recall_at_10_diff1': np.float64(0.08693319023343174), 'nauc_recall_at_20_max': np.float64(0.1891154637331187), 'nauc_recall_at_20_std': np.float64(0.011179679813970167), 'nauc_recall_at_20_diff1': np.float64(0.016501207405419938), 'nauc_recall_at_100_max': np.float64(0.08328414274215183), 'nauc_recall_at_100_std': np.float64(-0.12976925140863968), 'nauc_recall_at_100_diff1': np.float64(-0.01911725248188895), 'nauc_recall_at_1000_max': np.float64(0.030458741952754713), 'nauc_recall_at_1000_std': np.float64(-0.03882265373013511), 'nauc_recall_at_1000_diff1': np.float64(0.08439650556941178), 'nauc_precision_at_1_max': nan, 'nauc_precision_at_1_std': nan, 'nauc_precision_at_1_diff1': nan, 'nauc_precision_at_3_max': nan, 'nauc_precision_at_3_std': nan, 'nauc_precision_at_3_diff1': nan, 'nauc_precision_at_5_max': np.float64(0.5492353099007246), 'nauc_precision_at_5_std': np.float64(0.043600751274483554), 'nauc_precision_at_5_diff1': np.float64(-0.20056345586262406), 'nauc_precision_at_10_max': np.float64(0.6994902066004827), 'nauc_precision_at_10_std': np.float64(-0.1625078257758698), 'nauc_precision_at_10_diff1': np.float64(0.08693319023343167), 'nauc_precision_at_20_max': np.float64(0.1891154637331186), 'nauc_precision_at_20_std': np.float64(0.011179679813970089), 'nauc_precision_at_20_diff1': np.float64(0.016501207405419934), 'nauc_precision_at_100_max': np.float64(0.08328414274215178), 'nauc_precision_at_100_std': np.float64(-0.12976925140863974), 'nauc_precision_at_100_diff1': np.float64(-0.019117252481888922), 'nauc_precision_at_1000_max': np.float64(0.030458741952754467), 'nauc_precision_at_1000_std': np.float64(-0.038822653730134965), 'nauc_precision_at_1000_diff1': np.float64(0.08439650556941189), 'nauc_mrr_at_1_max': nan, 'nauc_mrr_at_1_std': nan, 'nauc_mrr_at_1_diff1': nan, 'nauc_mrr_at_3_max': nan, 'nauc_mrr_at_3_std': nan, 'nauc_mrr_at_3_diff1': nan, 'nauc_mrr_at_5_max': np.float64(0.5492353099007243), 'nauc_mrr_at_5_std': np.float64(0.04360075127448346), 'nauc_mrr_at_5_diff1': np.float64(-0.2005634558626241), 'nauc_mrr_at_10_max': np.float64(0.6243627582506036), 'nauc_mrr_at_10_std': np.float64(-0.05945353725069318), 'nauc_mrr_at_10_diff1': np.float64(-0.05681513281459619), 'nauc_mrr_at_20_max': np.float64(0.39466787149109983), 'nauc_mrr_at_20_std': np.float64(-0.00595582617382368), 'nauc_mrr_at_20_diff1': np.float64(-0.06711577464768609), 'nauc_mrr_at_100_max': np.float64(0.27782986298570506), 'nauc_mrr_at_100_std': np.float64(-0.05365847050625711), 'nauc_mrr_at_100_diff1': np.float64(-0.058054380193831655), 'nauc_mrr_at_1000_max': np.float64(0.25371481488540326), 'nauc_mrr_at_1000_std': np.float64(-0.043707260630964896), 'nauc_mrr_at_1000_diff1': np.float64(-0.03425283962196362), 'main_score': 0.00575}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 40.91it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:10,  5.86s/it]Batches:  15%|█▌        | 2/13 [00:08<00:45,  4.18s/it]Batches:  23%|██▎       | 3/13 [00:11<00:33,  3.31s/it]Batches:  31%|███       | 4/13 [00:13<00:24,  2.77s/it]Batches:  38%|███▊      | 5/13 [00:14<00:19,  2.41s/it]Batches:  46%|████▌     | 6/13 [00:16<00:14,  2.14s/it]Batches:  54%|█████▍    | 7/13 [00:17<00:11,  1.91s/it]Batches:  62%|██████▏   | 8/13 [00:19<00:08,  1.69s/it]Batches:  69%|██████▉   | 9/13 [00:20<00:06,  1.54s/it]Batches:  77%|███████▋  | 10/13 [00:21<00:04,  1.44s/it]Batches:  85%|████████▍ | 11/13 [00:22<00:02,  1.37s/it]Batches:  92%|█████████▏| 12/13 [00:23<00:01,  1.33s/it]Batches: 100%|██████████| 13/13 [00:25<00:00,  1.29s/it]Batches: 100%|██████████| 13/13 [00:25<00:00,  1.94s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 29.40 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 29.66 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.015, 'ndcg_at_3': 0.0175, 'ndcg_at_5': 0.01965, 'ndcg_at_10': 0.02123, 'ndcg_at_20': 0.02248, 'ndcg_at_100': 0.03563, 'ndcg_at_1000': 0.06479, 'map_at_1': 0.015, 'map_at_3': 0.01667, 'map_at_5': 0.01792, 'map_at_10': 0.01854, 'map_at_20': 0.01887, 'map_at_100': 0.02045, 'map_at_1000': 0.0212, 'recall_at_1': 0.015, 'recall_at_3': 0.02, 'recall_at_5': 0.025, 'recall_at_10': 0.03, 'recall_at_20': 0.035, 'recall_at_100': 0.11, 'recall_at_1000': 0.36, 'precision_at_1': 0.015, 'precision_at_3': 0.00667, 'precision_at_5': 0.005, 'precision_at_10': 0.003, 'precision_at_20': 0.00175, 'precision_at_100': 0.0011, 'precision_at_1000': 0.00036, 'mrr_at_1': 0.015, 'mrr_at_3': 0.016666666666666666, 'mrr_at_5': 0.017916666666666664, 'mrr_at_10': 0.018541666666666665, 'mrr_at_20': 0.018875, 'mrr_at_100': 0.020446345981474653, 'mrr_at_1000': 0.021199235903740912, 'nauc_ndcg_at_1_max': np.float64(-0.21169841695733838), 'nauc_ndcg_at_1_std': np.float64(0.14327877649584117), 'nauc_ndcg_at_1_diff1': np.float64(0.4741078615508453), 'nauc_ndcg_at_3_max': np.float64(-0.0385986431062901), 'nauc_ndcg_at_3_std': np.float64(0.04070681129978137), 'nauc_ndcg_at_3_diff1': np.float64(0.3608800643949558), 'nauc_ndcg_at_5_max': np.float64(0.001114472098427312), 'nauc_ndcg_at_5_std': np.float64(-0.009232767052512367), 'nauc_ndcg_at_5_diff1': np.float64(0.28644317206327163), 'nauc_ndcg_at_10_max': np.float64(0.07532615459104579), 'nauc_ndcg_at_10_std': np.float64(-0.05124571786411224), 'nauc_ndcg_at_10_diff1': np.float64(0.24150021942476213), 'nauc_ndcg_at_20_max': np.float64(0.12674100990675316), 'nauc_ndcg_at_20_std': np.float64(0.007206942772499141), 'nauc_ndcg_at_20_diff1': np.float64(0.2460792983204922), 'nauc_ndcg_at_100_max': np.float64(0.0910270340772759), 'nauc_ndcg_at_100_std': np.float64(-0.0048643636839120555), 'nauc_ndcg_at_100_diff1': np.float64(0.18114447083473414), 'nauc_ndcg_at_1000_max': np.float64(0.06198190561679241), 'nauc_ndcg_at_1000_std': np.float64(-0.07273037117065707), 'nauc_ndcg_at_1000_diff1': np.float64(0.12217755846103534), 'nauc_map_at_1_max': np.float64(-0.21169841695733838), 'nauc_map_at_1_std': np.float64(0.14327877649584117), 'nauc_map_at_1_diff1': np.float64(0.4741078615508453), 'nauc_map_at_3_max': np.float64(-0.09052857526160454), 'nauc_map_at_3_std': np.float64(0.07147840085859948), 'nauc_map_at_3_diff1': np.float64(0.3948484035417228), 'nauc_map_at_5_max': np.float64(-0.06161823525374224), 'nauc_map_at_5_std': np.float64(0.0375325250684821), 'nauc_map_at_5_diff1': np.float64(0.34508083688483193), 'nauc_map_at_10_max': np.float64(-0.02583335091934647), 'nauc_map_at_10_std': np.float64(0.016894631643367873), 'nauc_map_at_10_diff1': np.float64(0.3227133911963415), 'nauc_map_at_20_max': np.float64(-0.007717088651455062), 'nauc_map_at_20_std': np.float64(0.03425631585275647), 'nauc_map_at_20_diff1': np.float64(0.32273351611739665), 'nauc_map_at_100_max': np.float64(-0.010526267387615817), 'nauc_map_at_100_std': np.float64(0.03203346092625943), 'nauc_map_at_100_diff1': np.float64(0.30419624426572645), 'nauc_map_at_1000_max': np.float64(-0.011050180612343603), 'nauc_map_at_1000_std': np.float64(0.02587990904848597), 'nauc_map_at_1000_diff1': np.float64(0.29749787286270535), 'nauc_recall_at_1_max': np.float64(-0.21169841695733838), 'nauc_recall_at_1_std': np.float64(0.14327877649584117), 'nauc_recall_at_1_diff1': np.float64(0.4741078615508453), 'nauc_recall_at_3_max': np.float64(0.09122618728199618), 'nauc_recall_at_3_std': np.float64(-0.0362221625972633), 'nauc_recall_at_3_diff1': np.float64(0.2759592165280386), 'nauc_recall_at_5_max': np.float64(0.1377515427958144), 'nauc_recall_at_5_std': np.float64(-0.11199356050442724), 'nauc_recall_at_5_diff1': np.float64(0.15707002951435473), 'nauc_recall_at_10_max': np.float64(0.281459618996512), 'nauc_recall_at_10_std': np.float64(-0.1891154637331187), 'nauc_recall_at_10_diff1': np.float64(0.0778105715052322), 'nauc_recall_at_20_max': np.float64(0.3841082448541529), 'nauc_recall_at_20_std': np.float64(-0.019241826056958983), 'nauc_recall_at_20_diff1': np.float64(0.11295948484035413), 'nauc_recall_at_100_max': np.float64(0.16058081888416334), 'nauc_recall_at_100_std': np.float64(-0.031897224249440116), 'nauc_recall_at_100_diff1': np.float64(0.07747187759518841), 'nauc_recall_at_1000_max': np.float64(0.07218679473048867), 'nauc_recall_at_1000_std': np.float64(-0.14213640896446755), 'nauc_recall_at_1000_diff1': np.float64(0.017457880648716624), 'nauc_precision_at_1_max': np.float64(-0.21169841695733838), 'nauc_precision_at_1_std': np.float64(0.14327877649584117), 'nauc_precision_at_1_diff1': np.float64(0.4741078615508453), 'nauc_precision_at_3_max': np.float64(0.09122618728199614), 'nauc_precision_at_3_std': np.float64(-0.036222162597263304), 'nauc_precision_at_3_diff1': np.float64(0.2759592165280387), 'nauc_precision_at_5_max': np.float64(0.13775154279581447), 'nauc_precision_at_5_std': np.float64(-0.11199356050442716), 'nauc_precision_at_5_diff1': np.float64(0.15707002951435467), 'nauc_precision_at_10_max': np.float64(0.281459618996512), 'nauc_precision_at_10_std': np.float64(-0.1891154637331188), 'nauc_precision_at_10_diff1': np.float64(0.07781057150523206), 'nauc_precision_at_20_max': np.float64(0.3841082448541531), 'nauc_precision_at_20_std': np.float64(-0.019241826056958948), 'nauc_precision_at_20_diff1': np.float64(0.11295948484035426), 'nauc_precision_at_100_max': np.float64(0.16058081888416348), 'nauc_precision_at_100_std': np.float64(-0.03189722424943996), 'nauc_precision_at_100_diff1': np.float64(0.07747187759518838), 'nauc_precision_at_1000_max': np.float64(0.07218679473048863), 'nauc_precision_at_1000_std': np.float64(-0.14213640896446747), 'nauc_precision_at_1000_diff1': np.float64(0.017457880648716534), 'nauc_mrr_at_1_max': np.float64(-0.21169841695733838), 'nauc_mrr_at_1_std': np.float64(0.14327877649584117), 'nauc_mrr_at_1_diff1': np.float64(0.4741078615508453), 'nauc_mrr_at_3_max': np.float64(-0.09052857526160454), 'nauc_mrr_at_3_std': np.float64(0.07147840085859948), 'nauc_mrr_at_3_diff1': np.float64(0.3948484035417228), 'nauc_mrr_at_5_max': np.float64(-0.06161823525374224), 'nauc_mrr_at_5_std': np.float64(0.0375325250684821), 'nauc_mrr_at_5_diff1': np.float64(0.34508083688483193), 'nauc_mrr_at_10_max': np.float64(-0.02583335091934647), 'nauc_mrr_at_10_std': np.float64(0.016894631643367873), 'nauc_mrr_at_10_diff1': np.float64(0.3227133911963415), 'nauc_mrr_at_20_max': np.float64(-0.007717088651455062), 'nauc_mrr_at_20_std': np.float64(0.03425631585275647), 'nauc_mrr_at_20_diff1': np.float64(0.32273351611739665), 'nauc_mrr_at_100_max': np.float64(-0.010526267387615817), 'nauc_mrr_at_100_std': np.float64(0.03203346092625943), 'nauc_mrr_at_100_diff1': np.float64(0.30419624426572645), 'nauc_mrr_at_1000_max': np.float64(-0.011050180612343603), 'nauc_mrr_at_1000_std': np.float64(0.02587990904848597), 'nauc_mrr_at_1000_diff1': np.float64(0.29749787286270535), 'main_score': 0.02123}}



==================================================
Running model: BAAI/bge-m3
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / BAAI/bge-m3 on GPU 0 in process Process-3
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:05,  3.38it/s]Batches:  26%|██▋       | 5/19 [00:00<00:00, 14.67it/s]Batches:  47%|████▋     | 9/19 [00:00<00:00, 21.29it/s]Batches:  68%|██████▊   | 13/19 [00:00<00:00, 26.14it/s]Batches:  89%|████████▉ | 17/19 [00:00<00:00, 29.67it/s]Batches: 100%|██████████| 19/19 [00:00<00:00, 24.01it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/290 [00:00<?, ?it/s]Batches:   0%|          | 1/290 [00:00<00:34,  8.33it/s]Batches:   1%|          | 2/290 [00:07<19:40,  4.10s/it]Batches:   1%|          | 3/290 [00:08<14:45,  3.09s/it]Batches:   1%|▏         | 4/290 [00:10<11:09,  2.34s/it]Batches:   2%|▏         | 5/290 [00:10<08:39,  1.82s/it]Batches:   2%|▏         | 6/290 [00:11<07:00,  1.48s/it]Batches:   2%|▏         | 7/290 [00:12<05:51,  1.24s/it]Batches:   3%|▎         | 8/290 [00:13<04:59,  1.06s/it]Batches:   3%|▎         | 9/290 [00:13<04:23,  1.07it/s]Batches:   3%|▎         | 10/290 [00:14<03:53,  1.20it/s]Batches:   4%|▍         | 11/290 [00:15<03:34,  1.30it/s]Batches:   4%|▍         | 12/290 [00:15<03:19,  1.39it/s]Batches:   4%|▍         | 13/290 [00:16<03:10,  1.46it/s]Batches:   5%|▍         | 14/290 [00:16<02:58,  1.54it/s]Batches:   5%|▌         | 15/290 [00:17<02:50,  1.62it/s]Batches:   6%|▌         | 16/290 [00:18<02:45,  1.65it/s]Batches:   6%|▌         | 17/290 [00:18<02:40,  1.70it/s]Batches:   6%|▌         | 18/290 [00:19<02:34,  1.76it/s]Batches:   7%|▋         | 19/290 [00:19<02:27,  1.83it/s]Batches:   7%|▋         | 20/290 [00:20<02:25,  1.85it/s]Batches:   7%|▋         | 21/290 [00:20<02:19,  1.93it/s]Batches:   8%|▊         | 22/290 [00:21<02:14,  1.99it/s]Batches:   8%|▊         | 23/290 [00:21<02:18,  1.93it/s]Batches:   8%|▊         | 24/290 [00:22<02:13,  2.00it/s]Batches:   9%|▊         | 25/290 [00:22<02:09,  2.05it/s]Batches:   9%|▉         | 26/290 [00:22<02:08,  2.05it/s]Batches:   9%|▉         | 27/290 [00:23<02:04,  2.11it/s]Batches:  10%|▉         | 28/290 [00:23<02:02,  2.13it/s]Batches:  10%|█         | 29/290 [00:24<02:01,  2.15it/s]Batches:  10%|█         | 30/290 [00:24<01:58,  2.19it/s]Batches:  11%|█         | 31/290 [00:25<01:56,  2.23it/s]Batches:  11%|█         | 32/290 [00:25<01:52,  2.30it/s]Batches:  11%|█▏        | 33/290 [00:26<01:52,  2.29it/s]Batches:  12%|█▏        | 34/290 [00:26<01:51,  2.30it/s]Batches:  12%|█▏        | 35/290 [00:26<01:50,  2.30it/s]Batches:  12%|█▏        | 36/290 [00:27<01:48,  2.34it/s]Batches:  13%|█▎        | 37/290 [00:27<01:46,  2.38it/s]Batches:  13%|█▎        | 38/290 [00:28<01:44,  2.41it/s]Batches:  13%|█▎        | 39/290 [00:28<01:43,  2.43it/s]Batches:  14%|█▍        | 40/290 [00:28<01:41,  2.45it/s]Batches:  14%|█▍        | 41/290 [00:29<01:41,  2.45it/s]Batches:  14%|█▍        | 42/290 [00:29<01:40,  2.46it/s]Batches:  15%|█▍        | 43/290 [00:30<01:39,  2.48it/s]Batches:  15%|█▌        | 44/290 [00:30<01:41,  2.43it/s]Batches:  16%|█▌        | 45/290 [00:30<01:39,  2.47it/s]Batches:  16%|█▌        | 46/290 [00:31<01:36,  2.52it/s]Batches:  16%|█▌        | 47/290 [00:31<01:35,  2.53it/s]Batches:  17%|█▋        | 48/290 [00:32<01:33,  2.59it/s]Batches:  17%|█▋        | 49/290 [00:32<01:31,  2.63it/s]Batches:  17%|█▋        | 50/290 [00:32<01:30,  2.64it/s]Batches:  18%|█▊        | 51/290 [00:33<01:31,  2.61it/s]Batches:  18%|█▊        | 52/290 [00:33<01:30,  2.63it/s]Batches:  18%|█▊        | 53/290 [00:33<01:29,  2.64it/s]Batches:  19%|█▊        | 54/290 [00:34<01:28,  2.66it/s]Batches:  19%|█▉        | 55/290 [00:34<01:25,  2.76it/s]Batches:  19%|█▉        | 56/290 [00:35<01:25,  2.73it/s]Batches:  20%|█▉        | 57/290 [00:35<01:23,  2.77it/s]Batches:  20%|██        | 58/290 [00:35<01:23,  2.78it/s]Batches:  20%|██        | 59/290 [00:36<01:22,  2.79it/s]Batches:  21%|██        | 60/290 [00:36<01:22,  2.80it/s]Batches:  21%|██        | 61/290 [00:36<01:19,  2.87it/s]Batches:  21%|██▏       | 62/290 [00:37<01:20,  2.83it/s]Batches:  22%|██▏       | 63/290 [00:37<01:19,  2.84it/s]Batches:  22%|██▏       | 64/290 [00:37<01:19,  2.85it/s]Batches:  22%|██▏       | 65/290 [00:38<01:18,  2.86it/s]Batches:  23%|██▎       | 66/290 [00:38<01:18,  2.84it/s]Batches:  23%|██▎       | 67/290 [00:38<01:17,  2.88it/s]Batches:  23%|██▎       | 68/290 [00:39<01:15,  2.94it/s]Batches:  24%|██▍       | 69/290 [00:39<01:14,  2.98it/s]Batches:  24%|██▍       | 70/290 [00:39<01:13,  3.01it/s]Batches:  24%|██▍       | 71/290 [00:40<01:12,  3.03it/s]Batches:  25%|██▍       | 72/290 [00:40<01:11,  3.05it/s]Batches:  25%|██▌       | 73/290 [00:40<01:10,  3.09it/s]Batches:  26%|██▌       | 74/290 [00:41<01:09,  3.10it/s]Batches:  26%|██▌       | 75/290 [00:41<01:10,  3.03it/s]Batches:  26%|██▌       | 76/290 [00:41<01:09,  3.08it/s]Batches:  27%|██▋       | 77/290 [00:42<01:08,  3.13it/s]Batches:  27%|██▋       | 78/290 [00:42<01:07,  3.16it/s]Batches:  27%|██▋       | 79/290 [00:42<01:06,  3.19it/s]Batches:  28%|██▊       | 80/290 [00:43<01:05,  3.21it/s]Batches:  28%|██▊       | 81/290 [00:43<01:05,  3.20it/s]Batches:  28%|██▊       | 82/290 [00:43<01:04,  3.23it/s]Batches:  29%|██▊       | 83/290 [00:43<01:03,  3.23it/s]Batches:  29%|██▉       | 84/290 [00:44<01:04,  3.20it/s]Batches:  29%|██▉       | 85/290 [00:44<01:04,  3.20it/s]Batches:  30%|██▉       | 86/290 [00:44<01:02,  3.25it/s]Batches:  30%|███       | 87/290 [00:45<01:03,  3.21it/s]Batches:  30%|███       | 88/290 [00:45<01:02,  3.25it/s]Batches:  31%|███       | 89/290 [00:45<01:01,  3.27it/s]Batches:  31%|███       | 90/290 [00:46<01:00,  3.31it/s]Batches:  31%|███▏      | 91/290 [00:46<00:59,  3.36it/s]Batches:  32%|███▏      | 92/290 [00:46<00:58,  3.36it/s]Batches:  32%|███▏      | 93/290 [00:47<00:58,  3.35it/s]Batches:  32%|███▏      | 94/290 [00:47<00:58,  3.35it/s]Batches:  33%|███▎      | 95/290 [00:47<00:58,  3.34it/s]Batches:  33%|███▎      | 96/290 [00:47<00:58,  3.33it/s]Batches:  33%|███▎      | 97/290 [00:48<00:57,  3.38it/s]Batches:  34%|███▍      | 98/290 [00:48<00:55,  3.43it/s]Batches:  34%|███▍      | 99/290 [00:48<00:55,  3.46it/s]Batches:  34%|███▍      | 100/290 [00:49<00:55,  3.43it/s]Batches:  35%|███▍      | 101/290 [00:49<00:53,  3.52it/s]Batches:  35%|███▌      | 102/290 [00:49<00:54,  3.47it/s]Batches:  36%|███▌      | 103/290 [00:49<00:54,  3.45it/s]Batches:  36%|███▌      | 104/290 [00:50<00:54,  3.44it/s]Batches:  36%|███▌      | 105/290 [00:50<00:52,  3.53it/s]Batches:  37%|███▋      | 106/290 [00:50<00:51,  3.54it/s]Batches:  37%|███▋      | 107/290 [00:51<00:50,  3.60it/s]Batches:  37%|███▋      | 108/290 [00:51<00:50,  3.62it/s]Batches:  38%|███▊      | 109/290 [00:51<00:49,  3.63it/s]Batches:  38%|███▊      | 110/290 [00:51<00:48,  3.68it/s]Batches:  38%|███▊      | 111/290 [00:52<00:49,  3.60it/s]Batches:  39%|███▊      | 112/290 [00:52<00:48,  3.65it/s]Batches:  39%|███▉      | 113/290 [00:52<00:47,  3.69it/s]Batches:  39%|███▉      | 114/290 [00:52<00:46,  3.81it/s]Batches:  40%|███▉      | 115/290 [00:53<00:46,  3.79it/s]Batches:  40%|████      | 116/290 [00:53<00:45,  3.79it/s]Batches:  40%|████      | 117/290 [00:53<00:45,  3.81it/s]Batches:  41%|████      | 118/290 [00:53<00:46,  3.74it/s]Batches:  41%|████      | 119/290 [00:54<00:45,  3.74it/s]Batches:  41%|████▏     | 120/290 [00:54<00:45,  3.77it/s]Batches:  42%|████▏     | 121/290 [00:54<00:44,  3.81it/s]Batches:  42%|████▏     | 122/290 [00:55<00:43,  3.82it/s]Batches:  42%|████▏     | 123/290 [00:55<00:43,  3.85it/s]Batches:  43%|████▎     | 124/290 [00:55<00:42,  3.87it/s]Batches:  43%|████▎     | 125/290 [00:55<00:42,  3.88it/s]Batches:  43%|████▎     | 126/290 [00:56<00:41,  3.97it/s]Batches:  44%|████▍     | 127/290 [00:56<00:41,  3.94it/s]Batches:  44%|████▍     | 128/290 [00:56<00:40,  3.99it/s]Batches:  44%|████▍     | 129/290 [00:56<00:40,  3.94it/s]Batches:  45%|████▍     | 130/290 [00:57<00:40,  3.93it/s]Batches:  45%|████▌     | 131/290 [00:57<00:40,  3.93it/s]Batches:  46%|████▌     | 132/290 [00:57<00:40,  3.89it/s]Batches:  46%|████▌     | 133/290 [00:57<00:39,  3.97it/s]Batches:  46%|████▌     | 134/290 [00:58<00:38,  4.05it/s]Batches:  47%|████▋     | 135/290 [00:58<00:37,  4.09it/s]Batches:  47%|████▋     | 136/290 [00:58<00:37,  4.08it/s]Batches:  47%|████▋     | 137/290 [00:58<00:37,  4.04it/s]Batches:  48%|████▊     | 138/290 [00:59<00:37,  4.08it/s]Batches:  48%|████▊     | 139/290 [00:59<00:37,  4.06it/s]Batches:  48%|████▊     | 140/290 [00:59<00:36,  4.16it/s]Batches:  49%|████▊     | 141/290 [00:59<00:36,  4.13it/s]Batches:  49%|████▉     | 142/290 [00:59<00:35,  4.19it/s]Batches:  49%|████▉     | 143/290 [01:00<00:34,  4.24it/s]Batches:  50%|████▉     | 144/290 [01:00<00:33,  4.30it/s]Batches:  50%|█████     | 145/290 [01:00<00:33,  4.33it/s]Batches:  50%|█████     | 146/290 [01:00<00:33,  4.36it/s]Batches:  51%|█████     | 147/290 [01:01<00:32,  4.36it/s]Batches:  51%|█████     | 148/290 [01:01<00:32,  4.36it/s]Batches:  51%|█████▏    | 149/290 [01:01<00:32,  4.37it/s]Batches:  52%|█████▏    | 150/290 [01:01<00:31,  4.38it/s]Batches:  52%|█████▏    | 151/290 [01:02<00:31,  4.41it/s]Batches:  52%|█████▏    | 152/290 [01:02<00:31,  4.40it/s]Batches:  53%|█████▎    | 153/290 [01:02<00:30,  4.49it/s]Batches:  53%|█████▎    | 154/290 [01:02<00:30,  4.48it/s]Batches:  53%|█████▎    | 155/290 [01:02<00:30,  4.48it/s]Batches:  54%|█████▍    | 156/290 [01:03<00:29,  4.54it/s]Batches:  54%|█████▍    | 157/290 [01:03<00:29,  4.50it/s]Batches:  54%|█████▍    | 158/290 [01:03<00:28,  4.56it/s]Batches:  55%|█████▍    | 159/290 [01:03<00:29,  4.51it/s]Batches:  55%|█████▌    | 160/290 [01:03<00:28,  4.58it/s]Batches:  56%|█████▌    | 161/290 [01:04<00:27,  4.64it/s]Batches:  56%|█████▌    | 162/290 [01:04<00:27,  4.58it/s]Batches:  56%|█████▌    | 163/290 [01:04<00:27,  4.63it/s]Batches:  57%|█████▋    | 164/290 [01:04<00:27,  4.59it/s]Batches:  57%|█████▋    | 165/290 [01:05<00:26,  4.64it/s]Batches:  57%|█████▋    | 166/290 [01:05<00:27,  4.55it/s]Batches:  58%|█████▊    | 167/290 [01:05<00:26,  4.62it/s]Batches:  58%|█████▊    | 168/290 [01:05<00:26,  4.55it/s]Batches:  58%|█████▊    | 169/290 [01:05<00:26,  4.65it/s]Batches:  59%|█████▊    | 170/290 [01:06<00:25,  4.74it/s]Batches:  59%|█████▉    | 171/290 [01:06<00:25,  4.74it/s]Batches:  59%|█████▉    | 172/290 [01:06<00:24,  4.75it/s]Batches:  60%|█████▉    | 173/290 [01:06<00:24,  4.76it/s]Batches:  60%|██████    | 174/290 [01:06<00:23,  4.84it/s]Batches:  60%|██████    | 175/290 [01:07<00:23,  4.87it/s]Batches:  61%|██████    | 176/290 [01:07<00:23,  4.89it/s]Batches:  61%|██████    | 177/290 [01:07<00:23,  4.87it/s]Batches:  61%|██████▏   | 178/290 [01:07<00:22,  4.90it/s]Batches:  62%|██████▏   | 179/290 [01:07<00:22,  4.94it/s]Batches:  62%|██████▏   | 180/290 [01:08<00:22,  4.89it/s]Batches:  62%|██████▏   | 181/290 [01:08<00:21,  5.00it/s]Batches:  63%|██████▎   | 182/290 [01:08<00:21,  5.04it/s]Batches:  63%|██████▎   | 183/290 [01:08<00:20,  5.11it/s]Batches:  63%|██████▎   | 184/290 [01:08<00:20,  5.16it/s]Batches:  64%|██████▍   | 185/290 [01:09<00:20,  5.13it/s]Batches:  64%|██████▍   | 186/290 [01:09<00:20,  5.03it/s]Batches:  64%|██████▍   | 187/290 [01:09<00:20,  5.05it/s]Batches:  65%|██████▍   | 188/290 [01:09<00:19,  5.12it/s]Batches:  65%|██████▌   | 189/290 [01:09<00:19,  5.11it/s]Batches:  66%|██████▌   | 190/290 [01:10<00:19,  5.00it/s]Batches:  66%|██████▌   | 191/290 [01:10<00:19,  5.04it/s]Batches:  66%|██████▌   | 192/290 [01:10<00:19,  5.14it/s]Batches:  67%|██████▋   | 193/290 [01:10<00:18,  5.12it/s]Batches:  67%|██████▋   | 194/290 [01:10<00:18,  5.22it/s]Batches:  67%|██████▋   | 195/290 [01:11<00:18,  5.15it/s]Batches:  68%|██████▊   | 196/290 [01:11<00:17,  5.25it/s]Batches:  68%|██████▊   | 197/290 [01:11<00:17,  5.27it/s]Batches:  68%|██████▊   | 198/290 [01:11<00:17,  5.38it/s]Batches:  69%|██████▊   | 199/290 [01:11<00:16,  5.40it/s]Batches:  69%|██████▉   | 200/290 [01:12<00:16,  5.47it/s]Batches:  69%|██████▉   | 201/290 [01:12<00:16,  5.54it/s]Batches:  70%|██████▉   | 202/290 [01:12<00:16,  5.47it/s]Batches:  70%|███████   | 203/290 [01:12<00:16,  5.43it/s]Batches:  70%|███████   | 204/290 [01:12<00:15,  5.52it/s]Batches:  71%|███████   | 205/290 [01:12<00:15,  5.58it/s]Batches:  71%|███████   | 206/290 [01:13<00:15,  5.55it/s]Batches:  71%|███████▏  | 207/290 [01:13<00:14,  5.54it/s]Batches:  72%|███████▏  | 208/290 [01:13<00:14,  5.56it/s]Batches:  72%|███████▏  | 209/290 [01:13<00:14,  5.58it/s]Batches:  72%|███████▏  | 210/290 [01:13<00:14,  5.60it/s]Batches:  73%|███████▎  | 211/290 [01:13<00:13,  5.71it/s]Batches:  73%|███████▎  | 212/290 [01:14<00:13,  5.74it/s]Batches:  73%|███████▎  | 213/290 [01:14<00:13,  5.72it/s]Batches:  74%|███████▍  | 214/290 [01:14<00:13,  5.75it/s]Batches:  74%|███████▍  | 215/290 [01:14<00:12,  5.90it/s]Batches:  74%|███████▍  | 216/290 [01:14<00:12,  5.87it/s]Batches:  75%|███████▍  | 217/290 [01:15<00:12,  5.79it/s]Batches:  75%|███████▌  | 218/290 [01:15<00:12,  5.97it/s]Batches:  76%|███████▌  | 219/290 [01:15<00:11,  6.09it/s]Batches:  76%|███████▌  | 220/290 [01:15<00:11,  6.21it/s]Batches:  76%|███████▌  | 221/290 [01:15<00:11,  6.16it/s]Batches:  77%|███████▋  | 222/290 [01:15<00:10,  6.24it/s]Batches:  77%|███████▋  | 223/290 [01:15<00:10,  6.28it/s]Batches:  77%|███████▋  | 224/290 [01:16<00:10,  6.35it/s]Batches:  78%|███████▊  | 225/290 [01:16<00:10,  6.39it/s]Batches:  78%|███████▊  | 226/290 [01:16<00:09,  6.51it/s]Batches:  78%|███████▊  | 227/290 [01:16<00:09,  6.54it/s]Batches:  79%|███████▊  | 228/290 [01:16<00:09,  6.54it/s]Batches:  79%|███████▉  | 229/290 [01:16<00:09,  6.63it/s]Batches:  79%|███████▉  | 230/290 [01:17<00:09,  6.63it/s]Batches:  80%|███████▉  | 231/290 [01:17<00:08,  6.58it/s]Batches:  80%|████████  | 232/290 [01:17<00:08,  6.59it/s]Batches:  80%|████████  | 233/290 [01:17<00:08,  6.66it/s]Batches:  81%|████████  | 234/290 [01:17<00:08,  6.77it/s]Batches:  81%|████████  | 235/290 [01:17<00:08,  6.78it/s]Batches:  81%|████████▏ | 236/290 [01:17<00:07,  6.86it/s]Batches:  82%|████████▏ | 237/290 [01:18<00:07,  6.87it/s]Batches:  82%|████████▏ | 238/290 [01:18<00:07,  6.90it/s]Batches:  82%|████████▏ | 239/290 [01:18<00:07,  6.92it/s]Batches:  83%|████████▎ | 240/290 [01:18<00:07,  6.94it/s]Batches:  83%|████████▎ | 241/290 [01:18<00:07,  6.89it/s]Batches:  83%|████████▎ | 242/290 [01:18<00:06,  7.00it/s]Batches:  84%|████████▍ | 243/290 [01:18<00:06,  7.06it/s]Batches:  84%|████████▍ | 244/290 [01:19<00:06,  7.07it/s]Batches:  84%|████████▍ | 245/290 [01:19<00:06,  7.12it/s]Batches:  85%|████████▍ | 246/290 [01:19<00:06,  7.11it/s]Batches:  85%|████████▌ | 247/290 [01:19<00:06,  7.01it/s]Batches:  86%|████████▌ | 248/290 [01:19<00:05,  7.10it/s]Batches:  86%|████████▌ | 249/290 [01:19<00:05,  7.27it/s]Batches:  86%|████████▌ | 250/290 [01:19<00:05,  7.41it/s]Batches:  87%|████████▋ | 251/290 [01:19<00:05,  7.49it/s]Batches:  87%|████████▋ | 252/290 [01:20<00:05,  7.43it/s]Batches:  87%|████████▋ | 253/290 [01:20<00:04,  7.50it/s]Batches:  88%|████████▊ | 254/290 [01:20<00:04,  7.54it/s]Batches:  88%|████████▊ | 255/290 [01:20<00:04,  7.66it/s]Batches:  88%|████████▊ | 256/290 [01:20<00:04,  7.78it/s]Batches:  89%|████████▊ | 257/290 [01:20<00:04,  7.79it/s]Batches:  89%|████████▉ | 258/290 [01:20<00:04,  7.87it/s]Batches:  89%|████████▉ | 259/290 [01:20<00:03,  8.08it/s]Batches:  90%|████████▉ | 260/290 [01:21<00:03,  8.18it/s]Batches:  90%|█████████ | 261/290 [01:21<00:03,  8.16it/s]Batches:  90%|█████████ | 262/290 [01:21<00:03,  8.28it/s]Batches:  91%|█████████ | 263/290 [01:21<00:03,  8.50it/s]Batches:  91%|█████████ | 264/290 [01:21<00:03,  8.51it/s]Batches:  91%|█████████▏| 265/290 [01:21<00:02,  8.76it/s]Batches:  92%|█████████▏| 266/290 [01:21<00:02,  8.90it/s]Batches:  92%|█████████▏| 267/290 [01:21<00:02,  9.00it/s]Batches:  92%|█████████▏| 268/290 [01:22<00:02,  9.07it/s]Batches:  93%|█████████▎| 269/290 [01:22<00:02,  9.23it/s]Batches:  93%|█████████▎| 270/290 [01:22<00:02,  9.32it/s]Batches:  93%|█████████▎| 271/290 [01:22<00:02,  9.31it/s]Batches:  94%|█████████▍| 273/290 [01:22<00:01,  9.72it/s]Batches:  95%|█████████▍| 275/290 [01:22<00:01,  9.98it/s]Batches:  95%|█████████▌| 276/290 [01:22<00:01,  9.89it/s]Batches:  96%|█████████▌| 278/290 [01:22<00:01, 10.34it/s]Batches:  97%|█████████▋| 280/290 [01:23<00:00, 10.50it/s]Batches:  97%|█████████▋| 282/290 [01:23<00:00, 11.04it/s]Batches:  98%|█████████▊| 284/290 [01:23<00:00, 11.43it/s]Batches:  99%|█████████▊| 286/290 [01:23<00:00, 12.38it/s]Batches:  99%|█████████▉| 288/290 [01:23<00:00, 13.24it/s]Batches: 100%|██████████| 290/290 [01:23<00:00, 14.68it/s]Batches: 100%|██████████| 290/290 [01:23<00:00,  3.46it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 85.57 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 86.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.75676, 'ndcg_at_3': 0.74791, 'ndcg_at_5': 0.77754, 'ndcg_at_10': 0.79405, 'ndcg_at_20': 0.80289, 'ndcg_at_100': 0.81105, 'ndcg_at_1000': 0.81929, 'map_at_1': 0.49267, 'map_at_3': 0.71019, 'map_at_5': 0.73924, 'map_at_10': 0.75068, 'map_at_20': 0.75409, 'map_at_100': 0.75588, 'map_at_1000': 0.75626, 'recall_at_1': 0.49267, 'recall_at_3': 0.75176, 'recall_at_5': 0.81346, 'recall_at_10': 0.85203, 'recall_at_20': 0.87968, 'recall_at_100': 0.9141, 'recall_at_1000': 0.96796, 'precision_at_1': 0.75676, 'precision_at_3': 0.44313, 'precision_at_5': 0.29493, 'precision_at_10': 0.15743, 'precision_at_20': 0.08193, 'precision_at_100': 0.0172, 'precision_at_1000': 0.00184, 'mrr_at_1': 0.7567567567567568, 'mrr_at_3': 0.8026463963963962, 'mrr_at_5': 0.809065315315315, 'mrr_at_10': 0.8111593736593736, 'mrr_at_20': 0.8123800402389797, 'mrr_at_100': 0.8129820393113771, 'mrr_at_1000': 0.8131176819899872, 'nauc_ndcg_at_1_max': np.float64(0.6004409767078538), 'nauc_ndcg_at_1_std': np.float64(0.3056509437634208), 'nauc_ndcg_at_1_diff1': np.float64(0.733564685115092), 'nauc_ndcg_at_3_max': np.float64(0.6092729334025931), 'nauc_ndcg_at_3_std': np.float64(0.25866032885907), 'nauc_ndcg_at_3_diff1': np.float64(0.6054013951584047), 'nauc_ndcg_at_5_max': np.float64(0.6509906586415192), 'nauc_ndcg_at_5_std': np.float64(0.30210068484335106), 'nauc_ndcg_at_5_diff1': np.float64(0.6238418504187758), 'nauc_ndcg_at_10_max': np.float64(0.677901974773586), 'nauc_ndcg_at_10_std': np.float64(0.35987771021811943), 'nauc_ndcg_at_10_diff1': np.float64(0.6302885124429262), 'nauc_ndcg_at_20_max': np.float64(0.6768232098229742), 'nauc_ndcg_at_20_std': np.float64(0.3688374813640457), 'nauc_ndcg_at_20_diff1': np.float64(0.6284643385980219), 'nauc_ndcg_at_100_max': np.float64(0.6768630279285994), 'nauc_ndcg_at_100_std': np.float64(0.37843517651343045), 'nauc_ndcg_at_100_diff1': np.float64(0.6359961983984979), 'nauc_ndcg_at_1000_max': np.float64(0.6658318500784468), 'nauc_ndcg_at_1000_std': np.float64(0.3613327838786333), 'nauc_ndcg_at_1000_diff1': np.float64(0.6338473482311605), 'nauc_map_at_1_max': np.float64(0.2789519671066579), 'nauc_map_at_1_std': np.float64(0.043338484369368206), 'nauc_map_at_1_diff1': np.float64(0.6606149953272771), 'nauc_map_at_3_max': np.float64(0.5605227755844461), 'nauc_map_at_3_std': np.float64(0.2104961965183136), 'nauc_map_at_3_diff1': np.float64(0.5916665330995543), 'nauc_map_at_5_max': np.float64(0.5977220283801926), 'nauc_map_at_5_std': np.float64(0.239568588369421), 'nauc_map_at_5_diff1': np.float64(0.6012828801837301), 'nauc_map_at_10_max': np.float64(0.6147408260448912), 'nauc_map_at_10_std': np.float64(0.27396835761844074), 'nauc_map_at_10_diff1': np.float64(0.6057452723427406), 'nauc_map_at_20_max': np.float64(0.6143563208405669), 'nauc_map_at_20_std': np.float64(0.276742270435723), 'nauc_map_at_20_diff1': np.float64(0.6050594418976999), 'nauc_map_at_100_max': np.float64(0.6147329654986178), 'nauc_map_at_100_std': np.float64(0.27839664065266817), 'nauc_map_at_100_diff1': np.float64(0.6074610172189073), 'nauc_map_at_1000_max': np.float64(0.6142808799071932), 'nauc_map_at_1000_std': np.float64(0.2777535403105099), 'nauc_map_at_1000_diff1': np.float64(0.6073564845705162), 'nauc_recall_at_1_max': np.float64(0.2789519671066579), 'nauc_recall_at_1_std': np.float64(0.043338484369368206), 'nauc_recall_at_1_diff1': np.float64(0.6606149953272771), 'nauc_recall_at_3_max': np.float64(0.6195795055811252), 'nauc_recall_at_3_std': np.float64(0.25210116535419186), 'nauc_recall_at_3_diff1': np.float64(0.5549790197723918), 'nauc_recall_at_5_max': np.float64(0.7135500268808825), 'nauc_recall_at_5_std': np.float64(0.3504720792523775), 'nauc_recall_at_5_diff1': np.float64(0.584423609937162), 'nauc_recall_at_10_max': np.float64(0.8028881422138773), 'nauc_recall_at_10_std': np.float64(0.5280584453731186), 'nauc_recall_at_10_diff1': np.float64(0.5943289326994741), 'nauc_recall_at_20_max': np.float64(0.8287976348105712), 'nauc_recall_at_20_std': np.float64(0.6138570052685672), 'nauc_recall_at_20_diff1': np.float64(0.5813900968151912), 'nauc_recall_at_100_max': np.float64(0.885920841896125), 'nauc_recall_at_100_std': np.float64(0.7925130360150211), 'nauc_recall_at_100_diff1': np.float64(0.620790115513722), 'nauc_recall_at_1000_max': np.float64(0.8893951650461698), 'nauc_recall_at_1000_std': np.float64(0.908942266283279), 'nauc_recall_at_1000_diff1': np.float64(0.5511369328228183), 'nauc_precision_at_1_max': np.float64(0.6004409767078538), 'nauc_precision_at_1_std': np.float64(0.3056509437634208), 'nauc_precision_at_1_diff1': np.float64(0.733564685115092), 'nauc_precision_at_3_max': np.float64(0.3897633058892868), 'nauc_precision_at_3_std': np.float64(0.2660099232096745), 'nauc_precision_at_3_diff1': np.float64(-0.0033508590425714883), 'nauc_precision_at_5_max': np.float64(0.3249889835054694), 'nauc_precision_at_5_std': np.float64(0.25654282884764673), 'nauc_precision_at_5_diff1': np.float64(-0.08105324547471025), 'nauc_precision_at_10_max': np.float64(0.2816031935192935), 'nauc_precision_at_10_std': np.float64(0.30570851296675766), 'nauc_precision_at_10_diff1': np.float64(-0.13641666339761727), 'nauc_precision_at_20_max': np.float64(0.22895177335346711), 'nauc_precision_at_20_std': np.float64(0.29028521348267383), 'nauc_precision_at_20_diff1': np.float64(-0.18962238004033924), 'nauc_precision_at_100_max': np.float64(0.15596081334229617), 'nauc_precision_at_100_std': np.float64(0.267173695536987), 'nauc_precision_at_100_diff1': np.float64(-0.23352187794170565), 'nauc_precision_at_1000_max': np.float64(0.0067781404379028245), 'nauc_precision_at_1000_std': np.float64(0.15395949020431401), 'nauc_precision_at_1000_diff1': np.float64(-0.35990568904125725), 'nauc_mrr_at_1_max': np.float64(0.6004409767078538), 'nauc_mrr_at_1_std': np.float64(0.3056509437634208), 'nauc_mrr_at_1_diff1': np.float64(0.733564685115092), 'nauc_mrr_at_3_max': np.float64(0.68914836868804), 'nauc_mrr_at_3_std': np.float64(0.38332225603422865), 'nauc_mrr_at_3_diff1': np.float64(0.7186594739549138), 'nauc_mrr_at_5_max': np.float64(0.6888801228180421), 'nauc_mrr_at_5_std': np.float64(0.39270866874049193), 'nauc_mrr_at_5_diff1': np.float64(0.7209733355169085), 'nauc_mrr_at_10_max': np.float64(0.6897440891787184), 'nauc_mrr_at_10_std': np.float64(0.3963588333134652), 'nauc_mrr_at_10_diff1': np.float64(0.7208324628160704), 'nauc_mrr_at_20_max': np.float64(0.688336867623408), 'nauc_mrr_at_20_std': np.float64(0.39657236146996266), 'nauc_mrr_at_20_diff1': np.float64(0.7206297856582866), 'nauc_mrr_at_100_max': np.float64(0.6877110638254341), 'nauc_mrr_at_100_std': np.float64(0.3964536952924918), 'nauc_mrr_at_100_diff1': np.float64(0.7204224854441412), 'nauc_mrr_at_1000_max': np.float64(0.6874919147005658), 'nauc_mrr_at_1000_std': np.float64(0.3960669270046734), 'nauc_mrr_at_1000_diff1': np.float64(0.7204077645198788), 'main_score': 0.79405}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  50%|█████     | 2/4 [00:00<00:00, 16.61it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 17.29it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 17.12it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/23 [00:00<?, ?it/s]Batches:   9%|▊         | 2/23 [00:02<00:23,  1.10s/it]Batches:  13%|█▎        | 3/23 [00:03<00:23,  1.18s/it]Batches:  17%|█▋        | 4/23 [00:04<00:22,  1.18s/it]Batches:  22%|██▏       | 5/23 [00:05<00:20,  1.13s/it]Batches:  26%|██▌       | 6/23 [00:06<00:18,  1.08s/it]Batches:  30%|███       | 7/23 [00:07<00:16,  1.01s/it]Batches:  35%|███▍      | 8/23 [00:08<00:14,  1.04it/s]Batches:  39%|███▉      | 9/23 [00:09<00:13,  1.07it/s]Batches:  43%|████▎     | 10/23 [00:10<00:11,  1.09it/s]Batches:  48%|████▊     | 11/23 [00:10<00:10,  1.14it/s]Batches:  52%|█████▏    | 12/23 [00:11<00:09,  1.18it/s]Batches:  57%|█████▋    | 13/23 [00:12<00:08,  1.24it/s]Batches:  61%|██████    | 14/23 [00:13<00:06,  1.31it/s]Batches:  65%|██████▌   | 15/23 [00:13<00:05,  1.37it/s]Batches:  70%|██████▉   | 16/23 [00:14<00:04,  1.45it/s]Batches:  74%|███████▍  | 17/23 [00:14<00:03,  1.54it/s]Batches:  78%|███████▊  | 18/23 [00:15<00:03,  1.65it/s]Batches:  83%|████████▎ | 19/23 [00:15<00:02,  1.77it/s]Batches:  87%|████████▋ | 20/23 [00:16<00:01,  1.99it/s]Batches:  91%|█████████▏| 21/23 [00:16<00:00,  2.22it/s]Batches:  96%|█████████▌| 22/23 [00:16<00:00,  2.65it/s]Batches: 100%|██████████| 23/23 [00:16<00:00,  3.30it/s]Batches: 100%|██████████| 23/23 [00:16<00:00,  1.36it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 17.27 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 17.40 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.67544, 'ndcg_at_3': 0.79031, 'ndcg_at_5': 0.81637, 'ndcg_at_10': 0.83008, 'ndcg_at_20': 0.83656, 'ndcg_at_100': 0.83656, 'ndcg_at_1000': 0.83656, 'map_at_1': 0.67544, 'map_at_3': 0.76316, 'map_at_5': 0.77807, 'map_at_10': 0.78346, 'map_at_20': 0.78514, 'map_at_100': 0.78514, 'map_at_1000': 0.78514, 'recall_at_1': 0.67544, 'recall_at_3': 0.86842, 'recall_at_5': 0.92982, 'recall_at_10': 0.97368, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.67544, 'precision_at_3': 0.28947, 'precision_at_5': 0.18596, 'precision_at_10': 0.09737, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6754385964912281, 'mrr_at_3': 0.763157894736842, 'mrr_at_5': 0.7780701754385964, 'mrr_at_10': 0.7834551656920076, 'mrr_at_20': 0.7851364522417152, 'mrr_at_100': 0.7851364522417152, 'mrr_at_1000': 0.7851364522417152, 'nauc_ndcg_at_1_max': np.float64(0.336170140077049), 'nauc_ndcg_at_1_std': np.float64(-0.414109409881053), 'nauc_ndcg_at_1_diff1': np.float64(0.7458196841797787), 'nauc_ndcg_at_3_max': np.float64(0.48018090636879757), 'nauc_ndcg_at_3_std': np.float64(-0.35255980074276044), 'nauc_ndcg_at_3_diff1': np.float64(0.7579191887220348), 'nauc_ndcg_at_5_max': np.float64(0.46033083419612225), 'nauc_ndcg_at_5_std': np.float64(-0.3737451683555684), 'nauc_ndcg_at_5_diff1': np.float64(0.7420060164656852), 'nauc_ndcg_at_10_max': np.float64(0.427014191152891), 'nauc_ndcg_at_10_std': np.float64(-0.43143047149879826), 'nauc_ndcg_at_10_diff1': np.float64(0.7477939461929645), 'nauc_ndcg_at_20_max': np.float64(0.4183290864437548), 'nauc_ndcg_at_20_std': np.float64(-0.40438403097706516), 'nauc_ndcg_at_20_diff1': np.float64(0.7479959191104514), 'nauc_ndcg_at_100_max': np.float64(0.4183290864437548), 'nauc_ndcg_at_100_std': np.float64(-0.40438403097706516), 'nauc_ndcg_at_100_diff1': np.float64(0.7479959191104514), 'nauc_ndcg_at_1000_max': np.float64(0.4183290864437548), 'nauc_ndcg_at_1000_std': np.float64(-0.40438403097706516), 'nauc_ndcg_at_1000_diff1': np.float64(0.7479959191104514), 'nauc_map_at_1_max': np.float64(0.336170140077049), 'nauc_map_at_1_std': np.float64(-0.414109409881053), 'nauc_map_at_1_diff1': np.float64(0.7458196841797787), 'nauc_map_at_3_max': np.float64(0.43539749968062214), 'nauc_map_at_3_std': np.float64(-0.37847225265122253), 'nauc_map_at_3_diff1': np.float64(0.7539865940326704), 'nauc_map_at_5_max': np.float64(0.4228032046558571), 'nauc_map_at_5_std': np.float64(-0.39011603199971223), 'nauc_map_at_5_diff1': np.float64(0.7459089722049166), 'nauc_map_at_10_max': np.float64(0.4118513196432917), 'nauc_map_at_10_std': np.float64(-0.4096886794877292), 'nauc_map_at_10_diff1': np.float64(0.7480655535449382), 'nauc_map_at_20_max': np.float64(0.40994529514037564), 'nauc_map_at_20_std': np.float64(-0.4041235885308545), 'nauc_map_at_20_diff1': np.float64(0.7480913240467126), 'nauc_map_at_100_max': np.float64(0.40994529514037564), 'nauc_map_at_100_std': np.float64(-0.4041235885308545), 'nauc_map_at_100_diff1': np.float64(0.7480913240467126), 'nauc_map_at_1000_max': np.float64(0.40994529514037564), 'nauc_map_at_1000_std': np.float64(-0.4041235885308545), 'nauc_map_at_1000_diff1': np.float64(0.7480913240467126), 'nauc_recall_at_1_max': np.float64(0.336170140077049), 'nauc_recall_at_1_std': np.float64(-0.414109409881053), 'nauc_recall_at_1_diff1': np.float64(0.7458196841797787), 'nauc_recall_at_3_max': np.float64(0.6905570135610254), 'nauc_recall_at_3_std': np.float64(-0.22618135533654984), 'nauc_recall_at_3_diff1': np.float64(0.7765098273273437), 'nauc_recall_at_5_max': np.float64(0.7510957493307917), 'nauc_recall_at_5_std': np.float64(-0.24381180954894452), 'nauc_recall_at_5_diff1': np.float64(0.7064297107719775), 'nauc_recall_at_10_max': np.float64(0.6148801048337426), 'nauc_recall_at_10_std': np.float64(-1.024257588006983), 'nauc_recall_at_10_diff1': np.float64(0.7424388206277525), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.336170140077049), 'nauc_precision_at_1_std': np.float64(-0.414109409881053), 'nauc_precision_at_1_diff1': np.float64(0.7458196841797787), 'nauc_precision_at_3_max': np.float64(0.690557013561025), 'nauc_precision_at_3_std': np.float64(-0.22618135533655087), 'nauc_precision_at_3_diff1': np.float64(0.7765098273273427), 'nauc_precision_at_5_max': np.float64(0.7510957493307909), 'nauc_precision_at_5_std': np.float64(-0.24381180954894718), 'nauc_precision_at_5_diff1': np.float64(0.7064297107719757), 'nauc_precision_at_10_max': np.float64(0.6148801048337371), 'nauc_precision_at_10_std': np.float64(-1.0242575880069984), 'nauc_precision_at_10_diff1': np.float64(0.7424388206277509), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.336170140077049), 'nauc_mrr_at_1_std': np.float64(-0.414109409881053), 'nauc_mrr_at_1_diff1': np.float64(0.7458196841797787), 'nauc_mrr_at_3_max': np.float64(0.43539749968062214), 'nauc_mrr_at_3_std': np.float64(-0.37847225265122253), 'nauc_mrr_at_3_diff1': np.float64(0.7539865940326704), 'nauc_mrr_at_5_max': np.float64(0.4228032046558571), 'nauc_mrr_at_5_std': np.float64(-0.39011603199971223), 'nauc_mrr_at_5_diff1': np.float64(0.7459089722049166), 'nauc_mrr_at_10_max': np.float64(0.4118513196432917), 'nauc_mrr_at_10_std': np.float64(-0.4096886794877292), 'nauc_mrr_at_10_diff1': np.float64(0.7480655535449382), 'nauc_mrr_at_20_max': np.float64(0.40994529514037564), 'nauc_mrr_at_20_std': np.float64(-0.4041235885308545), 'nauc_mrr_at_20_diff1': np.float64(0.7480913240467126), 'nauc_mrr_at_100_max': np.float64(0.40994529514037564), 'nauc_mrr_at_100_std': np.float64(-0.4041235885308545), 'nauc_mrr_at_100_diff1': np.float64(0.7480913240467126), 'nauc_mrr_at_1000_max': np.float64(0.40994529514037564), 'nauc_mrr_at_1000_std': np.float64(-0.4041235885308545), 'nauc_mrr_at_1000_diff1': np.float64(0.7480913240467126), 'main_score': 0.83008}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches: 100%|██████████| 3/3 [00:00<00:00, 23.33it/s]Batches: 100%|██████████| 3/3 [00:00<00:00, 23.17it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.69it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.53it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.38 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 1.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.67532, 'ndcg_at_3': 0.76685, 'ndcg_at_5': 0.78306, 'ndcg_at_10': 0.80412, 'ndcg_at_20': 0.81099, 'ndcg_at_100': 0.81803, 'ndcg_at_1000': 0.81803, 'map_at_1': 0.67532, 'map_at_3': 0.74459, 'map_at_5': 0.75368, 'map_at_10': 0.76239, 'map_at_20': 0.76444, 'map_at_100': 0.7653, 'map_at_1000': 0.7653, 'recall_at_1': 0.67532, 'recall_at_3': 0.83117, 'recall_at_5': 0.87013, 'recall_at_10': 0.93506, 'recall_at_20': 0.96104, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.67532, 'precision_at_3': 0.27706, 'precision_at_5': 0.17403, 'precision_at_10': 0.09351, 'precision_at_20': 0.04805, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6753246753246753, 'mrr_at_3': 0.7445887445887447, 'mrr_at_5': 0.7536796536796538, 'mrr_at_10': 0.7623891981034839, 'mrr_at_20': 0.7644356365135587, 'mrr_at_100': 0.765300226623, 'mrr_at_1000': 0.765300226623, 'nauc_ndcg_at_1_max': np.float64(0.2923486241773153), 'nauc_ndcg_at_1_std': np.float64(-0.14113187264225374), 'nauc_ndcg_at_1_diff1': np.float64(0.6562465610611244), 'nauc_ndcg_at_3_max': np.float64(0.2957261118765833), 'nauc_ndcg_at_3_std': np.float64(-0.1669115648012619), 'nauc_ndcg_at_3_diff1': np.float64(0.5594550811473704), 'nauc_ndcg_at_5_max': np.float64(0.2715504531622847), 'nauc_ndcg_at_5_std': np.float64(-0.231577091224693), 'nauc_ndcg_at_5_diff1': np.float64(0.5816286642082346), 'nauc_ndcg_at_10_max': np.float64(0.27936017201735985), 'nauc_ndcg_at_10_std': np.float64(-0.23489702342436491), 'nauc_ndcg_at_10_diff1': np.float64(0.5691397820536505), 'nauc_ndcg_at_20_max': np.float64(0.2643206426149416), 'nauc_ndcg_at_20_std': np.float64(-0.1841509467955105), 'nauc_ndcg_at_20_diff1': np.float64(0.5596142899845385), 'nauc_ndcg_at_100_max': np.float64(0.2862629130506407), 'nauc_ndcg_at_100_std': np.float64(-0.1801172856670342), 'nauc_ndcg_at_100_diff1': np.float64(0.5863829285899035), 'nauc_ndcg_at_1000_max': np.float64(0.2862629130506407), 'nauc_ndcg_at_1000_std': np.float64(-0.1801172856670342), 'nauc_ndcg_at_1000_diff1': np.float64(0.5863829285899035), 'nauc_map_at_1_max': np.float64(0.2923486241773153), 'nauc_map_at_1_std': np.float64(-0.14113187264225374), 'nauc_map_at_1_diff1': np.float64(0.6562465610611244), 'nauc_map_at_3_max': np.float64(0.3008896632226807), 'nauc_map_at_3_std': np.float64(-0.15775222111292986), 'nauc_map_at_3_diff1': np.float64(0.5882399698411667), 'nauc_map_at_5_max': np.float64(0.2896018482846817), 'nauc_map_at_5_std': np.float64(-0.1893640157933465), 'nauc_map_at_5_diff1': np.float64(0.6011825802675416), 'nauc_map_at_10_max': np.float64(0.2933935645857382), 'nauc_map_at_10_std': np.float64(-0.1870047943320845), 'nauc_map_at_10_diff1': np.float64(0.596903792453234), 'nauc_map_at_20_max': np.float64(0.2898190873177562), 'nauc_map_at_20_std': np.float64(-0.17399345717993836), 'nauc_map_at_20_diff1': np.float64(0.5948084784833071), 'nauc_map_at_100_max': np.float64(0.2924115950702348), 'nauc_map_at_100_std': np.float64(-0.17318296732546787), 'nauc_map_at_100_diff1': np.float64(0.5979237469677664), 'nauc_map_at_1000_max': np.float64(0.2924115950702348), 'nauc_map_at_1000_std': np.float64(-0.17318296732546787), 'nauc_map_at_1000_diff1': np.float64(0.5979237469677664), 'nauc_recall_at_1_max': np.float64(0.2923486241773153), 'nauc_recall_at_1_std': np.float64(-0.14113187264225374), 'nauc_recall_at_1_diff1': np.float64(0.6562465610611244), 'nauc_recall_at_3_max': np.float64(0.27143597899302946), 'nauc_recall_at_3_std': np.float64(-0.2046222448022942), 'nauc_recall_at_3_diff1': np.float64(0.4436117771546839), 'nauc_recall_at_5_max': np.float64(0.1715034869029567), 'nauc_recall_at_5_std': np.float64(-0.4558217241628853), 'nauc_recall_at_5_diff1': np.float64(0.4887066625206389), 'nauc_recall_at_10_max': np.float64(0.13450912346094304), 'nauc_recall_at_10_std': np.float64(-0.7262196475190429), 'nauc_recall_at_10_diff1': np.float64(0.31051762722087156), 'nauc_recall_at_20_max': np.float64(-0.20163456083415854), 'nauc_recall_at_20_std': np.float64(-0.2453969933433915), 'nauc_recall_at_20_diff1': np.float64(-0.012909070638077955), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2923486241773153), 'nauc_precision_at_1_std': np.float64(-0.14113187264225374), 'nauc_precision_at_1_diff1': np.float64(0.6562465610611244), 'nauc_precision_at_3_max': np.float64(0.2714359789930319), 'nauc_precision_at_3_std': np.float64(-0.20462224480229224), 'nauc_precision_at_3_diff1': np.float64(0.44361177715468525), 'nauc_precision_at_5_max': np.float64(0.1715034869029589), 'nauc_precision_at_5_std': np.float64(-0.45582172416288225), 'nauc_precision_at_5_diff1': np.float64(0.4887066625206391), 'nauc_precision_at_10_max': np.float64(0.13450912346094948), 'nauc_precision_at_10_std': np.float64(-0.7262196475190367), 'nauc_precision_at_10_diff1': np.float64(0.31051762722087517), 'nauc_precision_at_20_max': np.float64(-0.20163456083414846), 'nauc_precision_at_20_std': np.float64(-0.2453969933433873), 'nauc_precision_at_20_diff1': np.float64(-0.012909070638074602), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.2923486241773153), 'nauc_mrr_at_1_std': np.float64(-0.14113187264225374), 'nauc_mrr_at_1_diff1': np.float64(0.6562465610611244), 'nauc_mrr_at_3_max': np.float64(0.3008896632226807), 'nauc_mrr_at_3_std': np.float64(-0.15775222111292986), 'nauc_mrr_at_3_diff1': np.float64(0.5882399698411667), 'nauc_mrr_at_5_max': np.float64(0.2896018482846817), 'nauc_mrr_at_5_std': np.float64(-0.1893640157933465), 'nauc_mrr_at_5_diff1': np.float64(0.6011825802675416), 'nauc_mrr_at_10_max': np.float64(0.2933935645857382), 'nauc_mrr_at_10_std': np.float64(-0.1870047943320845), 'nauc_mrr_at_10_diff1': np.float64(0.596903792453234), 'nauc_mrr_at_20_max': np.float64(0.2898190873177562), 'nauc_mrr_at_20_std': np.float64(-0.17399345717993836), 'nauc_mrr_at_20_diff1': np.float64(0.5948084784833071), 'nauc_mrr_at_100_max': np.float64(0.2924115950702348), 'nauc_mrr_at_100_std': np.float64(-0.17318296732546787), 'nauc_mrr_at_100_diff1': np.float64(0.5979237469677664), 'nauc_mrr_at_1000_max': np.float64(0.2924115950702348), 'nauc_mrr_at_1000_std': np.float64(-0.17318296732546787), 'nauc_mrr_at_1000_diff1': np.float64(0.5979237469677664), 'main_score': 0.80412}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:01, 24.34it/s]Batches:  21%|██        | 6/29 [00:00<00:00, 23.28it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 23.97it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 24.92it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 26.02it/s]Batches:  62%|██████▏   | 18/29 [00:00<00:00, 27.18it/s]Batches:  72%|███████▏  | 21/29 [00:00<00:00, 27.98it/s]Batches:  83%|████████▎ | 24/29 [00:00<00:00, 28.54it/s]Batches:  97%|█████████▋| 28/29 [00:01<00:00, 30.79it/s]Batches: 100%|██████████| 29/29 [00:01<00:00, 27.91it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  4.06it/s]Batches:  19%|█▉        | 3/16 [00:00<00:03,  3.94it/s]Batches:  25%|██▌       | 4/16 [00:01<00:03,  3.93it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  4.08it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.20it/s]Batches:  44%|████▍     | 7/16 [00:01<00:02,  4.33it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  4.50it/s]Batches:  56%|█████▋    | 9/16 [00:02<00:01,  4.74it/s]Batches:  62%|██████▎   | 10/16 [00:02<00:01,  4.94it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.17it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  5.57it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  5.90it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  6.17it/s]Batches:  94%|█████████▍| 15/16 [00:02<00:00,  6.58it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  7.22it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  5.16it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.41 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:00, 28.28it/s]Batches:  21%|██        | 6/29 [00:00<00:00, 26.53it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 26.90it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 27.52it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 28.30it/s]Batches:  66%|██████▌   | 19/29 [00:00<00:00, 29.34it/s]Batches:  79%|███████▉  | 23/29 [00:00<00:00, 30.59it/s]Batches:  93%|█████████▎| 27/29 [00:00<00:00, 32.59it/s]Batches: 100%|██████████| 29/29 [00:00<00:00, 30.56it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  4.08it/s]Batches:  19%|█▉        | 3/16 [00:00<00:03,  3.94it/s]Batches:  25%|██▌       | 4/16 [00:01<00:03,  3.92it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  4.07it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.19it/s]Batches:  44%|████▍     | 7/16 [00:01<00:02,  4.32it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  4.48it/s]Batches:  56%|█████▋    | 9/16 [00:02<00:01,  4.72it/s]Batches:  62%|██████▎   | 10/16 [00:02<00:01,  4.92it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.17it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  5.54it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  5.86it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  6.13it/s]Batches:  94%|█████████▍| 15/16 [00:03<00:00,  6.56it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  7.20it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  5.14it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.34 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:01, 25.15it/s]Batches:  21%|██        | 6/29 [00:00<00:00, 23.53it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 24.10it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 25.00it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 26.01it/s]Batches:  62%|██████▏   | 18/29 [00:00<00:00, 27.15it/s]Batches:  72%|███████▏  | 21/29 [00:00<00:00, 27.95it/s]Batches:  83%|████████▎ | 24/29 [00:00<00:00, 28.46it/s]Batches:  97%|█████████▋| 28/29 [00:01<00:00, 30.55it/s]Batches: 100%|██████████| 29/29 [00:01<00:00, 27.92it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  4.49it/s]Batches:  19%|█▉        | 3/16 [00:00<00:02,  4.52it/s]Batches:  25%|██▌       | 4/16 [00:00<00:02,  4.46it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  4.56it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.74it/s]Batches:  44%|████▍     | 7/16 [00:01<00:01,  4.94it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  5.20it/s]Batches:  56%|█████▋    | 9/16 [00:01<00:01,  5.36it/s]Batches:  62%|██████▎   | 10/16 [00:01<00:01,  5.64it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.87it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  6.16it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  6.51it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  6.79it/s]Batches:  94%|█████████▍| 15/16 [00:02<00:00,  7.40it/s]Batches: 100%|██████████| 16/16 [00:02<00:00,  7.99it/s]Batches: 100%|██████████| 16/16 [00:02<00:00,  5.80it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.07 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 14.15 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.87889, 'ndcg_at_3': 0.9185, 'ndcg_at_5': 0.92577, 'ndcg_at_10': 0.93164, 'ndcg_at_20': 0.93303, 'ndcg_at_100': 0.93448, 'ndcg_at_1000': 0.93539, 'map_at_1': 0.87889, 'map_at_3': 0.90944, 'map_at_5': 0.91344, 'map_at_10': 0.91594, 'map_at_20': 0.91631, 'map_at_100': 0.91652, 'map_at_1000': 0.91656, 'recall_at_1': 0.87889, 'recall_at_3': 0.94444, 'recall_at_5': 0.96222, 'recall_at_10': 0.98, 'recall_at_20': 0.98556, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.87889, 'precision_at_3': 0.31481, 'precision_at_5': 0.19244, 'precision_at_10': 0.098, 'precision_at_20': 0.04928, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8788888888888889, 'mrr_at_3': 0.9094444444444446, 'mrr_at_5': 0.9134444444444446, 'mrr_at_10': 0.915938712522046, 'mrr_at_20': 0.9163125423958758, 'mrr_at_100': 0.9165196696089475, 'mrr_at_1000': 0.9165613420972883, 'nauc_ndcg_at_1_max': np.float64(0.7360338011378074), 'nauc_ndcg_at_1_std': np.float64(0.055233653871440136), 'nauc_ndcg_at_1_diff1': np.float64(0.9182364852426823), 'nauc_ndcg_at_3_max': np.float64(0.7833482042650488), 'nauc_ndcg_at_3_std': np.float64(0.09610521311242015), 'nauc_ndcg_at_3_diff1': np.float64(0.9121176059457036), 'nauc_ndcg_at_5_max': np.float64(0.7764607899687949), 'nauc_ndcg_at_5_std': np.float64(0.09570954287447543), 'nauc_ndcg_at_5_diff1': np.float64(0.9141395218023763), 'nauc_ndcg_at_10_max': np.float64(0.769537674473529), 'nauc_ndcg_at_10_std': np.float64(0.09838891524632452), 'nauc_ndcg_at_10_diff1': np.float64(0.914857655889842), 'nauc_ndcg_at_20_max': np.float64(0.7676635353081863), 'nauc_ndcg_at_20_std': np.float64(0.08682263886524719), 'nauc_ndcg_at_20_diff1': np.float64(0.91593068556539), 'nauc_ndcg_at_100_max': np.float64(0.7672413292997466), 'nauc_ndcg_at_100_std': np.float64(0.09739655293777892), 'nauc_ndcg_at_100_diff1': np.float64(0.9152384365333261), 'nauc_ndcg_at_1000_max': np.float64(0.7658476741472501), 'nauc_ndcg_at_1000_std': np.float64(0.08783028480120193), 'nauc_ndcg_at_1000_diff1': np.float64(0.9145982546159986), 'nauc_map_at_1_max': np.float64(0.7360338011378074), 'nauc_map_at_1_std': np.float64(0.055233653871440136), 'nauc_map_at_1_diff1': np.float64(0.9182364852426823), 'nauc_map_at_3_max': np.float64(0.7698593668502859), 'nauc_map_at_3_std': np.float64(0.08250297146424689), 'nauc_map_at_3_diff1': np.float64(0.9131876782636175), 'nauc_map_at_5_max': np.float64(0.7658910154050281), 'nauc_map_at_5_std': np.float64(0.08177793016479339), 'nauc_map_at_5_diff1': np.float64(0.9140255060135355), 'nauc_map_at_10_max': np.float64(0.763197065026625), 'nauc_map_at_10_std': np.float64(0.08254448049332629), 'nauc_map_at_10_diff1': np.float64(0.9143139179478519), 'nauc_map_at_20_max': np.float64(0.7627389376229389), 'nauc_map_at_20_std': np.float64(0.0799713735263409), 'nauc_map_at_20_diff1': np.float64(0.9145308131541325), 'nauc_map_at_100_max': np.float64(0.7626093328877492), 'nauc_map_at_100_std': np.float64(0.08115864225106753), 'nauc_map_at_100_diff1': np.float64(0.9144325380134781), 'nauc_map_at_1000_max': np.float64(0.7625594223308878), 'nauc_map_at_1000_std': np.float64(0.08078533832109351), 'nauc_map_at_1000_diff1': np.float64(0.9144018424312078), 'nauc_recall_at_1_max': np.float64(0.7360338011378074), 'nauc_recall_at_1_std': np.float64(0.055233653871440136), 'nauc_recall_at_1_diff1': np.float64(0.9182364852426823), 'nauc_recall_at_3_max': np.float64(0.8447338935574227), 'nauc_recall_at_3_std': np.float64(0.15945845004668527), 'nauc_recall_at_3_diff1': np.float64(0.907749766573295), 'nauc_recall_at_5_max': np.float64(0.8416817707475147), 'nauc_recall_at_5_std': np.float64(0.18645301257758004), 'nauc_recall_at_5_diff1': np.float64(0.9168589004229126), 'nauc_recall_at_10_max': np.float64(0.8285610540512551), 'nauc_recall_at_10_std': np.float64(0.2889563232700448), 'nauc_recall_at_10_diff1': np.float64(0.9255628177196826), 'nauc_recall_at_20_max': np.float64(0.8182862888745368), 'nauc_recall_at_20_std': np.float64(0.15194282841342197), 'nauc_recall_at_20_diff1': np.float64(0.9497234791352488), 'nauc_recall_at_100_max': np.float64(0.8665577342047819), 'nauc_recall_at_100_std': np.float64(0.7584811702458742), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7360338011378074), 'nauc_precision_at_1_std': np.float64(0.055233653871440136), 'nauc_precision_at_1_diff1': np.float64(0.9182364852426823), 'nauc_precision_at_3_max': np.float64(0.8447338935574222), 'nauc_precision_at_3_std': np.float64(0.15945845004668682), 'nauc_precision_at_3_diff1': np.float64(0.9077497665732935), 'nauc_precision_at_5_max': np.float64(0.8416817707475116), 'nauc_precision_at_5_std': np.float64(0.18645301257757552), 'nauc_precision_at_5_diff1': np.float64(0.9168589004229141), 'nauc_precision_at_10_max': np.float64(0.8285610540512508), 'nauc_precision_at_10_std': np.float64(0.2889563232700455), 'nauc_precision_at_10_diff1': np.float64(0.9255628177196747), 'nauc_precision_at_20_max': np.float64(0.8182862888745052), 'nauc_precision_at_20_std': np.float64(0.1519428284134084), 'nauc_precision_at_20_diff1': np.float64(0.949723479135242), 'nauc_precision_at_100_max': np.float64(0.8665577342047719), 'nauc_precision_at_100_std': np.float64(0.7584811702458871), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505334), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7360338011378074), 'nauc_mrr_at_1_std': np.float64(0.055233653871440136), 'nauc_mrr_at_1_diff1': np.float64(0.9182364852426823), 'nauc_mrr_at_3_max': np.float64(0.7698593668502859), 'nauc_mrr_at_3_std': np.float64(0.08250297146424689), 'nauc_mrr_at_3_diff1': np.float64(0.9131876782636175), 'nauc_mrr_at_5_max': np.float64(0.7658910154050281), 'nauc_mrr_at_5_std': np.float64(0.08177793016479339), 'nauc_mrr_at_5_diff1': np.float64(0.9140255060135355), 'nauc_mrr_at_10_max': np.float64(0.763197065026625), 'nauc_mrr_at_10_std': np.float64(0.08254448049332629), 'nauc_mrr_at_10_diff1': np.float64(0.9143139179478519), 'nauc_mrr_at_20_max': np.float64(0.7627389376229389), 'nauc_mrr_at_20_std': np.float64(0.0799713735263409), 'nauc_mrr_at_20_diff1': np.float64(0.9145308131541325), 'nauc_mrr_at_100_max': np.float64(0.7626093328877492), 'nauc_mrr_at_100_std': np.float64(0.08115864225106753), 'nauc_mrr_at_100_diff1': np.float64(0.9144325380134781), 'nauc_mrr_at_1000_max': np.float64(0.7625594223308878), 'nauc_mrr_at_1000_std': np.float64(0.08078533832109351), 'nauc_mrr_at_1000_diff1': np.float64(0.9144018424312078), 'main_score': 0.93164}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.83556, 'ndcg_at_3': 0.88803, 'ndcg_at_5': 0.89668, 'ndcg_at_10': 0.90365, 'ndcg_at_20': 0.90829, 'ndcg_at_100': 0.91028, 'ndcg_at_1000': 0.911, 'map_at_1': 0.83556, 'map_at_3': 0.87574, 'map_at_5': 0.88052, 'map_at_10': 0.88327, 'map_at_20': 0.88462, 'map_at_100': 0.88495, 'map_at_1000': 0.88497, 'recall_at_1': 0.83556, 'recall_at_3': 0.92333, 'recall_at_5': 0.94444, 'recall_at_10': 0.96667, 'recall_at_20': 0.98444, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.83556, 'precision_at_3': 0.30778, 'precision_at_5': 0.18889, 'precision_at_10': 0.09667, 'precision_at_20': 0.04922, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8355555555555556, 'mrr_at_3': 0.8757407407407409, 'mrr_at_5': 0.8805185185185187, 'mrr_at_10': 0.8832663139329808, 'mrr_at_20': 0.8846182396703555, 'mrr_at_100': 0.8849464937287592, 'mrr_at_1000': 0.8849749325397649, 'nauc_ndcg_at_1_max': np.float64(0.6620807511237589), 'nauc_ndcg_at_1_std': np.float64(0.05348498550416149), 'nauc_ndcg_at_1_diff1': np.float64(0.8673830358805222), 'nauc_ndcg_at_3_max': np.float64(0.7046413690365483), 'nauc_ndcg_at_3_std': np.float64(0.12717513638981803), 'nauc_ndcg_at_3_diff1': np.float64(0.8509468666257631), 'nauc_ndcg_at_5_max': np.float64(0.7041140837858083), 'nauc_ndcg_at_5_std': np.float64(0.12814143423088434), 'nauc_ndcg_at_5_diff1': np.float64(0.849510553173776), 'nauc_ndcg_at_10_max': np.float64(0.701026901481694), 'nauc_ndcg_at_10_std': np.float64(0.14075623622130473), 'nauc_ndcg_at_10_diff1': np.float64(0.8477011560099511), 'nauc_ndcg_at_20_max': np.float64(0.6966836378939858), 'nauc_ndcg_at_20_std': np.float64(0.12927198789204877), 'nauc_ndcg_at_20_diff1': np.float64(0.8495343252357374), 'nauc_ndcg_at_100_max': np.float64(0.6943035655845461), 'nauc_ndcg_at_100_std': np.float64(0.11991478266036447), 'nauc_ndcg_at_100_diff1': np.float64(0.8508516789196892), 'nauc_ndcg_at_1000_max': np.float64(0.6933498509696858), 'nauc_ndcg_at_1000_std': np.float64(0.11443873671850584), 'nauc_ndcg_at_1000_diff1': np.float64(0.8527012462802727), 'nauc_map_at_1_max': np.float64(0.6620807511237589), 'nauc_map_at_1_std': np.float64(0.05348498550416149), 'nauc_map_at_1_diff1': np.float64(0.8673830358805222), 'nauc_map_at_3_max': np.float64(0.6940007000047526), 'nauc_map_at_3_std': np.float64(0.10619835484479548), 'nauc_map_at_3_diff1': np.float64(0.8556449045847431), 'nauc_map_at_5_max': np.float64(0.6928210519115601), 'nauc_map_at_5_std': np.float64(0.10521440661745296), 'nauc_map_at_5_diff1': np.float64(0.8549919507891112), 'nauc_map_at_10_max': np.float64(0.691361711480954), 'nauc_map_at_10_std': np.float64(0.10799233041904452), 'nauc_map_at_10_diff1': np.float64(0.8545939543607107), 'nauc_map_at_20_max': np.float64(0.6902918325884226), 'nauc_map_at_20_std': np.float64(0.10508842671827126), 'nauc_map_at_20_diff1': np.float64(0.8550816588802468), 'nauc_map_at_100_max': np.float64(0.6898299533073919), 'nauc_map_at_100_std': np.float64(0.10369584797022877), 'nauc_map_at_100_diff1': np.float64(0.855275356255775), 'nauc_map_at_1000_max': np.float64(0.6898140243410444), 'nauc_map_at_1000_std': np.float64(0.10353937270721077), 'nauc_map_at_1000_diff1': np.float64(0.855347628670212), 'nauc_recall_at_1_max': np.float64(0.6620807511237589), 'nauc_recall_at_1_std': np.float64(0.05348498550416149), 'nauc_recall_at_1_diff1': np.float64(0.8673830358805222), 'nauc_recall_at_3_max': np.float64(0.7509776857602934), 'nauc_recall_at_3_std': np.float64(0.22059161828982624), 'nauc_recall_at_3_diff1': np.float64(0.8300112315457603), 'nauc_recall_at_5_max': np.float64(0.7704388422035484), 'nauc_recall_at_5_std': np.float64(0.2653127917833834), 'nauc_recall_at_5_diff1': np.float64(0.8170961718020519), 'nauc_recall_at_10_max': np.float64(0.7902427637721744), 'nauc_recall_at_10_std': np.float64(0.48392468098350666), 'nauc_recall_at_10_diff1': np.float64(0.778260192966078), 'nauc_recall_at_20_max': np.float64(0.7947512338268609), 'nauc_recall_at_20_std': np.float64(0.6165466186474606), 'nauc_recall_at_20_diff1': np.float64(0.7402627717753743), 'nauc_recall_at_100_max': np.float64(0.8193277310924408), 'nauc_recall_at_100_std': np.float64(0.782446311858087), 'nauc_recall_at_100_diff1': np.float64(0.6438842203548035), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6620807511237589), 'nauc_precision_at_1_std': np.float64(0.05348498550416149), 'nauc_precision_at_1_diff1': np.float64(0.8673830358805222), 'nauc_precision_at_3_max': np.float64(0.7509776857602969), 'nauc_precision_at_3_std': np.float64(0.22059161828983137), 'nauc_precision_at_3_diff1': np.float64(0.8300112315457603), 'nauc_precision_at_5_max': np.float64(0.7704388422035447), 'nauc_precision_at_5_std': np.float64(0.2653127917833765), 'nauc_precision_at_5_diff1': np.float64(0.8170961718020517), 'nauc_precision_at_10_max': np.float64(0.790242763772179), 'nauc_precision_at_10_std': np.float64(0.48392468098350033), 'nauc_precision_at_10_diff1': np.float64(0.7782601929660737), 'nauc_precision_at_20_max': np.float64(0.7947512338268672), 'nauc_precision_at_20_std': np.float64(0.6165466186474461), 'nauc_precision_at_20_diff1': np.float64(0.7402627717753778), 'nauc_precision_at_100_max': np.float64(0.819327731092435), 'nauc_precision_at_100_std': np.float64(0.7824463118580629), 'nauc_precision_at_100_diff1': np.float64(0.6438842203548022), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6620807511237589), 'nauc_mrr_at_1_std': np.float64(0.05348498550416149), 'nauc_mrr_at_1_diff1': np.float64(0.8673830358805222), 'nauc_mrr_at_3_max': np.float64(0.6940007000047526), 'nauc_mrr_at_3_std': np.float64(0.10619835484479548), 'nauc_mrr_at_3_diff1': np.float64(0.8556449045847431), 'nauc_mrr_at_5_max': np.float64(0.6928210519115601), 'nauc_mrr_at_5_std': np.float64(0.10521440661745296), 'nauc_mrr_at_5_diff1': np.float64(0.8549919507891112), 'nauc_mrr_at_10_max': np.float64(0.691361711480954), 'nauc_mrr_at_10_std': np.float64(0.10799233041904452), 'nauc_mrr_at_10_diff1': np.float64(0.8545939543607107), 'nauc_mrr_at_20_max': np.float64(0.6902918325884226), 'nauc_mrr_at_20_std': np.float64(0.10508842671827126), 'nauc_mrr_at_20_diff1': np.float64(0.8550816588802468), 'nauc_mrr_at_100_max': np.float64(0.6898299533073919), 'nauc_mrr_at_100_std': np.float64(0.10369584797022877), 'nauc_mrr_at_100_diff1': np.float64(0.855275356255775), 'nauc_mrr_at_1000_max': np.float64(0.6898140243410444), 'nauc_mrr_at_1000_std': np.float64(0.10353937270721077), 'nauc_mrr_at_1000_diff1': np.float64(0.855347628670212), 'main_score': 0.90365}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.79667, 'ndcg_at_3': 0.86325, 'ndcg_at_5': 0.87693, 'ndcg_at_10': 0.88363, 'ndcg_at_20': 0.88648, 'ndcg_at_100': 0.89038, 'ndcg_at_1000': 0.89116, 'map_at_1': 0.79667, 'map_at_3': 0.84741, 'map_at_5': 0.85496, 'map_at_10': 0.85787, 'map_at_20': 0.85867, 'map_at_100': 0.8592, 'map_at_1000': 0.85925, 'recall_at_1': 0.79667, 'recall_at_3': 0.90889, 'recall_at_5': 0.94222, 'recall_at_10': 0.96222, 'recall_at_20': 0.97333, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.79667, 'precision_at_3': 0.30296, 'precision_at_5': 0.18844, 'precision_at_10': 0.09622, 'precision_at_20': 0.04867, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7966666666666666, 'mrr_at_3': 0.8474074074074077, 'mrr_at_5': 0.8549629629629634, 'mrr_at_10': 0.8578650793650797, 'mrr_at_20': 0.8586734267672094, 'mrr_at_100': 0.8592039439643446, 'mrr_at_1000': 0.8592467110152766, 'nauc_ndcg_at_1_max': np.float64(0.6163243388374275), 'nauc_ndcg_at_1_std': np.float64(0.07164637905101645), 'nauc_ndcg_at_1_diff1': np.float64(0.8702250130821565), 'nauc_ndcg_at_3_max': np.float64(0.6625695478441651), 'nauc_ndcg_at_3_std': np.float64(0.13701665752617875), 'nauc_ndcg_at_3_diff1': np.float64(0.8507464933321702), 'nauc_ndcg_at_5_max': np.float64(0.6557638094232093), 'nauc_ndcg_at_5_std': np.float64(0.15745646851391326), 'nauc_ndcg_at_5_diff1': np.float64(0.8570505968282397), 'nauc_ndcg_at_10_max': np.float64(0.6475703207508358), 'nauc_ndcg_at_10_std': np.float64(0.1422797846281043), 'nauc_ndcg_at_10_diff1': np.float64(0.8567728449023886), 'nauc_ndcg_at_20_max': np.float64(0.6510508012250286), 'nauc_ndcg_at_20_std': np.float64(0.15212758928270584), 'nauc_ndcg_at_20_diff1': np.float64(0.8594313083100255), 'nauc_ndcg_at_100_max': np.float64(0.6464585395890068), 'nauc_ndcg_at_100_std': np.float64(0.13631972155577624), 'nauc_ndcg_at_100_diff1': np.float64(0.8588633851935984), 'nauc_ndcg_at_1000_max': np.float64(0.645465796921435), 'nauc_ndcg_at_1000_std': np.float64(0.13240406904224863), 'nauc_ndcg_at_1000_diff1': np.float64(0.8588358520863845), 'nauc_map_at_1_max': np.float64(0.6163243388374275), 'nauc_map_at_1_std': np.float64(0.07164637905101645), 'nauc_map_at_1_diff1': np.float64(0.8702250130821565), 'nauc_map_at_3_max': np.float64(0.6492018403346966), 'nauc_map_at_3_std': np.float64(0.11860755714696808), 'nauc_map_at_3_diff1': np.float64(0.8558682567291922), 'nauc_map_at_5_max': np.float64(0.6449249342806429), 'nauc_map_at_5_std': np.float64(0.1277634095588614), 'nauc_map_at_5_diff1': np.float64(0.8589466899055904), 'nauc_map_at_10_max': np.float64(0.641709583131691), 'nauc_map_at_10_std': np.float64(0.121384800872592), 'nauc_map_at_10_diff1': np.float64(0.8588613413517707), 'nauc_map_at_20_max': np.float64(0.6425710944098023), 'nauc_map_at_20_std': np.float64(0.1237131469715452), 'nauc_map_at_20_diff1': np.float64(0.8594870506841481), 'nauc_map_at_100_max': np.float64(0.6419321905712058), 'nauc_map_at_100_std': np.float64(0.12179724364431067), 'nauc_map_at_100_diff1': np.float64(0.8594694509113175), 'nauc_map_at_1000_max': np.float64(0.6418851630612379), 'nauc_map_at_1000_std': np.float64(0.12161212115529317), 'nauc_map_at_1000_diff1': np.float64(0.859468841140476), 'nauc_recall_at_1_max': np.float64(0.6163243388374275), 'nauc_recall_at_1_std': np.float64(0.07164637905101645), 'nauc_recall_at_1_diff1': np.float64(0.8702250130821565), 'nauc_recall_at_3_max': np.float64(0.7232185557149695), 'nauc_recall_at_3_std': np.float64(0.22018970189702047), 'nauc_recall_at_3_diff1': np.float64(0.8278734257930809), 'nauc_recall_at_5_max': np.float64(0.7277167277167285), 'nauc_recall_at_5_std': np.float64(0.3644060188177846), 'nauc_recall_at_5_diff1': np.float64(0.8476980535804093), 'nauc_recall_at_10_max': np.float64(0.695185917504258), 'nauc_recall_at_10_std': np.float64(0.347091777887624), 'nauc_recall_at_10_diff1': np.float64(0.8408716427747571), 'nauc_recall_at_20_max': np.float64(0.7660480859010214), 'nauc_recall_at_20_std': np.float64(0.5798124805477695), 'nauc_recall_at_20_diff1': np.float64(0.8759142545907237), 'nauc_recall_at_100_max': np.float64(0.7735760971055182), 'nauc_recall_at_100_std': np.float64(0.6373482726423895), 'nauc_recall_at_100_diff1': np.float64(0.8627450980392323), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6163243388374275), 'nauc_precision_at_1_std': np.float64(0.07164637905101645), 'nauc_precision_at_1_diff1': np.float64(0.8702250130821565), 'nauc_precision_at_3_max': np.float64(0.7232185557149703), 'nauc_precision_at_3_std': np.float64(0.22018970189701878), 'nauc_precision_at_3_diff1': np.float64(0.8278734257930804), 'nauc_precision_at_5_max': np.float64(0.7277167277167269), 'nauc_precision_at_5_std': np.float64(0.36440601881777845), 'nauc_precision_at_5_diff1': np.float64(0.8476980535804056), 'nauc_precision_at_10_max': np.float64(0.6951859175042543), 'nauc_precision_at_10_std': np.float64(0.3470917778876209), 'nauc_precision_at_10_diff1': np.float64(0.8408716427747522), 'nauc_precision_at_20_max': np.float64(0.7660480859010207), 'nauc_precision_at_20_std': np.float64(0.5798124805477631), 'nauc_precision_at_20_diff1': np.float64(0.8759142545907178), 'nauc_precision_at_100_max': np.float64(0.7735760971054999), 'nauc_precision_at_100_std': np.float64(0.6373482726424144), 'nauc_precision_at_100_diff1': np.float64(0.8627450980391947), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6163243388374275), 'nauc_mrr_at_1_std': np.float64(0.07164637905101645), 'nauc_mrr_at_1_diff1': np.float64(0.8702250130821565), 'nauc_mrr_at_3_max': np.float64(0.6492018403346966), 'nauc_mrr_at_3_std': np.float64(0.11860755714696808), 'nauc_mrr_at_3_diff1': np.float64(0.8558682567291922), 'nauc_mrr_at_5_max': np.float64(0.6449249342806429), 'nauc_mrr_at_5_std': np.float64(0.1277634095588614), 'nauc_mrr_at_5_diff1': np.float64(0.8589466899055904), 'nauc_mrr_at_10_max': np.float64(0.641709583131691), 'nauc_mrr_at_10_std': np.float64(0.121384800872592), 'nauc_mrr_at_10_diff1': np.float64(0.8588613413517707), 'nauc_mrr_at_20_max': np.float64(0.6425710944098023), 'nauc_mrr_at_20_std': np.float64(0.1237131469715452), 'nauc_mrr_at_20_diff1': np.float64(0.8594870506841481), 'nauc_mrr_at_100_max': np.float64(0.6419321905712058), 'nauc_mrr_at_100_std': np.float64(0.12179724364431067), 'nauc_mrr_at_100_diff1': np.float64(0.8594694509113175), 'nauc_mrr_at_1000_max': np.float64(0.6418851630612379), 'nauc_mrr_at_1000_std': np.float64(0.12161212115529317), 'nauc_mrr_at_1000_diff1': np.float64(0.859468841140476), 'main_score': 0.88363}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/21 [00:00<?, ?it/s]Batches:  10%|▉         | 2/21 [00:00<00:00, 19.36it/s]Batches:  24%|██▍       | 5/21 [00:00<00:00, 23.11it/s]Batches:  43%|████▎     | 9/21 [00:00<00:00, 28.44it/s]Batches:  62%|██████▏   | 13/21 [00:00<00:00, 31.98it/s]Batches:  86%|████████▌ | 18/21 [00:00<00:00, 35.92it/s]Batches: 100%|██████████| 21/21 [00:00<00:00, 33.91it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/28 [00:00<?, ?it/s]Batches:   7%|▋         | 2/28 [00:00<00:01, 13.32it/s]Batches:  18%|█▊        | 5/28 [00:00<00:01, 18.78it/s]Batches:  29%|██▊       | 8/28 [00:00<00:00, 22.65it/s]Batches:  39%|███▉      | 11/28 [00:00<00:00, 24.60it/s]Batches:  50%|█████     | 14/28 [00:00<00:00, 26.24it/s]Batches:  64%|██████▍   | 18/28 [00:00<00:00, 28.70it/s]Batches:  79%|███████▊  | 22/28 [00:00<00:00, 31.68it/s]Batches:  96%|█████████▋| 27/28 [00:00<00:00, 36.43it/s]Batches: 100%|██████████| 28/28 [00:00<00:00, 29.80it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.90 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/21 [00:00<?, ?it/s]Batches:  14%|█▍        | 3/21 [00:00<00:00, 20.24it/s]Batches:  29%|██▊       | 6/21 [00:00<00:00, 24.50it/s]Batches:  48%|████▊     | 10/21 [00:00<00:00, 29.74it/s]Batches:  67%|██████▋   | 14/21 [00:00<00:00, 33.07it/s]Batches:  90%|█████████ | 19/21 [00:00<00:00, 36.92it/s]Batches: 100%|██████████| 21/21 [00:00<00:00, 34.05it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/37 [00:00<?, ?it/s]Batches:   5%|▌         | 2/37 [00:02<00:37,  1.06s/it]Batches:   8%|▊         | 3/37 [00:02<00:23,  1.48it/s]Batches:  11%|█         | 4/37 [00:02<00:15,  2.09it/s]Batches:  14%|█▎        | 5/37 [00:02<00:11,  2.77it/s]Batches:  16%|█▌        | 6/37 [00:02<00:08,  3.50it/s]Batches:  19%|█▉        | 7/37 [00:02<00:06,  4.30it/s]Batches:  24%|██▍       | 9/37 [00:02<00:04,  6.05it/s]Batches:  27%|██▋       | 10/37 [00:03<00:04,  6.54it/s]Batches:  32%|███▏      | 12/37 [00:03<00:03,  8.26it/s]Batches:  38%|███▊      | 14/37 [00:03<00:02,  9.73it/s]Batches:  43%|████▎     | 16/37 [00:03<00:01, 10.58it/s]Batches:  49%|████▊     | 18/37 [00:03<00:01, 11.50it/s]Batches:  54%|█████▍    | 20/37 [00:03<00:01, 12.58it/s]Batches:  59%|█████▉    | 22/37 [00:03<00:01, 14.06it/s]Batches:  65%|██████▍   | 24/37 [00:04<00:00, 15.37it/s]Batches:  73%|███████▎  | 27/37 [00:04<00:00, 17.14it/s]Batches:  81%|████████  | 30/37 [00:04<00:00, 18.88it/s]Batches:  89%|████████▉ | 33/37 [00:04<00:00, 21.49it/s]Batches: 100%|██████████| 37/37 [00:04<00:00, 24.67it/s]Batches: 100%|██████████| 37/37 [00:04<00:00,  8.14it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.57 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/20 [00:00<?, ?it/s]Batches:  10%|█         | 2/20 [00:00<00:01, 17.45it/s]Batches:  25%|██▌       | 5/20 [00:00<00:00, 22.45it/s]Batches:  45%|████▌     | 9/20 [00:00<00:00, 28.53it/s]Batches:  65%|██████▌   | 13/20 [00:00<00:00, 32.20it/s]Batches:  90%|█████████ | 18/20 [00:00<00:00, 36.94it/s]Batches: 100%|██████████| 20/20 [00:00<00:00, 33.73it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/28 [00:00<?, ?it/s]Batches:   7%|▋         | 2/28 [00:00<00:01, 13.35it/s]Batches:  18%|█▊        | 5/28 [00:00<00:01, 18.73it/s]Batches:  29%|██▊       | 8/28 [00:00<00:00, 22.55it/s]Batches:  39%|███▉      | 11/28 [00:00<00:00, 24.50it/s]Batches:  50%|█████     | 14/28 [00:00<00:00, 26.12it/s]Batches:  64%|██████▍   | 18/28 [00:00<00:00, 28.55it/s]Batches:  79%|███████▊  | 22/28 [00:00<00:00, 31.55it/s]Batches:  96%|█████████▋| 27/28 [00:00<00:00, 36.36it/s]Batches: 100%|██████████| 28/28 [00:00<00:00, 29.70it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.92 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 11.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.29969, 'ndcg_at_3': 0.30874, 'ndcg_at_5': 0.33207, 'ndcg_at_10': 0.36083, 'ndcg_at_20': 0.38684, 'ndcg_at_100': 0.43808, 'ndcg_at_1000': 0.46559, 'map_at_1': 0.20894, 'map_at_3': 0.2794, 'map_at_5': 0.29826, 'map_at_10': 0.31263, 'map_at_20': 0.32057, 'map_at_100': 0.32842, 'map_at_1000': 0.32963, 'recall_at_1': 0.20894, 'recall_at_3': 0.32164, 'recall_at_5': 0.37734, 'recall_at_10': 0.4565, 'recall_at_20': 0.55059, 'recall_at_100': 0.80196, 'recall_at_1000': 1.0, 'precision_at_1': 0.29969, 'precision_at_3': 0.16769, 'precision_at_5': 0.12049, 'precision_at_10': 0.07339, 'precision_at_20': 0.04373, 'precision_at_100': 0.01275, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.3012232415902141, 'mrr_at_3': 0.34148827726809394, 'mrr_at_5': 0.3533384301732927, 'mrr_at_10': 0.3626377360322315, 'mrr_at_20': 0.3689076696813086, 'mrr_at_100': 0.37446192229421565, 'mrr_at_1000': 0.3752567744835727, 'nauc_ndcg_at_1_max': np.float64(0.16036953351373992), 'nauc_ndcg_at_1_std': np.float64(-0.27628061637556306), 'nauc_ndcg_at_1_diff1': np.float64(0.4739748753019021), 'nauc_ndcg_at_3_max': np.float64(0.1661091945843179), 'nauc_ndcg_at_3_std': np.float64(-0.27622541196275735), 'nauc_ndcg_at_3_diff1': np.float64(0.44019092396762827), 'nauc_ndcg_at_5_max': np.float64(0.16726310448887255), 'nauc_ndcg_at_5_std': np.float64(-0.27327632001933855), 'nauc_ndcg_at_5_diff1': np.float64(0.43144674850697684), 'nauc_ndcg_at_10_max': np.float64(0.18134138847841752), 'nauc_ndcg_at_10_std': np.float64(-0.26531853388410515), 'nauc_ndcg_at_10_diff1': np.float64(0.4388739986543487), 'nauc_ndcg_at_20_max': np.float64(0.18622617930641144), 'nauc_ndcg_at_20_std': np.float64(-0.26250950628840886), 'nauc_ndcg_at_20_diff1': np.float64(0.4356620524311745), 'nauc_ndcg_at_100_max': np.float64(0.20302907523951996), 'nauc_ndcg_at_100_std': np.float64(-0.22272227930962626), 'nauc_ndcg_at_100_diff1': np.float64(0.43053313056287174), 'nauc_ndcg_at_1000_max': np.float64(0.1905665234637526), 'nauc_ndcg_at_1000_std': np.float64(-0.24631752844120994), 'nauc_ndcg_at_1000_diff1': np.float64(0.4365205827825694), 'nauc_map_at_1_max': np.float64(0.13854284289519359), 'nauc_map_at_1_std': np.float64(-0.2452136146627398), 'nauc_map_at_1_diff1': np.float64(0.4763842499096326), 'nauc_map_at_3_max': np.float64(0.17254779678739718), 'nauc_map_at_3_std': np.float64(-0.268724646247068), 'nauc_map_at_3_diff1': np.float64(0.4391864169068497), 'nauc_map_at_5_max': np.float64(0.16908464408362223), 'nauc_map_at_5_std': np.float64(-0.27166888999711925), 'nauc_map_at_5_diff1': np.float64(0.4310336610568424), 'nauc_map_at_10_max': np.float64(0.17581689143750073), 'nauc_map_at_10_std': np.float64(-0.2705007173003743), 'nauc_map_at_10_diff1': np.float64(0.4360517410708463), 'nauc_map_at_20_max': np.float64(0.17766319003159725), 'nauc_map_at_20_std': np.float64(-0.2704821239402203), 'nauc_map_at_20_diff1': np.float64(0.4366940083293156), 'nauc_map_at_100_max': np.float64(0.17966650220348776), 'nauc_map_at_100_std': np.float64(-0.26465858843009216), 'nauc_map_at_100_diff1': np.float64(0.4357015113440531), 'nauc_map_at_1000_max': np.float64(0.1793027489106988), 'nauc_map_at_1000_std': np.float64(-0.2654777287288446), 'nauc_map_at_1000_diff1': np.float64(0.4357413622706888), 'nauc_recall_at_1_max': np.float64(0.13854284289519359), 'nauc_recall_at_1_std': np.float64(-0.2452136146627398), 'nauc_recall_at_1_diff1': np.float64(0.4763842499096326), 'nauc_recall_at_3_max': np.float64(0.15919744597863614), 'nauc_recall_at_3_std': np.float64(-0.26957065331521735), 'nauc_recall_at_3_diff1': np.float64(0.4118684124430158), 'nauc_recall_at_5_max': np.float64(0.15746330901970873), 'nauc_recall_at_5_std': np.float64(-0.2632903690243722), 'nauc_recall_at_5_diff1': np.float64(0.3872357077075556), 'nauc_recall_at_10_max': np.float64(0.19381012460429922), 'nauc_recall_at_10_std': np.float64(-0.23436828228388612), 'nauc_recall_at_10_diff1': np.float64(0.3988096195861225), 'nauc_recall_at_20_max': np.float64(0.2084767289752829), 'nauc_recall_at_20_std': np.float64(-0.22265254957557698), 'nauc_recall_at_20_diff1': np.float64(0.37800523343844544), 'nauc_recall_at_100_max': np.float64(0.3384084172097074), 'nauc_recall_at_100_std': np.float64(0.07928212220425672), 'nauc_recall_at_100_diff1': np.float64(0.3078252171240789), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.16036953351373992), 'nauc_precision_at_1_std': np.float64(-0.27628061637556306), 'nauc_precision_at_1_diff1': np.float64(0.4739748753019021), 'nauc_precision_at_3_max': np.float64(0.18122173410071726), 'nauc_precision_at_3_std': np.float64(-0.2567043215963174), 'nauc_precision_at_3_diff1': np.float64(0.3378333070589199), 'nauc_precision_at_5_max': np.float64(0.1554550049956641), 'nauc_precision_at_5_std': np.float64(-0.24180845484190416), 'nauc_precision_at_5_diff1': np.float64(0.290729541778719), 'nauc_precision_at_10_max': np.float64(0.1643627103941248), 'nauc_precision_at_10_std': np.float64(-0.21860014184635101), 'nauc_precision_at_10_diff1': np.float64(0.28455008810078686), 'nauc_precision_at_20_max': np.float64(0.16477777191116325), 'nauc_precision_at_20_std': np.float64(-0.18651987868268488), 'nauc_precision_at_20_diff1': np.float64(0.25222565983172496), 'nauc_precision_at_100_max': np.float64(0.20523244705487917), 'nauc_precision_at_100_std': np.float64(0.06400716793210835), 'nauc_precision_at_100_diff1': np.float64(0.11322430246123903), 'nauc_precision_at_1000_max': np.float64(0.12700703924892656), 'nauc_precision_at_1000_std': np.float64(0.07119374603768011), 'nauc_precision_at_1000_diff1': np.float64(0.005738353521907607), 'nauc_mrr_at_1_max': np.float64(0.16656854330601686), 'nauc_mrr_at_1_std': np.float64(-0.26761844928944944), 'nauc_mrr_at_1_diff1': np.float64(0.46919227399117747), 'nauc_mrr_at_3_max': np.float64(0.16516849625629595), 'nauc_mrr_at_3_std': np.float64(-0.2733990374978357), 'nauc_mrr_at_3_diff1': np.float64(0.4597795258359567), 'nauc_mrr_at_5_max': np.float64(0.16828001111161248), 'nauc_mrr_at_5_std': np.float64(-0.27187647093205203), 'nauc_mrr_at_5_diff1': np.float64(0.4584104368766614), 'nauc_mrr_at_10_max': np.float64(0.1736587770122211), 'nauc_mrr_at_10_std': np.float64(-0.2651129855530757), 'nauc_mrr_at_10_diff1': np.float64(0.4595111379797913), 'nauc_mrr_at_20_max': np.float64(0.17500406633947224), 'nauc_mrr_at_20_std': np.float64(-0.26345915879127696), 'nauc_mrr_at_20_diff1': np.float64(0.45742809313792326), 'nauc_mrr_at_100_max': np.float64(0.1764659189361399), 'nauc_mrr_at_100_std': np.float64(-0.2598917268336406), 'nauc_mrr_at_100_diff1': np.float64(0.4570814905622467), 'nauc_mrr_at_1000_max': np.float64(0.17584479219710913), 'nauc_mrr_at_1000_std': np.float64(-0.26085744655892457), 'nauc_mrr_at_1000_diff1': np.float64(0.45729662724734704), 'main_score': 0.36083}, 'eng-kor': {'ndcg_at_1': 0.25994, 'ndcg_at_3': 0.28859, 'ndcg_at_5': 0.31071, 'ndcg_at_10': 0.34097, 'ndcg_at_20': 0.36704, 'ndcg_at_100': 0.42407, 'ndcg_at_1000': 0.45495, 'map_at_1': 0.15329, 'map_at_3': 0.23869, 'map_at_5': 0.26591, 'map_at_10': 0.28211, 'map_at_20': 0.29105, 'map_at_100': 0.30033, 'map_at_1000': 0.30226, 'recall_at_1': 0.15329, 'recall_at_3': 0.29177, 'recall_at_5': 0.36307, 'recall_at_10': 0.4367, 'recall_at_20': 0.52339, 'recall_at_100': 0.79322, 'recall_at_1000': 0.99592, 'precision_at_1': 0.25994, 'precision_at_3': 0.19113, 'precision_at_5': 0.14618, 'precision_at_10': 0.09098, 'precision_at_20': 0.05413, 'precision_at_100': 0.01578, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.2599388379204893, 'mrr_at_3': 0.3246687054026505, 'mrr_at_5': 0.33904179408766566, 'mrr_at_10': 0.3485176690451919, 'mrr_at_20': 0.35397486827529157, 'mrr_at_100': 0.35993172575778004, 'mrr_at_1000': 0.36063952034453695, 'nauc_ndcg_at_1_max': np.float64(0.057147760742959436), 'nauc_ndcg_at_1_std': np.float64(-0.33036442287893925), 'nauc_ndcg_at_1_diff1': np.float64(0.4932698402485779), 'nauc_ndcg_at_3_max': np.float64(0.01333717863280632), 'nauc_ndcg_at_3_std': np.float64(-0.3269820535215641), 'nauc_ndcg_at_3_diff1': np.float64(0.3958505613149547), 'nauc_ndcg_at_5_max': np.float64(0.004872403771688151), 'nauc_ndcg_at_5_std': np.float64(-0.33796576122118294), 'nauc_ndcg_at_5_diff1': np.float64(0.3891041993512005), 'nauc_ndcg_at_10_max': np.float64(0.004903649764391959), 'nauc_ndcg_at_10_std': np.float64(-0.33622046849680726), 'nauc_ndcg_at_10_diff1': np.float64(0.3877510519245756), 'nauc_ndcg_at_20_max': np.float64(0.005347611162799741), 'nauc_ndcg_at_20_std': np.float64(-0.3333227743975014), 'nauc_ndcg_at_20_diff1': np.float64(0.382337268651163), 'nauc_ndcg_at_100_max': np.float64(0.01822183922412112), 'nauc_ndcg_at_100_std': np.float64(-0.3119570550697157), 'nauc_ndcg_at_100_diff1': np.float64(0.3736204768886421), 'nauc_ndcg_at_1000_max': np.float64(0.025478311863305406), 'nauc_ndcg_at_1000_std': np.float64(-0.3135559719299999), 'nauc_ndcg_at_1000_diff1': np.float64(0.38998503957315245), 'nauc_map_at_1_max': np.float64(0.02404894735225604), 'nauc_map_at_1_std': np.float64(-0.2958887726957041), 'nauc_map_at_1_diff1': np.float64(0.49852568637580613), 'nauc_map_at_3_max': np.float64(0.010136085993912492), 'nauc_map_at_3_std': np.float64(-0.3217815240658463), 'nauc_map_at_3_diff1': np.float64(0.4222013776089469), 'nauc_map_at_5_max': np.float64(0.00784040840222447), 'nauc_map_at_5_std': np.float64(-0.333646684697192), 'nauc_map_at_5_diff1': np.float64(0.40647453183337523), 'nauc_map_at_10_max': np.float64(0.007792945212886593), 'nauc_map_at_10_std': np.float64(-0.33401676582266493), 'nauc_map_at_10_diff1': np.float64(0.4050857717148575), 'nauc_map_at_20_max': np.float64(0.008587253687752358), 'nauc_map_at_20_std': np.float64(-0.33421441567561455), 'nauc_map_at_20_diff1': np.float64(0.40291247339467057), 'nauc_map_at_100_max': np.float64(0.00999834034490326), 'nauc_map_at_100_std': np.float64(-0.3315000593794023), 'nauc_map_at_100_diff1': np.float64(0.4015497416795462), 'nauc_map_at_1000_max': np.float64(0.011405848497918411), 'nauc_map_at_1000_std': np.float64(-0.33046532032122916), 'nauc_map_at_1000_diff1': np.float64(0.40226372796757837), 'nauc_recall_at_1_max': np.float64(0.02404894735225604), 'nauc_recall_at_1_std': np.float64(-0.2958887726957041), 'nauc_recall_at_1_diff1': np.float64(0.49852568637580613), 'nauc_recall_at_3_max': np.float64(-0.006004096452956056), 'nauc_recall_at_3_std': np.float64(-0.29302186995925117), 'nauc_recall_at_3_diff1': np.float64(0.33628511779923886), 'nauc_recall_at_5_max': np.float64(-0.0127304827540012), 'nauc_recall_at_5_std': np.float64(-0.3175634383646668), 'nauc_recall_at_5_diff1': np.float64(0.31865956050985655), 'nauc_recall_at_10_max': np.float64(-0.0150857823864439), 'nauc_recall_at_10_std': np.float64(-0.3107430801334924), 'nauc_recall_at_10_diff1': np.float64(0.3097083306895549), 'nauc_recall_at_20_max': np.float64(-0.022532940637716797), 'nauc_recall_at_20_std': np.float64(-0.30186268870653005), 'nauc_recall_at_20_diff1': np.float64(0.286070471392095), 'nauc_recall_at_100_max': np.float64(0.01909966925378612), 'nauc_recall_at_100_std': np.float64(-0.16809671666048576), 'nauc_recall_at_100_diff1': np.float64(0.16627657178276536), 'nauc_recall_at_1000_max': np.float64(0.459646771815093), 'nauc_recall_at_1000_std': np.float64(0.35316247214157614), 'nauc_recall_at_1000_diff1': np.float64(0.5720905885610953), 'nauc_precision_at_1_max': np.float64(0.057147760742959436), 'nauc_precision_at_1_std': np.float64(-0.33036442287893925), 'nauc_precision_at_1_diff1': np.float64(0.4932698402485779), 'nauc_precision_at_3_max': np.float64(0.00461726406111989), 'nauc_precision_at_3_std': np.float64(-0.3148008782795308), 'nauc_precision_at_3_diff1': np.float64(0.2603627393385583), 'nauc_precision_at_5_max': np.float64(-0.0035837827562565593), 'nauc_precision_at_5_std': np.float64(-0.3142870970521295), 'nauc_precision_at_5_diff1': np.float64(0.21110877531171163), 'nauc_precision_at_10_max': np.float64(-0.0033784513521296126), 'nauc_precision_at_10_std': np.float64(-0.2798787278299724), 'nauc_precision_at_10_diff1': np.float64(0.19232194764074734), 'nauc_precision_at_20_max': np.float64(0.008810919798039354), 'nauc_precision_at_20_std': np.float64(-0.24592783621714245), 'nauc_precision_at_20_diff1': np.float64(0.1628337505030489), 'nauc_precision_at_100_max': np.float64(0.07423047732844952), 'nauc_precision_at_100_std': np.float64(-0.0750545936290214), 'nauc_precision_at_100_diff1': np.float64(0.052371030353125736), 'nauc_precision_at_1000_max': np.float64(0.10829418337507772), 'nauc_precision_at_1000_std': np.float64(0.012377008907229219), 'nauc_precision_at_1000_diff1': np.float64(0.018385980950516967), 'nauc_mrr_at_1_max': np.float64(0.057147760742959436), 'nauc_mrr_at_1_std': np.float64(-0.33036442287893925), 'nauc_mrr_at_1_diff1': np.float64(0.4932698402485779), 'nauc_mrr_at_3_max': np.float64(0.027951377591010493), 'nauc_mrr_at_3_std': np.float64(-0.33298500148454946), 'nauc_mrr_at_3_diff1': np.float64(0.4221909842276611), 'nauc_mrr_at_5_max': np.float64(0.026195421592095574), 'nauc_mrr_at_5_std': np.float64(-0.33793652527089124), 'nauc_mrr_at_5_diff1': np.float64(0.4218793823120598), 'nauc_mrr_at_10_max': np.float64(0.028247098286711854), 'nauc_mrr_at_10_std': np.float64(-0.33355606687397393), 'nauc_mrr_at_10_diff1': np.float64(0.4219693272124396), 'nauc_mrr_at_20_max': np.float64(0.029673996059950213), 'nauc_mrr_at_20_std': np.float64(-0.3308598873193995), 'nauc_mrr_at_20_diff1': np.float64(0.42237070913891395), 'nauc_mrr_at_100_max': np.float64(0.030817396916975378), 'nauc_mrr_at_100_std': np.float64(-0.329162977015318), 'nauc_mrr_at_100_diff1': np.float64(0.4212990371940219), 'nauc_mrr_at_1000_max': np.float64(0.03070562089224761), 'nauc_mrr_at_1000_std': np.float64(-0.3295373990990911), 'nauc_mrr_at_1000_diff1': np.float64(0.4218168240270122), 'main_score': 0.34097}, 'kor-eng': {'ndcg_at_1': 0.24267, 'ndcg_at_3': 0.26974, 'ndcg_at_5': 0.29077, 'ndcg_at_10': 0.31942, 'ndcg_at_20': 0.34732, 'ndcg_at_100': 0.40268, 'ndcg_at_1000': 0.43369, 'map_at_1': 0.17277, 'map_at_3': 0.24078, 'map_at_5': 0.25699, 'map_at_10': 0.27013, 'map_at_20': 0.27949, 'map_at_100': 0.28848, 'map_at_1000': 0.28987, 'recall_at_1': 0.17277, 'recall_at_3': 0.29015, 'recall_at_5': 0.33854, 'recall_at_10': 0.41503, 'recall_at_20': 0.51226, 'recall_at_100': 0.77696, 'recall_at_1000': 1.0, 'precision_at_1': 0.24267, 'precision_at_3': 0.15255, 'precision_at_5': 0.11107, 'precision_at_10': 0.06954, 'precision_at_20': 0.043, 'precision_at_100': 0.01326, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.24429967426710097, 'mrr_at_3': 0.29288816503800225, 'mrr_at_5': 0.30485884907709015, 'mrr_at_10': 0.31722894369474164, 'mrr_at_20': 0.3231440871775782, 'mrr_at_100': 0.3287278142787348, 'mrr_at_1000': 0.3295437775626029, 'nauc_ndcg_at_1_max': np.float64(0.1470220161647062), 'nauc_ndcg_at_1_std': np.float64(-0.18184622537720502), 'nauc_ndcg_at_1_diff1': np.float64(0.4933141110384315), 'nauc_ndcg_at_3_max': np.float64(0.13494231549072347), 'nauc_ndcg_at_3_std': np.float64(-0.19887203766524394), 'nauc_ndcg_at_3_diff1': np.float64(0.423630121176791), 'nauc_ndcg_at_5_max': np.float64(0.1290374417990188), 'nauc_ndcg_at_5_std': np.float64(-0.20132921001169748), 'nauc_ndcg_at_5_diff1': np.float64(0.41318641257532046), 'nauc_ndcg_at_10_max': np.float64(0.13377236639131757), 'nauc_ndcg_at_10_std': np.float64(-0.1964470111539637), 'nauc_ndcg_at_10_diff1': np.float64(0.4076922527542564), 'nauc_ndcg_at_20_max': np.float64(0.1296701819508619), 'nauc_ndcg_at_20_std': np.float64(-0.19670817461073511), 'nauc_ndcg_at_20_diff1': np.float64(0.4050337236502074), 'nauc_ndcg_at_100_max': np.float64(0.15555396779603672), 'nauc_ndcg_at_100_std': np.float64(-0.1431939147601259), 'nauc_ndcg_at_100_diff1': np.float64(0.40633947321459063), 'nauc_ndcg_at_1000_max': np.float64(0.14764989116411936), 'nauc_ndcg_at_1000_std': np.float64(-0.16501997936926627), 'nauc_ndcg_at_1000_diff1': np.float64(0.4165497097838407), 'nauc_map_at_1_max': np.float64(0.12167560986697107), 'nauc_map_at_1_std': np.float64(-0.16440428374787602), 'nauc_map_at_1_diff1': np.float64(0.4925810221309357), 'nauc_map_at_3_max': np.float64(0.13352045371655888), 'nauc_map_at_3_std': np.float64(-0.196758827888465), 'nauc_map_at_3_diff1': np.float64(0.4238608232688355), 'nauc_map_at_5_max': np.float64(0.12860927943251335), 'nauc_map_at_5_std': np.float64(-0.20071633130113767), 'nauc_map_at_5_diff1': np.float64(0.41673283582646764), 'nauc_map_at_10_max': np.float64(0.13130823380595733), 'nauc_map_at_10_std': np.float64(-0.19951911152217844), 'nauc_map_at_10_diff1': np.float64(0.4141473420854904), 'nauc_map_at_20_max': np.float64(0.12872722710722778), 'nauc_map_at_20_std': np.float64(-0.20075228415574803), 'nauc_map_at_20_diff1': np.float64(0.41416472530119924), 'nauc_map_at_100_max': np.float64(0.1323654192236389), 'nauc_map_at_100_std': np.float64(-0.1919983899781421), 'nauc_map_at_100_diff1': np.float64(0.41464470061394576), 'nauc_map_at_1000_max': np.float64(0.13236823476534548), 'nauc_map_at_1000_std': np.float64(-0.1925253786508961), 'nauc_map_at_1000_diff1': np.float64(0.41518640334346507), 'nauc_recall_at_1_max': np.float64(0.12167560986697107), 'nauc_recall_at_1_std': np.float64(-0.16440428374787602), 'nauc_recall_at_1_diff1': np.float64(0.4925810221309357), 'nauc_recall_at_3_max': np.float64(0.12682016391977954), 'nauc_recall_at_3_std': np.float64(-0.20341052110217941), 'nauc_recall_at_3_diff1': np.float64(0.3757273582663656), 'nauc_recall_at_5_max': np.float64(0.1185482342600925), 'nauc_recall_at_5_std': np.float64(-0.20587844250384485), 'nauc_recall_at_5_diff1': np.float64(0.3598059148605256), 'nauc_recall_at_10_max': np.float64(0.12826659208335056), 'nauc_recall_at_10_std': np.float64(-0.1943975091252743), 'nauc_recall_at_10_diff1': np.float64(0.33956407535116556), 'nauc_recall_at_20_max': np.float64(0.11352166597469808), 'nauc_recall_at_20_std': np.float64(-0.19408222099233943), 'nauc_recall_at_20_diff1': np.float64(0.317679503564471), 'nauc_recall_at_100_max': np.float64(0.23425675276197166), 'nauc_recall_at_100_std': np.float64(0.10921505542278978), 'nauc_recall_at_100_diff1': np.float64(0.27966581240649957), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1470220161647062), 'nauc_precision_at_1_std': np.float64(-0.18184622537720502), 'nauc_precision_at_1_diff1': np.float64(0.4933141110384315), 'nauc_precision_at_3_max': np.float64(0.13552665742834516), 'nauc_precision_at_3_std': np.float64(-0.19881480307611593), 'nauc_precision_at_3_diff1': np.float64(0.31992163766273557), 'nauc_precision_at_5_max': np.float64(0.11026835194152086), 'nauc_precision_at_5_std': np.float64(-0.19152693283731337), 'nauc_precision_at_5_diff1': np.float64(0.28623210182482245), 'nauc_precision_at_10_max': np.float64(0.11926061953347789), 'nauc_precision_at_10_std': np.float64(-0.15367486499405267), 'nauc_precision_at_10_diff1': np.float64(0.26536633318911446), 'nauc_precision_at_20_max': np.float64(0.0963507558339687), 'nauc_precision_at_20_std': np.float64(-0.12574891572105426), 'nauc_precision_at_20_diff1': np.float64(0.22872657885495534), 'nauc_precision_at_100_max': np.float64(0.20102015016691627), 'nauc_precision_at_100_std': np.float64(0.14444275898938244), 'nauc_precision_at_100_diff1': np.float64(0.11837321725063916), 'nauc_precision_at_1000_max': np.float64(0.16256377281794238), 'nauc_precision_at_1000_std': np.float64(0.14917420534621734), 'nauc_precision_at_1000_diff1': np.float64(0.04861193672132261), 'nauc_mrr_at_1_max': np.float64(0.14284795445041523), 'nauc_mrr_at_1_std': np.float64(-0.18505944774228267), 'nauc_mrr_at_1_diff1': np.float64(0.4866883544713498), 'nauc_mrr_at_3_max': np.float64(0.13811497200499723), 'nauc_mrr_at_3_std': np.float64(-0.19140152351019749), 'nauc_mrr_at_3_diff1': np.float64(0.45472453729872436), 'nauc_mrr_at_5_max': np.float64(0.1393148254467272), 'nauc_mrr_at_5_std': np.float64(-0.1880681385353164), 'nauc_mrr_at_5_diff1': np.float64(0.45087925451670985), 'nauc_mrr_at_10_max': np.float64(0.1415173412265146), 'nauc_mrr_at_10_std': np.float64(-0.18468675216350983), 'nauc_mrr_at_10_diff1': np.float64(0.45066741802335175), 'nauc_mrr_at_20_max': np.float64(0.14224835522131873), 'nauc_mrr_at_20_std': np.float64(-0.18304092527724797), 'nauc_mrr_at_20_diff1': np.float64(0.44946054868094715), 'nauc_mrr_at_100_max': np.float64(0.1440777660575633), 'nauc_mrr_at_100_std': np.float64(-0.17818090837104358), 'nauc_mrr_at_100_diff1': np.float64(0.44936646994538176), 'nauc_mrr_at_1000_max': np.float64(0.14365674590680608), 'nauc_mrr_at_1000_std': np.float64(-0.17908715640721853), 'nauc_mrr_at_1000_diff1': np.float64(0.4495633024856914), 'main_score': 0.31942}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/7 [00:00<?, ?it/s]Batches:  29%|██▊       | 2/7 [00:00<00:01,  4.13it/s]Batches:  57%|█████▋    | 4/7 [00:00<00:00,  7.35it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 12.31it/s]Batches: 100%|██████████| 7/7 [00:00<00:00,  9.69it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/193 [00:00<?, ?it/s]Batches:   1%|          | 1/193 [00:00<03:10,  1.01it/s]Batches:   1%|          | 2/193 [00:38<1:11:58, 22.61s/it]Batches:   2%|▏         | 3/193 [01:16<1:33:49, 29.63s/it]Batches:   2%|▏         | 4/193 [01:54<1:43:50, 32.96s/it]Batches:   3%|▎         | 5/193 [02:32<1:49:07, 34.83s/it]Batches:   3%|▎         | 6/193 [03:11<1:52:04, 35.96s/it]Batches:   4%|▎         | 7/193 [03:49<1:53:44, 36.69s/it]Batches:   4%|▍         | 8/193 [04:27<1:54:35, 37.16s/it]Batches:   5%|▍         | 9/193 [05:05<1:54:56, 37.48s/it]Batches:   5%|▌         | 10/193 [05:43<1:54:58, 37.70s/it]Batches:   6%|▌         | 11/193 [06:22<1:54:48, 37.85s/it]Batches:   6%|▌         | 12/193 [07:00<1:54:29, 37.95s/it]Batches:   7%|▋         | 13/193 [07:38<1:54:05, 38.03s/it]Batches:   7%|▋         | 14/193 [08:16<1:53:36, 38.08s/it]Batches:   8%|▊         | 15/193 [08:54<1:53:05, 38.12s/it]Batches:   8%|▊         | 16/193 [09:33<1:52:31, 38.14s/it]Batches:   9%|▉         | 17/193 [10:11<1:51:54, 38.15s/it]Batches:   9%|▉         | 18/193 [10:49<1:51:18, 38.17s/it]Batches:  10%|▉         | 19/193 [11:27<1:50:41, 38.17s/it]Batches:  10%|█         | 20/193 [12:05<1:50:03, 38.17s/it]Batches:  11%|█         | 21/193 [12:43<1:49:26, 38.18s/it]Batches:  11%|█▏        | 22/193 [13:22<1:48:55, 38.22s/it]Batches:  12%|█▏        | 23/193 [14:08<1:55:16, 40.68s/it]Batches:  12%|█▏        | 24/193 [14:46<1:52:29, 39.94s/it]Batches:  13%|█▎        | 25/193 [15:25<1:50:21, 39.41s/it]Batches:  13%|█▎        | 26/193 [16:03<1:48:41, 39.05s/it]Batches:  14%|█▍        | 27/193 [16:41<1:47:19, 38.79s/it]Batches:  15%|█▍        | 28/193 [17:19<1:46:10, 38.61s/it]Batches:  15%|█▌        | 29/193 [17:57<1:45:11, 38.48s/it]Batches:  16%|█▌        | 30/193 [18:36<1:44:18, 38.39s/it]Batches:  16%|█▌        | 31/193 [19:14<1:43:29, 38.33s/it]Batches:  17%|█▋        | 32/193 [19:52<1:42:44, 38.29s/it]Batches:  17%|█▋        | 33/193 [20:30<1:42:00, 38.25s/it]Batches:  18%|█▊        | 34/193 [21:08<1:41:19, 38.23s/it]Batches:  18%|█▊        | 35/193 [21:46<1:40:38, 38.22s/it]Batches:  19%|█▊        | 36/193 [22:25<1:39:58, 38.20s/it]Batches:  19%|█▉        | 37/193 [23:03<1:39:18, 38.20s/it]Batches:  20%|█▉        | 38/193 [23:41<1:38:39, 38.19s/it]Batches:  20%|██        | 39/193 [24:27<1:44:25, 40.68s/it]Batches:  21%|██        | 40/193 [25:06<1:41:50, 39.93s/it]Batches:  21%|██        | 41/193 [25:44<1:39:50, 39.41s/it]Batches:  22%|██▏       | 42/193 [26:22<1:38:15, 39.04s/it]Batches:  22%|██▏       | 43/193 [27:00<1:36:57, 38.78s/it]Batches:  23%|██▎       | 44/193 [27:47<1:42:02, 41.09s/it]Batches:  23%|██▎       | 45/193 [28:25<1:39:13, 40.22s/it]Batches:  24%|██▍       | 46/193 [29:11<1:43:09, 42.11s/it]Batches:  24%|██▍       | 47/193 [29:58<1:45:39, 43.42s/it]Batches:  25%|██▍       | 48/193 [30:36<1:41:07, 41.85s/it]Batches:  25%|██▌       | 49/193 [31:14<1:37:48, 40.75s/it]Batches:  26%|██▌       | 50/193 [31:52<1:35:16, 39.98s/it]Batches:  26%|██▋       | 51/193 [32:39<1:39:15, 41.94s/it]Batches:  27%|██▋       | 52/193 [33:17<1:35:54, 40.82s/it]Batches:  27%|██▋       | 53/193 [34:04<1:39:12, 42.52s/it]Batches:  28%|██▊       | 54/193 [34:50<1:41:15, 43.71s/it]Batches:  28%|██▊       | 55/193 [35:37<1:42:27, 44.54s/it]Batches:  29%|██▉       | 56/193 [36:23<1:43:02, 45.13s/it]Batches:  30%|██▉       | 57/193 [37:10<1:43:13, 45.54s/it]Batches:  30%|███       | 58/193 [37:56<1:43:05, 45.82s/it]Batches:  31%|███       | 59/193 [38:43<1:42:46, 46.02s/it]Batches:  31%|███       | 60/193 [39:29<1:42:19, 46.16s/it]Batches:  32%|███▏      | 61/193 [40:15<1:41:46, 46.26s/it]Batches:  32%|███▏      | 62/193 [41:02<1:41:08, 46.33s/it]Batches:  33%|███▎      | 63/193 [41:48<1:40:28, 46.37s/it]Batches:  33%|███▎      | 64/193 [42:35<1:39:46, 46.41s/it]Batches:  34%|███▎      | 65/193 [43:21<1:39:03, 46.43s/it]Batches:  34%|███▍      | 66/193 [44:08<1:38:19, 46.45s/it]Batches:  35%|███▍      | 67/193 [44:54<1:37:34, 46.47s/it]Batches:  35%|███▌      | 68/193 [45:41<1:36:49, 46.47s/it]Batches:  36%|███▌      | 69/193 [46:27<1:36:03, 46.48s/it]Batches:  36%|███▋      | 70/193 [47:14<1:35:17, 46.48s/it]Batches:  37%|███▋      | 71/193 [48:00<1:34:31, 46.49s/it]Batches:  37%|███▋      | 72/193 [48:47<1:33:45, 46.49s/it]Batches:  38%|███▊      | 73/193 [49:33<1:32:58, 46.49s/it]Batches:  38%|███▊      | 74/193 [50:20<1:32:11, 46.48s/it]Batches:  39%|███▉      | 75/193 [51:06<1:31:24, 46.48s/it]Batches:  39%|███▉      | 76/193 [51:53<1:30:38, 46.48s/it]Batches:  40%|███▉      | 77/193 [52:39<1:29:51, 46.48s/it]Batches:  40%|████      | 78/193 [53:26<1:29:04, 46.48s/it]Batches:  41%|████      | 79/193 [54:12<1:28:17, 46.47s/it]Batches:  41%|████▏     | 80/193 [54:59<1:27:31, 46.47s/it]Batches:  42%|████▏     | 81/193 [55:45<1:26:45, 46.48s/it]Batches:  42%|████▏     | 82/193 [56:32<1:25:59, 46.48s/it]Batches:  43%|████▎     | 83/193 [57:18<1:25:12, 46.48s/it]Batches:  44%|████▎     | 84/193 [58:05<1:24:26, 46.48s/it]Batches:  44%|████▍     | 85/193 [58:51<1:23:39, 46.48s/it]Batches:  45%|████▍     | 86/193 [59:38<1:22:52, 46.47s/it]Batches:  45%|████▌     | 87/193 [1:00:24<1:22:05, 46.47s/it]Batches:  46%|████▌     | 88/193 [1:01:10<1:21:19, 46.47s/it]Batches:  46%|████▌     | 89/193 [1:01:57<1:20:33, 46.47s/it]Batches:  47%|████▋     | 90/193 [1:02:43<1:19:46, 46.47s/it]Batches:  47%|████▋     | 91/193 [1:03:30<1:18:59, 46.47s/it]Batches:  48%|████▊     | 92/193 [1:04:16<1:18:12, 46.46s/it]Batches:  48%|████▊     | 93/193 [1:05:03<1:17:26, 46.46s/it]Batches:  49%|████▊     | 94/193 [1:05:49<1:16:39, 46.46s/it]Batches:  49%|████▉     | 95/193 [1:06:36<1:15:53, 46.46s/it]Batches:  50%|████▉     | 96/193 [1:07:22<1:15:07, 46.47s/it]Batches:  50%|█████     | 97/193 [1:08:09<1:14:20, 46.46s/it]Batches:  51%|█████     | 98/193 [1:08:55<1:13:33, 46.46s/it]Batches:  51%|█████▏    | 99/193 [1:09:42<1:12:47, 46.46s/it]Batches:  52%|█████▏    | 100/193 [1:10:28<1:12:00, 46.46s/it]Batches:  52%|█████▏    | 101/193 [1:11:14<1:11:13, 46.45s/it]Batches:  53%|█████▎    | 102/193 [1:12:01<1:10:27, 46.45s/it]Batches:  53%|█████▎    | 103/193 [1:12:47<1:09:40, 46.45s/it]Batches:  54%|█████▍    | 104/193 [1:13:34<1:08:53, 46.44s/it]Batches:  54%|█████▍    | 105/193 [1:14:23<1:09:17, 47.25s/it]Batches:  55%|█████▍    | 106/193 [1:15:09<1:08:09, 47.00s/it]Batches:  55%|█████▌    | 107/193 [1:15:57<1:07:46, 47.28s/it]Batches:  56%|█████▌    | 108/193 [1:16:44<1:06:37, 47.03s/it]Batches:  56%|█████▋    | 109/193 [1:17:30<1:05:35, 46.85s/it]Batches:  57%|█████▋    | 110/193 [1:18:14<1:03:23, 45.82s/it]Batches:  58%|█████▊    | 111/193 [1:18:57<1:01:41, 45.14s/it]Batches:  58%|█████▊    | 112/193 [1:19:43<1:01:26, 45.51s/it]Batches:  59%|█████▊    | 113/193 [1:20:31<1:01:21, 46.02s/it]Batches:  59%|█████▉    | 114/193 [1:21:14<59:36, 45.27s/it]  Batches:  60%|█████▉    | 115/193 [1:21:56<57:37, 44.32s/it]Batches:  60%|██████    | 116/193 [1:22:43<57:40, 44.94s/it]Batches:  61%|██████    | 117/193 [1:23:32<58:23, 46.10s/it]Batches:  61%|██████    | 118/193 [1:24:20<58:41, 46.95s/it]Batches:  62%|██████▏   | 119/193 [1:24:51<51:51, 42.05s/it]Batches:  62%|██████▏   | 120/193 [1:25:23<47:30, 39.05s/it]Batches:  63%|██████▎   | 121/193 [1:25:50<42:18, 35.26s/it]Batches:  63%|██████▎   | 122/193 [1:26:12<37:16, 31.51s/it]Batches:  64%|██████▎   | 123/193 [1:26:32<32:43, 28.04s/it]Batches:  64%|██████▍   | 124/193 [1:26:51<28:55, 25.16s/it]Batches:  65%|██████▍   | 125/193 [1:27:09<26:14, 23.15s/it]Batches:  65%|██████▌   | 126/193 [1:27:26<23:46, 21.30s/it]Batches:  66%|██████▌   | 127/193 [1:27:41<21:15, 19.33s/it]Batches:  66%|██████▋   | 128/193 [1:27:54<19:01, 17.56s/it]Batches:  67%|██████▋   | 129/193 [1:28:09<17:46, 16.66s/it]Batches:  67%|██████▋   | 130/193 [1:28:23<16:51, 16.06s/it]Batches:  68%|██████▊   | 131/193 [1:28:36<15:28, 14.97s/it]Batches:  68%|██████▊   | 132/193 [1:28:48<14:11, 13.96s/it]Batches:  69%|██████▉   | 133/193 [1:29:00<13:28, 13.48s/it]Batches:  69%|██████▉   | 134/193 [1:29:11<12:36, 12.82s/it]Batches:  70%|██████▉   | 135/193 [1:29:21<11:34, 11.97s/it]Batches:  70%|███████   | 136/193 [1:29:30<10:28, 11.03s/it]Batches:  71%|███████   | 137/193 [1:29:41<10:09, 10.88s/it]Batches:  72%|███████▏  | 138/193 [1:29:49<09:14, 10.08s/it]Batches:  72%|███████▏  | 139/193 [1:29:56<08:26,  9.38s/it]Batches:  73%|███████▎  | 140/193 [1:30:05<08:04,  9.14s/it]Batches:  73%|███████▎  | 141/193 [1:30:12<07:14,  8.36s/it]Batches:  74%|███████▎  | 142/193 [1:30:18<06:35,  7.76s/it]Batches:  74%|███████▍  | 143/193 [1:30:25<06:14,  7.48s/it]Batches:  75%|███████▍  | 144/193 [1:30:32<05:59,  7.34s/it]Batches:  75%|███████▌  | 145/193 [1:30:39<05:44,  7.19s/it]Batches:  76%|███████▌  | 146/193 [1:30:45<05:22,  6.86s/it]Batches:  76%|███████▌  | 147/193 [1:30:50<04:59,  6.51s/it]Batches:  77%|███████▋  | 148/193 [1:30:56<04:36,  6.15s/it]Batches:  77%|███████▋  | 149/193 [1:31:01<04:25,  6.03s/it]Batches:  78%|███████▊  | 150/193 [1:31:07<04:09,  5.81s/it]Batches:  78%|███████▊  | 151/193 [1:31:12<03:54,  5.59s/it]Batches:  79%|███████▉  | 152/193 [1:31:17<03:41,  5.41s/it]Batches:  79%|███████▉  | 153/193 [1:31:22<03:31,  5.28s/it]Batches:  80%|███████▉  | 154/193 [1:31:27<03:27,  5.33s/it]Batches:  80%|████████  | 155/193 [1:31:32<03:11,  5.03s/it]Batches:  81%|████████  | 156/193 [1:31:37<03:13,  5.23s/it]Batches:  81%|████████▏ | 157/193 [1:31:42<02:57,  4.94s/it]Batches:  82%|████████▏ | 158/193 [1:31:46<02:42,  4.65s/it]Batches:  82%|████████▏ | 159/193 [1:31:50<02:38,  4.65s/it]Batches:  83%|████████▎ | 160/193 [1:31:54<02:28,  4.49s/it]Batches:  83%|████████▎ | 161/193 [1:31:59<02:25,  4.55s/it]Batches:  84%|████████▍ | 162/193 [1:32:02<02:10,  4.20s/it]Batches:  84%|████████▍ | 163/193 [1:32:06<02:04,  4.15s/it]Batches:  85%|████████▍ | 164/193 [1:32:10<01:56,  4.02s/it]Batches:  85%|████████▌ | 165/193 [1:32:13<01:47,  3.83s/it]Batches:  86%|████████▌ | 166/193 [1:32:17<01:40,  3.72s/it]Batches:  87%|████████▋ | 167/193 [1:32:20<01:32,  3.57s/it]Batches:  87%|████████▋ | 168/193 [1:32:24<01:27,  3.51s/it]Batches:  88%|████████▊ | 169/193 [1:32:27<01:23,  3.50s/it]Batches:  88%|████████▊ | 170/193 [1:32:30<01:17,  3.39s/it]Batches:  89%|████████▊ | 171/193 [1:32:34<01:15,  3.43s/it]Batches:  89%|████████▉ | 172/193 [1:32:37<01:09,  3.32s/it]Batches:  90%|████████▉ | 173/193 [1:32:40<01:06,  3.35s/it]Batches:  90%|█████████ | 174/193 [1:32:43<01:00,  3.19s/it]Batches:  91%|█████████ | 175/193 [1:32:46<00:55,  3.07s/it]Batches:  91%|█████████ | 176/193 [1:32:49<00:53,  3.17s/it]Batches:  92%|█████████▏| 177/193 [1:32:52<00:47,  2.97s/it]Batches:  92%|█████████▏| 178/193 [1:32:54<00:43,  2.89s/it]Batches:  93%|█████████▎| 179/193 [1:32:57<00:39,  2.82s/it]Batches:  93%|█████████▎| 180/193 [1:33:00<00:35,  2.73s/it]Batches:  94%|█████████▍| 181/193 [1:33:02<00:32,  2.67s/it]Batches:  94%|█████████▍| 182/193 [1:33:05<00:30,  2.76s/it]Batches:  95%|█████████▍| 183/193 [1:33:08<00:26,  2.68s/it]Batches:  95%|█████████▌| 184/193 [1:33:10<00:23,  2.66s/it]Batches:  96%|█████████▌| 185/193 [1:33:13<00:20,  2.58s/it]Batches:  96%|█████████▋| 186/193 [1:33:15<00:17,  2.56s/it]Batches:  97%|█████████▋| 187/193 [1:33:17<00:14,  2.50s/it]Batches:  97%|█████████▋| 188/193 [1:33:20<00:11,  2.38s/it]Batches:  98%|█████████▊| 189/193 [1:33:22<00:09,  2.28s/it]Batches:  98%|█████████▊| 190/193 [1:33:24<00:07,  2.39s/it]Batches:  99%|█████████▉| 191/193 [1:33:27<00:04,  2.36s/it]Batches:  99%|█████████▉| 192/193 [1:33:29<00:02,  2.26s/it]Batches: 100%|██████████| 193/193 [1:33:31<00:00,  2.20s/it]Batches: 100%|██████████| 193/193 [1:33:31<00:00, 29.07s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5618.34 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 5618.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.305, 'ndcg_at_3': 0.38375, 'ndcg_at_5': 0.4044, 'ndcg_at_10': 0.43011, 'ndcg_at_20': 0.44091, 'ndcg_at_100': 0.475, 'ndcg_at_1000': 0.49695, 'map_at_1': 0.305, 'map_at_3': 0.36583, 'map_at_5': 0.37733, 'map_at_10': 0.38785, 'map_at_20': 0.39052, 'map_at_100': 0.39515, 'map_at_1000': 0.39604, 'recall_at_1': 0.305, 'recall_at_3': 0.435, 'recall_at_5': 0.485, 'recall_at_10': 0.565, 'recall_at_20': 0.61, 'recall_at_100': 0.795, 'recall_at_1000': 0.965, 'precision_at_1': 0.305, 'precision_at_3': 0.145, 'precision_at_5': 0.097, 'precision_at_10': 0.0565, 'precision_at_20': 0.0305, 'precision_at_100': 0.00795, 'precision_at_1000': 0.00097, 'mrr_at_1': 0.305, 'mrr_at_3': 0.36583333333333334, 'mrr_at_5': 0.37733333333333335, 'mrr_at_10': 0.3878531746031747, 'mrr_at_20': 0.39052307545825365, 'mrr_at_100': 0.39515483729101825, 'mrr_at_1000': 0.3960392433192078, 'nauc_ndcg_at_1_max': np.float64(0.5608308005418264), 'nauc_ndcg_at_1_std': np.float64(0.0563526454473775), 'nauc_ndcg_at_1_diff1': np.float64(0.6522943384528295), 'nauc_ndcg_at_3_max': np.float64(0.5663435443475426), 'nauc_ndcg_at_3_std': np.float64(0.04678024829103677), 'nauc_ndcg_at_3_diff1': np.float64(0.5879274570764406), 'nauc_ndcg_at_5_max': np.float64(0.5515072831320688), 'nauc_ndcg_at_5_std': np.float64(0.03817704892536418), 'nauc_ndcg_at_5_diff1': np.float64(0.5610142142367601), 'nauc_ndcg_at_10_max': np.float64(0.5557633877636018), 'nauc_ndcg_at_10_std': np.float64(0.06410434020832524), 'nauc_ndcg_at_10_diff1': np.float64(0.5546526730229415), 'nauc_ndcg_at_20_max': np.float64(0.5475832962469729), 'nauc_ndcg_at_20_std': np.float64(0.06805509553296839), 'nauc_ndcg_at_20_diff1': np.float64(0.5429081173519749), 'nauc_ndcg_at_100_max': np.float64(0.557117248702266), 'nauc_ndcg_at_100_std': np.float64(0.09310448697291461), 'nauc_ndcg_at_100_diff1': np.float64(0.5458353116449804), 'nauc_ndcg_at_1000_max': np.float64(0.5567176672598735), 'nauc_ndcg_at_1000_std': np.float64(0.08525219672256432), 'nauc_ndcg_at_1000_diff1': np.float64(0.5571054665518175), 'nauc_map_at_1_max': np.float64(0.5608308005418264), 'nauc_map_at_1_std': np.float64(0.0563526454473775), 'nauc_map_at_1_diff1': np.float64(0.6522943384528295), 'nauc_map_at_3_max': np.float64(0.5664799406416307), 'nauc_map_at_3_std': np.float64(0.05032782710221144), 'nauc_map_at_3_diff1': np.float64(0.60131329290114), 'nauc_map_at_5_max': np.float64(0.5583534314009817), 'nauc_map_at_5_std': np.float64(0.04508261866567717), 'nauc_map_at_5_diff1': np.float64(0.5863527663604615), 'nauc_map_at_10_max': np.float64(0.5601596948204381), 'nauc_map_at_10_std': np.float64(0.05652632363778106), 'nauc_map_at_10_diff1': np.float64(0.583233343861228), 'nauc_map_at_20_max': np.float64(0.5579725481672463), 'nauc_map_at_20_std': np.float64(0.05707539378182075), 'nauc_map_at_20_diff1': np.float64(0.5804005223060995), 'nauc_map_at_100_max': np.float64(0.5588414761629625), 'nauc_map_at_100_std': np.float64(0.059772443355463965), 'nauc_map_at_100_diff1': np.float64(0.580535671754654), 'nauc_map_at_1000_max': np.float64(0.5588807046314765), 'nauc_map_at_1000_std': np.float64(0.059710527119030514), 'nauc_map_at_1000_diff1': np.float64(0.5810058467099459), 'nauc_recall_at_1_max': np.float64(0.5608308005418264), 'nauc_recall_at_1_std': np.float64(0.0563526454473775), 'nauc_recall_at_1_diff1': np.float64(0.6522943384528295), 'nauc_recall_at_3_max': np.float64(0.5653697587920716), 'nauc_recall_at_3_std': np.float64(0.03617793237319166), 'nauc_recall_at_3_diff1': np.float64(0.5506419400855921), 'nauc_recall_at_5_max': np.float64(0.5289053542670441), 'nauc_recall_at_5_std': np.float64(0.017118544095328505), 'nauc_recall_at_5_diff1': np.float64(0.48499890648092314), 'nauc_recall_at_10_max': np.float64(0.5411228225420865), 'nauc_recall_at_10_std': np.float64(0.09538353945293275), 'nauc_recall_at_10_diff1': np.float64(0.4627307695052414), 'nauc_recall_at_20_max': np.float64(0.5047814723611256), 'nauc_recall_at_20_std': np.float64(0.11872856646473179), 'nauc_recall_at_20_diff1': np.float64(0.4042496940764129), 'nauc_recall_at_100_max': np.float64(0.5716490866992541), 'nauc_recall_at_100_std': np.float64(0.38390483540985126), 'nauc_recall_at_100_diff1': np.float64(0.35817805383022694), 'nauc_recall_at_1000_max': np.float64(0.5815659597172216), 'nauc_recall_at_1000_std': np.float64(1.0), 'nauc_recall_at_1000_diff1': np.float64(0.271842070161403), 'nauc_precision_at_1_max': np.float64(0.5608308005418264), 'nauc_precision_at_1_std': np.float64(0.0563526454473775), 'nauc_precision_at_1_diff1': np.float64(0.6522943384528295), 'nauc_precision_at_3_max': np.float64(0.5653697587920712), 'nauc_precision_at_3_std': np.float64(0.03617793237319149), 'nauc_precision_at_3_diff1': np.float64(0.5506419400855919), 'nauc_precision_at_5_max': np.float64(0.5289053542670439), 'nauc_precision_at_5_std': np.float64(0.017118544095328325), 'nauc_precision_at_5_diff1': np.float64(0.48499890648092314), 'nauc_precision_at_10_max': np.float64(0.5411228225420862), 'nauc_precision_at_10_std': np.float64(0.0953835394529327), 'nauc_precision_at_10_diff1': np.float64(0.46273076950524145), 'nauc_precision_at_20_max': np.float64(0.5047814723611258), 'nauc_precision_at_20_std': np.float64(0.11872856646473169), 'nauc_precision_at_20_diff1': np.float64(0.4042496940764128), 'nauc_precision_at_100_max': np.float64(0.571649086699255), 'nauc_precision_at_100_std': np.float64(0.3839048354098527), 'nauc_precision_at_100_diff1': np.float64(0.35817805383022844), 'nauc_precision_at_1000_max': np.float64(0.5815659597172199), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(0.2718420701613969), 'nauc_mrr_at_1_max': np.float64(0.5608308005418264), 'nauc_mrr_at_1_std': np.float64(0.0563526454473775), 'nauc_mrr_at_1_diff1': np.float64(0.6522943384528295), 'nauc_mrr_at_3_max': np.float64(0.5664799406416307), 'nauc_mrr_at_3_std': np.float64(0.05032782710221144), 'nauc_mrr_at_3_diff1': np.float64(0.60131329290114), 'nauc_mrr_at_5_max': np.float64(0.5583534314009817), 'nauc_mrr_at_5_std': np.float64(0.04508261866567717), 'nauc_mrr_at_5_diff1': np.float64(0.5863527663604615), 'nauc_mrr_at_10_max': np.float64(0.5601596948204381), 'nauc_mrr_at_10_std': np.float64(0.05652632363778106), 'nauc_mrr_at_10_diff1': np.float64(0.583233343861228), 'nauc_mrr_at_20_max': np.float64(0.5579725481672463), 'nauc_mrr_at_20_std': np.float64(0.05707539378182075), 'nauc_mrr_at_20_diff1': np.float64(0.5804005223060995), 'nauc_mrr_at_100_max': np.float64(0.5588414761629625), 'nauc_mrr_at_100_std': np.float64(0.059772443355463965), 'nauc_mrr_at_100_diff1': np.float64(0.580535671754654), 'nauc_mrr_at_1000_max': np.float64(0.5588807046314765), 'nauc_mrr_at_1000_std': np.float64(0.059710527119030514), 'nauc_mrr_at_1000_diff1': np.float64(0.5810058467099459), 'main_score': 0.43011}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/7 [00:00<?, ?it/s]Batches:  29%|██▊       | 2/7 [00:00<00:00,  8.34it/s]Batches:  57%|█████▋    | 4/7 [00:00<00:00, 11.72it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 17.03it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 14.71it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/193 [00:00<?, ?it/s]Batches:   1%|          | 1/193 [00:00<03:02,  1.05it/s]Batches:   1%|          | 2/193 [00:39<1:12:38, 22.82s/it]Batches:   2%|▏         | 3/193 [01:17<1:34:23, 29.81s/it]Batches:   2%|▏         | 4/193 [01:55<1:44:15, 33.10s/it]Batches:   3%|▎         | 5/193 [02:33<1:49:25, 34.92s/it]Batches:   3%|▎         | 6/193 [03:11<1:52:17, 36.03s/it]Batches:   4%|▎         | 7/193 [03:49<1:53:51, 36.73s/it]Batches:   4%|▍         | 8/193 [04:28<1:54:38, 37.18s/it]Batches:   5%|▍         | 9/193 [05:06<1:54:59, 37.49s/it]Batches:   5%|▌         | 10/193 [05:44<1:55:00, 37.71s/it]Batches:   6%|▌         | 11/193 [06:22<1:54:46, 37.84s/it]Batches:   6%|▌         | 12/193 [07:00<1:54:27, 37.94s/it]Batches:   7%|▋         | 13/193 [07:38<1:54:02, 38.01s/it]Batches:   7%|▋         | 14/193 [08:17<1:53:32, 38.06s/it]Batches:   8%|▊         | 15/193 [08:55<1:52:59, 38.09s/it]Batches:   8%|▊         | 16/193 [09:33<1:52:25, 38.11s/it]Batches:   9%|▉         | 17/193 [10:11<1:51:50, 38.13s/it]Batches:   9%|▉         | 18/193 [10:49<1:51:14, 38.14s/it]Batches:  10%|▉         | 19/193 [11:27<1:50:36, 38.14s/it]Batches:  10%|█         | 20/193 [12:05<1:49:59, 38.15s/it]Batches:  11%|█         | 21/193 [12:44<1:49:23, 38.16s/it]Batches:  11%|█▏        | 22/193 [13:22<1:48:46, 38.17s/it]Batches:  12%|█▏        | 23/193 [14:08<1:55:12, 40.66s/it]Batches:  12%|█▏        | 24/193 [14:47<1:52:25, 39.91s/it]Batches:  13%|█▎        | 25/193 [15:25<1:50:18, 39.39s/it]Batches:  13%|█▎        | 26/193 [16:03<1:48:37, 39.02s/it]Batches:  14%|█▍        | 27/193 [16:41<1:47:16, 38.77s/it]Batches:  15%|█▍        | 28/193 [17:19<1:46:07, 38.59s/it]Batches:  15%|█▌        | 29/193 [17:57<1:45:07, 38.46s/it]Batches:  16%|█▌        | 30/193 [18:36<1:44:15, 38.37s/it]Batches:  16%|█▌        | 31/193 [19:14<1:43:25, 38.31s/it]Batches:  17%|█▋        | 32/193 [19:52<1:42:40, 38.26s/it]Batches:  17%|█▋        | 33/193 [20:30<1:41:57, 38.23s/it]Batches:  18%|█▊        | 34/193 [21:08<1:41:15, 38.21s/it]Batches:  18%|█▊        | 35/193 [21:46<1:40:34, 38.19s/it]Batches:  19%|█▊        | 36/193 [22:24<1:39:55, 38.19s/it]Batches:  19%|█▉        | 37/193 [23:03<1:39:15, 38.18s/it]Batches:  20%|█▉        | 38/193 [23:41<1:38:36, 38.17s/it]Batches:  20%|██        | 39/193 [24:27<1:44:22, 40.66s/it]Batches:  21%|██        | 40/193 [25:05<1:41:46, 39.91s/it]Batches:  21%|██        | 41/193 [25:44<1:39:46, 39.38s/it]Batches:  22%|██▏       | 42/193 [26:22<1:38:12, 39.02s/it]Batches:  22%|██▏       | 43/193 [27:00<1:36:54, 38.76s/it]Batches:  23%|██▎       | 44/193 [27:46<1:42:00, 41.08s/it]Batches:  23%|██▎       | 45/193 [28:25<1:39:10, 40.21s/it]Batches:  24%|██▍       | 46/193 [29:11<1:43:05, 42.08s/it]Batches:  24%|██▍       | 47/193 [29:58<1:45:36, 43.40s/it]Batches:  25%|██▍       | 48/193 [30:36<1:41:05, 41.83s/it]Batches:  25%|██▌       | 49/193 [31:14<1:37:45, 40.73s/it]Batches:  26%|██▌       | 50/193 [31:52<1:35:13, 39.96s/it]Batches:  26%|██▋       | 51/193 [32:38<1:39:11, 41.92s/it]Batches:  27%|██▋       | 52/193 [33:17<1:35:50, 40.78s/it]Batches:  27%|██▋       | 53/193 [34:03<1:39:07, 42.48s/it]Batches:  28%|██▊       | 54/193 [34:50<1:41:11, 43.68s/it]Batches:  28%|██▊       | 55/193 [35:36<1:42:23, 44.52s/it]Batches:  29%|██▉       | 56/193 [36:23<1:43:00, 45.11s/it]Batches:  30%|██▉       | 57/193 [37:09<1:43:11, 45.52s/it]Batches:  30%|███       | 58/193 [37:55<1:43:04, 45.81s/it]Batches:  31%|███       | 59/193 [38:42<1:42:45, 46.01s/it]Batches:  31%|███       | 60/193 [39:28<1:42:18, 46.16s/it]Batches:  32%|███▏      | 61/193 [40:15<1:41:45, 46.25s/it]Batches:  32%|███▏      | 62/193 [41:01<1:41:07, 46.32s/it]Batches:  33%|███▎      | 63/193 [41:48<1:40:27, 46.37s/it]Batches:  33%|███▎      | 64/193 [42:34<1:39:45, 46.40s/it]Batches:  34%|███▎      | 65/193 [43:21<1:39:02, 46.42s/it]Batches:  34%|███▍      | 66/193 [44:07<1:38:18, 46.45s/it]Batches:  35%|███▍      | 67/193 [44:54<1:37:33, 46.45s/it]Batches:  35%|███▌      | 68/193 [45:40<1:36:48, 46.47s/it]Batches:  36%|███▌      | 69/193 [46:27<1:36:02, 46.47s/it]Batches:  36%|███▋      | 70/193 [47:13<1:35:16, 46.48s/it]Batches:  37%|███▋      | 71/193 [48:00<1:34:30, 46.48s/it]Batches:  37%|███▋      | 72/193 [48:46<1:33:44, 46.48s/it]Batches:  38%|███▊      | 73/193 [49:33<1:32:56, 46.47s/it]Batches:  38%|███▊      | 74/193 [50:19<1:32:10, 46.47s/it]Batches:  39%|███▉      | 75/193 [51:06<1:31:23, 46.47s/it]Batches:  39%|███▉      | 76/193 [51:52<1:30:36, 46.47s/it]Batches:  40%|███▉      | 77/193 [52:39<1:29:50, 46.47s/it]Batches:  40%|████      | 78/193 [53:25<1:29:03, 46.47s/it]Batches:  41%|████      | 79/193 [54:12<1:28:17, 46.47s/it]Batches:  41%|████▏     | 80/193 [54:58<1:27:30, 46.47s/it]Batches:  42%|████▏     | 81/193 [55:44<1:26:44, 46.47s/it]Batches:  42%|████▏     | 82/193 [56:31<1:25:57, 46.47s/it]Batches:  43%|████▎     | 83/193 [57:17<1:25:11, 46.46s/it]Batches:  44%|████▎     | 84/193 [58:04<1:24:24, 46.47s/it]Batches:  44%|████▍     | 85/193 [58:50<1:23:38, 46.46s/it]Batches:  45%|████▍     | 86/193 [59:37<1:22:51, 46.47s/it]Batches:  45%|████▌     | 87/193 [1:00:23<1:22:05, 46.47s/it]Batches:  46%|████▌     | 88/193 [1:01:10<1:21:18, 46.47s/it]Batches:  46%|████▌     | 89/193 [1:01:56<1:20:32, 46.47s/it]Batches:  47%|████▋     | 90/193 [1:02:43<1:19:45, 46.46s/it]Batches:  47%|████▋     | 91/193 [1:03:29<1:18:58, 46.46s/it]Batches:  48%|████▊     | 92/193 [1:04:16<1:18:11, 46.45s/it]Batches:  48%|████▊     | 93/193 [1:05:02<1:17:24, 46.44s/it]Batches:  49%|████▊     | 94/193 [1:05:48<1:16:38, 46.45s/it]Batches:  49%|████▉     | 95/193 [1:06:35<1:15:51, 46.44s/it]Batches:  50%|████▉     | 96/193 [1:07:21<1:15:05, 46.44s/it]Batches:  50%|█████     | 97/193 [1:08:08<1:14:17, 46.43s/it]Batches:  51%|█████     | 98/193 [1:08:54<1:13:31, 46.43s/it]Batches:  51%|█████▏    | 99/193 [1:09:41<1:12:44, 46.43s/it]Batches:  52%|█████▏    | 100/193 [1:10:27<1:11:57, 46.43s/it]Batches:  52%|█████▏    | 101/193 [1:11:13<1:11:10, 46.42s/it]Batches:  53%|█████▎    | 102/193 [1:12:00<1:10:24, 46.42s/it]Batches:  53%|█████▎    | 103/193 [1:12:46<1:09:37, 46.42s/it]Batches:  54%|█████▍    | 104/193 [1:13:33<1:08:50, 46.41s/it]Batches:  54%|█████▍    | 105/193 [1:14:22<1:09:15, 47.23s/it]Batches:  55%|█████▍    | 106/193 [1:15:08<1:08:07, 46.98s/it]Batches:  55%|█████▌    | 107/193 [1:15:56<1:07:44, 47.27s/it]Batches:  56%|█████▌    | 108/193 [1:16:42<1:06:35, 47.01s/it]Batches:  56%|█████▋    | 109/193 [1:17:29<1:05:33, 46.83s/it]Batches:  57%|█████▋    | 110/193 [1:18:12<1:03:23, 45.82s/it]Batches:  58%|█████▊    | 111/193 [1:18:56<1:01:41, 45.14s/it]Batches:  58%|█████▊    | 112/193 [1:19:42<1:01:26, 45.51s/it]Batches:  59%|█████▊    | 113/193 [1:20:29<1:01:20, 46.01s/it]Batches:  59%|█████▉    | 114/193 [1:21:13<59:35, 45.27s/it]  Batches:  60%|█████▉    | 115/193 [1:21:55<57:36, 44.31s/it]Batches:  60%|██████    | 116/193 [1:22:41<57:39, 44.93s/it]Batches:  61%|██████    | 117/193 [1:23:30<58:22, 46.09s/it]Batches:  61%|██████    | 118/193 [1:24:19<58:40, 46.93s/it]Batches:  62%|██████▏   | 119/193 [1:24:50<51:50, 42.04s/it]Batches:  62%|██████▏   | 120/193 [1:25:22<47:29, 39.04s/it]Batches:  63%|██████▎   | 121/193 [1:25:48<42:17, 35.25s/it]Batches:  63%|██████▎   | 122/193 [1:26:11<37:16, 31.50s/it]Batches:  64%|██████▎   | 123/193 [1:26:31<32:42, 28.04s/it]Batches:  64%|██████▍   | 124/193 [1:26:49<28:55, 25.15s/it]Batches:  65%|██████▍   | 125/193 [1:27:08<26:13, 23.15s/it]Batches:  65%|██████▌   | 126/193 [1:27:25<23:46, 21.29s/it]Batches:  66%|██████▌   | 127/193 [1:27:39<21:15, 19.32s/it]Batches:  66%|██████▋   | 128/193 [1:27:53<19:00, 17.55s/it]Batches:  67%|██████▋   | 129/193 [1:28:07<17:45, 16.66s/it]Batches:  67%|██████▋   | 130/193 [1:28:22<16:51, 16.05s/it]Batches:  68%|██████▊   | 131/193 [1:28:35<15:27, 14.96s/it]Batches:  68%|██████▊   | 132/193 [1:28:46<14:11, 13.96s/it]Batches:  69%|██████▉   | 133/193 [1:28:58<13:28, 13.48s/it]Batches:  69%|██████▉   | 134/193 [1:29:10<12:36, 12.81s/it]Batches:  70%|██████▉   | 135/193 [1:29:20<11:34, 11.97s/it]Batches:  70%|███████   | 136/193 [1:29:29<10:28, 11.03s/it]Batches:  71%|███████   | 137/193 [1:29:39<10:09, 10.88s/it]Batches:  72%|███████▏  | 138/193 [1:29:47<09:14, 10.08s/it]Batches:  72%|███████▏  | 139/193 [1:29:55<08:26,  9.38s/it]Batches:  73%|███████▎  | 140/193 [1:30:04<08:04,  9.14s/it]Batches:  73%|███████▎  | 141/193 [1:30:10<07:14,  8.35s/it]Batches:  74%|███████▎  | 142/193 [1:30:17<06:35,  7.76s/it]Batches:  74%|███████▍  | 143/193 [1:30:23<06:13,  7.48s/it]Batches:  75%|███████▍  | 144/193 [1:30:30<05:59,  7.34s/it]Batches:  75%|███████▌  | 145/193 [1:30:37<05:44,  7.18s/it]Batches:  76%|███████▌  | 146/193 [1:30:43<05:22,  6.86s/it]Batches:  76%|███████▌  | 147/193 [1:30:49<04:59,  6.51s/it]Batches:  77%|███████▋  | 148/193 [1:30:54<04:36,  6.15s/it]Batches:  77%|███████▋  | 149/193 [1:31:00<04:25,  6.03s/it]Batches:  78%|███████▊  | 150/193 [1:31:05<04:09,  5.81s/it]Batches:  78%|███████▊  | 151/193 [1:31:10<03:54,  5.59s/it]Batches:  79%|███████▉  | 152/193 [1:31:15<03:41,  5.41s/it]Batches:  79%|███████▉  | 153/193 [1:31:20<03:31,  5.28s/it]Batches:  80%|███████▉  | 154/193 [1:31:26<03:27,  5.33s/it]Batches:  80%|████████  | 155/193 [1:31:30<03:11,  5.03s/it]Batches:  81%|████████  | 156/193 [1:31:36<03:13,  5.23s/it]Batches:  81%|████████▏ | 157/193 [1:31:40<02:57,  4.93s/it]Batches:  82%|████████▏ | 158/193 [1:31:44<02:42,  4.65s/it]Batches:  82%|████████▏ | 159/193 [1:31:49<02:38,  4.65s/it]Batches:  83%|████████▎ | 160/193 [1:31:53<02:28,  4.49s/it]Batches:  83%|████████▎ | 161/193 [1:31:58<02:25,  4.55s/it]Batches:  84%|████████▍ | 162/193 [1:32:01<02:10,  4.20s/it]Batches:  84%|████████▍ | 163/193 [1:32:05<02:04,  4.15s/it]Batches:  85%|████████▍ | 164/193 [1:32:09<01:56,  4.02s/it]Batches:  85%|████████▌ | 165/193 [1:32:12<01:47,  3.83s/it]Batches:  86%|████████▌ | 166/193 [1:32:16<01:40,  3.72s/it]Batches:  87%|████████▋ | 167/193 [1:32:19<01:32,  3.57s/it]Batches:  87%|████████▋ | 168/193 [1:32:22<01:27,  3.51s/it]Batches:  88%|████████▊ | 169/193 [1:32:26<01:24,  3.50s/it]Batches:  88%|████████▊ | 170/193 [1:32:29<01:17,  3.39s/it]Batches:  89%|████████▊ | 171/193 [1:32:32<01:15,  3.43s/it]Batches:  89%|████████▉ | 172/193 [1:32:35<01:09,  3.32s/it]Batches:  90%|████████▉ | 173/193 [1:32:39<01:06,  3.35s/it]Batches:  90%|█████████ | 174/193 [1:32:42<01:00,  3.19s/it]Batches:  91%|█████████ | 175/193 [1:32:44<00:55,  3.07s/it]Batches:  91%|█████████ | 176/193 [1:32:48<00:53,  3.17s/it]Batches:  92%|█████████▏| 177/193 [1:32:50<00:47,  2.97s/it]Batches:  92%|█████████▏| 178/193 [1:32:53<00:43,  2.89s/it]Batches:  93%|█████████▎| 179/193 [1:32:56<00:39,  2.82s/it]Batches:  93%|█████████▎| 180/193 [1:32:58<00:35,  2.73s/it]Batches:  94%|█████████▍| 181/193 [1:33:01<00:32,  2.67s/it]Batches:  94%|█████████▍| 182/193 [1:33:04<00:30,  2.76s/it]Batches:  95%|█████████▍| 183/193 [1:33:06<00:26,  2.68s/it]Batches:  95%|█████████▌| 184/193 [1:33:09<00:23,  2.66s/it]Batches:  96%|█████████▌| 185/193 [1:33:11<00:20,  2.58s/it]Batches:  96%|█████████▋| 186/193 [1:33:14<00:17,  2.57s/it]Batches:  97%|█████████▋| 187/193 [1:33:16<00:15,  2.50s/it]Batches:  97%|█████████▋| 188/193 [1:33:18<00:11,  2.38s/it]Batches:  98%|█████████▊| 189/193 [1:33:20<00:09,  2.28s/it]Batches:  98%|█████████▊| 190/193 [1:33:23<00:07,  2.39s/it]Batches:  99%|█████████▉| 191/193 [1:33:25<00:04,  2.36s/it]Batches:  99%|█████████▉| 192/193 [1:33:27<00:02,  2.26s/it]Batches: 100%|██████████| 193/193 [1:33:29<00:00,  2.20s/it]Batches: 100%|██████████| 193/193 [1:33:29<00:00, 29.07s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5616.27 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 5616.58 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.315, 'ndcg_at_3': 0.38797, 'ndcg_at_5': 0.41465, 'ndcg_at_10': 0.42728, 'ndcg_at_20': 0.44197, 'ndcg_at_100': 0.4708, 'ndcg_at_1000': 0.49414, 'map_at_1': 0.315, 'map_at_3': 0.37, 'map_at_5': 0.38475, 'map_at_10': 0.38977, 'map_at_20': 0.39356, 'map_at_100': 0.39754, 'map_at_1000': 0.39831, 'recall_at_1': 0.315, 'recall_at_3': 0.44, 'recall_at_5': 0.505, 'recall_at_10': 0.545, 'recall_at_20': 0.605, 'recall_at_100': 0.76, 'recall_at_1000': 0.95, 'precision_at_1': 0.315, 'precision_at_3': 0.14667, 'precision_at_5': 0.101, 'precision_at_10': 0.0545, 'precision_at_20': 0.03025, 'precision_at_100': 0.0076, 'precision_at_1000': 0.00095, 'mrr_at_1': 0.315, 'mrr_at_3': 0.37, 'mrr_at_5': 0.3847500000000001, 'mrr_at_10': 0.3897698412698414, 'mrr_at_20': 0.39356284197828323, 'mrr_at_100': 0.3975364807486607, 'mrr_at_1000': 0.398309315165428, 'nauc_ndcg_at_1_max': np.float64(0.4481595482862911), 'nauc_ndcg_at_1_std': np.float64(-0.03792893019762483), 'nauc_ndcg_at_1_diff1': np.float64(0.6806754246551459), 'nauc_ndcg_at_3_max': np.float64(0.4706892075831608), 'nauc_ndcg_at_3_std': np.float64(0.03690585168881346), 'nauc_ndcg_at_3_diff1': np.float64(0.6617572971976259), 'nauc_ndcg_at_5_max': np.float64(0.48058093705348043), 'nauc_ndcg_at_5_std': np.float64(0.07384049008083444), 'nauc_ndcg_at_5_diff1': np.float64(0.6585927852329279), 'nauc_ndcg_at_10_max': np.float64(0.47785124426174147), 'nauc_ndcg_at_10_std': np.float64(0.07606618544656002), 'nauc_ndcg_at_10_diff1': np.float64(0.6357168723135498), 'nauc_ndcg_at_20_max': np.float64(0.48480138347365553), 'nauc_ndcg_at_20_std': np.float64(0.08688008419865503), 'nauc_ndcg_at_20_diff1': np.float64(0.6416960939448727), 'nauc_ndcg_at_100_max': np.float64(0.4822404456613312), 'nauc_ndcg_at_100_std': np.float64(0.1027648550108664), 'nauc_ndcg_at_100_diff1': np.float64(0.635859540261683), 'nauc_ndcg_at_1000_max': np.float64(0.479940037436154), 'nauc_ndcg_at_1000_std': np.float64(0.09172524019606888), 'nauc_ndcg_at_1000_diff1': np.float64(0.6428097047373263), 'nauc_map_at_1_max': np.float64(0.4481595482862911), 'nauc_map_at_1_std': np.float64(-0.03792893019762483), 'nauc_map_at_1_diff1': np.float64(0.6806754246551459), 'nauc_map_at_3_max': np.float64(0.4683804468855765), 'nauc_map_at_3_std': np.float64(0.01923821721086023), 'nauc_map_at_3_diff1': np.float64(0.6690542521026155), 'nauc_map_at_5_max': np.float64(0.4740915890417542), 'nauc_map_at_5_std': np.float64(0.03970725804693442), 'nauc_map_at_5_diff1': np.float64(0.6675321967565364), 'nauc_map_at_10_max': np.float64(0.4726482183566381), 'nauc_map_at_10_std': np.float64(0.03992466480001028), 'nauc_map_at_10_diff1': np.float64(0.6584969505864283), 'nauc_map_at_20_max': np.float64(0.4750531319415043), 'nauc_map_at_20_std': np.float64(0.04278409018479869), 'nauc_map_at_20_diff1': np.float64(0.6602038571715491), 'nauc_map_at_100_max': np.float64(0.4746250022073627), 'nauc_map_at_100_std': np.float64(0.04469178094094635), 'nauc_map_at_100_diff1': np.float64(0.6595691851449524), 'nauc_map_at_1000_max': np.float64(0.4743857559179589), 'nauc_map_at_1000_std': np.float64(0.04456651013258996), 'nauc_map_at_1000_diff1': np.float64(0.6598014592604037), 'nauc_recall_at_1_max': np.float64(0.4481595482862911), 'nauc_recall_at_1_std': np.float64(-0.03792893019762483), 'nauc_recall_at_1_diff1': np.float64(0.6806754246551459), 'nauc_recall_at_3_max': np.float64(0.47603356475439795), 'nauc_recall_at_3_std': np.float64(0.08725922639244142), 'nauc_recall_at_3_diff1': np.float64(0.6397987680743328), 'nauc_recall_at_5_max': np.float64(0.4993337038698746), 'nauc_recall_at_5_std': np.float64(0.17841334467264416), 'nauc_recall_at_5_diff1': np.float64(0.6306978363790989), 'nauc_recall_at_10_max': np.float64(0.49297820485066035), 'nauc_recall_at_10_std': np.float64(0.19283225207231988), 'nauc_recall_at_10_diff1': np.float64(0.5547462586506702), 'nauc_recall_at_20_max': np.float64(0.5196634050294594), 'nauc_recall_at_20_std': np.float64(0.2474901364796777), 'nauc_recall_at_20_diff1': np.float64(0.5748392264903833), 'nauc_recall_at_100_max': np.float64(0.5155857921605947), 'nauc_recall_at_100_std': np.float64(0.4437029505927141), 'nauc_recall_at_100_diff1': np.float64(0.4993185947910358), 'nauc_recall_at_1000_max': np.float64(0.5622315592903827), 'nauc_recall_at_1000_std': np.float64(0.8977591036414535), 'nauc_recall_at_1000_diff1': np.float64(0.38692810457516086), 'nauc_precision_at_1_max': np.float64(0.4481595482862911), 'nauc_precision_at_1_std': np.float64(-0.03792893019762483), 'nauc_precision_at_1_diff1': np.float64(0.6806754246551459), 'nauc_precision_at_3_max': np.float64(0.47603356475439784), 'nauc_precision_at_3_std': np.float64(0.08725922639244146), 'nauc_precision_at_3_diff1': np.float64(0.6397987680743332), 'nauc_precision_at_5_max': np.float64(0.4993337038698742), 'nauc_precision_at_5_std': np.float64(0.17841334467264405), 'nauc_precision_at_5_diff1': np.float64(0.6306978363790986), 'nauc_precision_at_10_max': np.float64(0.49297820485065996), 'nauc_precision_at_10_std': np.float64(0.19283225207231972), 'nauc_precision_at_10_diff1': np.float64(0.55474625865067), 'nauc_precision_at_20_max': np.float64(0.5196634050294592), 'nauc_precision_at_20_std': np.float64(0.24749013647967752), 'nauc_precision_at_20_diff1': np.float64(0.5748392264903835), 'nauc_precision_at_100_max': np.float64(0.515585792160596), 'nauc_precision_at_100_std': np.float64(0.44370295059271386), 'nauc_precision_at_100_diff1': np.float64(0.49931859479103574), 'nauc_precision_at_1000_max': np.float64(0.562231559290378), 'nauc_precision_at_1000_std': np.float64(0.8977591036414542), 'nauc_precision_at_1000_diff1': np.float64(0.3869281045751624), 'nauc_mrr_at_1_max': np.float64(0.4481595482862911), 'nauc_mrr_at_1_std': np.float64(-0.03792893019762483), 'nauc_mrr_at_1_diff1': np.float64(0.6806754246551459), 'nauc_mrr_at_3_max': np.float64(0.4683804468855765), 'nauc_mrr_at_3_std': np.float64(0.01923821721086023), 'nauc_mrr_at_3_diff1': np.float64(0.6690542521026155), 'nauc_mrr_at_5_max': np.float64(0.4740915890417542), 'nauc_mrr_at_5_std': np.float64(0.03970725804693442), 'nauc_mrr_at_5_diff1': np.float64(0.6675321967565364), 'nauc_mrr_at_10_max': np.float64(0.4726482183566381), 'nauc_mrr_at_10_std': np.float64(0.03992466480001028), 'nauc_mrr_at_10_diff1': np.float64(0.6584969505864283), 'nauc_mrr_at_20_max': np.float64(0.4750531319415043), 'nauc_mrr_at_20_std': np.float64(0.04278409018479869), 'nauc_mrr_at_20_diff1': np.float64(0.6602038571715491), 'nauc_mrr_at_100_max': np.float64(0.4746250022073627), 'nauc_mrr_at_100_std': np.float64(0.04469178094094635), 'nauc_mrr_at_100_diff1': np.float64(0.6595691851449524), 'nauc_mrr_at_1000_max': np.float64(0.4743857559179589), 'nauc_mrr_at_1000_std': np.float64(0.04456651013258996), 'nauc_mrr_at_1000_diff1': np.float64(0.6598014592604037), 'main_score': 0.42728}}



==================================================
Running model: intfloat/multilingual-e5-small
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/multilingual-e5-small
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'query': 'query: ', 'passage': 'passage: '}
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / intfloat/multilingual-e5-small on GPU 0 in process Process-4
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  2.91it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  5.55it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:05,  3.55it/s]Batches:  11%|█         | 2/19 [00:01<00:14,  1.14it/s]Batches:  16%|█▌        | 3/19 [00:02<00:15,  1.05it/s]Batches:  21%|██        | 4/19 [00:03<00:13,  1.13it/s]Batches:  26%|██▋       | 5/19 [00:04<00:11,  1.24it/s]Batches:  32%|███▏      | 6/19 [00:04<00:09,  1.35it/s]Batches:  37%|███▋      | 7/19 [00:05<00:07,  1.50it/s]Batches:  42%|████▏     | 8/19 [00:05<00:06,  1.64it/s]Batches:  47%|████▋     | 9/19 [00:06<00:05,  1.78it/s]Batches:  53%|█████▎    | 10/19 [00:06<00:04,  1.90it/s]Batches:  58%|█████▊    | 11/19 [00:06<00:03,  2.11it/s]Batches:  63%|██████▎   | 12/19 [00:07<00:03,  2.28it/s]Batches:  68%|██████▊   | 13/19 [00:07<00:02,  2.46it/s]Batches:  74%|███████▎  | 14/19 [00:07<00:01,  2.64it/s]Batches:  79%|███████▉  | 15/19 [00:08<00:01,  2.88it/s]Batches:  84%|████████▍ | 16/19 [00:08<00:00,  3.18it/s]Batches:  89%|████████▉ | 17/19 [00:08<00:00,  3.51it/s]Batches:  95%|█████████▍| 18/19 [00:08<00:00,  3.95it/s]Batches: 100%|██████████| 19/19 [00:09<00:00,  4.50it/s]Batches: 100%|██████████| 19/19 [00:09<00:00,  2.11it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.20 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 10.83 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.70946, 'ndcg_at_3': 0.69862, 'ndcg_at_5': 0.72895, 'ndcg_at_10': 0.75157, 'ndcg_at_20': 0.75909, 'ndcg_at_100': 0.76968, 'ndcg_at_1000': 0.77842, 'map_at_1': 0.4655, 'map_at_3': 0.6543, 'map_at_5': 0.68306, 'map_at_10': 0.6978, 'map_at_20': 0.70128, 'map_at_100': 0.70356, 'map_at_1000': 0.70396, 'recall_at_1': 0.4655, 'recall_at_3': 0.70503, 'recall_at_5': 0.7675, 'recall_at_10': 0.82169, 'recall_at_20': 0.84396, 'recall_at_100': 0.88959, 'recall_at_1000': 0.94553, 'precision_at_1': 0.70946, 'precision_at_3': 0.40935, 'precision_at_5': 0.27601, 'precision_at_10': 0.15084, 'precision_at_20': 0.07838, 'precision_at_100': 0.01662, 'precision_at_1000': 0.00179, 'mrr_at_1': 0.7094594594594594, 'mrr_at_3': 0.7668918918918917, 'mrr_at_5': 0.7726351351351349, 'mrr_at_10': 0.7755342395967393, 'mrr_at_20': 0.7760676314444693, 'mrr_at_100': 0.7769212489361353, 'mrr_at_1000': 0.7771072265550619, 'nauc_ndcg_at_1_max': np.float64(0.5766346799075928), 'nauc_ndcg_at_1_std': np.float64(0.287026162875023), 'nauc_ndcg_at_1_diff1': np.float64(0.685119749954338), 'nauc_ndcg_at_3_max': np.float64(0.5739590413041299), 'nauc_ndcg_at_3_std': np.float64(0.2795931635950405), 'nauc_ndcg_at_3_diff1': np.float64(0.5758941904182479), 'nauc_ndcg_at_5_max': np.float64(0.6317306804098507), 'nauc_ndcg_at_5_std': np.float64(0.335582748658552), 'nauc_ndcg_at_5_diff1': np.float64(0.5866867118925719), 'nauc_ndcg_at_10_max': np.float64(0.658832903489693), 'nauc_ndcg_at_10_std': np.float64(0.36124687334257166), 'nauc_ndcg_at_10_diff1': np.float64(0.6002622679058943), 'nauc_ndcg_at_20_max': np.float64(0.6643479890870099), 'nauc_ndcg_at_20_std': np.float64(0.3792317000367893), 'nauc_ndcg_at_20_diff1': np.float64(0.6052662906639449), 'nauc_ndcg_at_100_max': np.float64(0.6610745201340645), 'nauc_ndcg_at_100_std': np.float64(0.38954715843828536), 'nauc_ndcg_at_100_diff1': np.float64(0.6122789400184262), 'nauc_ndcg_at_1000_max': np.float64(0.6564764278465486), 'nauc_ndcg_at_1000_std': np.float64(0.38155527406482265), 'nauc_ndcg_at_1000_diff1': np.float64(0.6134310183168443), 'nauc_map_at_1_max': np.float64(0.29338478320959144), 'nauc_map_at_1_std': np.float64(0.05287728544502341), 'nauc_map_at_1_diff1': np.float64(0.5890620019236731), 'nauc_map_at_3_max': np.float64(0.5304599618721426), 'nauc_map_at_3_std': np.float64(0.22702781828583524), 'nauc_map_at_3_diff1': np.float64(0.563060738604609), 'nauc_map_at_5_max': np.float64(0.5794918702985703), 'nauc_map_at_5_std': np.float64(0.2724935368518438), 'nauc_map_at_5_diff1': np.float64(0.5686131972789663), 'nauc_map_at_10_max': np.float64(0.5938659792593926), 'nauc_map_at_10_std': np.float64(0.2856068897720382), 'nauc_map_at_10_diff1': np.float64(0.5765725144622771), 'nauc_map_at_20_max': np.float64(0.5964819033911), 'nauc_map_at_20_std': np.float64(0.29272546688557866), 'nauc_map_at_20_diff1': np.float64(0.5779571136423193), 'nauc_map_at_100_max': np.float64(0.5955042819557741), 'nauc_map_at_100_std': np.float64(0.29475780997421375), 'nauc_map_at_100_diff1': np.float64(0.5791244442559803), 'nauc_map_at_1000_max': np.float64(0.5953754970921675), 'nauc_map_at_1000_std': np.float64(0.29462023438331475), 'nauc_map_at_1000_diff1': np.float64(0.5791313744345391), 'nauc_recall_at_1_max': np.float64(0.29338478320959144), 'nauc_recall_at_1_std': np.float64(0.05287728544502341), 'nauc_recall_at_1_diff1': np.float64(0.5890620019236731), 'nauc_recall_at_3_max': np.float64(0.5722972396382203), 'nauc_recall_at_3_std': np.float64(0.2839138990865646), 'nauc_recall_at_3_diff1': np.float64(0.5258704464784557), 'nauc_recall_at_5_max': np.float64(0.6720576752554087), 'nauc_recall_at_5_std': np.float64(0.4000336793363972), 'nauc_recall_at_5_diff1': np.float64(0.5286361464051987), 'nauc_recall_at_10_max': np.float64(0.7644281100472732), 'nauc_recall_at_10_std': np.float64(0.49376123740341865), 'nauc_recall_at_10_diff1': np.float64(0.5584293671193131), 'nauc_recall_at_20_max': np.float64(0.8039368296476209), 'nauc_recall_at_20_std': np.float64(0.5892670152753934), 'nauc_recall_at_20_diff1': np.float64(0.5827017651183409), 'nauc_recall_at_100_max': np.float64(0.8369432265872095), 'nauc_recall_at_100_std': np.float64(0.7371104967600931), 'nauc_recall_at_100_diff1': np.float64(0.6338933517786078), 'nauc_recall_at_1000_max': np.float64(0.9124386308531632), 'nauc_recall_at_1000_std': np.float64(0.8835647413067012), 'nauc_recall_at_1000_diff1': np.float64(0.6971578091097107), 'nauc_precision_at_1_max': np.float64(0.5766346799075928), 'nauc_precision_at_1_std': np.float64(0.287026162875023), 'nauc_precision_at_1_diff1': np.float64(0.685119749954338), 'nauc_precision_at_3_max': np.float64(0.4440930571952993), 'nauc_precision_at_3_std': np.float64(0.33026150731979703), 'nauc_precision_at_3_diff1': np.float64(0.11787914428306626), 'nauc_precision_at_5_max': np.float64(0.402049163236469), 'nauc_precision_at_5_std': np.float64(0.3462664005898467), 'nauc_precision_at_5_diff1': np.float64(0.02901018557778263), 'nauc_precision_at_10_max': np.float64(0.3531033123603171), 'nauc_precision_at_10_std': np.float64(0.3410327930550393), 'nauc_precision_at_10_diff1': np.float64(-0.02648329675447909), 'nauc_precision_at_20_max': np.float64(0.3167973274766834), 'nauc_precision_at_20_std': np.float64(0.3463777789403529), 'nauc_precision_at_20_diff1': np.float64(-0.052018627850537444), 'nauc_precision_at_100_max': np.float64(0.2404946357853683), 'nauc_precision_at_100_std': np.float64(0.33487282545240854), 'nauc_precision_at_100_diff1': np.float64(-0.09899721751706723), 'nauc_precision_at_1000_max': np.float64(0.1101191921989063), 'nauc_precision_at_1000_std': np.float64(0.2407475897819386), 'nauc_precision_at_1000_diff1': np.float64(-0.202156202052047), 'nauc_mrr_at_1_max': np.float64(0.5766346799075928), 'nauc_mrr_at_1_std': np.float64(0.287026162875023), 'nauc_mrr_at_1_diff1': np.float64(0.685119749954338), 'nauc_mrr_at_3_max': np.float64(0.6693306334880584), 'nauc_mrr_at_3_std': np.float64(0.3795336368640758), 'nauc_mrr_at_3_diff1': np.float64(0.6754825556812021), 'nauc_mrr_at_5_max': np.float64(0.6661850587998155), 'nauc_mrr_at_5_std': np.float64(0.3886964422435426), 'nauc_mrr_at_5_diff1': np.float64(0.6755775969931895), 'nauc_mrr_at_10_max': np.float64(0.6683723622861234), 'nauc_mrr_at_10_std': np.float64(0.3904358346792765), 'nauc_mrr_at_10_diff1': np.float64(0.6755316447974663), 'nauc_mrr_at_20_max': np.float64(0.6677544098971011), 'nauc_mrr_at_20_std': np.float64(0.3904699183521428), 'nauc_mrr_at_20_diff1': np.float64(0.675777519472839), 'nauc_mrr_at_100_max': np.float64(0.6670230447572645), 'nauc_mrr_at_100_std': np.float64(0.3905571029230324), 'nauc_mrr_at_100_diff1': np.float64(0.6763644341760295), 'nauc_mrr_at_1000_max': np.float64(0.6668153683870198), 'nauc_mrr_at_1000_std': np.float64(0.3902901692979351), 'nauc_mrr_at_1000_diff1': np.float64(0.6763642630616934), 'main_score': 0.75157}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 46.06it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.45it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.19 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 2.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.65789, 'ndcg_at_3': 0.76493, 'ndcg_at_5': 0.7785, 'ndcg_at_10': 0.80068, 'ndcg_at_20': 0.81411, 'ndcg_at_100': 0.81411, 'ndcg_at_1000': 0.81411, 'map_at_1': 0.65789, 'map_at_3': 0.7383, 'map_at_5': 0.74532, 'map_at_10': 0.75416, 'map_at_20': 0.7579, 'map_at_100': 0.7579, 'map_at_1000': 0.7579, 'recall_at_1': 0.65789, 'recall_at_3': 0.84211, 'recall_at_5': 0.87719, 'recall_at_10': 0.94737, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.65789, 'precision_at_3': 0.2807, 'precision_at_5': 0.17544, 'precision_at_10': 0.09474, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6578947368421053, 'mrr_at_3': 0.7383040935672514, 'mrr_at_5': 0.7453216374269005, 'mrr_at_10': 0.7541597048175996, 'mrr_at_20': 0.7579023680997365, 'mrr_at_100': 0.7579023680997365, 'mrr_at_1000': 0.7579023680997365, 'nauc_ndcg_at_1_max': np.float64(0.36872268898533067), 'nauc_ndcg_at_1_std': np.float64(-0.4401392469826774), 'nauc_ndcg_at_1_diff1': np.float64(0.6560236602262656), 'nauc_ndcg_at_3_max': np.float64(0.4234841909277944), 'nauc_ndcg_at_3_std': np.float64(-0.4824682275486362), 'nauc_ndcg_at_3_diff1': np.float64(0.624826053405146), 'nauc_ndcg_at_5_max': np.float64(0.3977079913947522), 'nauc_ndcg_at_5_std': np.float64(-0.4727377181506764), 'nauc_ndcg_at_5_diff1': np.float64(0.6162637799700798), 'nauc_ndcg_at_10_max': np.float64(0.3730096635511718), 'nauc_ndcg_at_10_std': np.float64(-0.4570357123084824), 'nauc_ndcg_at_10_diff1': np.float64(0.6373482101221916), 'nauc_ndcg_at_20_max': np.float64(0.37849267470469455), 'nauc_ndcg_at_20_std': np.float64(-0.46450573804215967), 'nauc_ndcg_at_20_diff1': np.float64(0.631082344702166), 'nauc_ndcg_at_100_max': np.float64(0.37849267470469455), 'nauc_ndcg_at_100_std': np.float64(-0.46450573804215967), 'nauc_ndcg_at_100_diff1': np.float64(0.631082344702166), 'nauc_ndcg_at_1000_max': np.float64(0.37849267470469455), 'nauc_ndcg_at_1000_std': np.float64(-0.46450573804215967), 'nauc_ndcg_at_1000_diff1': np.float64(0.631082344702166), 'nauc_map_at_1_max': np.float64(0.36872268898533067), 'nauc_map_at_1_std': np.float64(-0.4401392469826774), 'nauc_map_at_1_diff1': np.float64(0.6560236602262656), 'nauc_map_at_3_max': np.float64(0.39750080901895046), 'nauc_map_at_3_std': np.float64(-0.47097924869111946), 'nauc_map_at_3_diff1': np.float64(0.62917541745435), 'nauc_map_at_5_max': np.float64(0.38497343555386), 'nauc_map_at_5_std': np.float64(-0.4662034259751144), 'nauc_map_at_5_diff1': np.float64(0.6253752016408517), 'nauc_map_at_10_max': np.float64(0.3764737919485942), 'nauc_map_at_10_std': np.float64(-0.4603411662441989), 'nauc_map_at_10_diff1': np.float64(0.6336126403051213), 'nauc_map_at_20_max': np.float64(0.3770956578619853), 'nauc_map_at_20_std': np.float64(-0.46271075804080886), 'nauc_map_at_20_diff1': np.float64(0.632053719125245), 'nauc_map_at_100_max': np.float64(0.3770956578619853), 'nauc_map_at_100_std': np.float64(-0.46271075804080886), 'nauc_map_at_100_diff1': np.float64(0.632053719125245), 'nauc_map_at_1000_max': np.float64(0.3770956578619853), 'nauc_map_at_1000_std': np.float64(-0.46271075804080886), 'nauc_map_at_1000_diff1': np.float64(0.632053719125245), 'nauc_recall_at_1_max': np.float64(0.36872268898533067), 'nauc_recall_at_1_std': np.float64(-0.4401392469826774), 'nauc_recall_at_1_diff1': np.float64(0.6560236602262656), 'nauc_recall_at_3_max': np.float64(0.5421742812098024), 'nauc_recall_at_3_std': np.float64(-0.5315536105998091), 'nauc_recall_at_3_diff1': np.float64(0.6090878259059774), 'nauc_recall_at_5_max': np.float64(0.4640358225626541), 'nauc_recall_at_5_std': np.float64(-0.503150492125607), 'nauc_recall_at_5_diff1': np.float64(0.5690295312193233), 'nauc_recall_at_10_max': np.float64(0.28898840143985643), 'nauc_recall_at_10_std': np.float64(-0.388301973489612), 'nauc_recall_at_10_diff1': np.float64(0.7073433520488993), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.36872268898533067), 'nauc_precision_at_1_std': np.float64(-0.4401392469826774), 'nauc_precision_at_1_diff1': np.float64(0.6560236602262656), 'nauc_precision_at_3_max': np.float64(0.5421742812098002), 'nauc_precision_at_3_std': np.float64(-0.5315536105998095), 'nauc_precision_at_3_diff1': np.float64(0.6090878259059757), 'nauc_precision_at_5_max': np.float64(0.4640358225626522), 'nauc_precision_at_5_std': np.float64(-0.5031504921256055), 'nauc_precision_at_5_diff1': np.float64(0.5690295312193225), 'nauc_precision_at_10_max': np.float64(0.2889884014398526), 'nauc_precision_at_10_std': np.float64(-0.388301973489614), 'nauc_precision_at_10_diff1': np.float64(0.7073433520488956), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.36872268898533067), 'nauc_mrr_at_1_std': np.float64(-0.4401392469826774), 'nauc_mrr_at_1_diff1': np.float64(0.6560236602262656), 'nauc_mrr_at_3_max': np.float64(0.39750080901895046), 'nauc_mrr_at_3_std': np.float64(-0.47097924869111946), 'nauc_mrr_at_3_diff1': np.float64(0.62917541745435), 'nauc_mrr_at_5_max': np.float64(0.38497343555386), 'nauc_mrr_at_5_std': np.float64(-0.4662034259751144), 'nauc_mrr_at_5_diff1': np.float64(0.6253752016408517), 'nauc_mrr_at_10_max': np.float64(0.3764737919485942), 'nauc_mrr_at_10_std': np.float64(-0.4603411662441989), 'nauc_mrr_at_10_diff1': np.float64(0.6336126403051213), 'nauc_mrr_at_20_max': np.float64(0.3770956578619853), 'nauc_mrr_at_20_std': np.float64(-0.46271075804080886), 'nauc_mrr_at_20_diff1': np.float64(0.632053719125245), 'nauc_mrr_at_100_max': np.float64(0.3770956578619853), 'nauc_mrr_at_100_std': np.float64(-0.46271075804080886), 'nauc_mrr_at_100_diff1': np.float64(0.632053719125245), 'nauc_mrr_at_1000_max': np.float64(0.3770956578619853), 'nauc_mrr_at_1000_std': np.float64(-0.46271075804080886), 'nauc_mrr_at_1000_diff1': np.float64(0.632053719125245), 'main_score': 0.80068}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 28.76it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.36 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.55844, 'ndcg_at_3': 0.68274, 'ndcg_at_5': 0.71573, 'ndcg_at_10': 0.73668, 'ndcg_at_20': 0.74668, 'ndcg_at_100': 0.75694, 'ndcg_at_1000': 0.75694, 'map_at_1': 0.55844, 'map_at_3': 0.65368, 'map_at_5': 0.67251, 'map_at_10': 0.68113, 'map_at_20': 0.68396, 'map_at_100': 0.68558, 'map_at_1000': 0.68558, 'recall_at_1': 0.55844, 'recall_at_3': 0.76623, 'recall_at_5': 0.84416, 'recall_at_10': 0.90909, 'recall_at_20': 0.94805, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.55844, 'precision_at_3': 0.25541, 'precision_at_5': 0.16883, 'precision_at_10': 0.09091, 'precision_at_20': 0.0474, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5584415584415584, 'mrr_at_3': 0.6536796536796537, 'mrr_at_5': 0.6725108225108226, 'mrr_at_10': 0.6811276025561741, 'mrr_at_20': 0.6839573846067354, 'mrr_at_100': 0.6855766218585322, 'mrr_at_1000': 0.6855766218585322, 'nauc_ndcg_at_1_max': np.float64(0.07066521787222413), 'nauc_ndcg_at_1_std': np.float64(-0.17792175457714043), 'nauc_ndcg_at_1_diff1': np.float64(0.55937676176893), 'nauc_ndcg_at_3_max': np.float64(0.10619126728752766), 'nauc_ndcg_at_3_std': np.float64(-0.21883346467070147), 'nauc_ndcg_at_3_diff1': np.float64(0.6028342770967995), 'nauc_ndcg_at_5_max': np.float64(0.044886852793084416), 'nauc_ndcg_at_5_std': np.float64(-0.20042531147499396), 'nauc_ndcg_at_5_diff1': np.float64(0.5980816495707385), 'nauc_ndcg_at_10_max': np.float64(0.07306809340721457), 'nauc_ndcg_at_10_std': np.float64(-0.12496628561991105), 'nauc_ndcg_at_10_diff1': np.float64(0.602180461424923), 'nauc_ndcg_at_20_max': np.float64(0.0704998646916556), 'nauc_ndcg_at_20_std': np.float64(-0.13039964417271568), 'nauc_ndcg_at_20_diff1': np.float64(0.5896130536519305), 'nauc_ndcg_at_100_max': np.float64(0.08735000875032328), 'nauc_ndcg_at_100_std': np.float64(-0.15883247371269535), 'nauc_ndcg_at_100_diff1': np.float64(0.5885655161653102), 'nauc_ndcg_at_1000_max': np.float64(0.08735000875032328), 'nauc_ndcg_at_1000_std': np.float64(-0.15883247371269535), 'nauc_ndcg_at_1000_diff1': np.float64(0.5885655161653102), 'nauc_map_at_1_max': np.float64(0.07066521787222413), 'nauc_map_at_1_std': np.float64(-0.17792175457714043), 'nauc_map_at_1_diff1': np.float64(0.55937676176893), 'nauc_map_at_3_max': np.float64(0.1048700254956332), 'nauc_map_at_3_std': np.float64(-0.1983892709222007), 'nauc_map_at_3_diff1': np.float64(0.588096957320964), 'nauc_map_at_5_max': np.float64(0.07271945638748804), 'nauc_map_at_5_std': np.float64(-0.18813702300628377), 'nauc_map_at_5_diff1': np.float64(0.5852140849286879), 'nauc_map_at_10_max': np.float64(0.08651967885284238), 'nauc_map_at_10_std': np.float64(-0.16089423219302526), 'nauc_map_at_10_diff1': np.float64(0.5870657937571075), 'nauc_map_at_20_max': np.float64(0.08607885727057123), 'nauc_map_at_20_std': np.float64(-0.16226310179510992), 'nauc_map_at_20_diff1': np.float64(0.5840939095692412), 'nauc_map_at_100_max': np.float64(0.08925986226773808), 'nauc_map_at_100_std': np.float64(-0.16578780237020024), 'nauc_map_at_100_diff1': np.float64(0.5840673694197391), 'nauc_map_at_1000_max': np.float64(0.08925986226773808), 'nauc_map_at_1000_std': np.float64(-0.16578780237020024), 'nauc_map_at_1000_diff1': np.float64(0.5840673694197391), 'nauc_recall_at_1_max': np.float64(0.07066521787222413), 'nauc_recall_at_1_std': np.float64(-0.17792175457714043), 'nauc_recall_at_1_diff1': np.float64(0.55937676176893), 'nauc_recall_at_3_max': np.float64(0.1063772476030141), 'nauc_recall_at_3_std': np.float64(-0.3008489309313968), 'nauc_recall_at_3_diff1': np.float64(0.6597833633383808), 'nauc_recall_at_5_max': np.float64(-0.11425615359625227), 'nauc_recall_at_5_std': np.float64(-0.2647231885384945), 'nauc_recall_at_5_diff1': np.float64(0.6631280953358314), 'nauc_recall_at_10_max': np.float64(-0.05636729572254811), 'nauc_recall_at_10_std': np.float64(0.23863037261271688), 'nauc_recall_at_10_diff1': np.float64(0.7227034806442434), 'nauc_recall_at_20_max': np.float64(-0.19287140369507577), 'nauc_recall_at_20_std': np.float64(0.4187089299703777), 'nauc_recall_at_20_diff1': np.float64(0.616902254122781), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.07066521787222413), 'nauc_precision_at_1_std': np.float64(-0.17792175457714043), 'nauc_precision_at_1_diff1': np.float64(0.55937676176893), 'nauc_precision_at_3_max': np.float64(0.10637724760301429), 'nauc_precision_at_3_std': np.float64(-0.300848930931394), 'nauc_precision_at_3_diff1': np.float64(0.6597833633383813), 'nauc_precision_at_5_max': np.float64(-0.11425615359625114), 'nauc_precision_at_5_std': np.float64(-0.2647231885384947), 'nauc_precision_at_5_diff1': np.float64(0.6631280953358322), 'nauc_precision_at_10_max': np.float64(-0.0563672957225449), 'nauc_precision_at_10_std': np.float64(0.2386303726127177), 'nauc_precision_at_10_diff1': np.float64(0.7227034806442454), 'nauc_precision_at_20_max': np.float64(-0.19287140369506778), 'nauc_precision_at_20_std': np.float64(0.4187089299703816), 'nauc_precision_at_20_diff1': np.float64(0.6169022541227838), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.07066521787222413), 'nauc_mrr_at_1_std': np.float64(-0.17792175457714043), 'nauc_mrr_at_1_diff1': np.float64(0.55937676176893), 'nauc_mrr_at_3_max': np.float64(0.1048700254956332), 'nauc_mrr_at_3_std': np.float64(-0.1983892709222007), 'nauc_mrr_at_3_diff1': np.float64(0.588096957320964), 'nauc_mrr_at_5_max': np.float64(0.07271945638748804), 'nauc_mrr_at_5_std': np.float64(-0.18813702300628377), 'nauc_mrr_at_5_diff1': np.float64(0.5852140849286879), 'nauc_mrr_at_10_max': np.float64(0.08651967885284238), 'nauc_mrr_at_10_std': np.float64(-0.16089423219302526), 'nauc_mrr_at_10_diff1': np.float64(0.5870657937571075), 'nauc_mrr_at_20_max': np.float64(0.08607885727057123), 'nauc_mrr_at_20_std': np.float64(-0.16226310179510992), 'nauc_mrr_at_20_diff1': np.float64(0.5840939095692412), 'nauc_mrr_at_100_max': np.float64(0.08925986226773808), 'nauc_mrr_at_100_std': np.float64(-0.16578780237020024), 'nauc_mrr_at_100_diff1': np.float64(0.5840673694197391), 'nauc_mrr_at_1000_max': np.float64(0.08925986226773808), 'nauc_mrr_at_1000_std': np.float64(-0.16578780237020024), 'nauc_mrr_at_1000_diff1': np.float64(0.5840673694197391), 'main_score': 0.73668}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 14.45it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 14.18it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.51 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 15.46it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 15.31it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.48 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 16.17it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 16.03it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.48 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 6.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.84889, 'ndcg_at_3': 0.88696, 'ndcg_at_5': 0.89705, 'ndcg_at_10': 0.90531, 'ndcg_at_20': 0.90838, 'ndcg_at_100': 0.91193, 'ndcg_at_1000': 0.91283, 'map_at_1': 0.84889, 'map_at_3': 0.87815, 'map_at_5': 0.88376, 'map_at_10': 0.88717, 'map_at_20': 0.888, 'map_at_100': 0.8885, 'map_at_1000': 0.88854, 'recall_at_1': 0.84889, 'recall_at_3': 0.91222, 'recall_at_5': 0.93667, 'recall_at_10': 0.96222, 'recall_at_20': 0.97444, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.84889, 'precision_at_3': 0.30407, 'precision_at_5': 0.18733, 'precision_at_10': 0.09622, 'precision_at_20': 0.04872, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8488888888888889, 'mrr_at_3': 0.8781481481481482, 'mrr_at_5': 0.8837592592592594, 'mrr_at_10': 0.8871710758377426, 'mrr_at_20': 0.8880033052220876, 'mrr_at_100': 0.8885033177076556, 'mrr_at_1000': 0.8885449107626566, 'nauc_ndcg_at_1_max': np.float64(0.8173234398345032), 'nauc_ndcg_at_1_std': np.float64(0.1042444833927131), 'nauc_ndcg_at_1_diff1': np.float64(0.9093171761866453), 'nauc_ndcg_at_3_max': np.float64(0.8237593265636195), 'nauc_ndcg_at_3_std': np.float64(0.0934607309138353), 'nauc_ndcg_at_3_diff1': np.float64(0.8802387199138326), 'nauc_ndcg_at_5_max': np.float64(0.8224146760632134), 'nauc_ndcg_at_5_std': np.float64(0.10931082706973504), 'nauc_ndcg_at_5_diff1': np.float64(0.8817259957851487), 'nauc_ndcg_at_10_max': np.float64(0.8218077627800805), 'nauc_ndcg_at_10_std': np.float64(0.1253860361330948), 'nauc_ndcg_at_10_diff1': np.float64(0.8888721921009058), 'nauc_ndcg_at_20_max': np.float64(0.8247107944685931), 'nauc_ndcg_at_20_std': np.float64(0.13759989058505856), 'nauc_ndcg_at_20_diff1': np.float64(0.8913596544839895), 'nauc_ndcg_at_100_max': np.float64(0.8213638377652307), 'nauc_ndcg_at_100_std': np.float64(0.12150314145145663), 'nauc_ndcg_at_100_diff1': np.float64(0.8910561766218634), 'nauc_ndcg_at_1000_max': np.float64(0.8221005884374746), 'nauc_ndcg_at_1000_std': np.float64(0.11799550026182913), 'nauc_ndcg_at_1000_diff1': np.float64(0.8908288989896431), 'nauc_map_at_1_max': np.float64(0.8173234398345032), 'nauc_map_at_1_std': np.float64(0.1042444833927131), 'nauc_map_at_1_diff1': np.float64(0.9093171761866453), 'nauc_map_at_3_max': np.float64(0.8221072866279964), 'nauc_map_at_3_std': np.float64(0.09881582442732599), 'nauc_map_at_3_diff1': np.float64(0.8878375695865522), 'nauc_map_at_5_max': np.float64(0.8215429100335581), 'nauc_map_at_5_std': np.float64(0.10724011198978041), 'nauc_map_at_5_diff1': np.float64(0.8888866246738191), 'nauc_map_at_10_max': np.float64(0.8211166928440419), 'nauc_map_at_10_std': np.float64(0.11152222570010063), 'nauc_map_at_10_diff1': np.float64(0.8916084661334417), 'nauc_map_at_20_max': np.float64(0.8217517524112766), 'nauc_map_at_20_std': np.float64(0.11400792875239284), 'nauc_map_at_20_diff1': np.float64(0.8922227459976874), 'nauc_map_at_100_max': np.float64(0.8213792215556506), 'nauc_map_at_100_std': np.float64(0.11200943057445756), 'nauc_map_at_100_diff1': np.float64(0.8922049779859754), 'nauc_map_at_1000_max': np.float64(0.8214248077637112), 'nauc_map_at_1000_std': np.float64(0.11195188871869823), 'nauc_map_at_1000_diff1': np.float64(0.8921937614458508), 'nauc_recall_at_1_max': np.float64(0.8173234398345032), 'nauc_recall_at_1_std': np.float64(0.1042444833927131), 'nauc_recall_at_1_diff1': np.float64(0.9093171761866453), 'nauc_recall_at_3_max': np.float64(0.8300594499403131), 'nauc_recall_at_3_std': np.float64(0.07138720467089646), 'nauc_recall_at_3_diff1': np.float64(0.8511742249642473), 'nauc_recall_at_5_max': np.float64(0.8259701541435285), 'nauc_recall_at_5_std': np.float64(0.12147198060510653), 'nauc_recall_at_5_diff1': np.float64(0.8461513260274869), 'nauc_recall_at_10_max': np.float64(0.8265364969517209), 'nauc_recall_at_10_std': np.float64(0.27006096556269293), 'nauc_recall_at_10_diff1': np.float64(0.8755972977426268), 'nauc_recall_at_20_max': np.float64(0.8693013437258947), 'nauc_recall_at_20_std': np.float64(0.5127065318881187), 'nauc_recall_at_20_diff1': np.float64(0.9024682336702778), 'nauc_recall_at_100_max': np.float64(0.7639277933395526), 'nauc_recall_at_100_std': np.float64(0.4997665732959751), 'nauc_recall_at_100_diff1': np.float64(0.910130718954248), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8173234398345032), 'nauc_precision_at_1_std': np.float64(0.1042444833927131), 'nauc_precision_at_1_diff1': np.float64(0.9093171761866453), 'nauc_precision_at_3_max': np.float64(0.8300594499403151), 'nauc_precision_at_3_std': np.float64(0.0713872046708973), 'nauc_precision_at_3_diff1': np.float64(0.8511742249642471), 'nauc_precision_at_5_max': np.float64(0.8259701541435274), 'nauc_precision_at_5_std': np.float64(0.1214719806051033), 'nauc_precision_at_5_diff1': np.float64(0.846151326027489), 'nauc_precision_at_10_max': np.float64(0.8265364969517152), 'nauc_precision_at_10_std': np.float64(0.27006096556269127), 'nauc_precision_at_10_diff1': np.float64(0.8755972977426221), 'nauc_precision_at_20_max': np.float64(0.8693013437258945), 'nauc_precision_at_20_std': np.float64(0.5127065318881154), 'nauc_precision_at_20_diff1': np.float64(0.9024682336702726), 'nauc_precision_at_100_max': np.float64(0.7639277933395436), 'nauc_precision_at_100_std': np.float64(0.4997665732960076), 'nauc_precision_at_100_diff1': np.float64(0.9101307189542385), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8173234398345032), 'nauc_mrr_at_1_std': np.float64(0.1042444833927131), 'nauc_mrr_at_1_diff1': np.float64(0.9093171761866453), 'nauc_mrr_at_3_max': np.float64(0.8221072866279964), 'nauc_mrr_at_3_std': np.float64(0.09881582442732599), 'nauc_mrr_at_3_diff1': np.float64(0.8878375695865522), 'nauc_mrr_at_5_max': np.float64(0.8215429100335581), 'nauc_mrr_at_5_std': np.float64(0.10724011198978041), 'nauc_mrr_at_5_diff1': np.float64(0.8888866246738191), 'nauc_mrr_at_10_max': np.float64(0.8211166928440419), 'nauc_mrr_at_10_std': np.float64(0.11152222570010063), 'nauc_mrr_at_10_diff1': np.float64(0.8916084661334417), 'nauc_mrr_at_20_max': np.float64(0.8217517524112766), 'nauc_mrr_at_20_std': np.float64(0.11400792875239284), 'nauc_mrr_at_20_diff1': np.float64(0.8922227459976874), 'nauc_mrr_at_100_max': np.float64(0.8213792215556506), 'nauc_mrr_at_100_std': np.float64(0.11200943057445756), 'nauc_mrr_at_100_diff1': np.float64(0.8922049779859754), 'nauc_mrr_at_1000_max': np.float64(0.8214248077637112), 'nauc_mrr_at_1000_std': np.float64(0.11195188871869823), 'nauc_mrr_at_1000_diff1': np.float64(0.8921937614458508), 'main_score': 0.90531}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.66333, 'ndcg_at_3': 0.74342, 'ndcg_at_5': 0.76059, 'ndcg_at_10': 0.77776, 'ndcg_at_20': 0.78834, 'ndcg_at_100': 0.79854, 'ndcg_at_1000': 0.79972, 'map_at_1': 0.66333, 'map_at_3': 0.72352, 'map_at_5': 0.73291, 'map_at_10': 0.74017, 'map_at_20': 0.74317, 'map_at_100': 0.7446, 'map_at_1000': 0.74466, 'recall_at_1': 0.66333, 'recall_at_3': 0.80111, 'recall_at_5': 0.84333, 'recall_at_10': 0.89556, 'recall_at_20': 0.93667, 'recall_at_100': 0.99111, 'recall_at_1000': 1.0, 'precision_at_1': 0.66333, 'precision_at_3': 0.26704, 'precision_at_5': 0.16867, 'precision_at_10': 0.08956, 'precision_at_20': 0.04683, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6633333333333333, 'mrr_at_3': 0.7235185185185183, 'mrr_at_5': 0.7329074074074071, 'mrr_at_10': 0.7401657848324512, 'mrr_at_20': 0.7431662161558961, 'mrr_at_100': 0.7446047246863822, 'mrr_at_1000': 0.7446580576005215, 'nauc_ndcg_at_1_max': np.float64(0.40182752649133824), 'nauc_ndcg_at_1_std': np.float64(0.04659394425357453), 'nauc_ndcg_at_1_diff1': np.float64(0.8165717266097584), 'nauc_ndcg_at_3_max': np.float64(0.3863041767801002), 'nauc_ndcg_at_3_std': np.float64(0.06490627741629232), 'nauc_ndcg_at_3_diff1': np.float64(0.778864640402583), 'nauc_ndcg_at_5_max': np.float64(0.38685354824799795), 'nauc_ndcg_at_5_std': np.float64(0.050173351675964296), 'nauc_ndcg_at_5_diff1': np.float64(0.778170465498708), 'nauc_ndcg_at_10_max': np.float64(0.38746361240809435), 'nauc_ndcg_at_10_std': np.float64(0.05866340081472894), 'nauc_ndcg_at_10_diff1': np.float64(0.7746117195336447), 'nauc_ndcg_at_20_max': np.float64(0.391031895180412), 'nauc_ndcg_at_20_std': np.float64(0.052453150105635296), 'nauc_ndcg_at_20_diff1': np.float64(0.7792900969788079), 'nauc_ndcg_at_100_max': np.float64(0.38721070963375537), 'nauc_ndcg_at_100_std': np.float64(0.05504607176342128), 'nauc_ndcg_at_100_diff1': np.float64(0.784374537195635), 'nauc_ndcg_at_1000_max': np.float64(0.3892825547348183), 'nauc_ndcg_at_1000_std': np.float64(0.05428192985031319), 'nauc_ndcg_at_1000_diff1': np.float64(0.7862800645681892), 'nauc_map_at_1_max': np.float64(0.40182752649133824), 'nauc_map_at_1_std': np.float64(0.04659394425357453), 'nauc_map_at_1_diff1': np.float64(0.8165717266097584), 'nauc_map_at_3_max': np.float64(0.3906172632316036), 'nauc_map_at_3_std': np.float64(0.05787649816388305), 'nauc_map_at_3_diff1': np.float64(0.7904210827470053), 'nauc_map_at_5_max': np.float64(0.3910688430816441), 'nauc_map_at_5_std': np.float64(0.049994914614961916), 'nauc_map_at_5_diff1': np.float64(0.7903409964119197), 'nauc_map_at_10_max': np.float64(0.39141033319314905), 'nauc_map_at_10_std': np.float64(0.053532844896510896), 'nauc_map_at_10_diff1': np.float64(0.7893774023852507), 'nauc_map_at_20_max': np.float64(0.39242117450008973), 'nauc_map_at_20_std': np.float64(0.052015338794002226), 'nauc_map_at_20_diff1': np.float64(0.7907515694059803), 'nauc_map_at_100_max': np.float64(0.39174343297657943), 'nauc_map_at_100_std': np.float64(0.0524312475722998), 'nauc_map_at_100_diff1': np.float64(0.7913998382292451), 'nauc_map_at_1000_max': np.float64(0.39178024731680877), 'nauc_map_at_1000_std': np.float64(0.05244331337500457), 'nauc_map_at_1000_diff1': np.float64(0.7914801061691839), 'nauc_recall_at_1_max': np.float64(0.40182752649133824), 'nauc_recall_at_1_std': np.float64(0.04659394425357453), 'nauc_recall_at_1_diff1': np.float64(0.8165717266097584), 'nauc_recall_at_3_max': np.float64(0.3703395834844265), 'nauc_recall_at_3_std': np.float64(0.09197261909410939), 'nauc_recall_at_3_diff1': np.float64(0.7355075900005024), 'nauc_recall_at_5_max': np.float64(0.36815967081621787), 'nauc_recall_at_5_std': np.float64(0.049321962035434215), 'nauc_recall_at_5_diff1': np.float64(0.723349389383545), 'nauc_recall_at_10_max': np.float64(0.36337575164312663), 'nauc_recall_at_10_std': np.float64(0.09256947080328431), 'nauc_recall_at_10_diff1': np.float64(0.678960984477695), 'nauc_recall_at_20_max': np.float64(0.3854734876406697), 'nauc_recall_at_20_std': np.float64(0.04283584778941062), 'nauc_recall_at_20_diff1': np.float64(0.6691074090454888), 'nauc_recall_at_100_max': np.float64(0.03793183940243902), 'nauc_recall_at_100_std': np.float64(0.21288515406162598), 'nauc_recall_at_100_diff1': np.float64(0.5195494864612596), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.40182752649133824), 'nauc_precision_at_1_std': np.float64(0.04659394425357453), 'nauc_precision_at_1_diff1': np.float64(0.8165717266097584), 'nauc_precision_at_3_max': np.float64(0.37033958348442686), 'nauc_precision_at_3_std': np.float64(0.09197261909410961), 'nauc_precision_at_3_diff1': np.float64(0.7355075900005023), 'nauc_precision_at_5_max': np.float64(0.36815967081621487), 'nauc_precision_at_5_std': np.float64(0.04932196203543292), 'nauc_precision_at_5_diff1': np.float64(0.7233493893835441), 'nauc_precision_at_10_max': np.float64(0.3633757516431236), 'nauc_precision_at_10_std': np.float64(0.09256947080328301), 'nauc_precision_at_10_diff1': np.float64(0.6789609844776933), 'nauc_precision_at_20_max': np.float64(0.38547348764066774), 'nauc_precision_at_20_std': np.float64(0.04283584778940714), 'nauc_precision_at_20_diff1': np.float64(0.6691074090454863), 'nauc_precision_at_100_max': np.float64(0.03793183940245609), 'nauc_precision_at_100_std': np.float64(0.2128851540616532), 'nauc_precision_at_100_diff1': np.float64(0.5195494864612626), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.40182752649133824), 'nauc_mrr_at_1_std': np.float64(0.04659394425357453), 'nauc_mrr_at_1_diff1': np.float64(0.8165717266097584), 'nauc_mrr_at_3_max': np.float64(0.3906172632316036), 'nauc_mrr_at_3_std': np.float64(0.05787649816388305), 'nauc_mrr_at_3_diff1': np.float64(0.7904210827470053), 'nauc_mrr_at_5_max': np.float64(0.3910688430816441), 'nauc_mrr_at_5_std': np.float64(0.049994914614961916), 'nauc_mrr_at_5_diff1': np.float64(0.7903409964119197), 'nauc_mrr_at_10_max': np.float64(0.39141033319314905), 'nauc_mrr_at_10_std': np.float64(0.053532844896510896), 'nauc_mrr_at_10_diff1': np.float64(0.7893774023852507), 'nauc_mrr_at_20_max': np.float64(0.39242117450008973), 'nauc_mrr_at_20_std': np.float64(0.052015338794002226), 'nauc_mrr_at_20_diff1': np.float64(0.7907515694059803), 'nauc_mrr_at_100_max': np.float64(0.39174343297657943), 'nauc_mrr_at_100_std': np.float64(0.0524312475722998), 'nauc_mrr_at_100_diff1': np.float64(0.7913998382292451), 'nauc_mrr_at_1000_max': np.float64(0.39178024731680877), 'nauc_mrr_at_1000_std': np.float64(0.05244331337500457), 'nauc_mrr_at_1000_diff1': np.float64(0.7914801061691839), 'main_score': 0.77776}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.55333, 'ndcg_at_3': 0.63403, 'ndcg_at_5': 0.65436, 'ndcg_at_10': 0.68329, 'ndcg_at_20': 0.69583, 'ndcg_at_100': 0.71146, 'ndcg_at_1000': 0.7166, 'map_at_1': 0.55333, 'map_at_3': 0.61463, 'map_at_5': 0.62602, 'map_at_10': 0.63785, 'map_at_20': 0.64125, 'map_at_100': 0.64346, 'map_at_1000': 0.6437, 'recall_at_1': 0.55333, 'recall_at_3': 0.69, 'recall_at_5': 0.73889, 'recall_at_10': 0.82889, 'recall_at_20': 0.87889, 'recall_at_100': 0.96222, 'recall_at_1000': 1.0, 'precision_at_1': 0.55333, 'precision_at_3': 0.23, 'precision_at_5': 0.14778, 'precision_at_10': 0.08289, 'precision_at_20': 0.04394, 'precision_at_100': 0.00962, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5533333333333333, 'mrr_at_3': 0.6146296296296297, 'mrr_at_5': 0.6260185185185185, 'mrr_at_10': 0.6378540564373899, 'mrr_at_20': 0.6412454197658015, 'mrr_at_100': 0.6434558134337773, 'mrr_at_1000': 0.6436974222566946, 'nauc_ndcg_at_1_max': np.float64(0.5936733716025138), 'nauc_ndcg_at_1_std': np.float64(0.21168619271758166), 'nauc_ndcg_at_1_diff1': np.float64(0.7829492322676209), 'nauc_ndcg_at_3_max': np.float64(0.6021168610511854), 'nauc_ndcg_at_3_std': np.float64(0.24690968718813117), 'nauc_ndcg_at_3_diff1': np.float64(0.73042971727456), 'nauc_ndcg_at_5_max': np.float64(0.5917504894472805), 'nauc_ndcg_at_5_std': np.float64(0.2488749210364445), 'nauc_ndcg_at_5_diff1': np.float64(0.7255046843011821), 'nauc_ndcg_at_10_max': np.float64(0.5988526451994077), 'nauc_ndcg_at_10_std': np.float64(0.2754497293551384), 'nauc_ndcg_at_10_diff1': np.float64(0.7250999239321614), 'nauc_ndcg_at_20_max': np.float64(0.5974094856781158), 'nauc_ndcg_at_20_std': np.float64(0.26976697517653925), 'nauc_ndcg_at_20_diff1': np.float64(0.7294778264163425), 'nauc_ndcg_at_100_max': np.float64(0.5979148105316068), 'nauc_ndcg_at_100_std': np.float64(0.2626791416043742), 'nauc_ndcg_at_100_diff1': np.float64(0.7321895274231675), 'nauc_ndcg_at_1000_max': np.float64(0.5968220164125382), 'nauc_ndcg_at_1000_std': np.float64(0.2563668545349687), 'nauc_ndcg_at_1000_diff1': np.float64(0.7359140835058405), 'nauc_map_at_1_max': np.float64(0.5936733716025138), 'nauc_map_at_1_std': np.float64(0.21168619271758166), 'nauc_map_at_1_diff1': np.float64(0.7829492322676209), 'nauc_map_at_3_max': np.float64(0.6001061908278962), 'nauc_map_at_3_std': np.float64(0.23774774638033352), 'nauc_map_at_3_diff1': np.float64(0.7434655267858342), 'nauc_map_at_5_max': np.float64(0.5946239747126786), 'nauc_map_at_5_std': np.float64(0.23889530835459716), 'nauc_map_at_5_diff1': np.float64(0.7412031262838832), 'nauc_map_at_10_max': np.float64(0.5970116478410402), 'nauc_map_at_10_std': np.float64(0.24850618003634511), 'nauc_map_at_10_diff1': np.float64(0.7414437064377993), 'nauc_map_at_20_max': np.float64(0.5965831678042499), 'nauc_map_at_20_std': np.float64(0.24689715247637192), 'nauc_map_at_20_diff1': np.float64(0.7426078135161391), 'nauc_map_at_100_max': np.float64(0.5965161365684637), 'nauc_map_at_100_std': np.float64(0.24606173238364235), 'nauc_map_at_100_diff1': np.float64(0.7429227613065333), 'nauc_map_at_1000_max': np.float64(0.596492941928904), 'nauc_map_at_1000_std': np.float64(0.24586499141258242), 'nauc_map_at_1000_diff1': np.float64(0.7430790753004968), 'nauc_recall_at_1_max': np.float64(0.5936733716025138), 'nauc_recall_at_1_std': np.float64(0.21168619271758166), 'nauc_recall_at_1_diff1': np.float64(0.7829492322676209), 'nauc_recall_at_3_max': np.float64(0.6086291063803101), 'nauc_recall_at_3_std': np.float64(0.27698898432799685), 'nauc_recall_at_3_diff1': np.float64(0.6879317541786458), 'nauc_recall_at_5_max': np.float64(0.57916914546128), 'nauc_recall_at_5_std': np.float64(0.28522488747207836), 'nauc_recall_at_5_diff1': np.float64(0.6674538944201863), 'nauc_recall_at_10_max': np.float64(0.6118006847295059), 'nauc_recall_at_10_std': np.float64(0.4304531524484852), 'nauc_recall_at_10_diff1': np.float64(0.6414883249772395), 'nauc_recall_at_20_max': np.float64(0.6057688093338819), 'nauc_recall_at_20_std': np.float64(0.44013797456148757), 'nauc_recall_at_20_diff1': np.float64(0.6475249607727969), 'nauc_recall_at_100_max': np.float64(0.6517136266271206), 'nauc_recall_at_100_std': np.float64(0.5573268523095478), 'nauc_recall_at_100_diff1': np.float64(0.5710578348986649), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.5936733716025138), 'nauc_precision_at_1_std': np.float64(0.21168619271758166), 'nauc_precision_at_1_diff1': np.float64(0.7829492322676209), 'nauc_precision_at_3_max': np.float64(0.6086291063803098), 'nauc_precision_at_3_std': np.float64(0.2769889843279967), 'nauc_precision_at_3_diff1': np.float64(0.6879317541786455), 'nauc_precision_at_5_max': np.float64(0.5791691454612793), 'nauc_precision_at_5_std': np.float64(0.2852248874720776), 'nauc_precision_at_5_diff1': np.float64(0.6674538944201852), 'nauc_precision_at_10_max': np.float64(0.6118006847295047), 'nauc_precision_at_10_std': np.float64(0.4304531524484829), 'nauc_precision_at_10_diff1': np.float64(0.6414883249772391), 'nauc_precision_at_20_max': np.float64(0.605768809333882), 'nauc_precision_at_20_std': np.float64(0.4401379745614866), 'nauc_precision_at_20_diff1': np.float64(0.6475249607727963), 'nauc_precision_at_100_max': np.float64(0.6517136266271244), 'nauc_precision_at_100_std': np.float64(0.5573268523095559), 'nauc_precision_at_100_diff1': np.float64(0.5710578348986652), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.5936733716025138), 'nauc_mrr_at_1_std': np.float64(0.21168619271758166), 'nauc_mrr_at_1_diff1': np.float64(0.7829492322676209), 'nauc_mrr_at_3_max': np.float64(0.6001061908278962), 'nauc_mrr_at_3_std': np.float64(0.23774774638033352), 'nauc_mrr_at_3_diff1': np.float64(0.7434655267858342), 'nauc_mrr_at_5_max': np.float64(0.5946239747126786), 'nauc_mrr_at_5_std': np.float64(0.23889530835459716), 'nauc_mrr_at_5_diff1': np.float64(0.7412031262838832), 'nauc_mrr_at_10_max': np.float64(0.5970116478410402), 'nauc_mrr_at_10_std': np.float64(0.24850618003634511), 'nauc_mrr_at_10_diff1': np.float64(0.7414437064377993), 'nauc_mrr_at_20_max': np.float64(0.5965831678042499), 'nauc_mrr_at_20_std': np.float64(0.24689715247637192), 'nauc_mrr_at_20_diff1': np.float64(0.7426078135161391), 'nauc_mrr_at_100_max': np.float64(0.5965161365684637), 'nauc_mrr_at_100_std': np.float64(0.24606173238364235), 'nauc_mrr_at_100_diff1': np.float64(0.7429227613065333), 'nauc_mrr_at_1000_max': np.float64(0.596492941928904), 'nauc_mrr_at_1000_std': np.float64(0.24586499141258242), 'nauc_mrr_at_1000_diff1': np.float64(0.7430790753004968), 'main_score': 0.68329}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 11.28it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 11.23it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.53it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.47it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.96 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 11.74it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 11.68it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  6.42it/s]Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.21it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.25 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 10.20it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 10.17it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.93it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.91it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.84 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 5.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.26147, 'ndcg_at_3': 0.28045, 'ndcg_at_5': 0.30316, 'ndcg_at_10': 0.32955, 'ndcg_at_20': 0.35328, 'ndcg_at_100': 0.39787, 'ndcg_at_1000': 0.43449, 'map_at_1': 0.1829, 'map_at_3': 0.2547, 'map_at_5': 0.27271, 'map_at_10': 0.28551, 'map_at_20': 0.29296, 'map_at_100': 0.29979, 'map_at_1000': 0.3012, 'recall_at_1': 0.1829, 'recall_at_3': 0.29669, 'recall_at_5': 0.3527, 'recall_at_10': 0.42513, 'recall_at_20': 0.50841, 'recall_at_100': 0.725, 'recall_at_1000': 1.0, 'precision_at_1': 0.26147, 'precision_at_3': 0.15851, 'precision_at_5': 0.11407, 'precision_at_10': 0.06881, 'precision_at_20': 0.04113, 'precision_at_100': 0.01173, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.26299694189602446, 'mrr_at_3': 0.30122324159021413, 'mrr_at_5': 0.31284403669724775, 'mrr_at_10': 0.3220304839570894, 'mrr_at_20': 0.3280895399573858, 'mrr_at_100': 0.3332782430139055, 'mrr_at_1000': 0.3342398234961508, 'nauc_ndcg_at_1_max': np.float64(0.1385600205497626), 'nauc_ndcg_at_1_std': np.float64(-0.24453435294892245), 'nauc_ndcg_at_1_diff1': np.float64(0.5392956847388286), 'nauc_ndcg_at_3_max': np.float64(0.12513407552452707), 'nauc_ndcg_at_3_std': np.float64(-0.24473018706031344), 'nauc_ndcg_at_3_diff1': np.float64(0.4659900434227112), 'nauc_ndcg_at_5_max': np.float64(0.12171486215352809), 'nauc_ndcg_at_5_std': np.float64(-0.24871105614187503), 'nauc_ndcg_at_5_diff1': np.float64(0.4629664342747141), 'nauc_ndcg_at_10_max': np.float64(0.12507887105286675), 'nauc_ndcg_at_10_std': np.float64(-0.24513949221714543), 'nauc_ndcg_at_10_diff1': np.float64(0.4514760288716317), 'nauc_ndcg_at_20_max': np.float64(0.1229840820857501), 'nauc_ndcg_at_20_std': np.float64(-0.23794086691739338), 'nauc_ndcg_at_20_diff1': np.float64(0.434906847258626), 'nauc_ndcg_at_100_max': np.float64(0.14114738973003463), 'nauc_ndcg_at_100_std': np.float64(-0.197934236295145), 'nauc_ndcg_at_100_diff1': np.float64(0.4317848340203343), 'nauc_ndcg_at_1000_max': np.float64(0.132122520779102), 'nauc_ndcg_at_1000_std': np.float64(-0.22091394481667645), 'nauc_ndcg_at_1000_diff1': np.float64(0.4480487563687222), 'nauc_map_at_1_max': np.float64(0.10594852351139246), 'nauc_map_at_1_std': np.float64(-0.21975224986765715), 'nauc_map_at_1_diff1': np.float64(0.5330235798141878), 'nauc_map_at_3_max': np.float64(0.1317626579538601), 'nauc_map_at_3_std': np.float64(-0.2375561272020834), 'nauc_map_at_3_diff1': np.float64(0.4711332793904356), 'nauc_map_at_5_max': np.float64(0.12467940362617137), 'nauc_map_at_5_std': np.float64(-0.24552057125445764), 'nauc_map_at_5_diff1': np.float64(0.4661719319744751), 'nauc_map_at_10_max': np.float64(0.12613789722621638), 'nauc_map_at_10_std': np.float64(-0.2451768834650104), 'nauc_map_at_10_diff1': np.float64(0.4594886305932684), 'nauc_map_at_20_max': np.float64(0.12459173349141058), 'nauc_map_at_20_std': np.float64(-0.24506370459753601), 'nauc_map_at_20_diff1': np.float64(0.45488438301063494), 'nauc_map_at_100_max': np.float64(0.1267528771134847), 'nauc_map_at_100_std': np.float64(-0.2388295838199294), 'nauc_map_at_100_diff1': np.float64(0.45413984075382186), 'nauc_map_at_1000_max': np.float64(0.12646694622078739), 'nauc_map_at_1000_std': np.float64(-0.2393622034831087), 'nauc_map_at_1000_diff1': np.float64(0.4547625396474703), 'nauc_recall_at_1_max': np.float64(0.10594852351139246), 'nauc_recall_at_1_std': np.float64(-0.21975224986765715), 'nauc_recall_at_1_diff1': np.float64(0.5330235798141878), 'nauc_recall_at_3_max': np.float64(0.1277313816640369), 'nauc_recall_at_3_std': np.float64(-0.23232818948602896), 'nauc_recall_at_3_diff1': np.float64(0.4343776208145679), 'nauc_recall_at_5_max': np.float64(0.11029906413803443), 'nauc_recall_at_5_std': np.float64(-0.2421950749892962), 'nauc_recall_at_5_diff1': np.float64(0.4198841074493421), 'nauc_recall_at_10_max': np.float64(0.12085195270128336), 'nauc_recall_at_10_std': np.float64(-0.22699140778754812), 'nauc_recall_at_10_diff1': np.float64(0.38800725097516486), 'nauc_recall_at_20_max': np.float64(0.1147766270375657), 'nauc_recall_at_20_std': np.float64(-0.19963182244844757), 'nauc_recall_at_20_diff1': np.float64(0.3240425736433208), 'nauc_recall_at_100_max': np.float64(0.21568964742986985), 'nauc_recall_at_100_std': np.float64(0.04325953880109098), 'nauc_recall_at_100_diff1': np.float64(0.2602045589014585), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1385600205497626), 'nauc_precision_at_1_std': np.float64(-0.24453435294892245), 'nauc_precision_at_1_diff1': np.float64(0.5392956847388286), 'nauc_precision_at_3_max': np.float64(0.11753911151010885), 'nauc_precision_at_3_std': np.float64(-0.23995784319872165), 'nauc_precision_at_3_diff1': np.float64(0.3313125830072944), 'nauc_precision_at_5_max': np.float64(0.09313210311726866), 'nauc_precision_at_5_std': np.float64(-0.24257389920748337), 'nauc_precision_at_5_diff1': np.float64(0.29790435878461363), 'nauc_precision_at_10_max': np.float64(0.0866227708077691), 'nauc_precision_at_10_std': np.float64(-0.2310414261521562), 'nauc_precision_at_10_diff1': np.float64(0.2555703977075303), 'nauc_precision_at_20_max': np.float64(0.07089083726194388), 'nauc_precision_at_20_std': np.float64(-0.19084330964261703), 'nauc_precision_at_20_diff1': np.float64(0.1895678436406259), 'nauc_precision_at_100_max': np.float64(0.1169566780587064), 'nauc_precision_at_100_std': np.float64(0.015819718692532805), 'nauc_precision_at_100_diff1': np.float64(0.08212885390664122), 'nauc_precision_at_1000_max': np.float64(0.04104503681814765), 'nauc_precision_at_1000_std': np.float64(0.019663768968182543), 'nauc_precision_at_1000_diff1': np.float64(-0.00901686802472959), 'nauc_mrr_at_1_max': np.float64(0.1365064000661457), 'nauc_mrr_at_1_std': np.float64(-0.2472867783270001), 'nauc_mrr_at_1_diff1': np.float64(0.533155004198135), 'nauc_mrr_at_3_max': np.float64(0.1282850739147785), 'nauc_mrr_at_3_std': np.float64(-0.2536804863426613), 'nauc_mrr_at_3_diff1': np.float64(0.4992540508384475), 'nauc_mrr_at_5_max': np.float64(0.1259288251990135), 'nauc_mrr_at_5_std': np.float64(-0.2528558892491385), 'nauc_mrr_at_5_diff1': np.float64(0.4965607142611202), 'nauc_mrr_at_10_max': np.float64(0.12737967772097838), 'nauc_mrr_at_10_std': np.float64(-0.2496291279814568), 'nauc_mrr_at_10_diff1': np.float64(0.4935024795995884), 'nauc_mrr_at_20_max': np.float64(0.1273642499250887), 'nauc_mrr_at_20_std': np.float64(-0.24545823160607994), 'nauc_mrr_at_20_diff1': np.float64(0.48894756721539834), 'nauc_mrr_at_100_max': np.float64(0.12958856650206144), 'nauc_mrr_at_100_std': np.float64(-0.2416082083494877), 'nauc_mrr_at_100_diff1': np.float64(0.48935253332714024), 'nauc_mrr_at_1000_max': np.float64(0.12940692539976054), 'nauc_mrr_at_1000_std': np.float64(-0.24233608055646896), 'nauc_mrr_at_1000_diff1': np.float64(0.48985170603503336), 'main_score': 0.32955}, 'eng-kor': {'ndcg_at_1': 0.17431, 'ndcg_at_3': 0.18137, 'ndcg_at_5': 0.19664, 'ndcg_at_10': 0.22384, 'ndcg_at_20': 0.25218, 'ndcg_at_100': 0.30817, 'ndcg_at_1000': 0.35811, 'map_at_1': 0.09962, 'map_at_3': 0.1479, 'map_at_5': 0.1632, 'map_at_10': 0.1759, 'map_at_20': 0.1847, 'map_at_100': 0.19376, 'map_at_1000': 0.1963, 'recall_at_1': 0.09962, 'recall_at_3': 0.18076, 'recall_at_5': 0.23053, 'recall_at_10': 0.30237, 'recall_at_20': 0.39656, 'recall_at_100': 0.65594, 'recall_at_1000': 0.99141, 'precision_at_1': 0.17431, 'precision_at_3': 0.11876, 'precision_at_5': 0.09113, 'precision_at_10': 0.05917, 'precision_at_20': 0.03876, 'precision_at_100': 0.01289, 'precision_at_1000': 0.00194, 'mrr_at_1': 0.1743119266055046, 'mrr_at_3': 0.21279306829765543, 'mrr_at_5': 0.2261722731906218, 'mrr_at_10': 0.23748543760011642, 'mrr_at_20': 0.2447803643748342, 'mrr_at_100': 0.2504608327892528, 'mrr_at_1000': 0.25162369266617834, 'nauc_ndcg_at_1_max': np.float64(0.2029583333999771), 'nauc_ndcg_at_1_std': np.float64(-0.13380386863089352), 'nauc_ndcg_at_1_diff1': np.float64(0.32049689389036756), 'nauc_ndcg_at_3_max': np.float64(0.1778334713685883), 'nauc_ndcg_at_3_std': np.float64(-0.1504525840870608), 'nauc_ndcg_at_3_diff1': np.float64(0.3029610403917149), 'nauc_ndcg_at_5_max': np.float64(0.15741827887205986), 'nauc_ndcg_at_5_std': np.float64(-0.15633529706319368), 'nauc_ndcg_at_5_diff1': np.float64(0.2837609348545294), 'nauc_ndcg_at_10_max': np.float64(0.1597907311173541), 'nauc_ndcg_at_10_std': np.float64(-0.15237665483631252), 'nauc_ndcg_at_10_diff1': np.float64(0.2731397508579589), 'nauc_ndcg_at_20_max': np.float64(0.15430987130033333), 'nauc_ndcg_at_20_std': np.float64(-0.13241748883847462), 'nauc_ndcg_at_20_diff1': np.float64(0.27446553879279434), 'nauc_ndcg_at_100_max': np.float64(0.17051343784546052), 'nauc_ndcg_at_100_std': np.float64(-0.08589639074785743), 'nauc_ndcg_at_100_diff1': np.float64(0.25182170321844916), 'nauc_ndcg_at_1000_max': np.float64(0.1679794278404614), 'nauc_ndcg_at_1000_std': np.float64(-0.10788780775876798), 'nauc_ndcg_at_1000_diff1': np.float64(0.2666382745241463), 'nauc_map_at_1_max': np.float64(0.19788482325553328), 'nauc_map_at_1_std': np.float64(-0.1605212191683792), 'nauc_map_at_1_diff1': np.float64(0.3774487178129821), 'nauc_map_at_3_max': np.float64(0.1886379394528974), 'nauc_map_at_3_std': np.float64(-0.15982465510325797), 'nauc_map_at_3_diff1': np.float64(0.3270464679692373), 'nauc_map_at_5_max': np.float64(0.17504711823165223), 'nauc_map_at_5_std': np.float64(-0.16117857682709974), 'nauc_map_at_5_diff1': np.float64(0.30862133555097837), 'nauc_map_at_10_max': np.float64(0.17876060003786357), 'nauc_map_at_10_std': np.float64(-0.15794218454701103), 'nauc_map_at_10_diff1': np.float64(0.3033829629959833), 'nauc_map_at_20_max': np.float64(0.1765027871155125), 'nauc_map_at_20_std': np.float64(-0.15209956227407792), 'nauc_map_at_20_diff1': np.float64(0.3028031462625417), 'nauc_map_at_100_max': np.float64(0.17679677902679447), 'nauc_map_at_100_std': np.float64(-0.14381366286143993), 'nauc_map_at_100_diff1': np.float64(0.2985912422832484), 'nauc_map_at_1000_max': np.float64(0.17748205625428867), 'nauc_map_at_1000_std': np.float64(-0.14348949710705572), 'nauc_map_at_1000_diff1': np.float64(0.2991880935425753), 'nauc_recall_at_1_max': np.float64(0.19788482325553328), 'nauc_recall_at_1_std': np.float64(-0.1605212191683792), 'nauc_recall_at_1_diff1': np.float64(0.3774487178129821), 'nauc_recall_at_3_max': np.float64(0.1677018057515319), 'nauc_recall_at_3_std': np.float64(-0.146313415798394), 'nauc_recall_at_3_diff1': np.float64(0.2915129088622437), 'nauc_recall_at_5_max': np.float64(0.12022076638879152), 'nauc_recall_at_5_std': np.float64(-0.15437411314206478), 'nauc_recall_at_5_diff1': np.float64(0.23735991709454), 'nauc_recall_at_10_max': np.float64(0.12086220904211756), 'nauc_recall_at_10_std': np.float64(-0.14621598243232492), 'nauc_recall_at_10_diff1': np.float64(0.2081986998645694), 'nauc_recall_at_20_max': np.float64(0.10624012559613846), 'nauc_recall_at_20_std': np.float64(-0.08555324007664036), 'nauc_recall_at_20_diff1': np.float64(0.21163559936445903), 'nauc_recall_at_100_max': np.float64(0.1764033567113626), 'nauc_recall_at_100_std': np.float64(0.1057105980300298), 'nauc_recall_at_100_diff1': np.float64(0.09765057294085117), 'nauc_recall_at_1000_max': np.float64(0.6686946788546253), 'nauc_recall_at_1000_std': np.float64(0.2766150387509139), 'nauc_recall_at_1000_diff1': np.float64(-0.1936144928546017), 'nauc_precision_at_1_max': np.float64(0.2029583333999771), 'nauc_precision_at_1_std': np.float64(-0.13380386863089352), 'nauc_precision_at_1_diff1': np.float64(0.32049689389036756), 'nauc_precision_at_3_max': np.float64(0.16012094861702805), 'nauc_precision_at_3_std': np.float64(-0.14439861721233702), 'nauc_precision_at_3_diff1': np.float64(0.24108462900358274), 'nauc_precision_at_5_max': np.float64(0.11851943358631274), 'nauc_precision_at_5_std': np.float64(-0.1349861627006572), 'nauc_precision_at_5_diff1': np.float64(0.20478686634300014), 'nauc_precision_at_10_max': np.float64(0.12167314009791819), 'nauc_precision_at_10_std': np.float64(-0.11148245472378807), 'nauc_precision_at_10_diff1': np.float64(0.17712004536742332), 'nauc_precision_at_20_max': np.float64(0.10266611079350438), 'nauc_precision_at_20_std': np.float64(-0.06282371215271502), 'nauc_precision_at_20_diff1': np.float64(0.17108820786495407), 'nauc_precision_at_100_max': np.float64(0.09654963031616139), 'nauc_precision_at_100_std': np.float64(0.10218214807121058), 'nauc_precision_at_100_diff1': np.float64(0.06846072169807792), 'nauc_precision_at_1000_max': np.float64(-0.005236066391411475), 'nauc_precision_at_1000_std': np.float64(0.055035354758162736), 'nauc_precision_at_1000_diff1': np.float64(-0.0015576742081407863), 'nauc_mrr_at_1_max': np.float64(0.2029583333999771), 'nauc_mrr_at_1_std': np.float64(-0.13380386863089352), 'nauc_mrr_at_1_diff1': np.float64(0.32049689389036756), 'nauc_mrr_at_3_max': np.float64(0.1770567851771855), 'nauc_mrr_at_3_std': np.float64(-0.13495848176136838), 'nauc_mrr_at_3_diff1': np.float64(0.28816616515491816), 'nauc_mrr_at_5_max': np.float64(0.1619809276509965), 'nauc_mrr_at_5_std': np.float64(-0.13576341071719686), 'nauc_mrr_at_5_diff1': np.float64(0.2775308738328707), 'nauc_mrr_at_10_max': np.float64(0.16134463263157411), 'nauc_mrr_at_10_std': np.float64(-0.13520143114041366), 'nauc_mrr_at_10_diff1': np.float64(0.27422085640223104), 'nauc_mrr_at_20_max': np.float64(0.1590457692427717), 'nauc_mrr_at_20_std': np.float64(-0.12937337268537685), 'nauc_mrr_at_20_diff1': np.float64(0.27440020109419494), 'nauc_mrr_at_100_max': np.float64(0.1625827615302975), 'nauc_mrr_at_100_std': np.float64(-0.12510856113946006), 'nauc_mrr_at_100_diff1': np.float64(0.2714731241268065), 'nauc_mrr_at_1000_max': np.float64(0.16263663145042392), 'nauc_mrr_at_1000_std': np.float64(-0.12564339930703866), 'nauc_mrr_at_1000_diff1': np.float64(0.27217440495109696), 'main_score': 0.22384}, 'kor-eng': {'ndcg_at_1': 0.17752, 'ndcg_at_3': 0.18711, 'ndcg_at_5': 0.20806, 'ndcg_at_10': 0.2296, 'ndcg_at_20': 0.2592, 'ndcg_at_100': 0.31029, 'ndcg_at_1000': 0.35666, 'map_at_1': 0.11989, 'map_at_3': 0.16374, 'map_at_5': 0.17882, 'map_at_10': 0.18972, 'map_at_20': 0.19881, 'map_at_100': 0.20665, 'map_at_1000': 0.2084, 'recall_at_1': 0.11989, 'recall_at_3': 0.19645, 'recall_at_5': 0.24614, 'recall_at_10': 0.30283, 'recall_at_20': 0.40478, 'recall_at_100': 0.64981, 'recall_at_1000': 1.0, 'precision_at_1': 0.17752, 'precision_at_3': 0.10532, 'precision_at_5': 0.08176, 'precision_at_10': 0.05163, 'precision_at_20': 0.03445, 'precision_at_100': 0.01143, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.1775244299674267, 'mrr_at_3': 0.2125407166123778, 'mrr_at_5': 0.22524429967426718, 'mrr_at_10': 0.23276265446460886, 'mrr_at_20': 0.24083075616364916, 'mrr_at_100': 0.24586855250570608, 'mrr_at_1000': 0.246843289061619, 'nauc_ndcg_at_1_max': np.float64(0.06204374613999269), 'nauc_ndcg_at_1_std': np.float64(-0.055298627785247356), 'nauc_ndcg_at_1_diff1': np.float64(0.2960684277743226), 'nauc_ndcg_at_3_max': np.float64(0.03178173360179919), 'nauc_ndcg_at_3_std': np.float64(-0.07230372699928762), 'nauc_ndcg_at_3_diff1': np.float64(0.24431511055563382), 'nauc_ndcg_at_5_max': np.float64(0.034064892845193664), 'nauc_ndcg_at_5_std': np.float64(-0.06878040352319326), 'nauc_ndcg_at_5_diff1': np.float64(0.2250821195009513), 'nauc_ndcg_at_10_max': np.float64(0.03124086942767835), 'nauc_ndcg_at_10_std': np.float64(-0.08212634971803227), 'nauc_ndcg_at_10_diff1': np.float64(0.22534209932834287), 'nauc_ndcg_at_20_max': np.float64(0.04349561675284856), 'nauc_ndcg_at_20_std': np.float64(-0.07443857580936757), 'nauc_ndcg_at_20_diff1': np.float64(0.22036378869476747), 'nauc_ndcg_at_100_max': np.float64(0.06012066444292969), 'nauc_ndcg_at_100_std': np.float64(-0.05055267554819076), 'nauc_ndcg_at_100_diff1': np.float64(0.20686773717354348), 'nauc_ndcg_at_1000_max': np.float64(0.05110626078877716), 'nauc_ndcg_at_1000_std': np.float64(-0.06167951021269635), 'nauc_ndcg_at_1000_diff1': np.float64(0.222061144568544), 'nauc_map_at_1_max': np.float64(0.04249489801843138), 'nauc_map_at_1_std': np.float64(-0.02248678007674917), 'nauc_map_at_1_diff1': np.float64(0.31616499944674326), 'nauc_map_at_3_max': np.float64(0.02307998761338801), 'nauc_map_at_3_std': np.float64(-0.06367768613811686), 'nauc_map_at_3_diff1': np.float64(0.25708120036666193), 'nauc_map_at_5_max': np.float64(0.029894210756738437), 'nauc_map_at_5_std': np.float64(-0.05944956327493896), 'nauc_map_at_5_diff1': np.float64(0.24037195276006268), 'nauc_map_at_10_max': np.float64(0.027201739410993797), 'nauc_map_at_10_std': np.float64(-0.06895484813286121), 'nauc_map_at_10_diff1': np.float64(0.2396092769661654), 'nauc_map_at_20_max': np.float64(0.029385688041942574), 'nauc_map_at_20_std': np.float64(-0.06826855873826122), 'nauc_map_at_20_diff1': np.float64(0.23742580996936025), 'nauc_map_at_100_max': np.float64(0.03290574312286675), 'nauc_map_at_100_std': np.float64(-0.06587777567563824), 'nauc_map_at_100_diff1': np.float64(0.23386232089383327), 'nauc_map_at_1000_max': np.float64(0.032416442984846826), 'nauc_map_at_1000_std': np.float64(-0.06611512852833226), 'nauc_map_at_1000_diff1': np.float64(0.23450518349799201), 'nauc_recall_at_1_max': np.float64(0.04249489801843138), 'nauc_recall_at_1_std': np.float64(-0.02248678007674917), 'nauc_recall_at_1_diff1': np.float64(0.31616499944674326), 'nauc_recall_at_3_max': np.float64(0.021845970307674916), 'nauc_recall_at_3_std': np.float64(-0.08353442531953978), 'nauc_recall_at_3_diff1': np.float64(0.21715983613220408), 'nauc_recall_at_5_max': np.float64(0.025558605004035652), 'nauc_recall_at_5_std': np.float64(-0.06799217571419744), 'nauc_recall_at_5_diff1': np.float64(0.1741720232177516), 'nauc_recall_at_10_max': np.float64(0.023709843683772245), 'nauc_recall_at_10_std': np.float64(-0.09161845182652668), 'nauc_recall_at_10_diff1': np.float64(0.17713830758964086), 'nauc_recall_at_20_max': np.float64(0.05479847473249548), 'nauc_recall_at_20_std': np.float64(-0.06749412186440905), 'nauc_recall_at_20_diff1': np.float64(0.15912208708973832), 'nauc_recall_at_100_max': np.float64(0.103236309950968), 'nauc_recall_at_100_std': np.float64(0.03241008941875858), 'nauc_recall_at_100_diff1': np.float64(0.09126964031351271), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.06204374613999269), 'nauc_precision_at_1_std': np.float64(-0.055298627785247356), 'nauc_precision_at_1_diff1': np.float64(0.2960684277743226), 'nauc_precision_at_3_max': np.float64(0.02409813224114374), 'nauc_precision_at_3_std': np.float64(-0.11153419030418392), 'nauc_precision_at_3_diff1': np.float64(0.1762458611996992), 'nauc_precision_at_5_max': np.float64(0.026278117248941604), 'nauc_precision_at_5_std': np.float64(-0.10532537958664578), 'nauc_precision_at_5_diff1': np.float64(0.1365180920616533), 'nauc_precision_at_10_max': np.float64(0.008684050997352926), 'nauc_precision_at_10_std': np.float64(-0.14342793647390842), 'nauc_precision_at_10_diff1': np.float64(0.12261474750584493), 'nauc_precision_at_20_max': np.float64(0.050428323996844424), 'nauc_precision_at_20_std': np.float64(-0.11840389683792774), 'nauc_precision_at_20_diff1': np.float64(0.1120236999157521), 'nauc_precision_at_100_max': np.float64(0.12476739805086275), 'nauc_precision_at_100_std': np.float64(0.011202157312844848), 'nauc_precision_at_100_diff1': np.float64(0.028301228485660086), 'nauc_precision_at_1000_max': np.float64(0.09539641683043755), 'nauc_precision_at_1000_std': np.float64(0.003888077223405562), 'nauc_precision_at_1000_diff1': np.float64(0.001332385434894896), 'nauc_mrr_at_1_max': np.float64(0.06204374613999269), 'nauc_mrr_at_1_std': np.float64(-0.055298627785247356), 'nauc_mrr_at_1_diff1': np.float64(0.2960684277743226), 'nauc_mrr_at_3_max': np.float64(0.05863646917297104), 'nauc_mrr_at_3_std': np.float64(-0.07258336390616486), 'nauc_mrr_at_3_diff1': np.float64(0.26277584488304845), 'nauc_mrr_at_5_max': np.float64(0.051656897600644465), 'nauc_mrr_at_5_std': np.float64(-0.07526316032821831), 'nauc_mrr_at_5_diff1': np.float64(0.2520185557329004), 'nauc_mrr_at_10_max': np.float64(0.052099360599420275), 'nauc_mrr_at_10_std': np.float64(-0.0784945824198841), 'nauc_mrr_at_10_diff1': np.float64(0.25058092807212595), 'nauc_mrr_at_20_max': np.float64(0.05817456368264788), 'nauc_mrr_at_20_std': np.float64(-0.0728271364128738), 'nauc_mrr_at_20_diff1': np.float64(0.24970228006264428), 'nauc_mrr_at_100_max': np.float64(0.059129476485770625), 'nauc_mrr_at_100_std': np.float64(-0.07048892705868942), 'nauc_mrr_at_100_diff1': np.float64(0.24916151582131987), 'nauc_mrr_at_1000_max': np.float64(0.058698393504949535), 'nauc_mrr_at_1000_std': np.float64(-0.07100735815152166), 'nauc_mrr_at_1000_diff1': np.float64(0.24949088821560228), 'main_score': 0.2296}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 19.70it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:01,  5.09s/it]Batches:  15%|█▌        | 2/13 [00:07<00:39,  3.61s/it]Batches:  23%|██▎       | 3/13 [00:09<00:28,  2.89s/it]Batches:  31%|███       | 4/13 [00:11<00:22,  2.52s/it]Batches:  38%|███▊      | 5/13 [00:13<00:17,  2.22s/it]Batches:  46%|████▌     | 6/13 [00:14<00:14,  2.00s/it]Batches:  54%|█████▍    | 7/13 [00:16<00:10,  1.76s/it]Batches:  62%|██████▏   | 8/13 [00:17<00:07,  1.59s/it]Batches:  69%|██████▉   | 9/13 [00:18<00:05,  1.47s/it]Batches:  77%|███████▋  | 10/13 [00:19<00:04,  1.38s/it]Batches:  85%|████████▍ | 11/13 [00:21<00:02,  1.33s/it]Batches:  92%|█████████▏| 12/13 [00:22<00:01,  1.29s/it]Batches: 100%|██████████| 13/13 [00:23<00:00,  1.27s/it]Batches: 100%|██████████| 13/13 [00:23<00:00,  1.80s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 28.76 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 29.03 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.135, 'ndcg_at_3': 0.17458, 'ndcg_at_5': 0.1948, 'ndcg_at_10': 0.21429, 'ndcg_at_20': 0.22669, 'ndcg_at_100': 0.25801, 'ndcg_at_1000': 0.29165, 'map_at_1': 0.135, 'map_at_3': 0.16417, 'map_at_5': 0.17517, 'map_at_10': 0.18325, 'map_at_20': 0.18652, 'map_at_100': 0.19047, 'map_at_1000': 0.19168, 'recall_at_1': 0.135, 'recall_at_3': 0.205, 'recall_at_5': 0.255, 'recall_at_10': 0.315, 'recall_at_20': 0.365, 'recall_at_100': 0.54, 'recall_at_1000': 0.81, 'precision_at_1': 0.135, 'precision_at_3': 0.06833, 'precision_at_5': 0.051, 'precision_at_10': 0.0315, 'precision_at_20': 0.01825, 'precision_at_100': 0.0054, 'precision_at_1000': 0.00081, 'mrr_at_1': 0.135, 'mrr_at_3': 0.16416666666666666, 'mrr_at_5': 0.17516666666666666, 'mrr_at_10': 0.1832460317460317, 'mrr_at_20': 0.18652259004755134, 'mrr_at_100': 0.19047319414978406, 'mrr_at_1000': 0.19167606320222721, 'nauc_ndcg_at_1_max': np.float64(0.5164199588275659), 'nauc_ndcg_at_1_std': np.float64(0.05767408424010702), 'nauc_ndcg_at_1_diff1': np.float64(0.47182738075787767), 'nauc_ndcg_at_3_max': np.float64(0.48551787026426946), 'nauc_ndcg_at_3_std': np.float64(0.06970560774812364), 'nauc_ndcg_at_3_diff1': np.float64(0.41073520827111304), 'nauc_ndcg_at_5_max': np.float64(0.44567512443414287), 'nauc_ndcg_at_5_std': np.float64(0.10259989034484286), 'nauc_ndcg_at_5_diff1': np.float64(0.36603181324158207), 'nauc_ndcg_at_10_max': np.float64(0.40489004207890444), 'nauc_ndcg_at_10_std': np.float64(0.09907401457237709), 'nauc_ndcg_at_10_diff1': np.float64(0.3360496852112413), 'nauc_ndcg_at_20_max': np.float64(0.40657634417623806), 'nauc_ndcg_at_20_std': np.float64(0.11182447570951327), 'nauc_ndcg_at_20_diff1': np.float64(0.3307317217685546), 'nauc_ndcg_at_100_max': np.float64(0.39227089517213426), 'nauc_ndcg_at_100_std': np.float64(0.12890680562966966), 'nauc_ndcg_at_100_diff1': np.float64(0.30184011341306044), 'nauc_ndcg_at_1000_max': np.float64(0.4214676808177101), 'nauc_ndcg_at_1000_std': np.float64(0.14338425061065935), 'nauc_ndcg_at_1000_diff1': np.float64(0.3408386385452705), 'nauc_map_at_1_max': np.float64(0.5164199588275659), 'nauc_map_at_1_std': np.float64(0.05767408424010702), 'nauc_map_at_1_diff1': np.float64(0.47182738075787767), 'nauc_map_at_3_max': np.float64(0.4910561086785603), 'nauc_map_at_3_std': np.float64(0.06360223041884165), 'nauc_map_at_3_diff1': np.float64(0.42428534739608537), 'nauc_map_at_5_max': np.float64(0.46850301116764936), 'nauc_map_at_5_std': np.float64(0.08396563601560003), 'nauc_map_at_5_diff1': np.float64(0.3981250559089497), 'nauc_map_at_10_max': np.float64(0.448794878020204), 'nauc_map_at_10_std': np.float64(0.0820487515521684), 'nauc_map_at_10_diff1': np.float64(0.38392904060781147), 'nauc_map_at_20_max': np.float64(0.44910631761129205), 'nauc_map_at_20_std': np.float64(0.08519502518259946), 'nauc_map_at_20_diff1': np.float64(0.382670044892076), 'nauc_map_at_100_max': np.float64(0.4479624306569573), 'nauc_map_at_100_std': np.float64(0.08812533883699762), 'nauc_map_at_100_diff1': np.float64(0.3777757757712673), 'nauc_map_at_1000_max': np.float64(0.44911843829155174), 'nauc_map_at_1000_std': np.float64(0.08865395416629718), 'nauc_map_at_1000_diff1': np.float64(0.379779577504471), 'nauc_recall_at_1_max': np.float64(0.5164199588275659), 'nauc_recall_at_1_std': np.float64(0.05767408424010702), 'nauc_recall_at_1_diff1': np.float64(0.47182738075787767), 'nauc_recall_at_3_max': np.float64(0.4723272602268822), 'nauc_recall_at_3_std': np.float64(0.085852246836202), 'nauc_recall_at_3_diff1': np.float64(0.3774013286752421), 'nauc_recall_at_5_max': np.float64(0.3881974671362016), 'nauc_recall_at_5_std': np.float64(0.14925960760296586), 'nauc_recall_at_5_diff1': np.float64(0.2868537515402059), 'nauc_recall_at_10_max': np.float64(0.29614876509680055), 'nauc_recall_at_10_std': np.float64(0.13929627617840526), 'nauc_recall_at_10_diff1': np.float64(0.22001596019339975), 'nauc_recall_at_20_max': np.float64(0.30447474000431946), 'nauc_recall_at_20_std': np.float64(0.18185626116721537), 'nauc_recall_at_20_diff1': np.float64(0.20389944433899906), 'nauc_recall_at_100_max': np.float64(0.22292378650218095), 'nauc_recall_at_100_std': np.float64(0.2564182712344749), 'nauc_recall_at_100_diff1': np.float64(0.07288627712483677), 'nauc_recall_at_1000_max': np.float64(0.4177929697731676), 'nauc_recall_at_1000_std': np.float64(0.5250405992980247), 'nauc_recall_at_1000_diff1': np.float64(0.30175755670805143), 'nauc_precision_at_1_max': np.float64(0.5164199588275659), 'nauc_precision_at_1_std': np.float64(0.05767408424010702), 'nauc_precision_at_1_diff1': np.float64(0.47182738075787767), 'nauc_precision_at_3_max': np.float64(0.47232726022688204), 'nauc_precision_at_3_std': np.float64(0.08585224683620207), 'nauc_precision_at_3_diff1': np.float64(0.37740132867524206), 'nauc_precision_at_5_max': np.float64(0.38819746713620157), 'nauc_precision_at_5_std': np.float64(0.149259607602966), 'nauc_precision_at_5_diff1': np.float64(0.286853751540206), 'nauc_precision_at_10_max': np.float64(0.29614876509680094), 'nauc_precision_at_10_std': np.float64(0.1392962761784056), 'nauc_precision_at_10_diff1': np.float64(0.2200159601934005), 'nauc_precision_at_20_max': np.float64(0.30447474000431984), 'nauc_precision_at_20_std': np.float64(0.1818562611672155), 'nauc_precision_at_20_diff1': np.float64(0.20389944433899906), 'nauc_precision_at_100_max': np.float64(0.22292378650218142), 'nauc_precision_at_100_std': np.float64(0.2564182712344754), 'nauc_precision_at_100_diff1': np.float64(0.0728862771248372), 'nauc_precision_at_1000_max': np.float64(0.4177929697731674), 'nauc_precision_at_1000_std': np.float64(0.5250405992980253), 'nauc_precision_at_1000_diff1': np.float64(0.3017575567080515), 'nauc_mrr_at_1_max': np.float64(0.5164199588275659), 'nauc_mrr_at_1_std': np.float64(0.05767408424010702), 'nauc_mrr_at_1_diff1': np.float64(0.47182738075787767), 'nauc_mrr_at_3_max': np.float64(0.4910561086785603), 'nauc_mrr_at_3_std': np.float64(0.06360223041884165), 'nauc_mrr_at_3_diff1': np.float64(0.42428534739608537), 'nauc_mrr_at_5_max': np.float64(0.46850301116764936), 'nauc_mrr_at_5_std': np.float64(0.08396563601560003), 'nauc_mrr_at_5_diff1': np.float64(0.3981250559089497), 'nauc_mrr_at_10_max': np.float64(0.448794878020204), 'nauc_mrr_at_10_std': np.float64(0.0820487515521684), 'nauc_mrr_at_10_diff1': np.float64(0.38392904060781147), 'nauc_mrr_at_20_max': np.float64(0.44910631761129205), 'nauc_mrr_at_20_std': np.float64(0.08519502518259946), 'nauc_mrr_at_20_diff1': np.float64(0.382670044892076), 'nauc_mrr_at_100_max': np.float64(0.4479624306569573), 'nauc_mrr_at_100_std': np.float64(0.08812533883699762), 'nauc_mrr_at_100_diff1': np.float64(0.3777757757712673), 'nauc_mrr_at_1000_max': np.float64(0.44911843829155174), 'nauc_mrr_at_1000_std': np.float64(0.08865395416629718), 'nauc_mrr_at_1000_diff1': np.float64(0.379779577504471), 'main_score': 0.21429}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 42.36it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:04,  5.38s/it]Batches:  15%|█▌        | 2/13 [00:08<00:42,  3.85s/it]Batches:  23%|██▎       | 3/13 [00:10<00:30,  3.10s/it]Batches:  31%|███       | 4/13 [00:12<00:23,  2.64s/it]Batches:  38%|███▊      | 5/13 [00:13<00:18,  2.30s/it]Batches:  46%|████▌     | 6/13 [00:15<00:14,  2.02s/it]Batches:  54%|█████▍    | 7/13 [00:16<00:10,  1.79s/it]Batches:  62%|██████▏   | 8/13 [00:18<00:08,  1.61s/it]Batches:  69%|██████▉   | 9/13 [00:19<00:05,  1.48s/it]Batches:  77%|███████▋  | 10/13 [00:20<00:04,  1.40s/it]Batches:  85%|████████▍ | 11/13 [00:21<00:02,  1.34s/it]Batches:  92%|█████████▏| 12/13 [00:22<00:01,  1.30s/it]Batches: 100%|██████████| 13/13 [00:24<00:00,  1.27s/it]Batches: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 28.43 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 28.69 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.14, 'ndcg_at_3': 0.1822, 'ndcg_at_5': 0.19446, 'ndcg_at_10': 0.20923, 'ndcg_at_20': 0.21918, 'ndcg_at_100': 0.24413, 'ndcg_at_1000': 0.28103, 'map_at_1': 0.14, 'map_at_3': 0.1725, 'map_at_5': 0.17925, 'map_at_10': 0.18548, 'map_at_20': 0.18811, 'map_at_100': 0.1912, 'map_at_1000': 0.1924, 'recall_at_1': 0.14, 'recall_at_3': 0.21, 'recall_at_5': 0.24, 'recall_at_10': 0.285, 'recall_at_20': 0.325, 'recall_at_100': 0.465, 'recall_at_1000': 0.765, 'precision_at_1': 0.14, 'precision_at_3': 0.07, 'precision_at_5': 0.048, 'precision_at_10': 0.0285, 'precision_at_20': 0.01625, 'precision_at_100': 0.00465, 'precision_at_1000': 0.00077, 'mrr_at_1': 0.14, 'mrr_at_3': 0.1725, 'mrr_at_5': 0.17925000000000002, 'mrr_at_10': 0.18547817460317462, 'mrr_at_20': 0.18810985490687504, 'mrr_at_100': 0.19119814608632146, 'mrr_at_1000': 0.19240017602490853, 'nauc_ndcg_at_1_max': np.float64(0.5129725486868343), 'nauc_ndcg_at_1_std': np.float64(-0.053460053460053523), 'nauc_ndcg_at_1_diff1': np.float64(0.6650367007509866), 'nauc_ndcg_at_3_max': np.float64(0.4911964382692246), 'nauc_ndcg_at_3_std': np.float64(-0.028275031560239396), 'nauc_ndcg_at_3_diff1': np.float64(0.5157777973625878), 'nauc_ndcg_at_5_max': np.float64(0.4755659819937588), 'nauc_ndcg_at_5_std': np.float64(0.003285982054611315), 'nauc_ndcg_at_5_diff1': np.float64(0.4960839601393147), 'nauc_ndcg_at_10_max': np.float64(0.49480379732832636), 'nauc_ndcg_at_10_std': np.float64(0.030367525196002065), 'nauc_ndcg_at_10_diff1': np.float64(0.49130326759966925), 'nauc_ndcg_at_20_max': np.float64(0.4822289274310817), 'nauc_ndcg_at_20_std': np.float64(0.058867516395837316), 'nauc_ndcg_at_20_diff1': np.float64(0.476984909067074), 'nauc_ndcg_at_100_max': np.float64(0.4625872635169477), 'nauc_ndcg_at_100_std': np.float64(0.04534133571107291), 'nauc_ndcg_at_100_diff1': np.float64(0.4623078536583448), 'nauc_ndcg_at_1000_max': np.float64(0.47400999223707635), 'nauc_ndcg_at_1000_std': np.float64(0.060145080204151), 'nauc_ndcg_at_1000_diff1': np.float64(0.4773990656550642), 'nauc_map_at_1_max': np.float64(0.5129725486868343), 'nauc_map_at_1_std': np.float64(-0.053460053460053523), 'nauc_map_at_1_diff1': np.float64(0.6650367007509866), 'nauc_map_at_3_max': np.float64(0.49671984641360245), 'nauc_map_at_3_std': np.float64(-0.034936033579515934), 'nauc_map_at_3_diff1': np.float64(0.54609190519907), 'nauc_map_at_5_max': np.float64(0.48743342578678833), 'nauc_map_at_5_std': np.float64(-0.016354945659780545), 'nauc_map_at_5_diff1': np.float64(0.5341056939657133), 'nauc_map_at_10_max': np.float64(0.49593428381774457), 'nauc_map_at_10_std': np.float64(-0.0034387514430296298), 'nauc_map_at_10_diff1': np.float64(0.5313695381754745), 'nauc_map_at_20_max': np.float64(0.49265725977075175), 'nauc_map_at_20_std': np.float64(0.004530513808894996), 'nauc_map_at_20_diff1': np.float64(0.5271162535228666), 'nauc_map_at_100_max': np.float64(0.489475326503946), 'nauc_map_at_100_std': np.float64(0.0013338792146313193), 'nauc_map_at_100_diff1': np.float64(0.5243945797820769), 'nauc_map_at_1000_max': np.float64(0.489872129517836), 'nauc_map_at_1000_std': np.float64(0.002067500679989672), 'nauc_map_at_1000_diff1': np.float64(0.525288938700444), 'nauc_recall_at_1_max': np.float64(0.5129725486868343), 'nauc_recall_at_1_std': np.float64(-0.053460053460053523), 'nauc_recall_at_1_diff1': np.float64(0.6650367007509866), 'nauc_recall_at_3_max': np.float64(0.4770218696058403), 'nauc_recall_at_3_std': np.float64(-0.011101081603243195), 'nauc_recall_at_3_diff1': np.float64(0.4401951003214721), 'nauc_recall_at_5_max': np.float64(0.44489875389408085), 'nauc_recall_at_5_std': np.float64(0.05474179247543719), 'nauc_recall_at_5_diff1': np.float64(0.40265546369518324), 'nauc_recall_at_10_max': np.float64(0.4960906931488445), 'nauc_recall_at_10_std': np.float64(0.11790940380473555), 'nauc_recall_at_10_diff1': np.float64(0.3977174357163137), 'nauc_recall_at_20_max': np.float64(0.45311801408027763), 'nauc_recall_at_20_std': np.float64(0.20942244169363727), 'nauc_recall_at_20_diff1': np.float64(0.3546094558072803), 'nauc_recall_at_100_max': np.float64(0.3699133216182595), 'nauc_recall_at_100_std': np.float64(0.1623853995958956), 'nauc_recall_at_100_diff1': np.float64(0.29708900165195706), 'nauc_recall_at_1000_max': np.float64(0.4295394295394298), 'nauc_recall_at_1000_std': np.float64(0.3775093775093781), 'nauc_recall_at_1000_diff1': np.float64(0.32260832260832234), 'nauc_precision_at_1_max': np.float64(0.5129725486868343), 'nauc_precision_at_1_std': np.float64(-0.053460053460053523), 'nauc_precision_at_1_diff1': np.float64(0.6650367007509866), 'nauc_precision_at_3_max': np.float64(0.4770218696058402), 'nauc_precision_at_3_std': np.float64(-0.01110108160324325), 'nauc_precision_at_3_diff1': np.float64(0.44019510032147174), 'nauc_precision_at_5_max': np.float64(0.4448987538940812), 'nauc_precision_at_5_std': np.float64(0.054741792475437395), 'nauc_precision_at_5_diff1': np.float64(0.4026554636951834), 'nauc_precision_at_10_max': np.float64(0.4960906931488446), 'nauc_precision_at_10_std': np.float64(0.11790940380473558), 'nauc_precision_at_10_diff1': np.float64(0.3977174357163142), 'nauc_precision_at_20_max': np.float64(0.45311801408027785), 'nauc_precision_at_20_std': np.float64(0.2094224416936371), 'nauc_precision_at_20_diff1': np.float64(0.3546094558072806), 'nauc_precision_at_100_max': np.float64(0.36991332161825985), 'nauc_precision_at_100_std': np.float64(0.16238539959589604), 'nauc_precision_at_100_diff1': np.float64(0.29708900165195723), 'nauc_precision_at_1000_max': np.float64(0.42953942953943014), 'nauc_precision_at_1000_std': np.float64(0.3775093775093777), 'nauc_precision_at_1000_diff1': np.float64(0.3226083226083224), 'nauc_mrr_at_1_max': np.float64(0.5129725486868343), 'nauc_mrr_at_1_std': np.float64(-0.053460053460053523), 'nauc_mrr_at_1_diff1': np.float64(0.6650367007509866), 'nauc_mrr_at_3_max': np.float64(0.49671984641360245), 'nauc_mrr_at_3_std': np.float64(-0.034936033579515934), 'nauc_mrr_at_3_diff1': np.float64(0.54609190519907), 'nauc_mrr_at_5_max': np.float64(0.48743342578678833), 'nauc_mrr_at_5_std': np.float64(-0.016354945659780545), 'nauc_mrr_at_5_diff1': np.float64(0.5341056939657133), 'nauc_mrr_at_10_max': np.float64(0.49593428381774457), 'nauc_mrr_at_10_std': np.float64(-0.0034387514430296298), 'nauc_mrr_at_10_diff1': np.float64(0.5313695381754745), 'nauc_mrr_at_20_max': np.float64(0.49265725977075175), 'nauc_mrr_at_20_std': np.float64(0.004530513808894996), 'nauc_mrr_at_20_diff1': np.float64(0.5271162535228666), 'nauc_mrr_at_100_max': np.float64(0.489475326503946), 'nauc_mrr_at_100_std': np.float64(0.0013338792146313193), 'nauc_mrr_at_100_diff1': np.float64(0.5243945797820769), 'nauc_mrr_at_1000_max': np.float64(0.4898721293885467), 'nauc_mrr_at_1000_std': np.float64(0.0020675355159871134), 'nauc_mrr_at_1000_diff1': np.float64(0.5252889239015804), 'main_score': 0.20923}}



==================================================
Running model: dragonkue/BGE-m3-ko
--------------------------------------------------
INFO:mteb.models.overview:Model not found in model registry, assuming it is on HF Hub model.
INFO:mteb.models.overview:Attempting to extract metadata by loading the model (dragonkue/BGE-m3-ko) using HuggingFace.
WARNING:mteb.model_meta:Loader not specified for model dragonkue/BGE-m3-ko, loading using sentence transformers.
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: dragonkue/BGE-m3-ko
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / dragonkue/BGE-m3-ko on GPU 0 in process Process-5
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'corpus' at /root/.cache/huggingface/datasets/taeminlee___ko-strategy_qa/corpus/0.0.0/d243889a3eb6654029dbd7e7f9319ae31d58f97c (last modified on Mon Jan 27 20:22:56 2025).
WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'corpus' at /root/.cache/huggingface/datasets/taeminlee___ko-strategy_qa/corpus/0.0.0/d243889a3eb6654029dbd7e7f9319ae31d58f97c (last modified on Mon Jan 27 20:22:56 2025).
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'queries' at /root/.cache/huggingface/datasets/taeminlee___ko-strategy_qa/queries/0.0.0/d243889a3eb6654029dbd7e7f9319ae31d58f97c (last modified on Mon Jan 27 20:22:58 2025).
WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'queries' at /root/.cache/huggingface/datasets/taeminlee___ko-strategy_qa/queries/0.0.0/d243889a3eb6654029dbd7e7f9319ae31d58f97c (last modified on Mon Jan 27 20:22:58 2025).
Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since taeminlee/Ko-StrategyQA couldn't be found on the Hugging Face Hub
ERROR:mteb.evaluation.MTEB:Error while evaluating Ko-StrategyQA: There are multiple 'taeminlee/Ko-StrategyQA' configurations in the cache: default, queries, corpus
Please specify which configuration to reload from the cache, e.g.
	load_dataset('taeminlee/Ko-StrategyQA', 'default')
Traceback (most recent call last):
  File "/workspace/KURE/eval/evaluate.py", line 241, in evaluate_model
    evaluation.run(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 630, in run
    raise e
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 534, in run
    task.load_data(**kwargs)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py", line 281, in load_data
    corpus, queries, qrels = HFDataLoader(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py", line 96, in load
    self._load_qrels(split)
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py", line 177, in _load_qrels
    qrels_ds = load_dataset(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/datasets/load.py", line 2606, in load_dataset
    builder_instance = load_dataset_builder(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/datasets/load.py", line 2314, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/datasets/packaged_modules/cache/cache.py", line 140, in __init__
    config_name, version, hash = _find_hash_in_cache(
  File "/workspace/KURE/.venv/lib/python3.10/site-packages/datasets/packaged_modules/cache/cache.py", line 85, in _find_hash_in_cache
    raise ValueError(
ValueError: There are multiple 'taeminlee/Ko-StrategyQA' configurations in the cache: default, queries, corpus
Please specify which configuration to reload from the cache, e.g.
	load_dataset('taeminlee/Ko-StrategyQA', 'default')
There are multiple 'taeminlee/Ko-StrategyQA' configurations in the cache: default, queries, corpus
Please specify which configuration to reload from the cache, e.g.
	load_dataset('taeminlee/Ko-StrategyQA', 'default')



==================================================
Running model: intfloat/multilingual-e5-base
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'query': 'query: ', 'passage': 'passage: '}
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / intfloat/multilingual-e5-base on GPU 0 in process Process-6
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  2.09it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.00it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:06,  2.97it/s]Batches:  11%|█         | 2/19 [00:03<00:35,  2.06s/it]Batches:  16%|█▌        | 3/19 [00:06<00:37,  2.34s/it]Batches:  21%|██        | 4/19 [00:08<00:33,  2.23s/it]Batches:  26%|██▋       | 5/19 [00:10<00:29,  2.08s/it]Batches:  32%|███▏      | 6/19 [00:11<00:25,  1.93s/it]Batches:  37%|███▋      | 7/19 [00:13<00:21,  1.78s/it]Batches:  42%|████▏     | 8/19 [00:14<00:18,  1.65s/it]Batches:  47%|████▋     | 9/19 [00:15<00:15,  1.53s/it]Batches:  53%|█████▎    | 10/19 [00:17<00:12,  1.44s/it]Batches:  58%|█████▊    | 11/19 [00:18<00:10,  1.32s/it]Batches:  63%|██████▎   | 12/19 [00:19<00:08,  1.24s/it]Batches:  68%|██████▊   | 13/19 [00:20<00:06,  1.16s/it]Batches:  74%|███████▎  | 14/19 [00:21<00:05,  1.08s/it]Batches:  79%|███████▉  | 15/19 [00:21<00:03,  1.00it/s]Batches:  84%|████████▍ | 16/19 [00:22<00:02,  1.09it/s]Batches:  89%|████████▉ | 17/19 [00:23<00:01,  1.20it/s]Batches:  95%|█████████▍| 18/19 [00:23<00:00,  1.35it/s]Batches: 100%|██████████| 19/19 [00:24<00:00,  1.53it/s]Batches: 100%|██████████| 19/19 [00:24<00:00,  1.28s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 25.55 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 26.17 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.73649, 'ndcg_at_3': 0.71865, 'ndcg_at_5': 0.7468, 'ndcg_at_10': 0.76355, 'ndcg_at_20': 0.77514, 'ndcg_at_100': 0.78456, 'ndcg_at_1000': 0.79272, 'map_at_1': 0.48055, 'map_at_3': 0.6768, 'map_at_5': 0.70509, 'map_at_10': 0.71596, 'map_at_20': 0.72063, 'map_at_100': 0.72269, 'map_at_1000': 0.72304, 'recall_at_1': 0.48055, 'recall_at_3': 0.72275, 'recall_at_5': 0.77861, 'recall_at_10': 0.82061, 'recall_at_20': 0.85825, 'recall_at_100': 0.89764, 'recall_at_1000': 0.95011, 'precision_at_1': 0.73649, 'precision_at_3': 0.42342, 'precision_at_5': 0.28378, 'precision_at_10': 0.15084, 'precision_at_20': 0.07922, 'precision_at_100': 0.01681, 'precision_at_1000': 0.00181, 'mrr_at_1': 0.7364864864864865, 'mrr_at_3': 0.784065315315315, 'mrr_at_5': 0.788119369369369, 'mrr_at_10': 0.7903548637923634, 'mrr_at_20': 0.7919637160083169, 'mrr_at_100': 0.7925485119906738, 'mrr_at_1000': 0.7927242938243799, 'nauc_ndcg_at_1_max': np.float64(0.6858079847057547), 'nauc_ndcg_at_1_std': np.float64(0.3765388440967593), 'nauc_ndcg_at_1_diff1': np.float64(0.7039530934167848), 'nauc_ndcg_at_3_max': np.float64(0.636290626191759), 'nauc_ndcg_at_3_std': np.float64(0.3056776331064701), 'nauc_ndcg_at_3_diff1': np.float64(0.6264794579305172), 'nauc_ndcg_at_5_max': np.float64(0.6952466157901112), 'nauc_ndcg_at_5_std': np.float64(0.37196337183328204), 'nauc_ndcg_at_5_diff1': np.float64(0.625869075116017), 'nauc_ndcg_at_10_max': np.float64(0.7180933779096977), 'nauc_ndcg_at_10_std': np.float64(0.4070068316170624), 'nauc_ndcg_at_10_diff1': np.float64(0.6278521640047413), 'nauc_ndcg_at_20_max': np.float64(0.7258280384831197), 'nauc_ndcg_at_20_std': np.float64(0.42983545353306446), 'nauc_ndcg_at_20_diff1': np.float64(0.6373392342929015), 'nauc_ndcg_at_100_max': np.float64(0.7256084162632179), 'nauc_ndcg_at_100_std': np.float64(0.44181624785201484), 'nauc_ndcg_at_100_diff1': np.float64(0.642682319085353), 'nauc_ndcg_at_1000_max': np.float64(0.7179995530658594), 'nauc_ndcg_at_1000_std': np.float64(0.4261845949670468), 'nauc_ndcg_at_1000_diff1': np.float64(0.64424755653158), 'nauc_map_at_1_max': np.float64(0.32940697064641544), 'nauc_map_at_1_std': np.float64(0.11559889953342109), 'nauc_map_at_1_diff1': np.float64(0.6018674995640366), 'nauc_map_at_3_max': np.float64(0.5870903892260443), 'nauc_map_at_3_std': np.float64(0.25101234031587527), 'nauc_map_at_3_diff1': np.float64(0.6073294597606239), 'nauc_map_at_5_max': np.float64(0.6388561752349948), 'nauc_map_at_5_std': np.float64(0.30314656514004323), 'nauc_map_at_5_diff1': np.float64(0.6037720970775445), 'nauc_map_at_10_max': np.float64(0.6528343968354539), 'nauc_map_at_10_std': np.float64(0.3226467274838311), 'nauc_map_at_10_diff1': np.float64(0.6065961876568182), 'nauc_map_at_20_max': np.float64(0.6570571699925494), 'nauc_map_at_20_std': np.float64(0.33129771879965536), 'nauc_map_at_20_diff1': np.float64(0.6107444546155024), 'nauc_map_at_100_max': np.float64(0.657123268389259), 'nauc_map_at_100_std': np.float64(0.33351708700930727), 'nauc_map_at_100_diff1': np.float64(0.6119223965896734), 'nauc_map_at_1000_max': np.float64(0.6567934929218409), 'nauc_map_at_1000_std': np.float64(0.3328898180127869), 'nauc_map_at_1000_diff1': np.float64(0.6120886347168524), 'nauc_recall_at_1_max': np.float64(0.32940697064641544), 'nauc_recall_at_1_std': np.float64(0.11559889953342109), 'nauc_recall_at_1_diff1': np.float64(0.6018674995640366), 'nauc_recall_at_3_max': np.float64(0.6127205173754705), 'nauc_recall_at_3_std': np.float64(0.2903940935173204), 'nauc_recall_at_3_diff1': np.float64(0.5897862739896276), 'nauc_recall_at_5_max': np.float64(0.7295534419284448), 'nauc_recall_at_5_std': np.float64(0.42258075167199766), 'nauc_recall_at_5_diff1': np.float64(0.5875005857489918), 'nauc_recall_at_10_max': np.float64(0.7969474008126761), 'nauc_recall_at_10_std': np.float64(0.5315121876669305), 'nauc_recall_at_10_diff1': np.float64(0.5794086907748127), 'nauc_recall_at_20_max': np.float64(0.8447530472239648), 'nauc_recall_at_20_std': np.float64(0.6616877200292428), 'nauc_recall_at_20_diff1': np.float64(0.6099124795283541), 'nauc_recall_at_100_max': np.float64(0.8895950225937042), 'nauc_recall_at_100_std': np.float64(0.842089393056033), 'nauc_recall_at_100_diff1': np.float64(0.6400112549494104), 'nauc_recall_at_1000_max': np.float64(0.8988977438568299), 'nauc_recall_at_1000_std': np.float64(0.8912083424270899), 'nauc_recall_at_1000_diff1': np.float64(0.6723513136663745), 'nauc_precision_at_1_max': np.float64(0.6858079847057547), 'nauc_precision_at_1_std': np.float64(0.3765388440967593), 'nauc_precision_at_1_diff1': np.float64(0.7039530934167848), 'nauc_precision_at_3_max': np.float64(0.46127555813841487), 'nauc_precision_at_3_std': np.float64(0.29389070032941417), 'nauc_precision_at_3_diff1': np.float64(0.1328685927957571), 'nauc_precision_at_5_max': np.float64(0.41494796228331343), 'nauc_precision_at_5_std': np.float64(0.3198824993031576), 'nauc_precision_at_5_diff1': np.float64(0.02893102490247378), 'nauc_precision_at_10_max': np.float64(0.3792982449178664), 'nauc_precision_at_10_std': np.float64(0.33785925216888235), 'nauc_precision_at_10_diff1': np.float64(-0.027536142258204773), 'nauc_precision_at_20_max': np.float64(0.3372528758223194), 'nauc_precision_at_20_std': np.float64(0.34947043305267833), 'nauc_precision_at_20_diff1': np.float64(-0.06191201640332512), 'nauc_precision_at_100_max': np.float64(0.24458203344170185), 'nauc_precision_at_100_std': np.float64(0.3186218386991172), 'nauc_precision_at_100_diff1': np.float64(-0.11260045412571985), 'nauc_precision_at_1000_max': np.float64(0.09521843731394646), 'nauc_precision_at_1000_std': np.float64(0.19015616075822983), 'nauc_precision_at_1000_diff1': np.float64(-0.21994374172961523), 'nauc_mrr_at_1_max': np.float64(0.6858079847057547), 'nauc_mrr_at_1_std': np.float64(0.3765388440967593), 'nauc_mrr_at_1_diff1': np.float64(0.7039530934167848), 'nauc_mrr_at_3_max': np.float64(0.7518004256417345), 'nauc_mrr_at_3_std': np.float64(0.45155163434304196), 'nauc_mrr_at_3_diff1': np.float64(0.7087505118984042), 'nauc_mrr_at_5_max': np.float64(0.7571960903936084), 'nauc_mrr_at_5_std': np.float64(0.45999482268765096), 'nauc_mrr_at_5_diff1': np.float64(0.7149092216925744), 'nauc_mrr_at_10_max': np.float64(0.7571695366472795), 'nauc_mrr_at_10_std': np.float64(0.46358167542606876), 'nauc_mrr_at_10_diff1': np.float64(0.7130938288592268), 'nauc_mrr_at_20_max': np.float64(0.7560514342722913), 'nauc_mrr_at_20_std': np.float64(0.4641020982610976), 'nauc_mrr_at_20_diff1': np.float64(0.7134291595723251), 'nauc_mrr_at_100_max': np.float64(0.755503983145516), 'nauc_mrr_at_100_std': np.float64(0.46382569286212155), 'nauc_mrr_at_100_diff1': np.float64(0.7133556295202433), 'nauc_mrr_at_1000_max': np.float64(0.7553376166599368), 'nauc_mrr_at_1000_std': np.float64(0.46353672735350226), 'nauc_mrr_at_1000_diff1': np.float64(0.7133054627456897), 'main_score': 0.76355}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 27.95it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.40it/s]Batches: 100%|██████████| 2/2 [00:03<00:00,  2.07s/it]Batches: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.85 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 5.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.64035, 'ndcg_at_3': 0.74645, 'ndcg_at_5': 0.78045, 'ndcg_at_10': 0.79752, 'ndcg_at_20': 0.80442, 'ndcg_at_100': 0.80827, 'ndcg_at_1000': 0.80956, 'map_at_1': 0.64035, 'map_at_3': 0.72222, 'map_at_5': 0.74196, 'map_at_10': 0.74901, 'map_at_20': 0.75103, 'map_at_100': 0.75181, 'map_at_1000': 0.75189, 'recall_at_1': 0.64035, 'recall_at_3': 0.81579, 'recall_at_5': 0.89474, 'recall_at_10': 0.94737, 'recall_at_20': 0.97368, 'recall_at_100': 0.99123, 'recall_at_1000': 1.0, 'precision_at_1': 0.64035, 'precision_at_3': 0.27193, 'precision_at_5': 0.17895, 'precision_at_10': 0.09474, 'precision_at_20': 0.04868, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6403508771929824, 'mrr_at_3': 0.7222222222222223, 'mrr_at_5': 0.7419590643274855, 'mrr_at_10': 0.7490079365079366, 'mrr_at_20': 0.7510283941204995, 'mrr_at_100': 0.751808506456676, 'mrr_at_1000': 0.751886827258681, 'nauc_ndcg_at_1_max': np.float64(0.23271019903304435), 'nauc_ndcg_at_1_std': np.float64(-0.5640115753195888), 'nauc_ndcg_at_1_diff1': np.float64(0.7112013453493657), 'nauc_ndcg_at_3_max': np.float64(0.26336568473785094), 'nauc_ndcg_at_3_std': np.float64(-0.5769159630372578), 'nauc_ndcg_at_3_diff1': np.float64(0.6616914652317964), 'nauc_ndcg_at_5_max': np.float64(0.3201079312415651), 'nauc_ndcg_at_5_std': np.float64(-0.5716641026307666), 'nauc_ndcg_at_5_diff1': np.float64(0.647354445410905), 'nauc_ndcg_at_10_max': np.float64(0.29752591673557843), 'nauc_ndcg_at_10_std': np.float64(-0.5863892017597498), 'nauc_ndcg_at_10_diff1': np.float64(0.6353600181941691), 'nauc_ndcg_at_20_max': np.float64(0.29042238107218876), 'nauc_ndcg_at_20_std': np.float64(-0.5788922792970898), 'nauc_ndcg_at_20_diff1': np.float64(0.651997768652368), 'nauc_ndcg_at_100_max': np.float64(0.2841887894561054), 'nauc_ndcg_at_100_std': np.float64(-0.5873918400849422), 'nauc_ndcg_at_100_diff1': np.float64(0.6644906484817493), 'nauc_ndcg_at_1000_max': np.float64(0.2807112227353227), 'nauc_ndcg_at_1000_std': np.float64(-0.5781138597877794), 'nauc_ndcg_at_1000_diff1': np.float64(0.6653614414214758), 'nauc_map_at_1_max': np.float64(0.23271019903304435), 'nauc_map_at_1_std': np.float64(-0.5640115753195888), 'nauc_map_at_1_diff1': np.float64(0.7112013453493657), 'nauc_map_at_3_max': np.float64(0.2570892542281406), 'nauc_map_at_3_std': np.float64(-0.571317005989482), 'nauc_map_at_3_diff1': np.float64(0.6752697621006652), 'nauc_map_at_5_max': np.float64(0.28519256115613123), 'nauc_map_at_5_std': np.float64(-0.5682331833213823), 'nauc_map_at_5_diff1': np.float64(0.6691055922420671), 'nauc_map_at_10_max': np.float64(0.27610706400977403), 'nauc_map_at_10_std': np.float64(-0.5733871417301553), 'nauc_map_at_10_diff1': np.float64(0.6658237829761234), 'nauc_map_at_20_max': np.float64(0.2741873392047378), 'nauc_map_at_20_std': np.float64(-0.5717522349353029), 'nauc_map_at_20_diff1': np.float64(0.6702570196763116), 'nauc_map_at_100_max': np.float64(0.27314558762940006), 'nauc_map_at_100_std': np.float64(-0.5730836867712397), 'nauc_map_at_100_diff1': np.float64(0.6722918045747075), 'nauc_map_at_1000_max': np.float64(0.27297805472316405), 'nauc_map_at_1000_std': np.float64(-0.5726423683151028), 'nauc_map_at_1000_diff1': np.float64(0.6723356332353837), 'nauc_recall_at_1_max': np.float64(0.23271019903304435), 'nauc_recall_at_1_std': np.float64(-0.5640115753195888), 'nauc_recall_at_1_diff1': np.float64(0.7112013453493657), 'nauc_recall_at_3_max': np.float64(0.2866030553499234), 'nauc_recall_at_3_std': np.float64(-0.6000744749701153), 'nauc_recall_at_3_diff1': np.float64(0.6085926375473392), 'nauc_recall_at_5_max': np.float64(0.5433636522514345), 'nauc_recall_at_5_std': np.float64(-0.5930010397419251), 'nauc_recall_at_5_diff1': np.float64(0.5125707346224897), 'nauc_recall_at_10_max': np.float64(0.5385542979657265), 'nauc_recall_at_10_std': np.float64(-0.7577965278796062), 'nauc_recall_at_10_diff1': np.float64(0.25703130513688316), 'nauc_recall_at_20_max': np.float64(0.6106419565585729), 'nauc_recall_at_20_std': np.float64(-0.7326974857051948), 'nauc_recall_at_20_diff1': np.float64(0.26640896924600216), 'nauc_recall_at_100_max': np.float64(0.7224066624409369), 'nauc_recall_at_100_std': np.float64(-1.756535991114336), 'nauc_recall_at_100_diff1': np.float64(0.5547596036174103), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.23271019903304435), 'nauc_precision_at_1_std': np.float64(-0.5640115753195888), 'nauc_precision_at_1_diff1': np.float64(0.7112013453493657), 'nauc_precision_at_3_max': np.float64(0.28660305534992264), 'nauc_precision_at_3_std': np.float64(-0.6000744749701165), 'nauc_precision_at_3_diff1': np.float64(0.6085926375473378), 'nauc_precision_at_5_max': np.float64(0.5433636522514341), 'nauc_precision_at_5_std': np.float64(-0.5930010397419233), 'nauc_precision_at_5_diff1': np.float64(0.5125707346224895), 'nauc_precision_at_10_max': np.float64(0.5385542979657244), 'nauc_precision_at_10_std': np.float64(-0.7577965278796114), 'nauc_precision_at_10_diff1': np.float64(0.25703130513687805), 'nauc_precision_at_20_max': np.float64(0.6106419565585748), 'nauc_precision_at_20_std': np.float64(-0.7326974857052104), 'nauc_precision_at_20_diff1': np.float64(0.2664089692459977), 'nauc_precision_at_100_max': np.float64(0.7224066624409552), 'nauc_precision_at_100_std': np.float64(-1.7565359911142433), 'nauc_precision_at_100_diff1': np.float64(0.554759603617449), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.23271019903304435), 'nauc_mrr_at_1_std': np.float64(-0.5640115753195888), 'nauc_mrr_at_1_diff1': np.float64(0.7112013453493657), 'nauc_mrr_at_3_max': np.float64(0.2570892542281406), 'nauc_mrr_at_3_std': np.float64(-0.571317005989482), 'nauc_mrr_at_3_diff1': np.float64(0.6752697621006652), 'nauc_mrr_at_5_max': np.float64(0.28519256115613123), 'nauc_mrr_at_5_std': np.float64(-0.5682331833213823), 'nauc_mrr_at_5_diff1': np.float64(0.6691055922420671), 'nauc_mrr_at_10_max': np.float64(0.27610706400977403), 'nauc_mrr_at_10_std': np.float64(-0.5733871417301553), 'nauc_mrr_at_10_diff1': np.float64(0.6658237829761234), 'nauc_mrr_at_20_max': np.float64(0.2741873392047378), 'nauc_mrr_at_20_std': np.float64(-0.5717522349353029), 'nauc_mrr_at_20_diff1': np.float64(0.6702570196763116), 'nauc_mrr_at_100_max': np.float64(0.27314558762940006), 'nauc_mrr_at_100_std': np.float64(-0.5730836867712397), 'nauc_mrr_at_100_diff1': np.float64(0.6722918045747075), 'nauc_mrr_at_1000_max': np.float64(0.27297805472316405), 'nauc_mrr_at_1000_std': np.float64(-0.5726423683151028), 'nauc_mrr_at_1000_diff1': np.float64(0.6723356332353837), 'main_score': 0.79752}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 29.23it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.68 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.76 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.58442, 'ndcg_at_3': 0.72201, 'ndcg_at_5': 0.73879, 'ndcg_at_10': 0.77203, 'ndcg_at_20': 0.77528, 'ndcg_at_100': 0.78303, 'ndcg_at_1000': 0.78303, 'map_at_1': 0.58442, 'map_at_3': 0.69264, 'map_at_5': 0.70238, 'map_at_10': 0.7159, 'map_at_20': 0.71677, 'map_at_100': 0.71802, 'map_at_1000': 0.71802, 'recall_at_1': 0.58442, 'recall_at_3': 0.80519, 'recall_at_5': 0.84416, 'recall_at_10': 0.94805, 'recall_at_20': 0.96104, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.58442, 'precision_at_3': 0.2684, 'precision_at_5': 0.16883, 'precision_at_10': 0.09481, 'precision_at_20': 0.04805, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5844155844155844, 'mrr_at_3': 0.6926406926406926, 'mrr_at_5': 0.7023809523809523, 'mrr_at_10': 0.7159039373325088, 'mrr_at_20': 0.7167697381983097, 'mrr_at_100': 0.7180190902896827, 'mrr_at_1000': 0.7180190902896827, 'nauc_ndcg_at_1_max': np.float64(0.16323654437643398), 'nauc_ndcg_at_1_std': np.float64(-0.15463541123486912), 'nauc_ndcg_at_1_diff1': np.float64(0.7730849905549931), 'nauc_ndcg_at_3_max': np.float64(0.19094549989384266), 'nauc_ndcg_at_3_std': np.float64(-0.07151120593375672), 'nauc_ndcg_at_3_diff1': np.float64(0.6574658310748505), 'nauc_ndcg_at_5_max': np.float64(0.18463280081684605), 'nauc_ndcg_at_5_std': np.float64(-0.1009792734356102), 'nauc_ndcg_at_5_diff1': np.float64(0.6557380415427442), 'nauc_ndcg_at_10_max': np.float64(0.17175618246048177), 'nauc_ndcg_at_10_std': np.float64(-0.08579200170290963), 'nauc_ndcg_at_10_diff1': np.float64(0.7000221387691848), 'nauc_ndcg_at_20_max': np.float64(0.16214537299119408), 'nauc_ndcg_at_20_std': np.float64(-0.10244557663552743), 'nauc_ndcg_at_20_diff1': np.float64(0.6947883208861702), 'nauc_ndcg_at_100_max': np.float64(0.17338517487228328), 'nauc_ndcg_at_100_std': np.float64(-0.1123379011258602), 'nauc_ndcg_at_100_diff1': np.float64(0.6972930152328541), 'nauc_ndcg_at_1000_max': np.float64(0.17338517487228328), 'nauc_ndcg_at_1000_std': np.float64(-0.1123379011258602), 'nauc_ndcg_at_1000_diff1': np.float64(0.6972930152328541), 'nauc_map_at_1_max': np.float64(0.16323654437643398), 'nauc_map_at_1_std': np.float64(-0.15463541123486912), 'nauc_map_at_1_diff1': np.float64(0.7730849905549931), 'nauc_map_at_3_max': np.float64(0.18438045879970635), 'nauc_map_at_3_std': np.float64(-0.0969266403909441), 'nauc_map_at_3_diff1': np.float64(0.6895156048217616), 'nauc_map_at_5_max': np.float64(0.18085499936323893), 'nauc_map_at_5_std': np.float64(-0.11320280218313829), 'nauc_map_at_5_diff1': np.float64(0.689721270225883), 'nauc_map_at_10_max': np.float64(0.17576332204748918), 'nauc_map_at_10_std': np.float64(-0.11259325010112323), 'nauc_map_at_10_diff1': np.float64(0.7059280638537124), 'nauc_map_at_20_max': np.float64(0.17371661217517576), 'nauc_map_at_20_std': np.float64(-0.11626608139650574), 'nauc_map_at_20_diff1': np.float64(0.7048274115980733), 'nauc_map_at_100_max': np.float64(0.1749739403055711), 'nauc_map_at_100_std': np.float64(-0.11753044732058268), 'nauc_map_at_100_diff1': np.float64(0.7049122955851462), 'nauc_map_at_1000_max': np.float64(0.1749739403055711), 'nauc_map_at_1000_std': np.float64(-0.11753044732058268), 'nauc_map_at_1000_diff1': np.float64(0.7049122955851462), 'nauc_recall_at_1_max': np.float64(0.16323654437643398), 'nauc_recall_at_1_std': np.float64(-0.15463541123486912), 'nauc_recall_at_1_diff1': np.float64(0.7730849905549931), 'nauc_recall_at_3_max': np.float64(0.2160886881649647), 'nauc_recall_at_3_std': np.float64(0.03003794963803853), 'nauc_recall_at_3_diff1': np.float64(0.5312918444354875), 'nauc_recall_at_5_max': np.float64(0.20013872348340017), 'nauc_recall_at_5_std': np.float64(-0.048010643612726514), 'nauc_recall_at_5_diff1': np.float64(0.49670706862146197), 'nauc_recall_at_10_max': np.float64(0.09791382994501428), 'nauc_recall_at_10_std': np.float64(0.3147984908111977), 'nauc_recall_at_10_diff1': np.float64(0.7120602067801166), 'nauc_recall_at_20_max': np.float64(-0.1103157752554104), 'nauc_recall_at_20_std': np.float64(0.13016042025750219), 'nauc_recall_at_20_diff1': np.float64(0.6160802757068197), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.16323654437643398), 'nauc_precision_at_1_std': np.float64(-0.15463541123486912), 'nauc_precision_at_1_diff1': np.float64(0.7730849905549931), 'nauc_precision_at_3_max': np.float64(0.2160886881649667), 'nauc_precision_at_3_std': np.float64(0.03003794963804101), 'nauc_precision_at_3_diff1': np.float64(0.5312918444354878), 'nauc_precision_at_5_max': np.float64(0.20013872348340253), 'nauc_precision_at_5_std': np.float64(-0.04801064361272453), 'nauc_precision_at_5_diff1': np.float64(0.4967070686214641), 'nauc_precision_at_10_max': np.float64(0.09791382994502315), 'nauc_precision_at_10_std': np.float64(0.31479849081120154), 'nauc_precision_at_10_diff1': np.float64(0.7120602067801151), 'nauc_precision_at_20_max': np.float64(-0.11031577525540454), 'nauc_precision_at_20_std': np.float64(0.1301604202575047), 'nauc_precision_at_20_diff1': np.float64(0.616080275706823), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.16323654437643398), 'nauc_mrr_at_1_std': np.float64(-0.15463541123486912), 'nauc_mrr_at_1_diff1': np.float64(0.7730849905549931), 'nauc_mrr_at_3_max': np.float64(0.18438045879970635), 'nauc_mrr_at_3_std': np.float64(-0.0969266403909441), 'nauc_mrr_at_3_diff1': np.float64(0.6895156048217616), 'nauc_mrr_at_5_max': np.float64(0.18085499936323893), 'nauc_mrr_at_5_std': np.float64(-0.11320280218313829), 'nauc_mrr_at_5_diff1': np.float64(0.689721270225883), 'nauc_mrr_at_10_max': np.float64(0.17576332204748918), 'nauc_mrr_at_10_std': np.float64(-0.11259325010112323), 'nauc_mrr_at_10_diff1': np.float64(0.7059280638537124), 'nauc_mrr_at_20_max': np.float64(0.17371661217517576), 'nauc_mrr_at_20_std': np.float64(-0.11626608139650574), 'nauc_mrr_at_20_diff1': np.float64(0.7048274115980733), 'nauc_mrr_at_100_max': np.float64(0.1749739403055711), 'nauc_mrr_at_100_std': np.float64(-0.11753044732058268), 'nauc_mrr_at_100_diff1': np.float64(0.7049122955851462), 'nauc_mrr_at_1000_max': np.float64(0.1749739403055711), 'nauc_mrr_at_1000_std': np.float64(-0.11753044732058268), 'nauc_mrr_at_1000_diff1': np.float64(0.7049122955851462), 'main_score': 0.77203}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  6.72it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  6.70it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.98 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.08it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.05it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.97 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  6.92it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  6.88it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.82 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 10.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.87778, 'ndcg_at_3': 0.91932, 'ndcg_at_5': 0.92263, 'ndcg_at_10': 0.92868, 'ndcg_at_20': 0.93071, 'ndcg_at_100': 0.93292, 'ndcg_at_1000': 0.9336, 'map_at_1': 0.87778, 'map_at_3': 0.90944, 'map_at_5': 0.91133, 'map_at_10': 0.9138, 'map_at_20': 0.91439, 'map_at_100': 0.91467, 'map_at_1000': 0.91469, 'recall_at_1': 0.87778, 'recall_at_3': 0.94778, 'recall_at_5': 0.95556, 'recall_at_10': 0.97444, 'recall_at_20': 0.98222, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.87778, 'precision_at_3': 0.31593, 'precision_at_5': 0.19111, 'precision_at_10': 0.09744, 'precision_at_20': 0.04911, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8777777777777778, 'mrr_at_3': 0.9094444444444447, 'mrr_at_5': 0.9113333333333336, 'mrr_at_10': 0.9137985008818343, 'mrr_at_20': 0.9143924634494812, 'mrr_at_100': 0.9146685714948152, 'mrr_at_1000': 0.9146886305512084, 'nauc_ndcg_at_1_max': np.float64(0.799260933831841), 'nauc_ndcg_at_1_std': np.float64(0.11366837666289938), 'nauc_ndcg_at_1_diff1': np.float64(0.9215546474219641), 'nauc_ndcg_at_3_max': np.float64(0.8379775133293821), 'nauc_ndcg_at_3_std': np.float64(0.17381112073015367), 'nauc_ndcg_at_3_diff1': np.float64(0.9190673661119936), 'nauc_ndcg_at_5_max': np.float64(0.8350861313142242), 'nauc_ndcg_at_5_std': np.float64(0.16991899186101822), 'nauc_ndcg_at_5_diff1': np.float64(0.9172056481173958), 'nauc_ndcg_at_10_max': np.float64(0.8289509732231671), 'nauc_ndcg_at_10_std': np.float64(0.1596542610882336), 'nauc_ndcg_at_10_diff1': np.float64(0.9150957154475938), 'nauc_ndcg_at_20_max': np.float64(0.82716744742434), 'nauc_ndcg_at_20_std': np.float64(0.16310395329427177), 'nauc_ndcg_at_20_diff1': np.float64(0.9154318158435176), 'nauc_ndcg_at_100_max': np.float64(0.8247226421327326), 'nauc_ndcg_at_100_std': np.float64(0.16028099913529092), 'nauc_ndcg_at_100_diff1': np.float64(0.9167224172494681), 'nauc_ndcg_at_1000_max': np.float64(0.824184031484245), 'nauc_ndcg_at_1000_std': np.float64(0.15512298069474917), 'nauc_ndcg_at_1000_diff1': np.float64(0.9167576396553385), 'nauc_map_at_1_max': np.float64(0.799260933831841), 'nauc_map_at_1_std': np.float64(0.11366837666289938), 'nauc_map_at_1_diff1': np.float64(0.9215546474219641), 'nauc_map_at_3_max': np.float64(0.8260591982830046), 'nauc_map_at_3_std': np.float64(0.15475753853438384), 'nauc_map_at_3_diff1': np.float64(0.9191364960344942), 'nauc_map_at_5_max': np.float64(0.8243424595178229), 'nauc_map_at_5_std': np.float64(0.15253983585873487), 'nauc_map_at_5_diff1': np.float64(0.9182178325391143), 'nauc_map_at_10_max': np.float64(0.8217179762219908), 'nauc_map_at_10_std': np.float64(0.14776156586300634), 'nauc_map_at_10_diff1': np.float64(0.9173620069052005), 'nauc_map_at_20_max': np.float64(0.8212567907630953), 'nauc_map_at_20_std': np.float64(0.1480711029323691), 'nauc_map_at_20_diff1': np.float64(0.9174648784829924), 'nauc_map_at_100_max': np.float64(0.8209388488088828), 'nauc_map_at_100_std': np.float64(0.14768093837442417), 'nauc_map_at_100_diff1': np.float64(0.9175628238240089), 'nauc_map_at_1000_max': np.float64(0.8209359588621885), 'nauc_map_at_1000_std': np.float64(0.14758622633517648), 'nauc_map_at_1000_diff1': np.float64(0.9175700238097899), 'nauc_recall_at_1_max': np.float64(0.799260933831841), 'nauc_recall_at_1_std': np.float64(0.11366837666289938), 'nauc_recall_at_1_diff1': np.float64(0.9215546474219641), 'nauc_recall_at_3_max': np.float64(0.8962492798537856), 'nauc_recall_at_3_std': np.float64(0.2673679400838344), 'nauc_recall_at_3_diff1': np.float64(0.9192442934620657), 'nauc_recall_at_5_max': np.float64(0.8948412698412709), 'nauc_recall_at_5_std': np.float64(0.26683006535947723), 'nauc_recall_at_5_diff1': np.float64(0.9116479925303471), 'nauc_recall_at_10_max': np.float64(0.8906954085982204), 'nauc_recall_at_10_std': np.float64(0.2649697560183457), 'nauc_recall_at_10_diff1': np.float64(0.8925222262818165), 'nauc_recall_at_20_max': np.float64(0.891164799253035), 'nauc_recall_at_20_std': np.float64(0.3770424836601331), 'nauc_recall_at_20_diff1': np.float64(0.8873716153127925), 'nauc_recall_at_100_max': np.float64(0.8846872082166294), 'nauc_recall_at_100_std': np.float64(0.6765639589169213), 'nauc_recall_at_100_diff1': np.float64(0.9183006535947761), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.799260933831841), 'nauc_precision_at_1_std': np.float64(0.11366837666289938), 'nauc_precision_at_1_diff1': np.float64(0.9215546474219641), 'nauc_precision_at_3_max': np.float64(0.8962492798537904), 'nauc_precision_at_3_std': np.float64(0.26736794008383474), 'nauc_precision_at_3_diff1': np.float64(0.9192442934620643), 'nauc_precision_at_5_max': np.float64(0.8948412698412691), 'nauc_precision_at_5_std': np.float64(0.26683006535947623), 'nauc_precision_at_5_diff1': np.float64(0.911647992530343), 'nauc_precision_at_10_max': np.float64(0.8906954085982189), 'nauc_precision_at_10_std': np.float64(0.2649697560183486), 'nauc_precision_at_10_diff1': np.float64(0.8925222262818151), 'nauc_precision_at_20_max': np.float64(0.8911647992530264), 'nauc_precision_at_20_std': np.float64(0.37704248366012), 'nauc_precision_at_20_diff1': np.float64(0.8873716153127876), 'nauc_precision_at_100_max': np.float64(0.884687208216607), 'nauc_precision_at_100_std': np.float64(0.6765639589169249), 'nauc_precision_at_100_diff1': np.float64(0.9183006535947483), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.799260933831841), 'nauc_mrr_at_1_std': np.float64(0.11366837666289938), 'nauc_mrr_at_1_diff1': np.float64(0.9215546474219641), 'nauc_mrr_at_3_max': np.float64(0.8260591982830046), 'nauc_mrr_at_3_std': np.float64(0.15475753853438384), 'nauc_mrr_at_3_diff1': np.float64(0.9191364960344942), 'nauc_mrr_at_5_max': np.float64(0.8243424595178229), 'nauc_mrr_at_5_std': np.float64(0.15253983585873487), 'nauc_mrr_at_5_diff1': np.float64(0.9182178325391143), 'nauc_mrr_at_10_max': np.float64(0.8217179762219908), 'nauc_mrr_at_10_std': np.float64(0.14776156586300634), 'nauc_mrr_at_10_diff1': np.float64(0.9173620069052005), 'nauc_mrr_at_20_max': np.float64(0.8212567907630953), 'nauc_mrr_at_20_std': np.float64(0.1480711029323691), 'nauc_mrr_at_20_diff1': np.float64(0.9174648784829924), 'nauc_mrr_at_100_max': np.float64(0.8209388488088828), 'nauc_mrr_at_100_std': np.float64(0.14768093837442417), 'nauc_mrr_at_100_diff1': np.float64(0.9175628238240089), 'nauc_mrr_at_1000_max': np.float64(0.8209359588621885), 'nauc_mrr_at_1000_std': np.float64(0.14758622633517648), 'nauc_mrr_at_1000_diff1': np.float64(0.9175700238097899), 'main_score': 0.92868}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.72667, 'ndcg_at_3': 0.79042, 'ndcg_at_5': 0.80955, 'ndcg_at_10': 0.82283, 'ndcg_at_20': 0.82747, 'ndcg_at_100': 0.83689, 'ndcg_at_1000': 0.83805, 'map_at_1': 0.72667, 'map_at_3': 0.77481, 'map_at_5': 0.78537, 'map_at_10': 0.79085, 'map_at_20': 0.79205, 'map_at_100': 0.79349, 'map_at_1000': 0.79354, 'recall_at_1': 0.72667, 'recall_at_3': 0.83556, 'recall_at_5': 0.88222, 'recall_at_10': 0.92333, 'recall_at_20': 0.94222, 'recall_at_100': 0.99111, 'recall_at_1000': 1.0, 'precision_at_1': 0.72667, 'precision_at_3': 0.27852, 'precision_at_5': 0.17644, 'precision_at_10': 0.09233, 'precision_at_20': 0.04711, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7266666666666667, 'mrr_at_3': 0.774814814814815, 'mrr_at_5': 0.7853703703703707, 'mrr_at_10': 0.7908456790123461, 'mrr_at_20': 0.7920526847879792, 'mrr_at_100': 0.7934928056608854, 'mrr_at_1000': 0.793538990477385, 'nauc_ndcg_at_1_max': np.float64(0.560422261720963), 'nauc_ndcg_at_1_std': np.float64(0.12586115183517807), 'nauc_ndcg_at_1_diff1': np.float64(0.8438314931821422), 'nauc_ndcg_at_3_max': np.float64(0.5679585650218014), 'nauc_ndcg_at_3_std': np.float64(0.15628807596368502), 'nauc_ndcg_at_3_diff1': np.float64(0.8195822806147087), 'nauc_ndcg_at_5_max': np.float64(0.5587825702586793), 'nauc_ndcg_at_5_std': np.float64(0.15612029203237102), 'nauc_ndcg_at_5_diff1': np.float64(0.8095848513111588), 'nauc_ndcg_at_10_max': np.float64(0.5567023121807358), 'nauc_ndcg_at_10_std': np.float64(0.17417787453234748), 'nauc_ndcg_at_10_diff1': np.float64(0.8101250409144324), 'nauc_ndcg_at_20_max': np.float64(0.5624189349413797), 'nauc_ndcg_at_20_std': np.float64(0.17099815701792506), 'nauc_ndcg_at_20_diff1': np.float64(0.8146190720348256), 'nauc_ndcg_at_100_max': np.float64(0.5588226115554171), 'nauc_ndcg_at_100_std': np.float64(0.16480730316388906), 'nauc_ndcg_at_100_diff1': np.float64(0.8195860199960943), 'nauc_ndcg_at_1000_max': np.float64(0.5606664898880551), 'nauc_ndcg_at_1000_std': np.float64(0.15969401918873752), 'nauc_ndcg_at_1000_diff1': np.float64(0.8197499082937609), 'nauc_map_at_1_max': np.float64(0.560422261720963), 'nauc_map_at_1_std': np.float64(0.12586115183517807), 'nauc_map_at_1_diff1': np.float64(0.8438314931821422), 'nauc_map_at_3_max': np.float64(0.5660999527289668), 'nauc_map_at_3_std': np.float64(0.1494942169502371), 'nauc_map_at_3_diff1': np.float64(0.8260187927862362), 'nauc_map_at_5_max': np.float64(0.561880380615228), 'nauc_map_at_5_std': np.float64(0.14899699856383378), 'nauc_map_at_5_diff1': np.float64(0.8215064787749222), 'nauc_map_at_10_max': np.float64(0.5608609888078221), 'nauc_map_at_10_std': np.float64(0.15473708791377086), 'nauc_map_at_10_diff1': np.float64(0.8217154451358325), 'nauc_map_at_20_max': np.float64(0.5619696743995988), 'nauc_map_at_20_std': np.float64(0.15390905856653878), 'nauc_map_at_20_diff1': np.float64(0.8227647973076403), 'nauc_map_at_100_max': np.float64(0.5616623686340935), 'nauc_map_at_100_std': np.float64(0.15295319052202627), 'nauc_map_at_100_diff1': np.float64(0.8234845751578477), 'nauc_map_at_1000_max': np.float64(0.5617154161554866), 'nauc_map_at_1000_std': np.float64(0.1527782088522249), 'nauc_map_at_1000_diff1': np.float64(0.8234897859527498), 'nauc_recall_at_1_max': np.float64(0.560422261720963), 'nauc_recall_at_1_std': np.float64(0.12586115183517807), 'nauc_recall_at_1_diff1': np.float64(0.8438314931821422), 'nauc_recall_at_3_max': np.float64(0.5747965263185886), 'nauc_recall_at_3_std': np.float64(0.18084222145383833), 'nauc_recall_at_3_diff1': np.float64(0.7956186663829558), 'nauc_recall_at_5_max': np.float64(0.5403959168269155), 'nauc_recall_at_5_std': np.float64(0.18949822978631597), 'nauc_recall_at_5_diff1': np.float64(0.7492946102834147), 'nauc_recall_at_10_max': np.float64(0.5223142397055422), 'nauc_recall_at_10_std': np.float64(0.330187147322698), 'nauc_recall_at_10_diff1': np.float64(0.7261735612119232), 'nauc_recall_at_20_max': np.float64(0.5787096890038078), 'nauc_recall_at_20_std': np.float64(0.3463782949077075), 'nauc_recall_at_20_diff1': np.float64(0.7486443295266847), 'nauc_recall_at_100_max': np.float64(0.31512605042016767), 'nauc_recall_at_100_std': np.float64(0.8045634920634981), 'nauc_recall_at_100_diff1': np.float64(0.7980859010270872), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.560422261720963), 'nauc_precision_at_1_std': np.float64(0.12586115183517807), 'nauc_precision_at_1_diff1': np.float64(0.8438314931821422), 'nauc_precision_at_3_max': np.float64(0.5747965263185904), 'nauc_precision_at_3_std': np.float64(0.18084222145384055), 'nauc_precision_at_3_diff1': np.float64(0.7956186663829573), 'nauc_precision_at_5_max': np.float64(0.5403959168269141), 'nauc_precision_at_5_std': np.float64(0.18949822978631403), 'nauc_precision_at_5_diff1': np.float64(0.7492946102834129), 'nauc_precision_at_10_max': np.float64(0.5223142397055406), 'nauc_precision_at_10_std': np.float64(0.3301871473226919), 'nauc_precision_at_10_diff1': np.float64(0.7261735612119219), 'nauc_precision_at_20_max': np.float64(0.5787096890038043), 'nauc_precision_at_20_std': np.float64(0.34637829490770417), 'nauc_precision_at_20_diff1': np.float64(0.7486443295266831), 'nauc_precision_at_100_max': np.float64(0.3151260504201801), 'nauc_precision_at_100_std': np.float64(0.8045634920635055), 'nauc_precision_at_100_diff1': np.float64(0.7980859010270617), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.560422261720963), 'nauc_mrr_at_1_std': np.float64(0.12586115183517807), 'nauc_mrr_at_1_diff1': np.float64(0.8438314931821422), 'nauc_mrr_at_3_max': np.float64(0.5660999527289668), 'nauc_mrr_at_3_std': np.float64(0.1494942169502371), 'nauc_mrr_at_3_diff1': np.float64(0.8260187927862362), 'nauc_mrr_at_5_max': np.float64(0.561880380615228), 'nauc_mrr_at_5_std': np.float64(0.14899699856383378), 'nauc_mrr_at_5_diff1': np.float64(0.8215064787749222), 'nauc_mrr_at_10_max': np.float64(0.5608609888078221), 'nauc_mrr_at_10_std': np.float64(0.15473708791377086), 'nauc_mrr_at_10_diff1': np.float64(0.8217154451358325), 'nauc_mrr_at_20_max': np.float64(0.5619696743995988), 'nauc_mrr_at_20_std': np.float64(0.15390905856653878), 'nauc_mrr_at_20_diff1': np.float64(0.8227647973076403), 'nauc_mrr_at_100_max': np.float64(0.5616623686340935), 'nauc_mrr_at_100_std': np.float64(0.15295319052202627), 'nauc_mrr_at_100_diff1': np.float64(0.8234845751578477), 'nauc_mrr_at_1000_max': np.float64(0.5617154161554866), 'nauc_mrr_at_1000_std': np.float64(0.1527782088522249), 'nauc_mrr_at_1000_diff1': np.float64(0.8234897859527498), 'main_score': 0.82283}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.66444, 'ndcg_at_3': 0.73594, 'ndcg_at_5': 0.7565, 'ndcg_at_10': 0.77524, 'ndcg_at_20': 0.78642, 'ndcg_at_100': 0.79551, 'ndcg_at_1000': 0.79729, 'map_at_1': 0.66444, 'map_at_3': 0.71907, 'map_at_5': 0.73046, 'map_at_10': 0.73824, 'map_at_20': 0.74128, 'map_at_100': 0.74246, 'map_at_1000': 0.74254, 'recall_at_1': 0.66444, 'recall_at_3': 0.78444, 'recall_at_5': 0.83444, 'recall_at_10': 0.89222, 'recall_at_20': 0.93667, 'recall_at_100': 0.98667, 'recall_at_1000': 1.0, 'precision_at_1': 0.66444, 'precision_at_3': 0.26148, 'precision_at_5': 0.16689, 'precision_at_10': 0.08922, 'precision_at_20': 0.04683, 'precision_at_100': 0.00987, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6644444444444444, 'mrr_at_3': 0.7190740740740743, 'mrr_at_5': 0.7304629629629632, 'mrr_at_10': 0.7382402998236333, 'mrr_at_20': 0.7412782930338401, 'mrr_at_100': 0.7424622167121282, 'mrr_at_1000': 0.7425399479231359, 'nauc_ndcg_at_1_max': np.float64(0.6255213235759166), 'nauc_ndcg_at_1_std': np.float64(0.16194235584310274), 'nauc_ndcg_at_1_diff1': np.float64(0.8195281021775603), 'nauc_ndcg_at_3_max': np.float64(0.6396965790529899), 'nauc_ndcg_at_3_std': np.float64(0.19901557248954965), 'nauc_ndcg_at_3_diff1': np.float64(0.7757766754986003), 'nauc_ndcg_at_5_max': np.float64(0.6412025750548266), 'nauc_ndcg_at_5_std': np.float64(0.2148997990723823), 'nauc_ndcg_at_5_diff1': np.float64(0.777266463466251), 'nauc_ndcg_at_10_max': np.float64(0.6401755531081292), 'nauc_ndcg_at_10_std': np.float64(0.23416053780066517), 'nauc_ndcg_at_10_diff1': np.float64(0.776980790774603), 'nauc_ndcg_at_20_max': np.float64(0.6474238317445925), 'nauc_ndcg_at_20_std': np.float64(0.23531316447325645), 'nauc_ndcg_at_20_diff1': np.float64(0.782997924515294), 'nauc_ndcg_at_100_max': np.float64(0.641147678776563), 'nauc_ndcg_at_100_std': np.float64(0.21969864365016378), 'nauc_ndcg_at_100_diff1': np.float64(0.7861182735886454), 'nauc_ndcg_at_1000_max': np.float64(0.6399061578992061), 'nauc_ndcg_at_1000_std': np.float64(0.21488055303395148), 'nauc_ndcg_at_1000_diff1': np.float64(0.7861236191707828), 'nauc_map_at_1_max': np.float64(0.6255213235759166), 'nauc_map_at_1_std': np.float64(0.16194235584310274), 'nauc_map_at_1_diff1': np.float64(0.8195281021775603), 'nauc_map_at_3_max': np.float64(0.6360744018755625), 'nauc_map_at_3_std': np.float64(0.19083591004405367), 'nauc_map_at_3_diff1': np.float64(0.786610187688215), 'nauc_map_at_5_max': np.float64(0.6363189564576122), 'nauc_map_at_5_std': np.float64(0.19808412603436282), 'nauc_map_at_5_diff1': np.float64(0.7877762737592369), 'nauc_map_at_10_max': np.float64(0.6359172299707678), 'nauc_map_at_10_std': np.float64(0.20454031162914182), 'nauc_map_at_10_diff1': np.float64(0.7880583637680022), 'nauc_map_at_20_max': np.float64(0.6373774697210272), 'nauc_map_at_20_std': np.float64(0.20461194000085434), 'nauc_map_at_20_diff1': np.float64(0.7896294447842023), 'nauc_map_at_100_max': np.float64(0.6367077990429704), 'nauc_map_at_100_std': np.float64(0.20293440007437535), 'nauc_map_at_100_diff1': np.float64(0.7899691659530444), 'nauc_map_at_1000_max': np.float64(0.636679580496758), 'nauc_map_at_1000_std': np.float64(0.20278639246259875), 'nauc_map_at_1000_diff1': np.float64(0.7899720871622794), 'nauc_recall_at_1_max': np.float64(0.6255213235759166), 'nauc_recall_at_1_std': np.float64(0.16194235584310274), 'nauc_recall_at_1_diff1': np.float64(0.8195281021775603), 'nauc_recall_at_3_max': np.float64(0.6523252831018428), 'nauc_recall_at_3_std': np.float64(0.2268243904737469), 'nauc_recall_at_3_diff1': np.float64(0.7381955824071117), 'nauc_recall_at_5_max': np.float64(0.6629504556598974), 'nauc_recall_at_5_std': np.float64(0.2899239355269335), 'nauc_recall_at_5_diff1': np.float64(0.7334373079388581), 'nauc_recall_at_10_max': np.float64(0.6661694539730049), 'nauc_recall_at_10_std': np.float64(0.43578668117815195), 'nauc_recall_at_10_diff1': np.float64(0.7104132857823081), 'nauc_recall_at_20_max': np.float64(0.7727816272707918), 'nauc_recall_at_20_std': np.float64(0.5824692450079454), 'nauc_recall_at_20_diff1': np.float64(0.733721558798958), 'nauc_recall_at_100_max': np.float64(0.7740040460628713), 'nauc_recall_at_100_std': np.float64(0.7100451291627723), 'nauc_recall_at_100_diff1': np.float64(0.7858309990662884), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6255213235759166), 'nauc_precision_at_1_std': np.float64(0.16194235584310274), 'nauc_precision_at_1_diff1': np.float64(0.8195281021775603), 'nauc_precision_at_3_max': np.float64(0.6523252831018433), 'nauc_precision_at_3_std': np.float64(0.2268243904737471), 'nauc_precision_at_3_diff1': np.float64(0.7381955824071126), 'nauc_precision_at_5_max': np.float64(0.6629504556598959), 'nauc_precision_at_5_std': np.float64(0.28992393552693146), 'nauc_precision_at_5_diff1': np.float64(0.7334373079388574), 'nauc_precision_at_10_max': np.float64(0.6661694539730024), 'nauc_precision_at_10_std': np.float64(0.4357866811781495), 'nauc_precision_at_10_diff1': np.float64(0.7104132857823072), 'nauc_precision_at_20_max': np.float64(0.7727816272707906), 'nauc_precision_at_20_std': np.float64(0.5824692450079442), 'nauc_precision_at_20_diff1': np.float64(0.7337215587989555), 'nauc_precision_at_100_max': np.float64(0.7740040460628638), 'nauc_precision_at_100_std': np.float64(0.7100451291627877), 'nauc_precision_at_100_diff1': np.float64(0.7858309990662994), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6255213235759166), 'nauc_mrr_at_1_std': np.float64(0.16194235584310274), 'nauc_mrr_at_1_diff1': np.float64(0.8195281021775603), 'nauc_mrr_at_3_max': np.float64(0.6360744018755625), 'nauc_mrr_at_3_std': np.float64(0.19083591004405367), 'nauc_mrr_at_3_diff1': np.float64(0.786610187688215), 'nauc_mrr_at_5_max': np.float64(0.6363189564576122), 'nauc_mrr_at_5_std': np.float64(0.19808412603436282), 'nauc_mrr_at_5_diff1': np.float64(0.7877762737592369), 'nauc_mrr_at_10_max': np.float64(0.6359172299707678), 'nauc_mrr_at_10_std': np.float64(0.20454031162914182), 'nauc_mrr_at_10_diff1': np.float64(0.7880583637680022), 'nauc_mrr_at_20_max': np.float64(0.6373774697210272), 'nauc_mrr_at_20_std': np.float64(0.20461194000085434), 'nauc_mrr_at_20_diff1': np.float64(0.7896294447842023), 'nauc_mrr_at_100_max': np.float64(0.6367077990429704), 'nauc_mrr_at_100_std': np.float64(0.20293440007437535), 'nauc_mrr_at_100_diff1': np.float64(0.7899691659530444), 'nauc_mrr_at_1000_max': np.float64(0.636679580496758), 'nauc_mrr_at_1000_std': np.float64(0.20278639246259875), 'nauc_mrr_at_1000_diff1': np.float64(0.7899720871622794), 'main_score': 0.77524}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.67it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.65it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.96it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.65 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.66it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.65it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  6.68it/s]Batches:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.60 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.64 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 9.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.30275, 'ndcg_at_3': 0.31866, 'ndcg_at_5': 0.33905, 'ndcg_at_10': 0.36069, 'ndcg_at_20': 0.38571, 'ndcg_at_100': 0.43625, 'ndcg_at_1000': 0.46606, 'map_at_1': 0.21481, 'map_at_3': 0.2905, 'map_at_5': 0.30786, 'map_at_10': 0.31819, 'map_at_20': 0.32627, 'map_at_100': 0.33387, 'map_at_1000': 0.33516, 'recall_at_1': 0.21481, 'recall_at_3': 0.33372, 'recall_at_5': 0.38509, 'recall_at_10': 0.44429, 'recall_at_20': 0.53168, 'recall_at_100': 0.78193, 'recall_at_1000': 1.0, 'precision_at_1': 0.30275, 'precision_at_3': 0.17482, 'precision_at_5': 0.12263, 'precision_at_10': 0.07141, 'precision_at_20': 0.04297, 'precision_at_100': 0.01248, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.30275229357798167, 'mrr_at_3': 0.3440366972477066, 'mrr_at_5': 0.3533639143730888, 'mrr_at_10': 0.36135563807582166, 'mrr_at_20': 0.3671662633458229, 'mrr_at_100': 0.37285306197308304, 'mrr_at_1000': 0.3736221693393797, 'nauc_ndcg_at_1_max': np.float64(0.22365383306396908), 'nauc_ndcg_at_1_std': np.float64(-0.26645605434126035), 'nauc_ndcg_at_1_diff1': np.float64(0.48504640241831776), 'nauc_ndcg_at_3_max': np.float64(0.20549898662174343), 'nauc_ndcg_at_3_std': np.float64(-0.2533596592071201), 'nauc_ndcg_at_3_diff1': np.float64(0.43553101733767347), 'nauc_ndcg_at_5_max': np.float64(0.20693147658234184), 'nauc_ndcg_at_5_std': np.float64(-0.2545305413805693), 'nauc_ndcg_at_5_diff1': np.float64(0.4225587695441424), 'nauc_ndcg_at_10_max': np.float64(0.19999112763097251), 'nauc_ndcg_at_10_std': np.float64(-0.2601096082625414), 'nauc_ndcg_at_10_diff1': np.float64(0.4162771288966551), 'nauc_ndcg_at_20_max': np.float64(0.20035740324493917), 'nauc_ndcg_at_20_std': np.float64(-0.25603806060197876), 'nauc_ndcg_at_20_diff1': np.float64(0.41831456229253894), 'nauc_ndcg_at_100_max': np.float64(0.2129928989939518), 'nauc_ndcg_at_100_std': np.float64(-0.22703733922966937), 'nauc_ndcg_at_100_diff1': np.float64(0.41243035819672635), 'nauc_ndcg_at_1000_max': np.float64(0.21028412624263557), 'nauc_ndcg_at_1000_std': np.float64(-0.2385147206353927), 'nauc_ndcg_at_1000_diff1': np.float64(0.4205010006029617), 'nauc_map_at_1_max': np.float64(0.15959686126723213), 'nauc_map_at_1_std': np.float64(-0.20796331653269645), 'nauc_map_at_1_diff1': np.float64(0.48514432281307956), 'nauc_map_at_3_max': np.float64(0.21074344546441529), 'nauc_map_at_3_std': np.float64(-0.2386688960545258), 'nauc_map_at_3_diff1': np.float64(0.4426742232767405), 'nauc_map_at_5_max': np.float64(0.2133753694750978), 'nauc_map_at_5_std': np.float64(-0.24227569100303628), 'nauc_map_at_5_diff1': np.float64(0.4332980701040247), 'nauc_map_at_10_max': np.float64(0.2081921918315355), 'nauc_map_at_10_std': np.float64(-0.24702028464663603), 'nauc_map_at_10_diff1': np.float64(0.4304693295948851), 'nauc_map_at_20_max': np.float64(0.20731177272463377), 'nauc_map_at_20_std': np.float64(-0.24757842122448667), 'nauc_map_at_20_diff1': np.float64(0.43054486484034565), 'nauc_map_at_100_max': np.float64(0.20904593684442044), 'nauc_map_at_100_std': np.float64(-0.24285433824569516), 'nauc_map_at_100_diff1': np.float64(0.42935400180817335), 'nauc_map_at_1000_max': np.float64(0.20893231689392702), 'nauc_map_at_1000_std': np.float64(-0.24308543566042776), 'nauc_map_at_1000_diff1': np.float64(0.42961068932408564), 'nauc_recall_at_1_max': np.float64(0.15959686126723213), 'nauc_recall_at_1_std': np.float64(-0.20796331653269645), 'nauc_recall_at_1_diff1': np.float64(0.48514432281307956), 'nauc_recall_at_3_max': np.float64(0.18498685148507174), 'nauc_recall_at_3_std': np.float64(-0.24862344210225615), 'nauc_recall_at_3_diff1': np.float64(0.3936308854125494), 'nauc_recall_at_5_max': np.float64(0.18766267088899702), 'nauc_recall_at_5_std': np.float64(-0.25256901516345587), 'nauc_recall_at_5_diff1': np.float64(0.3677562165817916), 'nauc_recall_at_10_max': np.float64(0.17132518446252754), 'nauc_recall_at_10_std': np.float64(-0.2645301871034324), 'nauc_recall_at_10_diff1': np.float64(0.34935722006409087), 'nauc_recall_at_20_max': np.float64(0.17073061417496116), 'nauc_recall_at_20_std': np.float64(-0.25110422810336486), 'nauc_recall_at_20_diff1': np.float64(0.3551238752877474), 'nauc_recall_at_100_max': np.float64(0.22809734919206476), 'nauc_recall_at_100_std': np.float64(-0.0639689151589093), 'nauc_recall_at_100_diff1': np.float64(0.28168730538400805), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.22365383306396908), 'nauc_precision_at_1_std': np.float64(-0.26645605434126035), 'nauc_precision_at_1_diff1': np.float64(0.48504640241831776), 'nauc_precision_at_3_max': np.float64(0.23054771411644534), 'nauc_precision_at_3_std': np.float64(-0.26043053473303907), 'nauc_precision_at_3_diff1': np.float64(0.3197277868626114), 'nauc_precision_at_5_max': np.float64(0.211260301971109), 'nauc_precision_at_5_std': np.float64(-0.24206268208121878), 'nauc_precision_at_5_diff1': np.float64(0.27302904750591267), 'nauc_precision_at_10_max': np.float64(0.1794621672513022), 'nauc_precision_at_10_std': np.float64(-0.23894429362629943), 'nauc_precision_at_10_diff1': np.float64(0.2383661017481684), 'nauc_precision_at_20_max': np.float64(0.16392545018550997), 'nauc_precision_at_20_std': np.float64(-0.20028651530585947), 'nauc_precision_at_20_diff1': np.float64(0.2085622758297434), 'nauc_precision_at_100_max': np.float64(0.1831172991717435), 'nauc_precision_at_100_std': np.float64(0.0015248727721582668), 'nauc_precision_at_100_diff1': np.float64(0.08052988850710768), 'nauc_precision_at_1000_max': np.float64(0.13281207973414894), 'nauc_precision_at_1000_std': np.float64(0.03702777512602303), 'nauc_precision_at_1000_diff1': np.float64(-0.018914124872467415), 'nauc_mrr_at_1_max': np.float64(0.22365383306396908), 'nauc_mrr_at_1_std': np.float64(-0.26645605434126035), 'nauc_mrr_at_1_diff1': np.float64(0.48504640241831776), 'nauc_mrr_at_3_max': np.float64(0.20896914537040218), 'nauc_mrr_at_3_std': np.float64(-0.2730896968385306), 'nauc_mrr_at_3_diff1': np.float64(0.4504803999602948), 'nauc_mrr_at_5_max': np.float64(0.20972074759347048), 'nauc_mrr_at_5_std': np.float64(-0.2727906910871489), 'nauc_mrr_at_5_diff1': np.float64(0.44881343340207414), 'nauc_mrr_at_10_max': np.float64(0.20811085326333742), 'nauc_mrr_at_10_std': np.float64(-0.27237533304532074), 'nauc_mrr_at_10_diff1': np.float64(0.4450688308277625), 'nauc_mrr_at_20_max': np.float64(0.2099648096859005), 'nauc_mrr_at_20_std': np.float64(-0.2693269981654777), 'nauc_mrr_at_20_diff1': np.float64(0.4464671018723737), 'nauc_mrr_at_100_max': np.float64(0.2106584122346581), 'nauc_mrr_at_100_std': np.float64(-0.26718060246814973), 'nauc_mrr_at_100_diff1': np.float64(0.4459712035125217), 'nauc_mrr_at_1000_max': np.float64(0.2105350798643324), 'nauc_mrr_at_1000_std': np.float64(-0.26742561605188436), 'nauc_mrr_at_1000_diff1': np.float64(0.44611501209015364), 'main_score': 0.36069}, 'eng-kor': {'ndcg_at_1': 0.17737, 'ndcg_at_3': 0.16856, 'ndcg_at_5': 0.17856, 'ndcg_at_10': 0.20148, 'ndcg_at_20': 0.22923, 'ndcg_at_100': 0.28543, 'ndcg_at_1000': 0.34227, 'map_at_1': 0.09414, 'map_at_3': 0.13541, 'map_at_5': 0.14789, 'map_at_10': 0.15803, 'map_at_20': 0.16692, 'map_at_100': 0.1757, 'map_at_1000': 0.17866, 'recall_at_1': 0.09414, 'recall_at_3': 0.16374, 'recall_at_5': 0.20064, 'recall_at_10': 0.26055, 'recall_at_20': 0.35497, 'recall_at_100': 0.61476, 'recall_at_1000': 0.99592, 'precision_at_1': 0.17737, 'precision_at_3': 0.11009, 'precision_at_5': 0.08135, 'precision_at_10': 0.05291, 'precision_at_20': 0.0354, 'precision_at_100': 0.01229, 'precision_at_1000': 0.00194, 'mrr_at_1': 0.17737003058103976, 'mrr_at_3': 0.21024464831804282, 'mrr_at_5': 0.21842507645259937, 'mrr_at_10': 0.2286363526042424, 'mrr_at_20': 0.23507732341575746, 'mrr_at_100': 0.24141481518808394, 'mrr_at_1000': 0.24275841275100346, 'nauc_ndcg_at_1_max': np.float64(0.25281952813321773), 'nauc_ndcg_at_1_std': np.float64(-0.10322278163978298), 'nauc_ndcg_at_1_diff1': np.float64(0.4033369499664993), 'nauc_ndcg_at_3_max': np.float64(0.21933385751984275), 'nauc_ndcg_at_3_std': np.float64(-0.09785653718888704), 'nauc_ndcg_at_3_diff1': np.float64(0.30540317541255185), 'nauc_ndcg_at_5_max': np.float64(0.21300270312838201), 'nauc_ndcg_at_5_std': np.float64(-0.10367682596724503), 'nauc_ndcg_at_5_diff1': np.float64(0.290223062445283), 'nauc_ndcg_at_10_max': np.float64(0.2204802656578329), 'nauc_ndcg_at_10_std': np.float64(-0.08315669038036567), 'nauc_ndcg_at_10_diff1': np.float64(0.2790712927892886), 'nauc_ndcg_at_20_max': np.float64(0.24675490880933862), 'nauc_ndcg_at_20_std': np.float64(-0.05094524679791449), 'nauc_ndcg_at_20_diff1': np.float64(0.2819270065380131), 'nauc_ndcg_at_100_max': np.float64(0.26548313571452103), 'nauc_ndcg_at_100_std': np.float64(-0.0108705083479695), 'nauc_ndcg_at_100_diff1': np.float64(0.27255428931827663), 'nauc_ndcg_at_1000_max': np.float64(0.24343637324499834), 'nauc_ndcg_at_1000_std': np.float64(-0.03778578389881893), 'nauc_ndcg_at_1000_diff1': np.float64(0.2856912372073617), 'nauc_map_at_1_max': np.float64(0.250405206326011), 'nauc_map_at_1_std': np.float64(-0.13520336912467026), 'nauc_map_at_1_diff1': np.float64(0.42383841325418287), 'nauc_map_at_3_max': np.float64(0.22854232581291226), 'nauc_map_at_3_std': np.float64(-0.10839033935341609), 'nauc_map_at_3_diff1': np.float64(0.3308851492829308), 'nauc_map_at_5_max': np.float64(0.2243829020636881), 'nauc_map_at_5_std': np.float64(-0.11013395271043995), 'nauc_map_at_5_diff1': np.float64(0.31457141895678165), 'nauc_map_at_10_max': np.float64(0.22596714633779053), 'nauc_map_at_10_std': np.float64(-0.10241596640938393), 'nauc_map_at_10_diff1': np.float64(0.3056511815165923), 'nauc_map_at_20_max': np.float64(0.23641728576352428), 'nauc_map_at_20_std': np.float64(-0.09051814637606816), 'nauc_map_at_20_diff1': np.float64(0.3057776643050341), 'nauc_map_at_100_max': np.float64(0.2411990978102096), 'nauc_map_at_100_std': np.float64(-0.08083442033052267), 'nauc_map_at_100_diff1': np.float64(0.3048963862309639), 'nauc_map_at_1000_max': np.float64(0.24034668937261533), 'nauc_map_at_1000_std': np.float64(-0.08103095861141758), 'nauc_map_at_1000_diff1': np.float64(0.3053993428396351), 'nauc_recall_at_1_max': np.float64(0.250405206326011), 'nauc_recall_at_1_std': np.float64(-0.13520336912467026), 'nauc_recall_at_1_diff1': np.float64(0.42383841325418287), 'nauc_recall_at_3_max': np.float64(0.19120399927021967), 'nauc_recall_at_3_std': np.float64(-0.08494071412694883), 'nauc_recall_at_3_diff1': np.float64(0.24753555717964568), 'nauc_recall_at_5_max': np.float64(0.18119340444328566), 'nauc_recall_at_5_std': np.float64(-0.09814578598765797), 'nauc_recall_at_5_diff1': np.float64(0.21679989815496223), 'nauc_recall_at_10_max': np.float64(0.19458983448728884), 'nauc_recall_at_10_std': np.float64(-0.051337513468547806), 'nauc_recall_at_10_diff1': np.float64(0.1946626084556666), 'nauc_recall_at_20_max': np.float64(0.2629741535771735), 'nauc_recall_at_20_std': np.float64(0.034103975248139094), 'nauc_recall_at_20_diff1': np.float64(0.20122402738932615), 'nauc_recall_at_100_max': np.float64(0.31793376334708096), 'nauc_recall_at_100_std': np.float64(0.17142940080470698), 'nauc_recall_at_100_diff1': np.float64(0.1418479527830795), 'nauc_recall_at_1000_max': np.float64(0.8156349912513978), 'nauc_recall_at_1000_std': np.float64(0.7555715146667914), 'nauc_recall_at_1000_diff1': np.float64(0.5758326388163159), 'nauc_precision_at_1_max': np.float64(0.25281952813321773), 'nauc_precision_at_1_std': np.float64(-0.10322278163978298), 'nauc_precision_at_1_diff1': np.float64(0.4033369499664993), 'nauc_precision_at_3_max': np.float64(0.21076596647953377), 'nauc_precision_at_3_std': np.float64(-0.06626938359139384), 'nauc_precision_at_3_diff1': np.float64(0.24438827121376572), 'nauc_precision_at_5_max': np.float64(0.18749098508944212), 'nauc_precision_at_5_std': np.float64(-0.07188348358340925), 'nauc_precision_at_5_diff1': np.float64(0.20700221690766976), 'nauc_precision_at_10_max': np.float64(0.19742365753024946), 'nauc_precision_at_10_std': np.float64(-0.022400643864277075), 'nauc_precision_at_10_diff1': np.float64(0.18029298355404208), 'nauc_precision_at_20_max': np.float64(0.23367065227326117), 'nauc_precision_at_20_std': np.float64(0.04838154362383047), 'nauc_precision_at_20_diff1': np.float64(0.17529097352342055), 'nauc_precision_at_100_max': np.float64(0.2321220026260983), 'nauc_precision_at_100_std': np.float64(0.17556095540343836), 'nauc_precision_at_100_diff1': np.float64(0.09759601754061357), 'nauc_precision_at_1000_max': np.float64(0.027010048687200763), 'nauc_precision_at_1000_std': np.float64(0.09102651003545263), 'nauc_precision_at_1000_diff1': np.float64(0.02383291229758173), 'nauc_mrr_at_1_max': np.float64(0.25281952813321773), 'nauc_mrr_at_1_std': np.float64(-0.10322278163978298), 'nauc_mrr_at_1_diff1': np.float64(0.4033369499664993), 'nauc_mrr_at_3_max': np.float64(0.21802898074597535), 'nauc_mrr_at_3_std': np.float64(-0.09401658878276505), 'nauc_mrr_at_3_diff1': np.float64(0.33432675213642143), 'nauc_mrr_at_5_max': np.float64(0.21379879473947802), 'nauc_mrr_at_5_std': np.float64(-0.0973603558544661), 'nauc_mrr_at_5_diff1': np.float64(0.32493806494580013), 'nauc_mrr_at_10_max': np.float64(0.21793245435659803), 'nauc_mrr_at_10_std': np.float64(-0.08581891602926649), 'nauc_mrr_at_10_diff1': np.float64(0.3211188752395298), 'nauc_mrr_at_20_max': np.float64(0.22223458229129398), 'nauc_mrr_at_20_std': np.float64(-0.08017294983521339), 'nauc_mrr_at_20_diff1': np.float64(0.321898666753148), 'nauc_mrr_at_100_max': np.float64(0.22369995452649225), 'nauc_mrr_at_100_std': np.float64(-0.07748369418742751), 'nauc_mrr_at_100_diff1': np.float64(0.3219582233771657), 'nauc_mrr_at_1000_max': np.float64(0.22325973425552859), 'nauc_mrr_at_1000_std': np.float64(-0.07847633642276278), 'nauc_mrr_at_1000_diff1': np.float64(0.32231518240884127), 'main_score': 0.20148}, 'kor-eng': {'ndcg_at_1': 0.21824, 'ndcg_at_3': 0.23881, 'ndcg_at_5': 0.26406, 'ndcg_at_10': 0.29263, 'ndcg_at_20': 0.31466, 'ndcg_at_100': 0.3642, 'ndcg_at_1000': 0.40446, 'map_at_1': 0.14722, 'map_at_3': 0.2117, 'map_at_5': 0.23153, 'map_at_10': 0.24572, 'map_at_20': 0.25264, 'map_at_100': 0.26066, 'map_at_1000': 0.26234, 'recall_at_1': 0.14722, 'recall_at_3': 0.24872, 'recall_at_5': 0.31177, 'recall_at_10': 0.39091, 'recall_at_20': 0.466, 'recall_at_100': 0.70168, 'recall_at_1000': 1.0, 'precision_at_1': 0.21824, 'precision_at_3': 0.14224, 'precision_at_5': 0.10749, 'precision_at_10': 0.06759, 'precision_at_20': 0.04072, 'precision_at_100': 0.01236, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.2182410423452769, 'mrr_at_3': 0.26112920738327916, 'mrr_at_5': 0.2736699239956569, 'mrr_at_10': 0.28444625407166113, 'mrr_at_20': 0.29012220278021594, 'mrr_at_100': 0.2950058054967865, 'mrr_at_1000': 0.29603960067252577, 'nauc_ndcg_at_1_max': np.float64(0.23916999910934264), 'nauc_ndcg_at_1_std': np.float64(-0.08078870533756279), 'nauc_ndcg_at_1_diff1': np.float64(0.4446874864765066), 'nauc_ndcg_at_3_max': np.float64(0.19204739459298753), 'nauc_ndcg_at_3_std': np.float64(-0.09359252897467076), 'nauc_ndcg_at_3_diff1': np.float64(0.38377007939763225), 'nauc_ndcg_at_5_max': np.float64(0.17921601582787194), 'nauc_ndcg_at_5_std': np.float64(-0.1014947108412644), 'nauc_ndcg_at_5_diff1': np.float64(0.3557709083054129), 'nauc_ndcg_at_10_max': np.float64(0.1598603925312353), 'nauc_ndcg_at_10_std': np.float64(-0.10739253057810857), 'nauc_ndcg_at_10_diff1': np.float64(0.34342650182736895), 'nauc_ndcg_at_20_max': np.float64(0.15180270912134258), 'nauc_ndcg_at_20_std': np.float64(-0.10958156492422332), 'nauc_ndcg_at_20_diff1': np.float64(0.3305328263689251), 'nauc_ndcg_at_100_max': np.float64(0.17965260524403515), 'nauc_ndcg_at_100_std': np.float64(-0.08122491724474822), 'nauc_ndcg_at_100_diff1': np.float64(0.339562875175407), 'nauc_ndcg_at_1000_max': np.float64(0.1808133327895995), 'nauc_ndcg_at_1000_std': np.float64(-0.08996555894747191), 'nauc_ndcg_at_1000_diff1': np.float64(0.35142457690462753), 'nauc_map_at_1_max': np.float64(0.24529236270282476), 'nauc_map_at_1_std': np.float64(-0.004688212359841111), 'nauc_map_at_1_diff1': np.float64(0.5070734238811194), 'nauc_map_at_3_max': np.float64(0.20104012126833412), 'nauc_map_at_3_std': np.float64(-0.07628803518006758), 'nauc_map_at_3_diff1': np.float64(0.40295825342965635), 'nauc_map_at_5_max': np.float64(0.19077273609554368), 'nauc_map_at_5_std': np.float64(-0.08499496025998478), 'nauc_map_at_5_diff1': np.float64(0.37612971547715945), 'nauc_map_at_10_max': np.float64(0.17822484528135826), 'nauc_map_at_10_std': np.float64(-0.09279843246339788), 'nauc_map_at_10_diff1': np.float64(0.3658732019343366), 'nauc_map_at_20_max': np.float64(0.17525189915636535), 'nauc_map_at_20_std': np.float64(-0.09435244487831614), 'nauc_map_at_20_diff1': np.float64(0.36207907758581914), 'nauc_map_at_100_max': np.float64(0.17991408619536303), 'nauc_map_at_100_std': np.float64(-0.08982435805402057), 'nauc_map_at_100_diff1': np.float64(0.3630158708686401), 'nauc_map_at_1000_max': np.float64(0.18010848096070384), 'nauc_map_at_1000_std': np.float64(-0.08999936954639572), 'nauc_map_at_1000_diff1': np.float64(0.36364650458349357), 'nauc_recall_at_1_max': np.float64(0.24529236270282476), 'nauc_recall_at_1_std': np.float64(-0.004688212359841111), 'nauc_recall_at_1_diff1': np.float64(0.5070734238811194), 'nauc_recall_at_3_max': np.float64(0.1744699445576355), 'nauc_recall_at_3_std': np.float64(-0.08642018776428495), 'nauc_recall_at_3_diff1': np.float64(0.35395455611773263), 'nauc_recall_at_5_max': np.float64(0.1343446345451416), 'nauc_recall_at_5_std': np.float64(-0.11348758147177891), 'nauc_recall_at_5_diff1': np.float64(0.2927550794400118), 'nauc_recall_at_10_max': np.float64(0.09287986292947803), 'nauc_recall_at_10_std': np.float64(-0.11951474652894345), 'nauc_recall_at_10_diff1': np.float64(0.2634681061506411), 'nauc_recall_at_20_max': np.float64(0.06392647995897967), 'nauc_recall_at_20_std': np.float64(-0.12668293400209021), 'nauc_recall_at_20_diff1': np.float64(0.2156825749351031), 'nauc_recall_at_100_max': np.float64(0.1641127988377667), 'nauc_recall_at_100_std': np.float64(0.0010560715079287173), 'nauc_recall_at_100_diff1': np.float64(0.23543072434985665), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.23916999910934264), 'nauc_precision_at_1_std': np.float64(-0.08078870533756279), 'nauc_precision_at_1_diff1': np.float64(0.4446874864765066), 'nauc_precision_at_3_max': np.float64(0.1352735356527621), 'nauc_precision_at_3_std': np.float64(-0.1604897997884064), 'nauc_precision_at_3_diff1': np.float64(0.2205084203050175), 'nauc_precision_at_5_max': np.float64(0.1003284578634536), 'nauc_precision_at_5_std': np.float64(-0.16309786348639163), 'nauc_precision_at_5_diff1': np.float64(0.15387150754118664), 'nauc_precision_at_10_max': np.float64(0.05442432624317679), 'nauc_precision_at_10_std': np.float64(-0.17842192575142593), 'nauc_precision_at_10_diff1': np.float64(0.13223329223196534), 'nauc_precision_at_20_max': np.float64(0.031054840058235694), 'nauc_precision_at_20_std': np.float64(-0.16778270792399078), 'nauc_precision_at_20_diff1': np.float64(0.09794018553176256), 'nauc_precision_at_100_max': np.float64(0.11877558098393813), 'nauc_precision_at_100_std': np.float64(-0.016417726786710003), 'nauc_precision_at_100_diff1': np.float64(0.0617682685125337), 'nauc_precision_at_1000_max': np.float64(0.08759636628632125), 'nauc_precision_at_1000_std': np.float64(-0.014889287290916334), 'nauc_precision_at_1000_diff1': np.float64(0.006633055518163547), 'nauc_mrr_at_1_max': np.float64(0.23916999910934264), 'nauc_mrr_at_1_std': np.float64(-0.08078870533756279), 'nauc_mrr_at_1_diff1': np.float64(0.4446874864765066), 'nauc_mrr_at_3_max': np.float64(0.21086282986637608), 'nauc_mrr_at_3_std': np.float64(-0.1023624177806897), 'nauc_mrr_at_3_diff1': np.float64(0.3904534717117424), 'nauc_mrr_at_5_max': np.float64(0.20353606462281326), 'nauc_mrr_at_5_std': np.float64(-0.10743586414085929), 'nauc_mrr_at_5_diff1': np.float64(0.38401972122916894), 'nauc_mrr_at_10_max': np.float64(0.19735653109654772), 'nauc_mrr_at_10_std': np.float64(-0.10730444084305658), 'nauc_mrr_at_10_diff1': np.float64(0.3816613970826813), 'nauc_mrr_at_20_max': np.float64(0.19652148095626984), 'nauc_mrr_at_20_std': np.float64(-0.10637111649893567), 'nauc_mrr_at_20_diff1': np.float64(0.3780889847315601), 'nauc_mrr_at_100_max': np.float64(0.198955548447567), 'nauc_mrr_at_100_std': np.float64(-0.10425957675034127), 'nauc_mrr_at_100_diff1': np.float64(0.3796023359961304), 'nauc_mrr_at_1000_max': np.float64(0.19890005186529072), 'nauc_mrr_at_1000_std': np.float64(-0.10452812470196678), 'nauc_mrr_at_1000_diff1': np.float64(0.37987811084483714), 'main_score': 0.29263}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 18.36it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:11,  5.95s/it]Batches:  15%|█▌        | 2/13 [00:09<00:47,  4.34s/it]Batches:  23%|██▎       | 3/13 [00:12<00:38,  3.84s/it]Batches:  31%|███       | 4/13 [00:15<00:32,  3.60s/it]Batches:  38%|███▊      | 5/13 [00:18<00:27,  3.47s/it]Batches:  46%|████▌     | 6/13 [00:22<00:23,  3.39s/it]Batches:  54%|█████▍    | 7/13 [00:25<00:20,  3.34s/it]Batches:  62%|██████▏   | 8/13 [00:28<00:16,  3.32s/it]Batches:  69%|██████▉   | 9/13 [00:31<00:13,  3.30s/it]Batches:  77%|███████▋  | 10/13 [00:35<00:09,  3.29s/it]Batches:  85%|████████▍ | 11/13 [00:38<00:06,  3.29s/it]Batches:  92%|█████████▏| 12/13 [00:41<00:03,  3.29s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.28s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.46s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 50.25 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 50.52 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.16, 'ndcg_at_3': 0.20155, 'ndcg_at_5': 0.22155, 'ndcg_at_10': 0.23766, 'ndcg_at_20': 0.24761, 'ndcg_at_100': 0.2765, 'ndcg_at_1000': 0.30876, 'map_at_1': 0.16, 'map_at_3': 0.19167, 'map_at_5': 0.20242, 'map_at_10': 0.20903, 'map_at_20': 0.21168, 'map_at_100': 0.21578, 'map_at_1000': 0.21688, 'recall_at_1': 0.16, 'recall_at_3': 0.23, 'recall_at_5': 0.28, 'recall_at_10': 0.33, 'recall_at_20': 0.37, 'recall_at_100': 0.525, 'recall_at_1000': 0.785, 'precision_at_1': 0.16, 'precision_at_3': 0.07667, 'precision_at_5': 0.056, 'precision_at_10': 0.033, 'precision_at_20': 0.0185, 'precision_at_100': 0.00525, 'precision_at_1000': 0.00079, 'mrr_at_1': 0.16, 'mrr_at_3': 0.19166666666666668, 'mrr_at_5': 0.20241666666666663, 'mrr_at_10': 0.20903174603174604, 'mrr_at_20': 0.21167943861693864, 'mrr_at_100': 0.215783785522135, 'mrr_at_1000': 0.21687962377974843, 'nauc_ndcg_at_1_max': np.float64(0.5224592871408816), 'nauc_ndcg_at_1_std': np.float64(0.11363112613304648), 'nauc_ndcg_at_1_diff1': np.float64(0.4773870794284836), 'nauc_ndcg_at_3_max': np.float64(0.47536644100741793), 'nauc_ndcg_at_3_std': np.float64(0.10162267713534295), 'nauc_ndcg_at_3_diff1': np.float64(0.42527666873945985), 'nauc_ndcg_at_5_max': np.float64(0.4675405208954469), 'nauc_ndcg_at_5_std': np.float64(0.10930382183498212), 'nauc_ndcg_at_5_diff1': np.float64(0.41059087810133726), 'nauc_ndcg_at_10_max': np.float64(0.43004170234676586), 'nauc_ndcg_at_10_std': np.float64(0.09353667167876474), 'nauc_ndcg_at_10_diff1': np.float64(0.37899637323724716), 'nauc_ndcg_at_20_max': np.float64(0.4274639301201697), 'nauc_ndcg_at_20_std': np.float64(0.10651189016151837), 'nauc_ndcg_at_20_diff1': np.float64(0.36734478358022304), 'nauc_ndcg_at_100_max': np.float64(0.4188747272395376), 'nauc_ndcg_at_100_std': np.float64(0.14084513620696146), 'nauc_ndcg_at_100_diff1': np.float64(0.3582291264246711), 'nauc_ndcg_at_1000_max': np.float64(0.4257915864027082), 'nauc_ndcg_at_1000_std': np.float64(0.15119068433043165), 'nauc_ndcg_at_1000_diff1': np.float64(0.35763026815785454), 'nauc_map_at_1_max': np.float64(0.5224592871408816), 'nauc_map_at_1_std': np.float64(0.11363112613304648), 'nauc_map_at_1_diff1': np.float64(0.4773870794284836), 'nauc_map_at_3_max': np.float64(0.48414054809763624), 'nauc_map_at_3_std': np.float64(0.10250367348103344), 'nauc_map_at_3_diff1': np.float64(0.4344793643094571), 'nauc_map_at_5_max': np.float64(0.4792715776070097), 'nauc_map_at_5_std': np.float64(0.10650287220411736), 'nauc_map_at_5_diff1': np.float64(0.42545269261198565), 'nauc_map_at_10_max': np.float64(0.46241285085930794), 'nauc_map_at_10_std': np.float64(0.09961547366420115), 'nauc_map_at_10_diff1': np.float64(0.4111243025689681), 'nauc_map_at_20_max': np.float64(0.46179111942523543), 'nauc_map_at_20_std': np.float64(0.10283069379805279), 'nauc_map_at_20_diff1': np.float64(0.40796056090406), 'nauc_map_at_100_max': np.float64(0.4593519956984368), 'nauc_map_at_100_std': np.float64(0.10843762042187415), 'nauc_map_at_100_diff1': np.float64(0.4057775934260692), 'nauc_map_at_1000_max': np.float64(0.4597192623308266), 'nauc_map_at_1000_std': np.float64(0.1088878465165411), 'nauc_map_at_1000_diff1': np.float64(0.40565279518187525), 'nauc_recall_at_1_max': np.float64(0.5224592871408816), 'nauc_recall_at_1_std': np.float64(0.11363112613304648), 'nauc_recall_at_1_diff1': np.float64(0.4773870794284836), 'nauc_recall_at_3_max': np.float64(0.45330303076524137), 'nauc_recall_at_3_std': np.float64(0.0999832217324324), 'nauc_recall_at_3_diff1': np.float64(0.40235048275651664), 'nauc_recall_at_5_max': np.float64(0.4389421196714899), 'nauc_recall_at_5_std': np.float64(0.11802335325995847), 'nauc_recall_at_5_diff1': np.float64(0.3740083244874014), 'nauc_recall_at_10_max': np.float64(0.34313216439669286), 'nauc_recall_at_10_std': np.float64(0.0761339883638881), 'nauc_recall_at_10_diff1': np.float64(0.2942378612986113), 'nauc_recall_at_20_max': np.float64(0.33514409955731994), 'nauc_recall_at_20_std': np.float64(0.12291228665822235), 'nauc_recall_at_20_diff1': np.float64(0.25535068360777774), 'nauc_recall_at_100_max': np.float64(0.304912316685468), 'nauc_recall_at_100_std': np.float64(0.2800601647694252), 'nauc_recall_at_100_diff1': np.float64(0.21876730591734192), 'nauc_recall_at_1000_max': np.float64(0.2966206725605223), 'nauc_recall_at_1000_std': np.float64(0.48898148038856976), 'nauc_recall_at_1000_diff1': np.float64(0.12434933487565095), 'nauc_precision_at_1_max': np.float64(0.5224592871408816), 'nauc_precision_at_1_std': np.float64(0.11363112613304648), 'nauc_precision_at_1_diff1': np.float64(0.4773870794284836), 'nauc_precision_at_3_max': np.float64(0.45330303076524175), 'nauc_precision_at_3_std': np.float64(0.09998322173243263), 'nauc_precision_at_3_diff1': np.float64(0.4023504827565167), 'nauc_precision_at_5_max': np.float64(0.4389421196714906), 'nauc_precision_at_5_std': np.float64(0.11802335325995887), 'nauc_precision_at_5_diff1': np.float64(0.3740083244874019), 'nauc_precision_at_10_max': np.float64(0.3431321643966932), 'nauc_precision_at_10_std': np.float64(0.07613398836388804), 'nauc_precision_at_10_diff1': np.float64(0.29423786129861146), 'nauc_precision_at_20_max': np.float64(0.33514409955732005), 'nauc_precision_at_20_std': np.float64(0.12291228665822236), 'nauc_precision_at_20_diff1': np.float64(0.25535068360777796), 'nauc_precision_at_100_max': np.float64(0.3049123166854683), 'nauc_precision_at_100_std': np.float64(0.2800601647694252), 'nauc_precision_at_100_diff1': np.float64(0.2187673059173419), 'nauc_precision_at_1000_max': np.float64(0.296620672560522), 'nauc_precision_at_1000_std': np.float64(0.48898148038856926), 'nauc_precision_at_1000_diff1': np.float64(0.12434933487565131), 'nauc_mrr_at_1_max': np.float64(0.5224592871408816), 'nauc_mrr_at_1_std': np.float64(0.11363112613304648), 'nauc_mrr_at_1_diff1': np.float64(0.4773870794284836), 'nauc_mrr_at_3_max': np.float64(0.48414054809763624), 'nauc_mrr_at_3_std': np.float64(0.10250367348103344), 'nauc_mrr_at_3_diff1': np.float64(0.4344793643094571), 'nauc_mrr_at_5_max': np.float64(0.4792715776070097), 'nauc_mrr_at_5_std': np.float64(0.10650287220411736), 'nauc_mrr_at_5_diff1': np.float64(0.42545269261198565), 'nauc_mrr_at_10_max': np.float64(0.46241285085930794), 'nauc_mrr_at_10_std': np.float64(0.09961547366420115), 'nauc_mrr_at_10_diff1': np.float64(0.4111243025689681), 'nauc_mrr_at_20_max': np.float64(0.46179111942523543), 'nauc_mrr_at_20_std': np.float64(0.10283069379805279), 'nauc_mrr_at_20_diff1': np.float64(0.40796056090406), 'nauc_mrr_at_100_max': np.float64(0.4593519956984368), 'nauc_mrr_at_100_std': np.float64(0.10843762042187415), 'nauc_mrr_at_100_diff1': np.float64(0.4057775934260692), 'nauc_mrr_at_1000_max': np.float64(0.4597192623308266), 'nauc_mrr_at_1000_std': np.float64(0.1088878465165411), 'nauc_mrr_at_1000_diff1': np.float64(0.40565279518187525), 'main_score': 0.23766}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:10,  5.91s/it]Batches:  15%|█▌        | 2/13 [00:09<00:47,  4.35s/it]Batches:  23%|██▎       | 3/13 [00:12<00:38,  3.86s/it]Batches:  31%|███       | 4/13 [00:15<00:32,  3.63s/it]Batches:  38%|███▊      | 5/13 [00:18<00:28,  3.50s/it]Batches:  46%|████▌     | 6/13 [00:22<00:23,  3.43s/it]Batches:  54%|█████▍    | 7/13 [00:25<00:20,  3.38s/it]Batches:  62%|██████▏   | 8/13 [00:28<00:16,  3.36s/it]Batches:  69%|██████▉   | 9/13 [00:32<00:13,  3.34s/it]Batches:  77%|███████▋  | 10/13 [00:35<00:09,  3.33s/it]Batches:  85%|████████▍ | 11/13 [00:38<00:06,  3.32s/it]Batches:  92%|█████████▏| 12/13 [00:42<00:03,  3.31s/it]Batches: 100%|██████████| 13/13 [00:45<00:00,  3.30s/it]Batches: 100%|██████████| 13/13 [00:45<00:00,  3.49s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 50.35 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 50.61 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.17, 'ndcg_at_3': 0.20327, 'ndcg_at_5': 0.2136, 'ndcg_at_10': 0.22486, 'ndcg_at_20': 0.24349, 'ndcg_at_100': 0.26791, 'ndcg_at_1000': 0.30737, 'map_at_1': 0.17, 'map_at_3': 0.19417, 'map_at_5': 0.19992, 'map_at_10': 0.20452, 'map_at_20': 0.20945, 'map_at_100': 0.21295, 'map_at_1000': 0.21427, 'recall_at_1': 0.17, 'recall_at_3': 0.23, 'recall_at_5': 0.255, 'recall_at_10': 0.29, 'recall_at_20': 0.365, 'recall_at_100': 0.495, 'recall_at_1000': 0.815, 'precision_at_1': 0.17, 'precision_at_3': 0.07667, 'precision_at_5': 0.051, 'precision_at_10': 0.029, 'precision_at_20': 0.01825, 'precision_at_100': 0.00495, 'precision_at_1000': 0.00082, 'mrr_at_1': 0.17, 'mrr_at_3': 0.19416666666666665, 'mrr_at_5': 0.19991666666666666, 'mrr_at_10': 0.20451984126984127, 'mrr_at_20': 0.20945311712281525, 'mrr_at_100': 0.2129479826793562, 'mrr_at_1000': 0.2142721941179602, 'nauc_ndcg_at_1_max': np.float64(0.5180696382405251), 'nauc_ndcg_at_1_std': np.float64(0.023432772878123738), 'nauc_ndcg_at_1_diff1': np.float64(0.5934927299730468), 'nauc_ndcg_at_3_max': np.float64(0.5281856243842368), 'nauc_ndcg_at_3_std': np.float64(0.08633380109016073), 'nauc_ndcg_at_3_diff1': np.float64(0.5024480480565693), 'nauc_ndcg_at_5_max': np.float64(0.5181217847759284), 'nauc_ndcg_at_5_std': np.float64(0.10348046484708498), 'nauc_ndcg_at_5_diff1': np.float64(0.5002530444688492), 'nauc_ndcg_at_10_max': np.float64(0.5306997041080913), 'nauc_ndcg_at_10_std': np.float64(0.09827948773797913), 'nauc_ndcg_at_10_diff1': np.float64(0.48659095860512674), 'nauc_ndcg_at_20_max': np.float64(0.5166720253899405), 'nauc_ndcg_at_20_std': np.float64(0.11924750957281219), 'nauc_ndcg_at_20_diff1': np.float64(0.4662179168588857), 'nauc_ndcg_at_100_max': np.float64(0.49986715299588624), 'nauc_ndcg_at_100_std': np.float64(0.11573952558693551), 'nauc_ndcg_at_100_diff1': np.float64(0.45761311543315036), 'nauc_ndcg_at_1000_max': np.float64(0.5076348172971382), 'nauc_ndcg_at_1000_std': np.float64(0.13996126632352657), 'nauc_ndcg_at_1000_diff1': np.float64(0.46291688826516936), 'nauc_map_at_1_max': np.float64(0.5180696382405251), 'nauc_map_at_1_std': np.float64(0.023432772878123738), 'nauc_map_at_1_diff1': np.float64(0.5934927299730468), 'nauc_map_at_3_max': np.float64(0.5258851216290541), 'nauc_map_at_3_std': np.float64(0.07157074713282353), 'nauc_map_at_3_diff1': np.float64(0.525610817973501), 'nauc_map_at_5_max': np.float64(0.5200983900181767), 'nauc_map_at_5_std': np.float64(0.08209387595688832), 'nauc_map_at_5_diff1': np.float64(0.524481893074894), 'nauc_map_at_10_max': np.float64(0.5259011127234215), 'nauc_map_at_10_std': np.float64(0.08045608374070097), 'nauc_map_at_10_diff1': np.float64(0.5182162044962908), 'nauc_map_at_20_max': np.float64(0.5210348343486106), 'nauc_map_at_20_std': np.float64(0.08549340137837198), 'nauc_map_at_20_diff1': np.float64(0.5113697633838645), 'nauc_map_at_100_max': np.float64(0.5178971110642436), 'nauc_map_at_100_std': np.float64(0.08419962372042392), 'nauc_map_at_100_diff1': np.float64(0.5089305311988365), 'nauc_map_at_1000_max': np.float64(0.5179525106865259), 'nauc_map_at_1000_std': np.float64(0.0847410446203826), 'nauc_map_at_1000_diff1': np.float64(0.5087580113845908), 'nauc_recall_at_1_max': np.float64(0.5180696382405251), 'nauc_recall_at_1_std': np.float64(0.023432772878123738), 'nauc_recall_at_1_diff1': np.float64(0.5934927299730468), 'nauc_recall_at_3_max': np.float64(0.534204786382148), 'nauc_recall_at_3_std': np.float64(0.12512774362807147), 'nauc_recall_at_3_diff1': np.float64(0.44094812464727506), 'nauc_recall_at_5_max': np.float64(0.5119097093112275), 'nauc_recall_at_5_std': np.float64(0.15933565184423693), 'nauc_recall_at_5_diff1': np.float64(0.43737468740202834), 'nauc_recall_at_10_max': np.float64(0.5445586033542575), 'nauc_recall_at_10_std': np.float64(0.14028954850761638), 'nauc_recall_at_10_diff1': np.float64(0.40477040781286494), 'nauc_recall_at_20_max': np.float64(0.5021434508577074), 'nauc_recall_at_20_std': np.float64(0.21520901100195683), 'nauc_recall_at_20_diff1': np.float64(0.34547846404565713), 'nauc_recall_at_100_max': np.float64(0.43252661891555766), 'nauc_recall_at_100_std': np.float64(0.20916714883315712), 'nauc_recall_at_100_diff1': np.float64(0.3174783690136534), 'nauc_recall_at_1000_max': np.float64(0.49034821596370226), 'nauc_recall_at_1000_std': np.float64(0.628654656750879), 'nauc_recall_at_1000_diff1': np.float64(0.28709694740516095), 'nauc_precision_at_1_max': np.float64(0.5180696382405251), 'nauc_precision_at_1_std': np.float64(0.023432772878123738), 'nauc_precision_at_1_diff1': np.float64(0.5934927299730468), 'nauc_precision_at_3_max': np.float64(0.5342047863821483), 'nauc_precision_at_3_std': np.float64(0.12512774362807152), 'nauc_precision_at_3_diff1': np.float64(0.4409481246472753), 'nauc_precision_at_5_max': np.float64(0.5119097093112275), 'nauc_precision_at_5_std': np.float64(0.15933565184423698), 'nauc_precision_at_5_diff1': np.float64(0.4373746874020287), 'nauc_precision_at_10_max': np.float64(0.5445586033542574), 'nauc_precision_at_10_std': np.float64(0.1402895485076166), 'nauc_precision_at_10_diff1': np.float64(0.40477040781286505), 'nauc_precision_at_20_max': np.float64(0.502143450857708), 'nauc_precision_at_20_std': np.float64(0.21520901100195702), 'nauc_precision_at_20_diff1': np.float64(0.3454784640456575), 'nauc_precision_at_100_max': np.float64(0.4325266189155581), 'nauc_precision_at_100_std': np.float64(0.20916714883315735), 'nauc_precision_at_100_diff1': np.float64(0.3174783690136539), 'nauc_precision_at_1000_max': np.float64(0.4903482159637017), 'nauc_precision_at_1000_std': np.float64(0.6286546567508802), 'nauc_precision_at_1000_diff1': np.float64(0.28709694740515956), 'nauc_mrr_at_1_max': np.float64(0.5180696382405251), 'nauc_mrr_at_1_std': np.float64(0.023432772878123738), 'nauc_mrr_at_1_diff1': np.float64(0.5934927299730468), 'nauc_mrr_at_3_max': np.float64(0.5258851216290541), 'nauc_mrr_at_3_std': np.float64(0.07157074713282353), 'nauc_mrr_at_3_diff1': np.float64(0.525610817973501), 'nauc_mrr_at_5_max': np.float64(0.5200983900181767), 'nauc_mrr_at_5_std': np.float64(0.08209387595688832), 'nauc_mrr_at_5_diff1': np.float64(0.524481893074894), 'nauc_mrr_at_10_max': np.float64(0.5259011127234215), 'nauc_mrr_at_10_std': np.float64(0.08045608374070097), 'nauc_mrr_at_10_diff1': np.float64(0.5182162044962908), 'nauc_mrr_at_20_max': np.float64(0.5210348343486106), 'nauc_mrr_at_20_std': np.float64(0.08549340137837198), 'nauc_mrr_at_20_diff1': np.float64(0.5113697633838645), 'nauc_mrr_at_100_max': np.float64(0.5178971110642436), 'nauc_mrr_at_100_std': np.float64(0.08419962372042392), 'nauc_mrr_at_100_diff1': np.float64(0.5089305311988365), 'nauc_mrr_at_1000_max': np.float64(0.5179525106865259), 'nauc_mrr_at_1000_std': np.float64(0.0847410446203826), 'nauc_mrr_at_1000_diff1': np.float64(0.5087580113845908), 'main_score': 0.22486}}



==================================================
Running model: nlpai-lab/KoE5
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: nlpai-lab/KoE5
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'query': 'query: ', 'passage': 'passage: '}
WARNING:mteb.models.overview:Failed to extract metadata from model: 'SentenceTransformerWrapper' object has no attribute 'model_card_data'. Upgrading to sentence-transformers v3.0.0 or above is recommended.
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / nlpai-lab/KoE5 on GPU 0 in process Process-7
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  1.01it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:06,  2.89it/s]Batches:  11%|█         | 2/19 [00:11<01:52,  6.63s/it]Batches:  16%|█▌        | 3/19 [00:20<02:02,  7.68s/it]Batches:  21%|██        | 4/19 [00:27<01:50,  7.39s/it]Batches:  26%|██▋       | 5/19 [00:33<01:36,  6.92s/it]Batches:  32%|███▏      | 6/19 [00:38<01:23,  6.45s/it]Batches:  37%|███▋      | 7/19 [00:43<01:11,  5.96s/it]Batches:  42%|████▏     | 8/19 [00:48<01:00,  5.54s/it]Batches:  47%|████▋     | 9/19 [00:52<00:51,  5.16s/it]Batches:  53%|█████▎    | 10/19 [00:57<00:43,  4.87s/it]Batches:  58%|█████▊    | 11/19 [01:00<00:35,  4.47s/it]Batches:  63%|██████▎   | 12/19 [01:04<00:29,  4.19s/it]Batches:  68%|██████▊   | 13/19 [01:07<00:23,  3.91s/it]Batches:  74%|███████▎  | 14/19 [01:10<00:18,  3.67s/it]Batches:  79%|███████▉  | 15/19 [01:13<00:13,  3.37s/it]Batches:  84%|████████▍ | 16/19 [01:15<00:09,  3.08s/it]Batches:  89%|████████▉ | 17/19 [01:17<00:05,  2.82s/it]Batches:  95%|█████████▍| 18/19 [01:19<00:02,  2.52s/it]Batches: 100%|██████████| 19/19 [01:21<00:00,  2.22s/it]Batches: 100%|██████████| 19/19 [01:21<00:00,  4.27s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 83.09 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 83.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.76689, 'ndcg_at_3': 0.75702, 'ndcg_at_5': 0.78307, 'ndcg_at_10': 0.80008, 'ndcg_at_20': 0.80834, 'ndcg_at_100': 0.81776, 'ndcg_at_1000': 0.82521, 'map_at_1': 0.50224, 'map_at_3': 0.71805, 'map_at_5': 0.74531, 'map_at_10': 0.75801, 'map_at_20': 0.76174, 'map_at_100': 0.76353, 'map_at_1000': 0.76387, 'recall_at_1': 0.50224, 'recall_at_3': 0.76087, 'recall_at_5': 0.81504, 'recall_at_10': 0.85344, 'recall_at_20': 0.87809, 'recall_at_100': 0.91914, 'recall_at_1000': 0.96585, 'precision_at_1': 0.76689, 'precision_at_3': 0.44707, 'precision_at_5': 0.29527, 'precision_at_10': 0.15777, 'precision_at_20': 0.08209, 'precision_at_100': 0.01733, 'precision_at_1000': 0.00184, 'mrr_at_1': 0.7668918918918919, 'mrr_at_3': 0.8127815315315313, 'mrr_at_5': 0.8163288288288286, 'mrr_at_10': 0.8182526276276274, 'mrr_at_20': 0.8190945409695407, 'mrr_at_100': 0.8198681055223843, 'mrr_at_1000': 0.8200447358419406, 'nauc_ndcg_at_1_max': np.float64(0.6367168927299622), 'nauc_ndcg_at_1_std': np.float64(0.1797255462450732), 'nauc_ndcg_at_1_diff1': np.float64(0.7153536856458215), 'nauc_ndcg_at_3_max': np.float64(0.6193225890761628), 'nauc_ndcg_at_3_std': np.float64(0.16695273529007681), 'nauc_ndcg_at_3_diff1': np.float64(0.6066549910978404), 'nauc_ndcg_at_5_max': np.float64(0.6818212630051793), 'nauc_ndcg_at_5_std': np.float64(0.23294879593797604), 'nauc_ndcg_at_5_diff1': np.float64(0.603741227754187), 'nauc_ndcg_at_10_max': np.float64(0.7093609962144929), 'nauc_ndcg_at_10_std': np.float64(0.2764905074705219), 'nauc_ndcg_at_10_diff1': np.float64(0.6190533858054285), 'nauc_ndcg_at_20_max': np.float64(0.7209179402000162), 'nauc_ndcg_at_20_std': np.float64(0.3030488569549388), 'nauc_ndcg_at_20_diff1': np.float64(0.6320458021594961), 'nauc_ndcg_at_100_max': np.float64(0.7128265191344082), 'nauc_ndcg_at_100_std': np.float64(0.3053516131697575), 'nauc_ndcg_at_100_diff1': np.float64(0.6317275921514075), 'nauc_ndcg_at_1000_max': np.float64(0.7017740521622267), 'nauc_ndcg_at_1000_std': np.float64(0.2871940426224995), 'nauc_ndcg_at_1000_diff1': np.float64(0.633209387968523), 'nauc_map_at_1_max': np.float64(0.29091469612516707), 'nauc_map_at_1_std': np.float64(-0.041544183402294585), 'nauc_map_at_1_diff1': np.float64(0.6407039079056288), 'nauc_map_at_3_max': np.float64(0.5665593954782121), 'nauc_map_at_3_std': np.float64(0.10966603066350789), 'nauc_map_at_3_diff1': np.float64(0.5900738657305518), 'nauc_map_at_5_max': np.float64(0.6176087413110913), 'nauc_map_at_5_std': np.float64(0.16072461952483239), 'nauc_map_at_5_diff1': np.float64(0.5829464965480328), 'nauc_map_at_10_max': np.float64(0.6339909454890105), 'nauc_map_at_10_std': np.float64(0.18617034845772062), 'nauc_map_at_10_diff1': np.float64(0.5923749667778005), 'nauc_map_at_20_max': np.float64(0.6388580471049708), 'nauc_map_at_20_std': np.float64(0.1962525689943241), 'nauc_map_at_20_diff1': np.float64(0.5977171275491291), 'nauc_map_at_100_max': np.float64(0.6372732434536403), 'nauc_map_at_100_std': np.float64(0.1967226339429915), 'nauc_map_at_100_diff1': np.float64(0.5971892993449279), 'nauc_map_at_1000_max': np.float64(0.6368142914602937), 'nauc_map_at_1000_std': np.float64(0.19600667039933853), 'nauc_map_at_1000_diff1': np.float64(0.5972954962902949), 'nauc_recall_at_1_max': np.float64(0.29091469612516707), 'nauc_recall_at_1_std': np.float64(-0.041544183402294585), 'nauc_recall_at_1_diff1': np.float64(0.6407039079056288), 'nauc_recall_at_3_max': np.float64(0.6246426708462954), 'nauc_recall_at_3_std': np.float64(0.17855913256991598), 'nauc_recall_at_3_diff1': np.float64(0.570011423577929), 'nauc_recall_at_5_max': np.float64(0.7484194405605811), 'nauc_recall_at_5_std': np.float64(0.3144622997742575), 'nauc_recall_at_5_diff1': np.float64(0.5487110746355588), 'nauc_recall_at_10_max': np.float64(0.8449272103086174), 'nauc_recall_at_10_std': np.float64(0.45086935495626596), 'nauc_recall_at_10_diff1': np.float64(0.5863070465583734), 'nauc_recall_at_20_max': np.float64(0.9284309177278965), 'nauc_recall_at_20_std': np.float64(0.604534239281333), 'nauc_recall_at_20_diff1': np.float64(0.6463966953750865), 'nauc_recall_at_100_max': np.float64(0.955087527405752), 'nauc_recall_at_100_std': np.float64(0.7621854034955842), 'nauc_recall_at_100_diff1': np.float64(0.6518817183992185), 'nauc_recall_at_1000_max': np.float64(0.9825486195833247), 'nauc_recall_at_1000_std': np.float64(0.8508864855593524), 'nauc_recall_at_1000_diff1': np.float64(0.722229751897174), 'nauc_precision_at_1_max': np.float64(0.6367168927299622), 'nauc_precision_at_1_std': np.float64(0.1797255462450732), 'nauc_precision_at_1_diff1': np.float64(0.7153536856458215), 'nauc_precision_at_3_max': np.float64(0.3727369576620084), 'nauc_precision_at_3_std': np.float64(0.2417544691664725), 'nauc_precision_at_3_diff1': np.float64(-0.0028509166513785832), 'nauc_precision_at_5_max': np.float64(0.3373018586224311), 'nauc_precision_at_5_std': np.float64(0.2866663123426568), 'nauc_precision_at_5_diff1': np.float64(-0.0951242611766236), 'nauc_precision_at_10_max': np.float64(0.28511337244894247), 'nauc_precision_at_10_std': np.float64(0.31819918857431584), 'nauc_precision_at_10_diff1': np.float64(-0.13980158620840913), 'nauc_precision_at_20_max': np.float64(0.24530994646011672), 'nauc_precision_at_20_std': np.float64(0.3275801664626258), 'nauc_precision_at_20_diff1': np.float64(-0.1568592411175028), 'nauc_precision_at_100_max': np.float64(0.14969003532471672), 'nauc_precision_at_100_std': np.float64(0.3054829396918457), 'nauc_precision_at_100_diff1': np.float64(-0.23501168923658147), 'nauc_precision_at_1000_max': np.float64(0.007161073542821553), 'nauc_precision_at_1000_std': np.float64(0.2063019640721369), 'nauc_precision_at_1000_diff1': np.float64(-0.32933520104718034), 'nauc_mrr_at_1_max': np.float64(0.6367168927299622), 'nauc_mrr_at_1_std': np.float64(0.1797255462450732), 'nauc_mrr_at_1_diff1': np.float64(0.7153536856458215), 'nauc_mrr_at_3_max': np.float64(0.7366049198735798), 'nauc_mrr_at_3_std': np.float64(0.2939209122656606), 'nauc_mrr_at_3_diff1': np.float64(0.7108485627220982), 'nauc_mrr_at_5_max': np.float64(0.736934209431478), 'nauc_mrr_at_5_std': np.float64(0.3008189699564541), 'nauc_mrr_at_5_diff1': np.float64(0.7094065640103121), 'nauc_mrr_at_10_max': np.float64(0.7370409336686649), 'nauc_mrr_at_10_std': np.float64(0.30411076208664795), 'nauc_mrr_at_10_diff1': np.float64(0.7091332962479558), 'nauc_mrr_at_20_max': np.float64(0.7357816306698388), 'nauc_mrr_at_20_std': np.float64(0.30487672649515535), 'nauc_mrr_at_20_diff1': np.float64(0.7098668857166636), 'nauc_mrr_at_100_max': np.float64(0.7347853756149684), 'nauc_mrr_at_100_std': np.float64(0.30402465803211526), 'nauc_mrr_at_100_diff1': np.float64(0.7098141357802885), 'nauc_mrr_at_1000_max': np.float64(0.7345190416806782), 'nauc_mrr_at_1000_std': np.float64(0.3035269580763068), 'nauc_mrr_at_1000_diff1': np.float64(0.709824810350201), 'main_score': 0.80008}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.41it/s]Batches: 100%|██████████| 2/2 [00:11<00:00,  6.75s/it]Batches: 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 15.38 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 15.51 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.7193, 'ndcg_at_3': 0.81986, 'ndcg_at_5': 0.83798, 'ndcg_at_10': 0.84339, 'ndcg_at_20': 0.84758, 'ndcg_at_100': 0.85391, 'ndcg_at_1000': 0.85391, 'map_at_1': 0.7193, 'map_at_3': 0.79678, 'map_at_5': 0.80687, 'map_at_10': 0.80894, 'map_at_20': 0.80997, 'map_at_100': 0.81076, 'map_at_1000': 0.81076, 'recall_at_1': 0.7193, 'recall_at_3': 0.88596, 'recall_at_5': 0.92982, 'recall_at_10': 0.94737, 'recall_at_20': 0.96491, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.7193, 'precision_at_3': 0.29532, 'precision_at_5': 0.18596, 'precision_at_10': 0.09474, 'precision_at_20': 0.04825, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7192982456140351, 'mrr_at_3': 0.7967836257309943, 'mrr_at_5': 0.8068713450292399, 'mrr_at_10': 0.8089424951267057, 'mrr_at_20': 0.8099658869395712, 'mrr_at_100': 0.8107636500019111, 'mrr_at_1000': 0.8107636500019111, 'nauc_ndcg_at_1_max': np.float64(-0.1251284973664897), 'nauc_ndcg_at_1_std': np.float64(-0.6485224985983171), 'nauc_ndcg_at_1_diff1': np.float64(0.6674090056378712), 'nauc_ndcg_at_3_max': np.float64(0.020530667149423275), 'nauc_ndcg_at_3_std': np.float64(-0.6630627158068408), 'nauc_ndcg_at_3_diff1': np.float64(0.5919667530188153), 'nauc_ndcg_at_5_max': np.float64(-0.04307026006368585), 'nauc_ndcg_at_5_std': np.float64(-0.7120648723045967), 'nauc_ndcg_at_5_diff1': np.float64(0.6323477601323944), 'nauc_ndcg_at_10_max': np.float64(-0.02291530543046443), 'nauc_ndcg_at_10_std': np.float64(-0.7310258910452394), 'nauc_ndcg_at_10_diff1': np.float64(0.6436986997944144), 'nauc_ndcg_at_20_max': np.float64(-0.02426566036832786), 'nauc_ndcg_at_20_std': np.float64(-0.699937879968727), 'nauc_ndcg_at_20_diff1': np.float64(0.6399616809257035), 'nauc_ndcg_at_100_max': np.float64(-0.04468898576313594), 'nauc_ndcg_at_100_std': np.float64(-0.6952142682019876), 'nauc_ndcg_at_100_diff1': np.float64(0.6334301799598651), 'nauc_ndcg_at_1000_max': np.float64(-0.04468898576313594), 'nauc_ndcg_at_1000_std': np.float64(-0.6952142682019876), 'nauc_ndcg_at_1000_diff1': np.float64(0.6334301799598651), 'nauc_map_at_1_max': np.float64(-0.1251284973664897), 'nauc_map_at_1_std': np.float64(-0.6485224985983171), 'nauc_map_at_1_diff1': np.float64(0.6674090056378712), 'nauc_map_at_3_max': np.float64(-0.02805045628386939), 'nauc_map_at_3_std': np.float64(-0.6626074040597936), 'nauc_map_at_3_diff1': np.float64(0.609689975413944), 'nauc_map_at_5_max': np.float64(-0.05999223752680984), 'nauc_map_at_5_std': np.float64(-0.6860149178877104), 'nauc_map_at_5_diff1': np.float64(0.6296484757032934), 'nauc_map_at_10_max': np.float64(-0.05429473185056241), 'nauc_map_at_10_std': np.float64(-0.6918629844580086), 'nauc_map_at_10_diff1': np.float64(0.633309415089511), 'nauc_map_at_20_max': np.float64(-0.05507130571170382), 'nauc_map_at_20_std': np.float64(-0.6854871094189069), 'nauc_map_at_20_diff1': np.float64(0.6326370926444672), 'nauc_map_at_100_max': np.float64(-0.05701885689693603), 'nauc_map_at_100_std': np.float64(-0.6853683208954745), 'nauc_map_at_100_diff1': np.float64(0.6320942680079616), 'nauc_map_at_1000_max': np.float64(-0.05701885689693603), 'nauc_map_at_1000_std': np.float64(-0.6853683208954745), 'nauc_map_at_1000_diff1': np.float64(0.6320942680079616), 'nauc_recall_at_1_max': np.float64(-0.1251284973664897), 'nauc_recall_at_1_std': np.float64(-0.6485224985983171), 'nauc_recall_at_1_diff1': np.float64(0.6674090056378712), 'nauc_recall_at_3_max': np.float64(0.2518702236748035), 'nauc_recall_at_3_std': np.float64(-0.6623529855929987), 'nauc_recall_at_3_diff1': np.float64(0.5124419476805673), 'nauc_recall_at_5_max': np.float64(0.05647406468664335), 'nauc_recall_at_5_std': np.float64(-0.9091407205206277), 'nauc_recall_at_5_diff1': np.float64(0.6723384771911676), 'nauc_recall_at_10_max': np.float64(0.2755948174983493), 'nauc_recall_at_10_std': np.float64(-1.13859488302729), 'nauc_recall_at_10_diff1': np.float64(0.7836190936419378), 'nauc_recall_at_20_max': np.float64(0.41564985485856165), 'nauc_recall_at_20_std': np.float64(-0.8296243289837761), 'nauc_recall_at_20_diff1': np.float64(0.7867387395585571), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(-0.1251284973664897), 'nauc_precision_at_1_std': np.float64(-0.6485224985983171), 'nauc_precision_at_1_diff1': np.float64(0.6674090056378712), 'nauc_precision_at_3_max': np.float64(0.2518702236748006), 'nauc_precision_at_3_std': np.float64(-0.6623529855930005), 'nauc_precision_at_3_diff1': np.float64(0.5124419476805667), 'nauc_precision_at_5_max': np.float64(0.0564740646866425), 'nauc_precision_at_5_std': np.float64(-0.9091407205206298), 'nauc_precision_at_5_diff1': np.float64(0.6723384771911648), 'nauc_precision_at_10_max': np.float64(0.2755948174983461), 'nauc_precision_at_10_std': np.float64(-1.1385948830272972), 'nauc_precision_at_10_diff1': np.float64(0.7836190936419349), 'nauc_precision_at_20_max': np.float64(0.4156498548585641), 'nauc_precision_at_20_std': np.float64(-0.8296243289837735), 'nauc_precision_at_20_diff1': np.float64(0.7867387395585554), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(-0.1251284973664897), 'nauc_mrr_at_1_std': np.float64(-0.6485224985983171), 'nauc_mrr_at_1_diff1': np.float64(0.6674090056378712), 'nauc_mrr_at_3_max': np.float64(-0.02805045628386939), 'nauc_mrr_at_3_std': np.float64(-0.6626074040597936), 'nauc_mrr_at_3_diff1': np.float64(0.609689975413944), 'nauc_mrr_at_5_max': np.float64(-0.05999223752680984), 'nauc_mrr_at_5_std': np.float64(-0.6860149178877104), 'nauc_mrr_at_5_diff1': np.float64(0.6296484757032934), 'nauc_mrr_at_10_max': np.float64(-0.05429473185056241), 'nauc_mrr_at_10_std': np.float64(-0.6918629844580086), 'nauc_mrr_at_10_diff1': np.float64(0.633309415089511), 'nauc_mrr_at_20_max': np.float64(-0.05507130571170382), 'nauc_mrr_at_20_std': np.float64(-0.6854871094189069), 'nauc_mrr_at_20_diff1': np.float64(0.6326370926444672), 'nauc_mrr_at_100_max': np.float64(-0.05701885689693603), 'nauc_mrr_at_100_std': np.float64(-0.6853683208954745), 'nauc_mrr_at_100_diff1': np.float64(0.6320942680079616), 'nauc_mrr_at_1000_max': np.float64(-0.05701885689693603), 'nauc_mrr_at_1000_std': np.float64(-0.6853683208954745), 'nauc_mrr_at_1000_diff1': np.float64(0.6320942680079616), 'main_score': 0.84339}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.97 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 2.06 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.71429, 'ndcg_at_3': 0.80102, 'ndcg_at_5': 0.82225, 'ndcg_at_10': 0.83507, 'ndcg_at_20': 0.83507, 'ndcg_at_100': 0.84618, 'ndcg_at_1000': 0.84618, 'map_at_1': 0.71429, 'map_at_3': 0.78139, 'map_at_5': 0.79307, 'map_at_10': 0.79848, 'map_at_20': 0.79848, 'map_at_100': 0.8006, 'map_at_1000': 0.8006, 'recall_at_1': 0.71429, 'recall_at_3': 0.85714, 'recall_at_5': 0.90909, 'recall_at_10': 0.94805, 'recall_at_20': 0.94805, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.71429, 'precision_at_3': 0.28571, 'precision_at_5': 0.18182, 'precision_at_10': 0.09481, 'precision_at_20': 0.0474, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7142857142857143, 'mrr_at_3': 0.7813852813852814, 'mrr_at_5': 0.7930735930735933, 'mrr_at_10': 0.7984848484848486, 'mrr_at_20': 0.7984848484848486, 'mrr_at_100': 0.8005995952099849, 'mrr_at_1000': 0.8005995952099849, 'nauc_ndcg_at_1_max': np.float64(0.32284171451891813), 'nauc_ndcg_at_1_std': np.float64(-0.20882769514998567), 'nauc_ndcg_at_1_diff1': np.float64(0.7577173196038672), 'nauc_ndcg_at_3_max': np.float64(0.35797191104736537), 'nauc_ndcg_at_3_std': np.float64(-0.3364824459168836), 'nauc_ndcg_at_3_diff1': np.float64(0.8231850214230185), 'nauc_ndcg_at_5_max': np.float64(0.32315494694121266), 'nauc_ndcg_at_5_std': np.float64(-0.33328124665004133), 'nauc_ndcg_at_5_diff1': np.float64(0.8030605288101285), 'nauc_ndcg_at_10_max': np.float64(0.3256076661295447), 'nauc_ndcg_at_10_std': np.float64(-0.2817943860852995), 'nauc_ndcg_at_10_diff1': np.float64(0.8035444610764061), 'nauc_ndcg_at_20_max': np.float64(0.3256076661295447), 'nauc_ndcg_at_20_std': np.float64(-0.2817943860852995), 'nauc_ndcg_at_20_diff1': np.float64(0.8035444610764061), 'nauc_ndcg_at_100_max': np.float64(0.33379727067161213), 'nauc_ndcg_at_100_std': np.float64(-0.2862451635342314), 'nauc_ndcg_at_100_diff1': np.float64(0.7956021251421836), 'nauc_ndcg_at_1000_max': np.float64(0.33379727067161213), 'nauc_ndcg_at_1000_std': np.float64(-0.2862451635342314), 'nauc_ndcg_at_1000_diff1': np.float64(0.7956021251421836), 'nauc_map_at_1_max': np.float64(0.32284171451891813), 'nauc_map_at_1_std': np.float64(-0.20882769514998567), 'nauc_map_at_1_diff1': np.float64(0.7577173196038672), 'nauc_map_at_3_max': np.float64(0.3491022360132139), 'nauc_map_at_3_std': np.float64(-0.29770470107793134), 'nauc_map_at_3_diff1': np.float64(0.8036211706145331), 'nauc_map_at_5_max': np.float64(0.3310666097797035), 'nauc_map_at_5_std': np.float64(-0.2977794052487303), 'nauc_map_at_5_diff1': np.float64(0.792365609522334), 'nauc_map_at_10_max': np.float64(0.3330035751571369), 'nauc_map_at_10_std': np.float64(-0.27943277460446947), 'nauc_map_at_10_diff1': np.float64(0.7926589773096495), 'nauc_map_at_20_max': np.float64(0.3330035751571369), 'nauc_map_at_20_std': np.float64(-0.27943277460446947), 'nauc_map_at_20_diff1': np.float64(0.7926589773096495), 'nauc_map_at_100_max': np.float64(0.3344967478481731), 'nauc_map_at_100_std': np.float64(-0.27987464893738734), 'nauc_map_at_100_diff1': np.float64(0.7913266849850282), 'nauc_map_at_1000_max': np.float64(0.3344967478481731), 'nauc_map_at_1000_std': np.float64(-0.27987464893738734), 'nauc_map_at_1000_diff1': np.float64(0.7913266849850282), 'nauc_recall_at_1_max': np.float64(0.32284171451891813), 'nauc_recall_at_1_std': np.float64(-0.20882769514998567), 'nauc_recall_at_1_diff1': np.float64(0.7577173196038672), 'nauc_recall_at_3_max': np.float64(0.3934861268650947), 'nauc_recall_at_3_std': np.float64(-0.49640966403608566), 'nauc_recall_at_3_diff1': np.float64(0.903678984880319), 'nauc_recall_at_5_max': np.float64(0.26660306298949915), 'nauc_recall_at_5_std': np.float64(-0.5325711292896324), 'nauc_recall_at_5_diff1': np.float64(0.8613853520214378), 'nauc_recall_at_10_max': np.float64(0.2307775161706363), 'nauc_recall_at_10_std': np.float64(-0.2191420978072253), 'nauc_recall_at_10_diff1': np.float64(0.9015345268542205), 'nauc_recall_at_20_max': np.float64(0.2307775161706363), 'nauc_recall_at_20_std': np.float64(-0.2191420978072253), 'nauc_recall_at_20_diff1': np.float64(0.9015345268542205), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.32284171451891813), 'nauc_precision_at_1_std': np.float64(-0.20882769514998567), 'nauc_precision_at_1_diff1': np.float64(0.7577173196038672), 'nauc_precision_at_3_max': np.float64(0.3934861268650965), 'nauc_precision_at_3_std': np.float64(-0.4964096640360838), 'nauc_precision_at_3_diff1': np.float64(0.9036789848803191), 'nauc_precision_at_5_max': np.float64(0.2666030629895003), 'nauc_precision_at_5_std': np.float64(-0.5325711292896321), 'nauc_precision_at_5_diff1': np.float64(0.8613853520214367), 'nauc_precision_at_10_max': np.float64(0.23077751617064066), 'nauc_precision_at_10_std': np.float64(-0.21914209780721652), 'nauc_precision_at_10_diff1': np.float64(0.9015345268542192), 'nauc_precision_at_20_max': np.float64(0.23077751617064066), 'nauc_precision_at_20_std': np.float64(-0.21914209780721652), 'nauc_precision_at_20_diff1': np.float64(0.9015345268542192), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.32284171451891813), 'nauc_mrr_at_1_std': np.float64(-0.20882769514998567), 'nauc_mrr_at_1_diff1': np.float64(0.7577173196038672), 'nauc_mrr_at_3_max': np.float64(0.3491022360132139), 'nauc_mrr_at_3_std': np.float64(-0.29770470107793134), 'nauc_mrr_at_3_diff1': np.float64(0.8036211706145331), 'nauc_mrr_at_5_max': np.float64(0.3310666097797035), 'nauc_mrr_at_5_std': np.float64(-0.2977794052487303), 'nauc_mrr_at_5_diff1': np.float64(0.792365609522334), 'nauc_mrr_at_10_max': np.float64(0.3330035751571369), 'nauc_mrr_at_10_std': np.float64(-0.27943277460446947), 'nauc_mrr_at_10_diff1': np.float64(0.7926589773096495), 'nauc_mrr_at_20_max': np.float64(0.3330035751571369), 'nauc_mrr_at_20_std': np.float64(-0.27943277460446947), 'nauc_mrr_at_20_diff1': np.float64(0.7926589773096495), 'nauc_mrr_at_100_max': np.float64(0.3344967478481731), 'nauc_mrr_at_100_std': np.float64(-0.27987464893738734), 'nauc_mrr_at_100_diff1': np.float64(0.7913266849850282), 'nauc_mrr_at_1000_max': np.float64(0.3344967478481731), 'nauc_mrr_at_1000_std': np.float64(-0.27987464893738734), 'nauc_mrr_at_1000_diff1': np.float64(0.7913266849850282), 'main_score': 0.83507}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.89 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.33it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.33it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.77 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.15it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.10 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 27.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.89333, 'ndcg_at_3': 0.93324, 'ndcg_at_5': 0.93998, 'ndcg_at_10': 0.94251, 'ndcg_at_20': 0.94393, 'ndcg_at_100': 0.94507, 'ndcg_at_1000': 0.94566, 'map_at_1': 0.89333, 'map_at_3': 0.92426, 'map_at_5': 0.92793, 'map_at_10': 0.92898, 'map_at_20': 0.92937, 'map_at_100': 0.9295, 'map_at_1000': 0.92952, 'recall_at_1': 0.89333, 'recall_at_3': 0.95889, 'recall_at_5': 0.97556, 'recall_at_10': 0.98333, 'recall_at_20': 0.98889, 'recall_at_100': 0.99556, 'recall_at_1000': 1.0, 'precision_at_1': 0.89333, 'precision_at_3': 0.31963, 'precision_at_5': 0.19511, 'precision_at_10': 0.09833, 'precision_at_20': 0.04944, 'precision_at_100': 0.00996, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8933333333333333, 'mrr_at_3': 0.9242592592592593, 'mrr_at_5': 0.927925925925926, 'mrr_at_10': 0.9289828042328042, 'mrr_at_20': 0.9293730158730159, 'mrr_at_100': 0.9294972174704905, 'mrr_at_1000': 0.9295225970670912, 'nauc_ndcg_at_1_max': np.float64(0.7792078528281168), 'nauc_ndcg_at_1_std': np.float64(-0.1528791088099168), 'nauc_ndcg_at_1_diff1': np.float64(0.9219914489683861), 'nauc_ndcg_at_3_max': np.float64(0.8331262056528227), 'nauc_ndcg_at_3_std': np.float64(-0.06283685906042585), 'nauc_ndcg_at_3_diff1': np.float64(0.9256420489413464), 'nauc_ndcg_at_5_max': np.float64(0.8222650665358133), 'nauc_ndcg_at_5_std': np.float64(-0.08101541630049999), 'nauc_ndcg_at_5_diff1': np.float64(0.9251077899816641), 'nauc_ndcg_at_10_max': np.float64(0.8180141073001267), 'nauc_ndcg_at_10_std': np.float64(-0.0908177224862573), 'nauc_ndcg_at_10_diff1': np.float64(0.9225885992841035), 'nauc_ndcg_at_20_max': np.float64(0.8162028689364406), 'nauc_ndcg_at_20_std': np.float64(-0.08806888636157015), 'nauc_ndcg_at_20_diff1': np.float64(0.9225685571953032), 'nauc_ndcg_at_100_max': np.float64(0.8155106567552204), 'nauc_ndcg_at_100_std': np.float64(-0.08371598384355847), 'nauc_ndcg_at_100_diff1': np.float64(0.9235614555171696), 'nauc_ndcg_at_1000_max': np.float64(0.8134769479311467), 'nauc_ndcg_at_1000_std': np.float64(-0.09530413213685224), 'nauc_ndcg_at_1000_diff1': np.float64(0.9234321310800012), 'nauc_map_at_1_max': np.float64(0.7792078528281168), 'nauc_map_at_1_std': np.float64(-0.1528791088099168), 'nauc_map_at_1_diff1': np.float64(0.9219914489683861), 'nauc_map_at_3_max': np.float64(0.8169103988574538), 'nauc_map_at_3_std': np.float64(-0.09255968166715849), 'nauc_map_at_3_diff1': np.float64(0.9245096080767995), 'nauc_map_at_5_max': np.float64(0.811087360962672), 'nauc_map_at_5_std': np.float64(-0.10305440425262838), 'nauc_map_at_5_diff1': np.float64(0.9241431361588304), 'nauc_map_at_10_max': np.float64(0.8095876086490258), 'nauc_map_at_10_std': np.float64(-0.10574632386413099), 'nauc_map_at_10_diff1': np.float64(0.9232644909975076), 'nauc_map_at_20_max': np.float64(0.8091726176091726), 'nauc_map_at_20_std': np.float64(-0.10501053945253029), 'nauc_map_at_20_diff1': np.float64(0.9232443580286058), 'nauc_map_at_100_max': np.float64(0.8090898721437118), 'nauc_map_at_100_std': np.float64(-0.10500435662013195), 'nauc_map_at_100_diff1': np.float64(0.9233917827008663), 'nauc_map_at_1000_max': np.float64(0.8090206958688105), 'nauc_map_at_1000_std': np.float64(-0.10539329815363037), 'nauc_map_at_1000_diff1': np.float64(0.9233864675994327), 'nauc_recall_at_1_max': np.float64(0.7792078528281168), 'nauc_recall_at_1_std': np.float64(-0.1528791088099168), 'nauc_recall_at_1_diff1': np.float64(0.9219914489683861), 'nauc_recall_at_3_max': np.float64(0.9172912408206558), 'nauc_recall_at_3_std': np.float64(0.09368612309788747), 'nauc_recall_at_3_diff1': np.float64(0.9315491962550781), 'nauc_recall_at_5_max': np.float64(0.90991851285969), 'nauc_recall_at_5_std': np.float64(0.0995034377387257), 'nauc_recall_at_5_diff1': np.float64(0.933155080213904), 'nauc_recall_at_10_max': np.float64(0.9038281979458463), 'nauc_recall_at_10_std': np.float64(0.059819483348899666), 'nauc_recall_at_10_diff1': np.float64(0.9106753812636191), 'nauc_recall_at_20_max': np.float64(0.9096638655462097), 'nauc_recall_at_20_std': np.float64(0.17969187675069964), 'nauc_recall_at_20_diff1': np.float64(0.9052287581699371), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.9673202614379001), 'nauc_recall_at_100_diff1': np.float64(0.9346405228758294), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7792078528281168), 'nauc_precision_at_1_std': np.float64(-0.1528791088099168), 'nauc_precision_at_1_diff1': np.float64(0.9219914489683861), 'nauc_precision_at_3_max': np.float64(0.9172912408206573), 'nauc_precision_at_3_std': np.float64(0.09368612309789238), 'nauc_precision_at_3_diff1': np.float64(0.9315491962550828), 'nauc_precision_at_5_max': np.float64(0.909918512859686), 'nauc_precision_at_5_std': np.float64(0.0995034377387245), 'nauc_precision_at_5_diff1': np.float64(0.9331550802138999), 'nauc_precision_at_10_max': np.float64(0.9038281979458412), 'nauc_precision_at_10_std': np.float64(0.05981948334889332), 'nauc_precision_at_10_diff1': np.float64(0.91067538126361), 'nauc_precision_at_20_max': np.float64(0.9096638655461987), 'nauc_precision_at_20_std': np.float64(0.17969187675070394), 'nauc_precision_at_20_diff1': np.float64(0.9052287581699321), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.9673202614378776), 'nauc_precision_at_100_diff1': np.float64(0.9346405228758011), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7792078528281168), 'nauc_mrr_at_1_std': np.float64(-0.1528791088099168), 'nauc_mrr_at_1_diff1': np.float64(0.9219914489683861), 'nauc_mrr_at_3_max': np.float64(0.8169103988574538), 'nauc_mrr_at_3_std': np.float64(-0.09255968166715849), 'nauc_mrr_at_3_diff1': np.float64(0.9245096080767995), 'nauc_mrr_at_5_max': np.float64(0.811087360962672), 'nauc_mrr_at_5_std': np.float64(-0.10305440425262838), 'nauc_mrr_at_5_diff1': np.float64(0.9241431361588304), 'nauc_mrr_at_10_max': np.float64(0.8095876086490258), 'nauc_mrr_at_10_std': np.float64(-0.10574632386413099), 'nauc_mrr_at_10_diff1': np.float64(0.9232644909975076), 'nauc_mrr_at_20_max': np.float64(0.8091726176091726), 'nauc_mrr_at_20_std': np.float64(-0.10501053945253029), 'nauc_mrr_at_20_diff1': np.float64(0.9232443580286058), 'nauc_mrr_at_100_max': np.float64(0.8090898721437118), 'nauc_mrr_at_100_std': np.float64(-0.10500435662013195), 'nauc_mrr_at_100_diff1': np.float64(0.9233917827008663), 'nauc_mrr_at_1000_max': np.float64(0.8090206958688105), 'nauc_mrr_at_1000_std': np.float64(-0.10539329815363037), 'nauc_mrr_at_1000_diff1': np.float64(0.9233864675994327), 'main_score': 0.94251}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.88222, 'ndcg_at_3': 0.92503, 'ndcg_at_5': 0.93014, 'ndcg_at_10': 0.93651, 'ndcg_at_20': 0.93764, 'ndcg_at_100': 0.93868, 'ndcg_at_1000': 0.93913, 'map_at_1': 0.88222, 'map_at_3': 0.91481, 'map_at_5': 0.9177, 'map_at_10': 0.92027, 'map_at_20': 0.92059, 'map_at_100': 0.92073, 'map_at_1000': 0.92075, 'recall_at_1': 0.88222, 'recall_at_3': 0.95444, 'recall_at_5': 0.96667, 'recall_at_10': 0.98667, 'recall_at_20': 0.99111, 'recall_at_100': 0.99667, 'recall_at_1000': 1.0, 'precision_at_1': 0.88222, 'precision_at_3': 0.31815, 'precision_at_5': 0.19333, 'precision_at_10': 0.09867, 'precision_at_20': 0.04956, 'precision_at_100': 0.00997, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8822222222222222, 'mrr_at_3': 0.914814814814815, 'mrr_at_5': 0.917703703703704, 'mrr_at_10': 0.9202733686067022, 'mrr_at_20': 0.9205878863329845, 'mrr_at_100': 0.920731019983486, 'mrr_at_1000': 0.9207500928454461, 'nauc_ndcg_at_1_max': np.float64(0.7432381431626621), 'nauc_ndcg_at_1_std': np.float64(-0.23120158869938737), 'nauc_ndcg_at_1_diff1': np.float64(0.9139154970077102), 'nauc_ndcg_at_3_max': np.float64(0.7920840420808655), 'nauc_ndcg_at_3_std': np.float64(-0.18397241078146917), 'nauc_ndcg_at_3_diff1': np.float64(0.9102034992574379), 'nauc_ndcg_at_5_max': np.float64(0.7840036131040621), 'nauc_ndcg_at_5_std': np.float64(-0.18590531342613936), 'nauc_ndcg_at_5_diff1': np.float64(0.9080144330930631), 'nauc_ndcg_at_10_max': np.float64(0.7772978942631096), 'nauc_ndcg_at_10_std': np.float64(-0.18079113454823553), 'nauc_ndcg_at_10_diff1': np.float64(0.9105233118069156), 'nauc_ndcg_at_20_max': np.float64(0.7737891995288245), 'nauc_ndcg_at_20_std': np.float64(-0.18472650828540493), 'nauc_ndcg_at_20_diff1': np.float64(0.9106919907682975), 'nauc_ndcg_at_100_max': np.float64(0.7735693178069648), 'nauc_ndcg_at_100_std': np.float64(-0.18860487479968238), 'nauc_ndcg_at_100_diff1': np.float64(0.9106455864754731), 'nauc_ndcg_at_1000_max': np.float64(0.7718917686412526), 'nauc_ndcg_at_1000_std': np.float64(-0.19711219617555498), 'nauc_ndcg_at_1000_diff1': np.float64(0.910309840690257), 'nauc_map_at_1_max': np.float64(0.7432381431626621), 'nauc_map_at_1_std': np.float64(-0.23120158869938737), 'nauc_map_at_1_diff1': np.float64(0.9139154970077102), 'nauc_map_at_3_max': np.float64(0.775728484998148), 'nauc_map_at_3_std': np.float64(-0.20419702020825395), 'nauc_map_at_3_diff1': np.float64(0.910729719718484), 'nauc_map_at_5_max': np.float64(0.7711235413411344), 'nauc_map_at_5_std': np.float64(-0.20651983963596712), 'nauc_map_at_5_diff1': np.float64(0.9096210108253402), 'nauc_map_at_10_max': np.float64(0.7685995087295452), 'nauc_map_at_10_std': np.float64(-0.20497000510700775), 'nauc_map_at_10_diff1': np.float64(0.9103310767339169), 'nauc_map_at_20_max': np.float64(0.7677931632230002), 'nauc_map_at_20_std': np.float64(-0.20619686634822945), 'nauc_map_at_20_diff1': np.float64(0.9103723300246829), 'nauc_map_at_100_max': np.float64(0.7678203461116878), 'nauc_map_at_100_std': np.float64(-0.2066944275679903), 'nauc_map_at_100_diff1': np.float64(0.9103896986298576), 'nauc_map_at_1000_max': np.float64(0.7677636365954222), 'nauc_map_at_1000_std': np.float64(-0.2069823724831138), 'nauc_map_at_1000_diff1': np.float64(0.910378752606316), 'nauc_recall_at_1_max': np.float64(0.7432381431626621), 'nauc_recall_at_1_std': np.float64(-0.23120158869938737), 'nauc_recall_at_1_diff1': np.float64(0.9139154970077102), 'nauc_recall_at_3_max': np.float64(0.8792671540160791), 'nauc_recall_at_3_std': np.float64(-0.07284051832114759), 'nauc_recall_at_3_diff1': np.float64(0.9079387852702074), 'nauc_recall_at_5_max': np.float64(0.8727357609710548), 'nauc_recall_at_5_std': np.float64(-0.03484282601929706), 'nauc_recall_at_5_diff1': np.float64(0.8970588235294114), 'nauc_recall_at_10_max': np.float64(0.9051120448179192), 'nauc_recall_at_10_std': np.float64(0.24778244631186175), 'nauc_recall_at_10_diff1': np.float64(0.9223856209150244), 'nauc_recall_at_20_max': np.float64(0.8740079365079421), 'nauc_recall_at_20_std': np.float64(0.37219887955183756), 'nauc_recall_at_20_diff1': np.float64(0.9325980392156854), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.9564270152505339), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7432381431626621), 'nauc_precision_at_1_std': np.float64(-0.23120158869938737), 'nauc_precision_at_1_diff1': np.float64(0.9139154970077102), 'nauc_precision_at_3_max': np.float64(0.8792671540160817), 'nauc_precision_at_3_std': np.float64(-0.0728405183211521), 'nauc_precision_at_3_diff1': np.float64(0.9079387852702043), 'nauc_precision_at_5_max': np.float64(0.8727357609710571), 'nauc_precision_at_5_std': np.float64(-0.034842826019295975), 'nauc_precision_at_5_diff1': np.float64(0.8970588235294136), 'nauc_precision_at_10_max': np.float64(0.9051120448179149), 'nauc_precision_at_10_std': np.float64(0.247782446311847), 'nauc_precision_at_10_diff1': np.float64(0.9223856209150375), 'nauc_precision_at_20_max': np.float64(0.8740079365079182), 'nauc_precision_at_20_std': np.float64(0.37219887955182474), 'nauc_precision_at_20_diff1': np.float64(0.9325980392156864), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.9564270152505041), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505041), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7432381431626621), 'nauc_mrr_at_1_std': np.float64(-0.23120158869938737), 'nauc_mrr_at_1_diff1': np.float64(0.9139154970077102), 'nauc_mrr_at_3_max': np.float64(0.775728484998148), 'nauc_mrr_at_3_std': np.float64(-0.20419702020825395), 'nauc_mrr_at_3_diff1': np.float64(0.910729719718484), 'nauc_mrr_at_5_max': np.float64(0.7711235413411344), 'nauc_mrr_at_5_std': np.float64(-0.20651983963596712), 'nauc_mrr_at_5_diff1': np.float64(0.9096210108253402), 'nauc_mrr_at_10_max': np.float64(0.7685995087295452), 'nauc_mrr_at_10_std': np.float64(-0.20497000510700775), 'nauc_mrr_at_10_diff1': np.float64(0.9103310767339169), 'nauc_mrr_at_20_max': np.float64(0.7677931632230002), 'nauc_mrr_at_20_std': np.float64(-0.20619686634822945), 'nauc_mrr_at_20_diff1': np.float64(0.9103723300246829), 'nauc_mrr_at_100_max': np.float64(0.7678203461116878), 'nauc_mrr_at_100_std': np.float64(-0.2066944275679903), 'nauc_mrr_at_100_diff1': np.float64(0.9103896986298576), 'nauc_mrr_at_1000_max': np.float64(0.7677636365954222), 'nauc_mrr_at_1000_std': np.float64(-0.2069823724831138), 'nauc_mrr_at_1000_diff1': np.float64(0.910378752606316), 'main_score': 0.93651}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.84111, 'ndcg_at_3': 0.88655, 'ndcg_at_5': 0.89687, 'ndcg_at_10': 0.90391, 'ndcg_at_20': 0.90799, 'ndcg_at_100': 0.90997, 'ndcg_at_1000': 0.91102, 'map_at_1': 0.84111, 'map_at_3': 0.87537, 'map_at_5': 0.88098, 'map_at_10': 0.88401, 'map_at_20': 0.88521, 'map_at_100': 0.88545, 'map_at_1000': 0.8855, 'recall_at_1': 0.84111, 'recall_at_3': 0.91889, 'recall_at_5': 0.94444, 'recall_at_10': 0.96556, 'recall_at_20': 0.98111, 'recall_at_100': 0.99222, 'recall_at_1000': 1.0, 'precision_at_1': 0.84111, 'precision_at_3': 0.3063, 'precision_at_5': 0.18889, 'precision_at_10': 0.09656, 'precision_at_20': 0.04906, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8411111111111111, 'mrr_at_3': 0.8753703703703706, 'mrr_at_5': 0.8809814814814817, 'mrr_at_10': 0.8840101410934745, 'mrr_at_20': 0.8852127172697349, 'mrr_at_100': 0.885449650280911, 'mrr_at_1000': 0.885497211675456, 'nauc_ndcg_at_1_max': np.float64(0.7673828165206228), 'nauc_ndcg_at_1_std': np.float64(-0.04837270899521724), 'nauc_ndcg_at_1_diff1': np.float64(0.8934627023392087), 'nauc_ndcg_at_3_max': np.float64(0.8169566966858675), 'nauc_ndcg_at_3_std': np.float64(0.0728963995153794), 'nauc_ndcg_at_3_diff1': np.float64(0.8735722119193429), 'nauc_ndcg_at_5_max': np.float64(0.8102399907635793), 'nauc_ndcg_at_5_std': np.float64(0.04683902089586952), 'nauc_ndcg_at_5_diff1': np.float64(0.8745160029013536), 'nauc_ndcg_at_10_max': np.float64(0.8066539438806426), 'nauc_ndcg_at_10_std': np.float64(0.042598080649337566), 'nauc_ndcg_at_10_diff1': np.float64(0.8729708547646923), 'nauc_ndcg_at_20_max': np.float64(0.8021959993665218), 'nauc_ndcg_at_20_std': np.float64(0.04301016312041599), 'nauc_ndcg_at_20_diff1': np.float64(0.8767445156889189), 'nauc_ndcg_at_100_max': np.float64(0.799971982790663), 'nauc_ndcg_at_100_std': np.float64(0.03584488608641146), 'nauc_ndcg_at_100_diff1': np.float64(0.8781033126465196), 'nauc_ndcg_at_1000_max': np.float64(0.7977777090577682), 'nauc_ndcg_at_1000_std': np.float64(0.02751690045587376), 'nauc_ndcg_at_1000_diff1': np.float64(0.8782251801092046), 'nauc_map_at_1_max': np.float64(0.7673828165206228), 'nauc_map_at_1_std': np.float64(-0.04837270899521724), 'nauc_map_at_1_diff1': np.float64(0.8934627023392087), 'nauc_map_at_3_max': np.float64(0.8000216517565892), 'nauc_map_at_3_std': np.float64(0.03202094054657089), 'nauc_map_at_3_diff1': np.float64(0.8784641018177448), 'nauc_map_at_5_max': np.float64(0.7958737454163957), 'nauc_map_at_5_std': np.float64(0.017080187929437385), 'nauc_map_at_5_diff1': np.float64(0.879274314209589), 'nauc_map_at_10_max': np.float64(0.7942137795875792), 'nauc_map_at_10_std': np.float64(0.015055468916451471), 'nauc_map_at_10_diff1': np.float64(0.8788222743852696), 'nauc_map_at_20_max': np.float64(0.7930329844519671), 'nauc_map_at_20_std': np.float64(0.014740922003401985), 'nauc_map_at_20_diff1': np.float64(0.87989605902825), 'nauc_map_at_100_max': np.float64(0.7927774217656682), 'nauc_map_at_100_std': np.float64(0.01384112454071335), 'nauc_map_at_100_diff1': np.float64(0.8800259583134593), 'nauc_map_at_1000_max': np.float64(0.7926999370150674), 'nauc_map_at_1000_std': np.float64(0.013580948072772584), 'nauc_map_at_1000_diff1': np.float64(0.8800205613602536), 'nauc_recall_at_1_max': np.float64(0.7673828165206228), 'nauc_recall_at_1_std': np.float64(-0.04837270899521724), 'nauc_recall_at_1_diff1': np.float64(0.8934627023392087), 'nauc_recall_at_3_max': np.float64(0.8908074645383278), 'nauc_recall_at_3_std': np.float64(0.25084737091183484), 'nauc_recall_at_3_diff1': np.float64(0.8532737295831584), 'nauc_recall_at_5_max': np.float64(0.8960317460317475), 'nauc_recall_at_5_std': np.float64(0.22169934640523029), 'nauc_recall_at_5_diff1': np.float64(0.8470774976657335), 'nauc_recall_at_10_max': np.float64(0.9192042408361157), 'nauc_recall_at_10_std': np.float64(0.288967199783136), 'nauc_recall_at_10_diff1': np.float64(0.8181831872533971), 'nauc_recall_at_20_max': np.float64(0.9314823968803185), 'nauc_recall_at_20_std': np.float64(0.5027736584830049), 'nauc_recall_at_20_diff1': np.float64(0.8359422200252595), 'nauc_recall_at_100_max': np.float64(0.9813258636788001), 'nauc_recall_at_100_std': np.float64(0.7409630518874236), 'nauc_recall_at_100_diff1': np.float64(0.8622782446311739), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7673828165206228), 'nauc_precision_at_1_std': np.float64(-0.04837270899521724), 'nauc_precision_at_1_diff1': np.float64(0.8934627023392087), 'nauc_precision_at_3_max': np.float64(0.8908074645383278), 'nauc_precision_at_3_std': np.float64(0.25084737091183645), 'nauc_precision_at_3_diff1': np.float64(0.8532737295831584), 'nauc_precision_at_5_max': np.float64(0.8960317460317422), 'nauc_precision_at_5_std': np.float64(0.22169934640522632), 'nauc_precision_at_5_diff1': np.float64(0.8470774976657317), 'nauc_precision_at_10_max': np.float64(0.9192042408361156), 'nauc_precision_at_10_std': np.float64(0.2889671997831299), 'nauc_precision_at_10_diff1': np.float64(0.818183187253392), 'nauc_precision_at_20_max': np.float64(0.9314823968803195), 'nauc_precision_at_20_std': np.float64(0.5027736584829903), 'nauc_precision_at_20_diff1': np.float64(0.835942220025268), 'nauc_precision_at_100_max': np.float64(0.9813258636787873), 'nauc_precision_at_100_std': np.float64(0.7409630518874429), 'nauc_precision_at_100_diff1': np.float64(0.8622782446311745), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7673828165206228), 'nauc_mrr_at_1_std': np.float64(-0.04837270899521724), 'nauc_mrr_at_1_diff1': np.float64(0.8934627023392087), 'nauc_mrr_at_3_max': np.float64(0.8000216517565892), 'nauc_mrr_at_3_std': np.float64(0.03202094054657089), 'nauc_mrr_at_3_diff1': np.float64(0.8784641018177448), 'nauc_mrr_at_5_max': np.float64(0.7958737454163957), 'nauc_mrr_at_5_std': np.float64(0.017080187929437385), 'nauc_mrr_at_5_diff1': np.float64(0.879274314209589), 'nauc_mrr_at_10_max': np.float64(0.7942137795875792), 'nauc_mrr_at_10_std': np.float64(0.015055468916451471), 'nauc_mrr_at_10_diff1': np.float64(0.8788222743852696), 'nauc_mrr_at_20_max': np.float64(0.7930329844519671), 'nauc_mrr_at_20_std': np.float64(0.014740922003401985), 'nauc_mrr_at_20_diff1': np.float64(0.87989605902825), 'nauc_mrr_at_100_max': np.float64(0.7927774217656682), 'nauc_mrr_at_100_std': np.float64(0.01384112454071335), 'nauc_mrr_at_100_diff1': np.float64(0.8800259583134593), 'nauc_mrr_at_1000_max': np.float64(0.7926999370150674), 'nauc_mrr_at_1000_std': np.float64(0.013580948072772584), 'nauc_mrr_at_1000_diff1': np.float64(0.8800205613602536), 'main_score': 0.90391}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.40 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  5.99it/s]Batches:  67%|██████▋   | 2/3 [00:10<00:06,  6.41s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.01s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.03s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 14.17 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.81 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 25.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.2737, 'ndcg_at_3': 0.29952, 'ndcg_at_5': 0.33097, 'ndcg_at_10': 0.35066, 'ndcg_at_20': 0.37492, 'ndcg_at_100': 0.42797, 'ndcg_at_1000': 0.45666, 'map_at_1': 0.19131, 'map_at_3': 0.27156, 'map_at_5': 0.29427, 'map_at_10': 0.30408, 'map_at_20': 0.31213, 'map_at_100': 0.3202, 'map_at_1000': 0.32145, 'recall_at_1': 0.19131, 'recall_at_3': 0.31814, 'recall_at_5': 0.39422, 'recall_at_10': 0.4476, 'recall_at_20': 0.53259, 'recall_at_100': 0.79307, 'recall_at_1000': 1.0, 'precision_at_1': 0.2737, 'precision_at_3': 0.16718, 'precision_at_5': 0.12416, 'precision_at_10': 0.07125, 'precision_at_20': 0.04228, 'precision_at_100': 0.01258, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.27522935779816515, 'mrr_at_3': 0.32212028542303783, 'mrr_at_5': 0.3388634046890927, 'mrr_at_10': 0.34545349740303866, 'mrr_at_20': 0.35107181542869037, 'mrr_at_100': 0.3570121567615531, 'mrr_at_1000': 0.35786400035287286, 'nauc_ndcg_at_1_max': np.float64(0.18478273585670998), 'nauc_ndcg_at_1_std': np.float64(-0.31807342680384515), 'nauc_ndcg_at_1_diff1': np.float64(0.46062551861494544), 'nauc_ndcg_at_3_max': np.float64(0.15013847985442622), 'nauc_ndcg_at_3_std': np.float64(-0.3237156148984235), 'nauc_ndcg_at_3_diff1': np.float64(0.41371944969401203), 'nauc_ndcg_at_5_max': np.float64(0.1610400439271062), 'nauc_ndcg_at_5_std': np.float64(-0.33082820356065773), 'nauc_ndcg_at_5_diff1': np.float64(0.4161737318927418), 'nauc_ndcg_at_10_max': np.float64(0.15427602140332725), 'nauc_ndcg_at_10_std': np.float64(-0.3259619644795758), 'nauc_ndcg_at_10_diff1': np.float64(0.4080358146912521), 'nauc_ndcg_at_20_max': np.float64(0.1521300523053886), 'nauc_ndcg_at_20_std': np.float64(-0.31244441722580535), 'nauc_ndcg_at_20_diff1': np.float64(0.39936560673261134), 'nauc_ndcg_at_100_max': np.float64(0.18811204407558732), 'nauc_ndcg_at_100_std': np.float64(-0.25834190358352116), 'nauc_ndcg_at_100_diff1': np.float64(0.40055433757866565), 'nauc_ndcg_at_1000_max': np.float64(0.1730686335850839), 'nauc_ndcg_at_1000_std': np.float64(-0.2926678382845918), 'nauc_ndcg_at_1000_diff1': np.float64(0.409352043379568), 'nauc_map_at_1_max': np.float64(0.14012396295028154), 'nauc_map_at_1_std': np.float64(-0.2933447558477882), 'nauc_map_at_1_diff1': np.float64(0.4777061091822854), 'nauc_map_at_3_max': np.float64(0.16174901634963323), 'nauc_map_at_3_std': np.float64(-0.31538080050604406), 'nauc_map_at_3_diff1': np.float64(0.41583159111916285), 'nauc_map_at_5_max': np.float64(0.16541361972443772), 'nauc_map_at_5_std': np.float64(-0.32548812398931265), 'nauc_map_at_5_diff1': np.float64(0.416345038669792), 'nauc_map_at_10_max': np.float64(0.16103537970969872), 'nauc_map_at_10_std': np.float64(-0.32503777944071344), 'nauc_map_at_10_diff1': np.float64(0.41299362534552725), 'nauc_map_at_20_max': np.float64(0.16019261482766603), 'nauc_map_at_20_std': np.float64(-0.3215446860053342), 'nauc_map_at_20_diff1': np.float64(0.41040724242967425), 'nauc_map_at_100_max': np.float64(0.16567733681043445), 'nauc_map_at_100_std': np.float64(-0.3128853427990528), 'nauc_map_at_100_diff1': np.float64(0.4102133464170339), 'nauc_map_at_1000_max': np.float64(0.16513242410663725), 'nauc_map_at_1000_std': np.float64(-0.3141519944071017), 'nauc_map_at_1000_diff1': np.float64(0.41062679262849794), 'nauc_recall_at_1_max': np.float64(0.14012396295028154), 'nauc_recall_at_1_std': np.float64(-0.2933447558477882), 'nauc_recall_at_1_diff1': np.float64(0.4777061091822854), 'nauc_recall_at_3_max': np.float64(0.1359168382947383), 'nauc_recall_at_3_std': np.float64(-0.31194448337435726), 'nauc_recall_at_3_diff1': np.float64(0.3849361371197937), 'nauc_recall_at_5_max': np.float64(0.1538609262812138), 'nauc_recall_at_5_std': np.float64(-0.3249312935156017), 'nauc_recall_at_5_diff1': np.float64(0.3844633841942806), 'nauc_recall_at_10_max': np.float64(0.13294003401397117), 'nauc_recall_at_10_std': np.float64(-0.31282126791818005), 'nauc_recall_at_10_diff1': np.float64(0.3591712788207327), 'nauc_recall_at_20_max': np.float64(0.12006091569134453), 'nauc_recall_at_20_std': np.float64(-0.2637785006914098), 'nauc_recall_at_20_diff1': np.float64(0.3242252495515925), 'nauc_recall_at_100_max': np.float64(0.3345332451429733), 'nauc_recall_at_100_std': np.float64(0.12495529467738369), 'nauc_recall_at_100_diff1': np.float64(0.2832247201123581), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.18478273585670998), 'nauc_precision_at_1_std': np.float64(-0.31807342680384515), 'nauc_precision_at_1_diff1': np.float64(0.46062551861494544), 'nauc_precision_at_3_max': np.float64(0.15258475902272714), 'nauc_precision_at_3_std': np.float64(-0.2985137253538266), 'nauc_precision_at_3_diff1': np.float64(0.2854559172268683), 'nauc_precision_at_5_max': np.float64(0.1500651160680117), 'nauc_precision_at_5_std': np.float64(-0.30143876723721863), 'nauc_precision_at_5_diff1': np.float64(0.2669222443359308), 'nauc_precision_at_10_max': np.float64(0.1210617698100394), 'nauc_precision_at_10_std': np.float64(-0.27548985963557165), 'nauc_precision_at_10_diff1': np.float64(0.23415224862463332), 'nauc_precision_at_20_max': np.float64(0.11098938573217373), 'nauc_precision_at_20_std': np.float64(-0.21514662243840546), 'nauc_precision_at_20_diff1': np.float64(0.19211125561102477), 'nauc_precision_at_100_max': np.float64(0.219798919185064), 'nauc_precision_at_100_std': np.float64(0.08542479922679183), 'nauc_precision_at_100_diff1': np.float64(0.09387061957798809), 'nauc_precision_at_1000_max': np.float64(0.12201578109620512), 'nauc_precision_at_1000_std': np.float64(0.04235933539624416), 'nauc_precision_at_1000_diff1': np.float64(0.005598514217803497), 'nauc_mrr_at_1_max': np.float64(0.180971841227373), 'nauc_mrr_at_1_std': np.float64(-0.3205775185600898), 'nauc_mrr_at_1_diff1': np.float64(0.45481694829443947), 'nauc_mrr_at_3_max': np.float64(0.15308780923134727), 'nauc_mrr_at_3_std': np.float64(-0.3297970149844163), 'nauc_mrr_at_3_diff1': np.float64(0.43651081119809315), 'nauc_mrr_at_5_max': np.float64(0.1597739004689999), 'nauc_mrr_at_5_std': np.float64(-0.3284487076279854), 'nauc_mrr_at_5_diff1': np.float64(0.4363715759652603), 'nauc_mrr_at_10_max': np.float64(0.16099270870791393), 'nauc_mrr_at_10_std': np.float64(-0.32307248054712556), 'nauc_mrr_at_10_diff1': np.float64(0.43379845865880096), 'nauc_mrr_at_20_max': np.float64(0.16093303654035482), 'nauc_mrr_at_20_std': np.float64(-0.3193634916873706), 'nauc_mrr_at_20_diff1': np.float64(0.43139897426162754), 'nauc_mrr_at_100_max': np.float64(0.16505761015855736), 'nauc_mrr_at_100_std': np.float64(-0.3139511114936511), 'nauc_mrr_at_100_diff1': np.float64(0.4321559365388336), 'nauc_mrr_at_1000_max': np.float64(0.16441609649853284), 'nauc_mrr_at_1000_std': np.float64(-0.31512067257034615), 'nauc_mrr_at_1000_diff1': np.float64(0.4323370564825208), 'main_score': 0.35066}, 'eng-kor': {'ndcg_at_1': 0.30122, 'ndcg_at_3': 0.32016, 'ndcg_at_5': 0.33264, 'ndcg_at_10': 0.36361, 'ndcg_at_20': 0.3902, 'ndcg_at_100': 0.4461, 'ndcg_at_1000': 0.4742, 'map_at_1': 0.17026, 'map_at_3': 0.26604, 'map_at_5': 0.28779, 'map_at_10': 0.30569, 'map_at_20': 0.31535, 'map_at_100': 0.32461, 'map_at_1000': 0.32611, 'recall_at_1': 0.17026, 'recall_at_3': 0.31914, 'recall_at_5': 0.37551, 'recall_at_10': 0.45178, 'recall_at_20': 0.53833, 'recall_at_100': 0.80499, 'recall_at_1000': 0.99554, 'precision_at_1': 0.30122, 'precision_at_3': 0.21203, 'precision_at_5': 0.15382, 'precision_at_10': 0.0945, 'precision_at_20': 0.05627, 'precision_at_100': 0.01602, 'precision_at_1000': 0.00194, 'mrr_at_1': 0.3012232415902141, 'mrr_at_3': 0.35958205912334373, 'mrr_at_5': 0.37150866462793075, 'mrr_at_10': 0.38023760982476573, 'mrr_at_20': 0.38564325242436137, 'mrr_at_100': 0.39116899649947334, 'mrr_at_1000': 0.39186776957459096, 'nauc_ndcg_at_1_max': np.float64(0.09122270133294437), 'nauc_ndcg_at_1_std': np.float64(-0.397300936878487), 'nauc_ndcg_at_1_diff1': np.float64(0.4103962669017795), 'nauc_ndcg_at_3_max': np.float64(0.06811303450923206), 'nauc_ndcg_at_3_std': np.float64(-0.40212846342747166), 'nauc_ndcg_at_3_diff1': np.float64(0.3816008489960056), 'nauc_ndcg_at_5_max': np.float64(0.07007364962625569), 'nauc_ndcg_at_5_std': np.float64(-0.3956611076615773), 'nauc_ndcg_at_5_diff1': np.float64(0.3686593122798395), 'nauc_ndcg_at_10_max': np.float64(0.0709919243575609), 'nauc_ndcg_at_10_std': np.float64(-0.4033634552221841), 'nauc_ndcg_at_10_diff1': np.float64(0.3572507050337783), 'nauc_ndcg_at_20_max': np.float64(0.08451346984658278), 'nauc_ndcg_at_20_std': np.float64(-0.3886255341236281), 'nauc_ndcg_at_20_diff1': np.float64(0.35731703826001954), 'nauc_ndcg_at_100_max': np.float64(0.08799784974557857), 'nauc_ndcg_at_100_std': np.float64(-0.37186123315692066), 'nauc_ndcg_at_100_diff1': np.float64(0.3657643352782841), 'nauc_ndcg_at_1000_max': np.float64(0.09103656911633401), 'nauc_ndcg_at_1000_std': np.float64(-0.3737333017776776), 'nauc_ndcg_at_1000_diff1': np.float64(0.3628783981866909), 'nauc_map_at_1_max': np.float64(0.0630133239894579), 'nauc_map_at_1_std': np.float64(-0.3497742685415477), 'nauc_map_at_1_diff1': np.float64(0.46049287918661735), 'nauc_map_at_3_max': np.float64(0.07467041345272188), 'nauc_map_at_3_std': np.float64(-0.39277572282783396), 'nauc_map_at_3_diff1': np.float64(0.41001344386383687), 'nauc_map_at_5_max': np.float64(0.08383008393091337), 'nauc_map_at_5_std': np.float64(-0.3911204355843689), 'nauc_map_at_5_diff1': np.float64(0.3983933329494627), 'nauc_map_at_10_max': np.float64(0.0869312976604191), 'nauc_map_at_10_std': np.float64(-0.39604427587417085), 'nauc_map_at_10_diff1': np.float64(0.3900110735943226), 'nauc_map_at_20_max': np.float64(0.09141587327640559), 'nauc_map_at_20_std': np.float64(-0.39248312035984706), 'nauc_map_at_20_diff1': np.float64(0.3905744920541136), 'nauc_map_at_100_max': np.float64(0.0905034392069404), 'nauc_map_at_100_std': np.float64(-0.3908521469624972), 'nauc_map_at_100_diff1': np.float64(0.3907442195554611), 'nauc_map_at_1000_max': np.float64(0.09127838021251461), 'nauc_map_at_1000_std': np.float64(-0.38994922576456176), 'nauc_map_at_1000_diff1': np.float64(0.39055170006244533), 'nauc_recall_at_1_max': np.float64(0.0630133239894579), 'nauc_recall_at_1_std': np.float64(-0.3497742685415477), 'nauc_recall_at_1_diff1': np.float64(0.46049287918661735), 'nauc_recall_at_3_max': np.float64(0.03315250269768863), 'nauc_recall_at_3_std': np.float64(-0.38081052480432154), 'nauc_recall_at_3_diff1': np.float64(0.34860540706157983), 'nauc_recall_at_5_max': np.float64(0.043836235815805084), 'nauc_recall_at_5_std': np.float64(-0.3689741446172498), 'nauc_recall_at_5_diff1': np.float64(0.30827971282178424), 'nauc_recall_at_10_max': np.float64(0.041133587343860675), 'nauc_recall_at_10_std': np.float64(-0.3917937947225005), 'nauc_recall_at_10_diff1': np.float64(0.2863014008696317), 'nauc_recall_at_20_max': np.float64(0.08117566142227187), 'nauc_recall_at_20_std': np.float64(-0.3406835436160669), 'nauc_recall_at_20_diff1': np.float64(0.27946785579178257), 'nauc_recall_at_100_max': np.float64(0.09917249026842827), 'nauc_recall_at_100_std': np.float64(-0.2242024437567541), 'nauc_recall_at_100_diff1': np.float64(0.33559922640241197), 'nauc_recall_at_1000_max': np.float64(0.08617668209469644), 'nauc_recall_at_1000_std': np.float64(-0.6137837304264496), 'nauc_recall_at_1000_diff1': np.float64(0.5377292301225426), 'nauc_precision_at_1_max': np.float64(0.09122270133294437), 'nauc_precision_at_1_std': np.float64(-0.397300936878487), 'nauc_precision_at_1_diff1': np.float64(0.4103962669017795), 'nauc_precision_at_3_max': np.float64(0.08598040976507433), 'nauc_precision_at_3_std': np.float64(-0.3593028990614615), 'nauc_precision_at_3_diff1': np.float64(0.25236214937547097), 'nauc_precision_at_5_max': np.float64(0.09557436697875245), 'nauc_precision_at_5_std': np.float64(-0.3238233265664882), 'nauc_precision_at_5_diff1': np.float64(0.206504489547144), 'nauc_precision_at_10_max': np.float64(0.09143402417922405), 'nauc_precision_at_10_std': np.float64(-0.2973547392633464), 'nauc_precision_at_10_diff1': np.float64(0.15543747030263136), 'nauc_precision_at_20_max': np.float64(0.11306823178518817), 'nauc_precision_at_20_std': np.float64(-0.23946049278152726), 'nauc_precision_at_20_diff1': np.float64(0.13970539353492695), 'nauc_precision_at_100_max': np.float64(0.12599490994320076), 'nauc_precision_at_100_std': np.float64(-0.06557644002992093), 'nauc_precision_at_100_diff1': np.float64(0.05320036231388014), 'nauc_precision_at_1000_max': np.float64(0.13439956993472651), 'nauc_precision_at_1000_std': np.float64(0.03825648662313364), 'nauc_precision_at_1000_diff1': np.float64(-0.05655782430294636), 'nauc_mrr_at_1_max': np.float64(0.09122270133294437), 'nauc_mrr_at_1_std': np.float64(-0.397300936878487), 'nauc_mrr_at_1_diff1': np.float64(0.4103962669017795), 'nauc_mrr_at_3_max': np.float64(0.05809387860849246), 'nauc_mrr_at_3_std': np.float64(-0.40458496939753685), 'nauc_mrr_at_3_diff1': np.float64(0.3607650016591954), 'nauc_mrr_at_5_max': np.float64(0.05902889823442907), 'nauc_mrr_at_5_std': np.float64(-0.4034534255924798), 'nauc_mrr_at_5_diff1': np.float64(0.3522112601961435), 'nauc_mrr_at_10_max': np.float64(0.060649028199349114), 'nauc_mrr_at_10_std': np.float64(-0.40273217716264914), 'nauc_mrr_at_10_diff1': np.float64(0.3504846065910287), 'nauc_mrr_at_20_max': np.float64(0.06449283186045081), 'nauc_mrr_at_20_std': np.float64(-0.39715495844640214), 'nauc_mrr_at_20_diff1': np.float64(0.3510768552917758), 'nauc_mrr_at_100_max': np.float64(0.06453005050005438), 'nauc_mrr_at_100_std': np.float64(-0.3958299253498969), 'nauc_mrr_at_100_diff1': np.float64(0.35261310769832566), 'nauc_mrr_at_1000_max': np.float64(0.06445696792925647), 'nauc_mrr_at_1000_std': np.float64(-0.3960556669263246), 'nauc_mrr_at_1000_diff1': np.float64(0.35269200078409135), 'main_score': 0.36361}, 'kor-eng': {'ndcg_at_1': 0.21661, 'ndcg_at_3': 0.24937, 'ndcg_at_5': 0.26993, 'ndcg_at_10': 0.30614, 'ndcg_at_20': 0.32626, 'ndcg_at_100': 0.3812, 'ndcg_at_1000': 0.41553, 'map_at_1': 0.14889, 'map_at_3': 0.21998, 'map_at_5': 0.23516, 'map_at_10': 0.25346, 'map_at_20': 0.25981, 'map_at_100': 0.2686, 'map_at_1000': 0.27014, 'recall_at_1': 0.14889, 'recall_at_3': 0.27454, 'recall_at_5': 0.32448, 'recall_at_10': 0.4216, 'recall_at_20': 0.4909, 'recall_at_100': 0.75291, 'recall_at_1000': 1.0, 'precision_at_1': 0.21661, 'precision_at_3': 0.14495, 'precision_at_5': 0.10456, 'precision_at_10': 0.06971, 'precision_at_20': 0.04112, 'precision_at_100': 0.01288, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.21661237785016288, 'mrr_at_3': 0.2662866449511401, 'mrr_at_5': 0.27923452768729645, 'mrr_at_10': 0.29075345121762053, 'mrr_at_20': 0.29599874973169404, 'mrr_at_100': 0.3020522731365438, 'mrr_at_1000': 0.302958041744962, 'nauc_ndcg_at_1_max': np.float64(0.1999944810544008), 'nauc_ndcg_at_1_std': np.float64(-0.1596080201600802), 'nauc_ndcg_at_1_diff1': np.float64(0.33740901044062355), 'nauc_ndcg_at_3_max': np.float64(0.1482670195777456), 'nauc_ndcg_at_3_std': np.float64(-0.2040467634245727), 'nauc_ndcg_at_3_diff1': np.float64(0.29881336605653613), 'nauc_ndcg_at_5_max': np.float64(0.12880930683718117), 'nauc_ndcg_at_5_std': np.float64(-0.21464303645223115), 'nauc_ndcg_at_5_diff1': np.float64(0.26977399346089515), 'nauc_ndcg_at_10_max': np.float64(0.13212375924106734), 'nauc_ndcg_at_10_std': np.float64(-0.21605477877824827), 'nauc_ndcg_at_10_diff1': np.float64(0.2705760393064094), 'nauc_ndcg_at_20_max': np.float64(0.13745136279736156), 'nauc_ndcg_at_20_std': np.float64(-0.20632670568320333), 'nauc_ndcg_at_20_diff1': np.float64(0.26365334457102946), 'nauc_ndcg_at_100_max': np.float64(0.16313753814770166), 'nauc_ndcg_at_100_std': np.float64(-0.15351265564676686), 'nauc_ndcg_at_100_diff1': np.float64(0.2444254702583081), 'nauc_ndcg_at_1000_max': np.float64(0.15889324392617588), 'nauc_ndcg_at_1000_std': np.float64(-0.17557151444314534), 'nauc_ndcg_at_1000_diff1': np.float64(0.2638184982536659), 'nauc_map_at_1_max': np.float64(0.15577040920214252), 'nauc_map_at_1_std': np.float64(-0.17169604535252767), 'nauc_map_at_1_diff1': np.float64(0.37355624071723426), 'nauc_map_at_3_max': np.float64(0.15057309668512775), 'nauc_map_at_3_std': np.float64(-0.20396464056220748), 'nauc_map_at_3_diff1': np.float64(0.30405261799344346), 'nauc_map_at_5_max': np.float64(0.14003192566298497), 'nauc_map_at_5_std': np.float64(-0.21110639749549373), 'nauc_map_at_5_diff1': np.float64(0.28049454701333115), 'nauc_map_at_10_max': np.float64(0.13971271877180338), 'nauc_map_at_10_std': np.float64(-0.21421676377276305), 'nauc_map_at_10_diff1': np.float64(0.28118959865700616), 'nauc_map_at_20_max': np.float64(0.14079803214466646), 'nauc_map_at_20_std': np.float64(-0.2124411515435915), 'nauc_map_at_20_diff1': np.float64(0.2783379382962833), 'nauc_map_at_100_max': np.float64(0.14493908980796408), 'nauc_map_at_100_std': np.float64(-0.20412693289212472), 'nauc_map_at_100_diff1': np.float64(0.2746392392590291), 'nauc_map_at_1000_max': np.float64(0.14498054112424608), 'nauc_map_at_1000_std': np.float64(-0.20457184169723125), 'nauc_map_at_1000_diff1': np.float64(0.27539022125602935), 'nauc_recall_at_1_max': np.float64(0.15577040920214252), 'nauc_recall_at_1_std': np.float64(-0.17169604535252767), 'nauc_recall_at_1_diff1': np.float64(0.37355624071723426), 'nauc_recall_at_3_max': np.float64(0.11562233256202345), 'nauc_recall_at_3_std': np.float64(-0.21550214097011122), 'nauc_recall_at_3_diff1': np.float64(0.2748226355661856), 'nauc_recall_at_5_max': np.float64(0.07666242316327561), 'nauc_recall_at_5_std': np.float64(-0.22846840896747536), 'nauc_recall_at_5_diff1': np.float64(0.2133193695719311), 'nauc_recall_at_10_max': np.float64(0.08991413677518453), 'nauc_recall_at_10_std': np.float64(-0.23052006331476554), 'nauc_recall_at_10_diff1': np.float64(0.2192175615115136), 'nauc_recall_at_20_max': np.float64(0.09992574025954884), 'nauc_recall_at_20_std': np.float64(-0.2072258063780811), 'nauc_recall_at_20_diff1': np.float64(0.19755904312802172), 'nauc_recall_at_100_max': np.float64(0.19953634957126565), 'nauc_recall_at_100_std': np.float64(0.07688256827536674), 'nauc_recall_at_100_diff1': np.float64(0.047343750173015633), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1999944810544008), 'nauc_precision_at_1_std': np.float64(-0.1596080201600802), 'nauc_precision_at_1_diff1': np.float64(0.33740901044062355), 'nauc_precision_at_3_max': np.float64(0.1517632901942953), 'nauc_precision_at_3_std': np.float64(-0.18603356922253142), 'nauc_precision_at_3_diff1': np.float64(0.19338903376280286), 'nauc_precision_at_5_max': np.float64(0.11840418939206036), 'nauc_precision_at_5_std': np.float64(-0.19022391159285162), 'nauc_precision_at_5_diff1': np.float64(0.13213350660356132), 'nauc_precision_at_10_max': np.float64(0.09968929952537983), 'nauc_precision_at_10_std': np.float64(-0.17119247479860028), 'nauc_precision_at_10_diff1': np.float64(0.12270686501836386), 'nauc_precision_at_20_max': np.float64(0.11950733862274829), 'nauc_precision_at_20_std': np.float64(-0.1242682898861257), 'nauc_precision_at_20_diff1': np.float64(0.10141506216433606), 'nauc_precision_at_100_max': np.float64(0.21951059823863653), 'nauc_precision_at_100_std': np.float64(0.1654453563845961), 'nauc_precision_at_100_diff1': np.float64(-0.0090438550124689), 'nauc_precision_at_1000_max': np.float64(0.1872749399058316), 'nauc_precision_at_1000_std': np.float64(0.183770376736487), 'nauc_precision_at_1000_diff1': np.float64(-0.035880393010250144), 'nauc_mrr_at_1_max': np.float64(0.1999944810544008), 'nauc_mrr_at_1_std': np.float64(-0.1596080201600802), 'nauc_mrr_at_1_diff1': np.float64(0.33740901044062355), 'nauc_mrr_at_3_max': np.float64(0.16624498810306568), 'nauc_mrr_at_3_std': np.float64(-0.19056963230635668), 'nauc_mrr_at_3_diff1': np.float64(0.3145750231821114), 'nauc_mrr_at_5_max': np.float64(0.15864107353931567), 'nauc_mrr_at_5_std': np.float64(-0.1917669677434899), 'nauc_mrr_at_5_diff1': np.float64(0.3031707905169204), 'nauc_mrr_at_10_max': np.float64(0.1637199501267214), 'nauc_mrr_at_10_std': np.float64(-0.1874035341015473), 'nauc_mrr_at_10_diff1': np.float64(0.30116251421854034), 'nauc_mrr_at_20_max': np.float64(0.16579929935571458), 'nauc_mrr_at_20_std': np.float64(-0.18378764407375864), 'nauc_mrr_at_20_diff1': np.float64(0.3004593587358366), 'nauc_mrr_at_100_max': np.float64(0.16703508260213223), 'nauc_mrr_at_100_std': np.float64(-0.18033508427797784), 'nauc_mrr_at_100_diff1': np.float64(0.2979534091976417), 'nauc_mrr_at_1000_max': np.float64(0.16673399252167967), 'nauc_mrr_at_1000_std': np.float64(-0.18115039668322358), 'nauc_mrr_at_1000_diff1': np.float64(0.29850927890695944), 'main_score': 0.30614}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:10,  5.85s/it]Batches:  15%|█▌        | 2/13 [00:16<01:36,  8.79s/it]Batches:  23%|██▎       | 3/13 [00:27<01:37,  9.76s/it]Batches:  31%|███       | 4/13 [00:38<01:32, 10.25s/it]Batches:  38%|███▊      | 5/13 [00:49<01:24, 10.54s/it]Batches:  46%|████▌     | 6/13 [01:00<01:15, 10.72s/it]Batches:  54%|█████▍    | 7/13 [01:11<01:05, 10.83s/it]Batches:  62%|██████▏   | 8/13 [01:22<00:54, 10.92s/it]Batches:  69%|██████▉   | 9/13 [01:34<00:43, 10.98s/it]Batches:  77%|███████▋  | 10/13 [01:45<00:33, 11.03s/it]Batches:  85%|████████▍ | 11/13 [01:56<00:22, 11.06s/it]Batches:  92%|█████████▏| 12/13 [02:07<00:11, 11.08s/it]Batches: 100%|██████████| 13/13 [02:18<00:00, 11.09s/it]Batches: 100%|██████████| 13/13 [02:18<00:00, 10.66s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 146.51 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 146.79 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.225, 'ndcg_at_3': 0.27089, 'ndcg_at_5': 0.29392, 'ndcg_at_10': 0.30869, 'ndcg_at_20': 0.32377, 'ndcg_at_100': 0.34748, 'ndcg_at_1000': 0.37894, 'map_at_1': 0.225, 'map_at_3': 0.25917, 'map_at_5': 0.27217, 'map_at_10': 0.27839, 'map_at_20': 0.28249, 'map_at_100': 0.28562, 'map_at_1000': 0.28656, 'recall_at_1': 0.225, 'recall_at_3': 0.305, 'recall_at_5': 0.36, 'recall_at_10': 0.405, 'recall_at_20': 0.465, 'recall_at_100': 0.595, 'recall_at_1000': 0.855, 'precision_at_1': 0.225, 'precision_at_3': 0.10167, 'precision_at_5': 0.072, 'precision_at_10': 0.0405, 'precision_at_20': 0.02325, 'precision_at_100': 0.00595, 'precision_at_1000': 0.00086, 'mrr_at_1': 0.225, 'mrr_at_3': 0.2591666666666667, 'mrr_at_5': 0.2721666666666667, 'mrr_at_10': 0.2783948412698413, 'mrr_at_20': 0.28249013486513497, 'mrr_at_100': 0.2856210546112084, 'mrr_at_1000': 0.2865550826753487, 'nauc_ndcg_at_1_max': np.float64(0.4705538236539276), 'nauc_ndcg_at_1_std': np.float64(-0.058784589924181264), 'nauc_ndcg_at_1_diff1': np.float64(0.5586960705076397), 'nauc_ndcg_at_3_max': np.float64(0.4258518504997637), 'nauc_ndcg_at_3_std': np.float64(-0.05437443315310704), 'nauc_ndcg_at_3_diff1': np.float64(0.4908716670181991), 'nauc_ndcg_at_5_max': np.float64(0.4390595623034592), 'nauc_ndcg_at_5_std': np.float64(-0.040078077863090804), 'nauc_ndcg_at_5_diff1': np.float64(0.4859565184409851), 'nauc_ndcg_at_10_max': np.float64(0.43947463568381123), 'nauc_ndcg_at_10_std': np.float64(-0.030194439183616174), 'nauc_ndcg_at_10_diff1': np.float64(0.46973038934283456), 'nauc_ndcg_at_20_max': np.float64(0.441598930338093), 'nauc_ndcg_at_20_std': np.float64(-0.022550640444449096), 'nauc_ndcg_at_20_diff1': np.float64(0.47711457240048044), 'nauc_ndcg_at_100_max': np.float64(0.44752944736864253), 'nauc_ndcg_at_100_std': np.float64(0.014536279874750873), 'nauc_ndcg_at_100_diff1': np.float64(0.4651022132533749), 'nauc_ndcg_at_1000_max': np.float64(0.45280397565939245), 'nauc_ndcg_at_1000_std': np.float64(0.008694053070665663), 'nauc_ndcg_at_1000_diff1': np.float64(0.4660598275346212), 'nauc_map_at_1_max': np.float64(0.4705538236539276), 'nauc_map_at_1_std': np.float64(-0.058784589924181264), 'nauc_map_at_1_diff1': np.float64(0.5586960705076397), 'nauc_map_at_3_max': np.float64(0.43715739329406483), 'nauc_map_at_3_std': np.float64(-0.05578045127686905), 'nauc_map_at_3_diff1': np.float64(0.5062583328599041), 'nauc_map_at_5_max': np.float64(0.44506965120497405), 'nauc_map_at_5_std': np.float64(-0.04750545663729009), 'nauc_map_at_5_diff1': np.float64(0.5039749240776535), 'nauc_map_at_10_max': np.float64(0.4440807062760643), 'nauc_map_at_10_std': np.float64(-0.04468313245045792), 'nauc_map_at_10_diff1': np.float64(0.4962892380511699), 'nauc_map_at_20_max': np.float64(0.4436478366100422), 'nauc_map_at_20_std': np.float64(-0.04357356693958735), 'nauc_map_at_20_diff1': np.float64(0.4974509233090044), 'nauc_map_at_100_max': np.float64(0.4450275819616694), 'nauc_map_at_100_std': np.float64(-0.038660364252145515), 'nauc_map_at_100_diff1': np.float64(0.49560258641813304), 'nauc_map_at_1000_max': np.float64(0.44504849728519563), 'nauc_map_at_1000_std': np.float64(-0.038992619454156975), 'nauc_map_at_1000_diff1': np.float64(0.4955255586619396), 'nauc_recall_at_1_max': np.float64(0.4705538236539276), 'nauc_recall_at_1_std': np.float64(-0.058784589924181264), 'nauc_recall_at_1_diff1': np.float64(0.5586960705076397), 'nauc_recall_at_3_max': np.float64(0.3950952576708202), 'nauc_recall_at_3_std': np.float64(-0.05044916333641102), 'nauc_recall_at_3_diff1': np.float64(0.4496215975793028), 'nauc_recall_at_5_max': np.float64(0.42402771217131147), 'nauc_recall_at_5_std': np.float64(-0.018671600272923), 'nauc_recall_at_5_diff1': np.float64(0.4372474151052326), 'nauc_recall_at_10_max': np.float64(0.4309367686028742), 'nauc_recall_at_10_std': np.float64(0.015925517579321348), 'nauc_recall_at_10_diff1': np.float64(0.39530745275537255), 'nauc_recall_at_20_max': np.float64(0.44600864809366825), 'nauc_recall_at_20_std': np.float64(0.05218472959898892), 'nauc_recall_at_20_diff1': np.float64(0.4278371209877519), 'nauc_recall_at_100_max': np.float64(0.47169198757443176), 'nauc_recall_at_100_std': np.float64(0.2710382433020728), 'nauc_recall_at_100_diff1': np.float64(0.3595962428150849), 'nauc_recall_at_1000_max': np.float64(0.6180240947682816), 'nauc_recall_at_1000_std': np.float64(0.5043625625020984), 'nauc_recall_at_1000_diff1': np.float64(0.267139836907279), 'nauc_precision_at_1_max': np.float64(0.4705538236539276), 'nauc_precision_at_1_std': np.float64(-0.058784589924181264), 'nauc_precision_at_1_diff1': np.float64(0.5586960705076397), 'nauc_precision_at_3_max': np.float64(0.39509525767082015), 'nauc_precision_at_3_std': np.float64(-0.050449163336410925), 'nauc_precision_at_3_diff1': np.float64(0.44962159757930276), 'nauc_precision_at_5_max': np.float64(0.42402771217131174), 'nauc_precision_at_5_std': np.float64(-0.018671600272922646), 'nauc_precision_at_5_diff1': np.float64(0.43724741510523296), 'nauc_precision_at_10_max': np.float64(0.4309367686028743), 'nauc_precision_at_10_std': np.float64(0.015925517579321397), 'nauc_precision_at_10_diff1': np.float64(0.3953074527553725), 'nauc_precision_at_20_max': np.float64(0.4460086480936678), 'nauc_precision_at_20_std': np.float64(0.052184729598988976), 'nauc_precision_at_20_diff1': np.float64(0.4278371209877518), 'nauc_precision_at_100_max': np.float64(0.47169198757443165), 'nauc_precision_at_100_std': np.float64(0.27103824330207266), 'nauc_precision_at_100_diff1': np.float64(0.3595962428150849), 'nauc_precision_at_1000_max': np.float64(0.6180240947682804), 'nauc_precision_at_1000_std': np.float64(0.5043625625020973), 'nauc_precision_at_1000_diff1': np.float64(0.26713983690727916), 'nauc_mrr_at_1_max': np.float64(0.4705538236539276), 'nauc_mrr_at_1_std': np.float64(-0.058784589924181264), 'nauc_mrr_at_1_diff1': np.float64(0.5586960705076397), 'nauc_mrr_at_3_max': np.float64(0.43715739329406483), 'nauc_mrr_at_3_std': np.float64(-0.05578045127686905), 'nauc_mrr_at_3_diff1': np.float64(0.5062583328599041), 'nauc_mrr_at_5_max': np.float64(0.44506965120497405), 'nauc_mrr_at_5_std': np.float64(-0.04750545663729009), 'nauc_mrr_at_5_diff1': np.float64(0.5039749240776535), 'nauc_mrr_at_10_max': np.float64(0.4440807062760643), 'nauc_mrr_at_10_std': np.float64(-0.04468313245045792), 'nauc_mrr_at_10_diff1': np.float64(0.4962892380511699), 'nauc_mrr_at_20_max': np.float64(0.4436478366100422), 'nauc_mrr_at_20_std': np.float64(-0.04357356693958735), 'nauc_mrr_at_20_diff1': np.float64(0.4974509233090044), 'nauc_mrr_at_100_max': np.float64(0.4450275819616694), 'nauc_mrr_at_100_std': np.float64(-0.038660364252145515), 'nauc_mrr_at_100_diff1': np.float64(0.49560258641813304), 'nauc_mrr_at_1000_max': np.float64(0.44504849728519563), 'nauc_mrr_at_1000_std': np.float64(-0.038992619454156975), 'nauc_mrr_at_1000_diff1': np.float64(0.4955255586619396), 'main_score': 0.30869}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 29.25it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:08,  5.72s/it]Batches:  15%|█▌        | 2/13 [00:16<01:37,  8.85s/it]Batches:  23%|██▎       | 3/13 [00:27<01:38,  9.87s/it]Batches:  31%|███       | 4/13 [00:38<01:33, 10.36s/it]Batches:  38%|███▊      | 5/13 [00:50<01:25, 10.63s/it]Batches:  46%|████▌     | 6/13 [01:01<01:15, 10.81s/it]Batches:  54%|█████▍    | 7/13 [01:12<01:05, 10.91s/it]Batches:  62%|██████▏   | 8/13 [01:23<00:54, 10.99s/it]Batches:  69%|██████▉   | 9/13 [01:34<00:44, 11.04s/it]Batches:  77%|███████▋  | 10/13 [01:45<00:33, 11.08s/it]Batches:  85%|████████▍ | 11/13 [01:56<00:22, 11.10s/it]Batches:  92%|█████████▏| 12/13 [02:08<00:11, 11.11s/it]Batches: 100%|██████████| 13/13 [02:19<00:00, 11.12s/it]Batches: 100%|██████████| 13/13 [02:19<00:00, 10.71s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 145.72 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 145.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.21, 'ndcg_at_3': 0.25839, 'ndcg_at_5': 0.27496, 'ndcg_at_10': 0.29422, 'ndcg_at_20': 0.31017, 'ndcg_at_100': 0.33265, 'ndcg_at_1000': 0.36357, 'map_at_1': 0.21, 'map_at_3': 0.24583, 'map_at_5': 0.25508, 'map_at_10': 0.26295, 'map_at_20': 0.26708, 'map_at_100': 0.26991, 'map_at_1000': 0.27095, 'recall_at_1': 0.21, 'recall_at_3': 0.295, 'recall_at_5': 0.335, 'recall_at_10': 0.395, 'recall_at_20': 0.46, 'recall_at_100': 0.585, 'recall_at_1000': 0.835, 'precision_at_1': 0.21, 'precision_at_3': 0.09833, 'precision_at_5': 0.067, 'precision_at_10': 0.0395, 'precision_at_20': 0.023, 'precision_at_100': 0.00585, 'precision_at_1000': 0.00084, 'mrr_at_1': 0.21, 'mrr_at_3': 0.24583333333333335, 'mrr_at_5': 0.25508333333333333, 'mrr_at_10': 0.2629464285714287, 'mrr_at_20': 0.26707917877616033, 'mrr_at_100': 0.2699074844783189, 'mrr_at_1000': 0.27094814561293573, 'nauc_ndcg_at_1_max': np.float64(0.5890224397041822), 'nauc_ndcg_at_1_std': np.float64(-0.06044626031323742), 'nauc_ndcg_at_1_diff1': np.float64(0.6437597985652526), 'nauc_ndcg_at_3_max': np.float64(0.5584074268194473), 'nauc_ndcg_at_3_std': np.float64(-0.038877830654709296), 'nauc_ndcg_at_3_diff1': np.float64(0.5941871898787882), 'nauc_ndcg_at_5_max': np.float64(0.5546463616504773), 'nauc_ndcg_at_5_std': np.float64(-0.03270964849256897), 'nauc_ndcg_at_5_diff1': np.float64(0.6001032735514831), 'nauc_ndcg_at_10_max': np.float64(0.5495709356998074), 'nauc_ndcg_at_10_std': np.float64(-0.009903153000061426), 'nauc_ndcg_at_10_diff1': np.float64(0.5855860402088727), 'nauc_ndcg_at_20_max': np.float64(0.5334021632144429), 'nauc_ndcg_at_20_std': np.float64(-0.0292445969650835), 'nauc_ndcg_at_20_diff1': np.float64(0.5743342832932331), 'nauc_ndcg_at_100_max': np.float64(0.5492838888900472), 'nauc_ndcg_at_100_std': np.float64(0.014018667337782901), 'nauc_ndcg_at_100_diff1': np.float64(0.5802480477342637), 'nauc_ndcg_at_1000_max': np.float64(0.5527261730583227), 'nauc_ndcg_at_1000_std': np.float64(0.015365660275101606), 'nauc_ndcg_at_1000_diff1': np.float64(0.5699912603235107), 'nauc_map_at_1_max': np.float64(0.5890224397041822), 'nauc_map_at_1_std': np.float64(-0.06044626031323742), 'nauc_map_at_1_diff1': np.float64(0.6437597985652526), 'nauc_map_at_3_max': np.float64(0.5655388339621944), 'nauc_map_at_3_std': np.float64(-0.04295974260959779), 'nauc_map_at_3_diff1': np.float64(0.6056887725170285), 'nauc_map_at_5_max': np.float64(0.5634194263131953), 'nauc_map_at_5_std': np.float64(-0.03926705649959931), 'nauc_map_at_5_diff1': np.float64(0.6090842844289199), 'nauc_map_at_10_max': np.float64(0.5605663848880248), 'nauc_map_at_10_std': np.float64(-0.029242256541835446), 'nauc_map_at_10_diff1': np.float64(0.6023176407829586), 'nauc_map_at_20_max': np.float64(0.5554448313082759), 'nauc_map_at_20_std': np.float64(-0.035068836554058784), 'nauc_map_at_20_diff1': np.float64(0.5994845168527906), 'nauc_map_at_100_max': np.float64(0.5573981154342734), 'nauc_map_at_100_std': np.float64(-0.02890453697300498), 'nauc_map_at_100_diff1': np.float64(0.599754447437361), 'nauc_map_at_1000_max': np.float64(0.5573641723030943), 'nauc_map_at_1000_std': np.float64(-0.028809539494729766), 'nauc_map_at_1000_diff1': np.float64(0.5993055629941758), 'nauc_recall_at_1_max': np.float64(0.5890224397041822), 'nauc_recall_at_1_std': np.float64(-0.06044626031323742), 'nauc_recall_at_1_diff1': np.float64(0.6437597985652526), 'nauc_recall_at_3_max': np.float64(0.5394072731978776), 'nauc_recall_at_3_std': np.float64(-0.02834898816862281), 'nauc_recall_at_3_diff1': np.float64(0.5635604476442824), 'nauc_recall_at_5_max': np.float64(0.5311543339818973), 'nauc_recall_at_5_std': np.float64(-0.015293281713804032), 'nauc_recall_at_5_diff1': np.float64(0.5772732404093258), 'nauc_recall_at_10_max': np.float64(0.5205718967953392), 'nauc_recall_at_10_std': np.float64(0.04711825695353978), 'nauc_recall_at_10_diff1': np.float64(0.5395469472814901), 'nauc_recall_at_20_max': np.float64(0.4650600509842053), 'nauc_recall_at_20_std': np.float64(-0.020019184778323842), 'nauc_recall_at_20_diff1': np.float64(0.4956242937110719), 'nauc_recall_at_100_max': np.float64(0.547493451820722), 'nauc_recall_at_100_std': np.float64(0.2115773268836503), 'nauc_recall_at_100_diff1': np.float64(0.5279182261912576), 'nauc_recall_at_1000_max': np.float64(0.6153536378009135), 'nauc_recall_at_1000_std': np.float64(0.4180115144825946), 'nauc_recall_at_1000_diff1': np.float64(0.3298034185484597), 'nauc_precision_at_1_max': np.float64(0.5890224397041822), 'nauc_precision_at_1_std': np.float64(-0.06044626031323742), 'nauc_precision_at_1_diff1': np.float64(0.6437597985652526), 'nauc_precision_at_3_max': np.float64(0.5394072731978777), 'nauc_precision_at_3_std': np.float64(-0.02834898816862272), 'nauc_precision_at_3_diff1': np.float64(0.5635604476442821), 'nauc_precision_at_5_max': np.float64(0.531154333981898), 'nauc_precision_at_5_std': np.float64(-0.01529328171380355), 'nauc_precision_at_5_diff1': np.float64(0.5772732404093264), 'nauc_precision_at_10_max': np.float64(0.5205718967953392), 'nauc_precision_at_10_std': np.float64(0.04711825695354005), 'nauc_precision_at_10_diff1': np.float64(0.5395469472814903), 'nauc_precision_at_20_max': np.float64(0.46506005098420566), 'nauc_precision_at_20_std': np.float64(-0.02001918477832353), 'nauc_precision_at_20_diff1': np.float64(0.4956242937110718), 'nauc_precision_at_100_max': np.float64(0.5474934518207223), 'nauc_precision_at_100_std': np.float64(0.21157732688365083), 'nauc_precision_at_100_diff1': np.float64(0.5279182261912579), 'nauc_precision_at_1000_max': np.float64(0.6153536378009128), 'nauc_precision_at_1000_std': np.float64(0.41801151448259366), 'nauc_precision_at_1000_diff1': np.float64(0.3298034185484586), 'nauc_mrr_at_1_max': np.float64(0.5890224397041822), 'nauc_mrr_at_1_std': np.float64(-0.06044626031323742), 'nauc_mrr_at_1_diff1': np.float64(0.6437597985652526), 'nauc_mrr_at_3_max': np.float64(0.5655388339621944), 'nauc_mrr_at_3_std': np.float64(-0.04295974260959779), 'nauc_mrr_at_3_diff1': np.float64(0.6056887725170285), 'nauc_mrr_at_5_max': np.float64(0.5634194263131953), 'nauc_mrr_at_5_std': np.float64(-0.03926705649959931), 'nauc_mrr_at_5_diff1': np.float64(0.6090842844289199), 'nauc_mrr_at_10_max': np.float64(0.5605663848880248), 'nauc_mrr_at_10_std': np.float64(-0.029242256541835446), 'nauc_mrr_at_10_diff1': np.float64(0.6023176407829586), 'nauc_mrr_at_20_max': np.float64(0.5554448313082759), 'nauc_mrr_at_20_std': np.float64(-0.035068836554058784), 'nauc_mrr_at_20_diff1': np.float64(0.5994845168527906), 'nauc_mrr_at_100_max': np.float64(0.5573981154342734), 'nauc_mrr_at_100_std': np.float64(-0.02890453697300498), 'nauc_mrr_at_100_diff1': np.float64(0.599754447437361), 'nauc_mrr_at_1000_max': np.float64(0.5573641723030943), 'nauc_mrr_at_1000_std': np.float64(-0.028809539494729766), 'nauc_mrr_at_1000_diff1': np.float64(0.5993055629941758), 'main_score': 0.29422}}



==================================================
Running model: intfloat/multilingual-e5-large
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/multilingual-e5-large
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'query': 'query: ', 'passage': 'passage: '}
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / intfloat/multilingual-e5-large on GPU 0 in process Process-8
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  1.00it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.88it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:07,  2.56it/s]Batches:  11%|█         | 2/19 [00:11<01:52,  6.60s/it]Batches:  16%|█▌        | 3/19 [00:20<02:02,  7.63s/it]Batches:  21%|██        | 4/19 [00:27<01:50,  7.34s/it]Batches:  26%|██▋       | 5/19 [00:33<01:36,  6.87s/it]Batches:  32%|███▏      | 6/19 [00:38<01:23,  6.41s/it]Batches:  37%|███▋      | 7/19 [00:43<01:11,  5.92s/it]Batches:  42%|████▏     | 8/19 [00:48<01:00,  5.50s/it]Batches:  47%|████▋     | 9/19 [00:52<00:51,  5.12s/it]Batches:  53%|█████▎    | 10/19 [00:56<00:43,  4.83s/it]Batches:  58%|█████▊    | 11/19 [01:00<00:35,  4.43s/it]Batches:  63%|██████▎   | 12/19 [01:03<00:29,  4.15s/it]Batches:  68%|██████▊   | 13/19 [01:06<00:23,  3.87s/it]Batches:  74%|███████▎  | 14/19 [01:09<00:18,  3.63s/it]Batches:  79%|███████▉  | 15/19 [01:12<00:13,  3.35s/it]Batches:  84%|████████▍ | 16/19 [01:15<00:09,  3.06s/it]Batches:  89%|████████▉ | 17/19 [01:17<00:05,  2.80s/it]Batches:  95%|█████████▍| 18/19 [01:19<00:02,  2.50s/it]Batches: 100%|██████████| 19/19 [01:20<00:00,  2.20s/it]Batches: 100%|██████████| 19/19 [01:20<00:00,  4.24s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 82.48 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 83.09 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.76858, 'ndcg_at_3': 0.76483, 'ndcg_at_5': 0.78681, 'ndcg_at_10': 0.80348, 'ndcg_at_20': 0.81154, 'ndcg_at_100': 0.82087, 'ndcg_at_1000': 0.82835, 'map_at_1': 0.50664, 'map_at_3': 0.7275, 'map_at_5': 0.75164, 'map_at_10': 0.76374, 'map_at_20': 0.76721, 'map_at_100': 0.76914, 'map_at_1000': 0.76945, 'recall_at_1': 0.50664, 'recall_at_3': 0.7696, 'recall_at_5': 0.8158, 'recall_at_10': 0.854, 'recall_at_20': 0.87852, 'recall_at_100': 0.91833, 'recall_at_1000': 0.96585, 'precision_at_1': 0.76858, 'precision_at_3': 0.45327, 'precision_at_5': 0.29628, 'precision_at_10': 0.15794, 'precision_at_20': 0.08201, 'precision_at_100': 0.0173, 'precision_at_1000': 0.00184, 'mrr_at_1': 0.768581081081081, 'mrr_at_3': 0.8153153153153152, 'mrr_at_5': 0.8185247747747747, 'mrr_at_10': 0.8201114060489061, 'mrr_at_20': 0.821053386412326, 'mrr_at_100': 0.8218358869087574, 'mrr_at_1000': 0.8220410843903181, 'nauc_ndcg_at_1_max': np.float64(0.619783943559237), 'nauc_ndcg_at_1_std': np.float64(0.24520417021488036), 'nauc_ndcg_at_1_diff1': np.float64(0.7389675684828687), 'nauc_ndcg_at_3_max': np.float64(0.6319521302138631), 'nauc_ndcg_at_3_std': np.float64(0.2680060266389483), 'nauc_ndcg_at_3_diff1': np.float64(0.6178715093585547), 'nauc_ndcg_at_5_max': np.float64(0.6764242485744868), 'nauc_ndcg_at_5_std': np.float64(0.31694007367796995), 'nauc_ndcg_at_5_diff1': np.float64(0.6405997079687031), 'nauc_ndcg_at_10_max': np.float64(0.7146099910954262), 'nauc_ndcg_at_10_std': np.float64(0.3679914038774038), 'nauc_ndcg_at_10_diff1': np.float64(0.6465969495009757), 'nauc_ndcg_at_20_max': np.float64(0.7134715845031814), 'nauc_ndcg_at_20_std': np.float64(0.3939633225716529), 'nauc_ndcg_at_20_diff1': np.float64(0.6493928925737483), 'nauc_ndcg_at_100_max': np.float64(0.7043670261868529), 'nauc_ndcg_at_100_std': np.float64(0.3897900357789412), 'nauc_ndcg_at_100_diff1': np.float64(0.6470735358009762), 'nauc_ndcg_at_1000_max': np.float64(0.6964562175019898), 'nauc_ndcg_at_1000_std': np.float64(0.37195544642850276), 'nauc_ndcg_at_1000_diff1': np.float64(0.6472404381887801), 'nauc_map_at_1_max': np.float64(0.2905536892814776), 'nauc_map_at_1_std': np.float64(-0.011034293163808993), 'nauc_map_at_1_diff1': np.float64(0.6764732370312437), 'nauc_map_at_3_max': np.float64(0.5780731469434045), 'nauc_map_at_3_std': np.float64(0.2027741002354236), 'nauc_map_at_3_diff1': np.float64(0.6061847436353337), 'nauc_map_at_5_max': np.float64(0.6208855054942963), 'nauc_map_at_5_std': np.float64(0.24142157875599662), 'nauc_map_at_5_diff1': np.float64(0.624348386827946), 'nauc_map_at_10_max': np.float64(0.6451676187166451), 'nauc_map_at_10_std': np.float64(0.2716152727684029), 'nauc_map_at_10_diff1': np.float64(0.6267964661890997), 'nauc_map_at_20_max': np.float64(0.6448366164382613), 'nauc_map_at_20_std': np.float64(0.2819218324018119), 'nauc_map_at_20_diff1': np.float64(0.6278280584599769), 'nauc_map_at_100_max': np.float64(0.6426234475759284), 'nauc_map_at_100_std': np.float64(0.28050253193435104), 'nauc_map_at_100_diff1': np.float64(0.6270244327686766), 'nauc_map_at_1000_max': np.float64(0.6423349743441891), 'nauc_map_at_1000_std': np.float64(0.279921772861948), 'nauc_map_at_1000_diff1': np.float64(0.6270232124471452), 'nauc_recall_at_1_max': np.float64(0.2905536892814776), 'nauc_recall_at_1_std': np.float64(-0.011034293163808993), 'nauc_recall_at_1_diff1': np.float64(0.6764732370312437), 'nauc_recall_at_3_max': np.float64(0.6343809223314516), 'nauc_recall_at_3_std': np.float64(0.2911839083650689), 'nauc_recall_at_3_diff1': np.float64(0.5668709737247727), 'nauc_recall_at_5_max': np.float64(0.7341251106852447), 'nauc_recall_at_5_std': np.float64(0.40014013976984053), 'nauc_recall_at_5_diff1': np.float64(0.6047177057671275), 'nauc_recall_at_10_max': np.float64(0.8589984248699257), 'nauc_recall_at_10_std': np.float64(0.5629988195620854), 'nauc_recall_at_10_diff1': np.float64(0.6232544482810121), 'nauc_recall_at_20_max': np.float64(0.8854683603368402), 'nauc_recall_at_20_std': np.float64(0.7169948683694372), 'nauc_recall_at_20_diff1': np.float64(0.6390604871621653), 'nauc_recall_at_100_max': np.float64(0.8941415813611865), 'nauc_recall_at_100_std': np.float64(0.8389314190049417), 'nauc_recall_at_100_diff1': np.float64(0.6237038348199009), 'nauc_recall_at_1000_max': np.float64(0.9389556221977473), 'nauc_recall_at_1000_std': np.float64(0.9317786678431724), 'nauc_recall_at_1000_diff1': np.float64(0.6123484988578439), 'nauc_precision_at_1_max': np.float64(0.619783943559237), 'nauc_precision_at_1_std': np.float64(0.24520417021488036), 'nauc_precision_at_1_diff1': np.float64(0.7389675684828687), 'nauc_precision_at_3_max': np.float64(0.37286499375085813), 'nauc_precision_at_3_std': np.float64(0.30817315779367294), 'nauc_precision_at_3_diff1': np.float64(-0.06277299917404543), 'nauc_precision_at_5_max': np.float64(0.32036525771869867), 'nauc_precision_at_5_std': np.float64(0.3122024855654004), 'nauc_precision_at_5_diff1': np.float64(-0.10813798215240919), 'nauc_precision_at_10_max': np.float64(0.2909053191625467), 'nauc_precision_at_10_std': np.float64(0.3443975592990956), 'nauc_precision_at_10_diff1': np.float64(-0.16726338149009454), 'nauc_precision_at_20_max': np.float64(0.23376163020027696), 'nauc_precision_at_20_std': np.float64(0.35240442591945115), 'nauc_precision_at_20_diff1': np.float64(-0.2060497574556575), 'nauc_precision_at_100_max': np.float64(0.13535950905854507), 'nauc_precision_at_100_std': np.float64(0.3011672467378491), 'nauc_precision_at_100_diff1': np.float64(-0.28632625129297085), 'nauc_precision_at_1000_max': np.float64(0.001086350645082997), 'nauc_precision_at_1000_std': np.float64(0.1934852025821731), 'nauc_precision_at_1000_diff1': np.float64(-0.3970271186614315), 'nauc_mrr_at_1_max': np.float64(0.619783943559237), 'nauc_mrr_at_1_std': np.float64(0.24520417021488036), 'nauc_mrr_at_1_diff1': np.float64(0.7389675684828687), 'nauc_mrr_at_3_max': np.float64(0.7146021491140149), 'nauc_mrr_at_3_std': np.float64(0.37798793931652225), 'nauc_mrr_at_3_diff1': np.float64(0.7173884183805199), 'nauc_mrr_at_5_max': np.float64(0.7148505549807599), 'nauc_mrr_at_5_std': np.float64(0.38756856589650296), 'nauc_mrr_at_5_diff1': np.float64(0.7175885111599681), 'nauc_mrr_at_10_max': np.float64(0.7150939227839377), 'nauc_mrr_at_10_std': np.float64(0.38803096948772753), 'nauc_mrr_at_10_diff1': np.float64(0.7180161399152217), 'nauc_mrr_at_20_max': np.float64(0.7139552353200426), 'nauc_mrr_at_20_std': np.float64(0.38946641086329103), 'nauc_mrr_at_20_diff1': np.float64(0.7178663921394264), 'nauc_mrr_at_100_max': np.float64(0.7129788361602002), 'nauc_mrr_at_100_std': np.float64(0.38805260787614737), 'nauc_mrr_at_100_diff1': np.float64(0.7176454571697286), 'nauc_mrr_at_1000_max': np.float64(0.7127501760528012), 'nauc_mrr_at_1000_std': np.float64(0.38744516297651393), 'nauc_mrr_at_1000_diff1': np.float64(0.717726508368629), 'main_score': 0.80348}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 27.87it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.61it/s]Batches: 100%|██████████| 2/2 [00:11<00:00,  6.70s/it]Batches: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 15.19 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 15.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.67544, 'ndcg_at_3': 0.78039, 'ndcg_at_5': 0.79889, 'ndcg_at_10': 0.81337, 'ndcg_at_20': 0.82015, 'ndcg_at_100': 0.82677, 'ndcg_at_1000': 0.82677, 'map_at_1': 0.67544, 'map_at_3': 0.75585, 'map_at_5': 0.76637, 'map_at_10': 0.77253, 'map_at_20': 0.77446, 'map_at_100': 0.77541, 'map_at_1000': 0.77541, 'recall_at_1': 0.67544, 'recall_at_3': 0.85088, 'recall_at_5': 0.89474, 'recall_at_10': 0.9386, 'recall_at_20': 0.96491, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.67544, 'precision_at_3': 0.28363, 'precision_at_5': 0.17895, 'precision_at_10': 0.09386, 'precision_at_20': 0.04825, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6754385964912281, 'mrr_at_3': 0.7558479532163744, 'mrr_at_5': 0.766374269005848, 'mrr_at_10': 0.7725250626566417, 'mrr_at_20': 0.7744555517581834, 'mrr_at_100': 0.77540714333768, 'mrr_at_1000': 0.77540714333768, 'nauc_ndcg_at_1_max': np.float64(0.08574937709970755), 'nauc_ndcg_at_1_std': np.float64(-0.6246105689080378), 'nauc_ndcg_at_1_diff1': np.float64(0.7283217227535123), 'nauc_ndcg_at_3_max': np.float64(0.11876515078143252), 'nauc_ndcg_at_3_std': np.float64(-0.6295132308461416), 'nauc_ndcg_at_3_diff1': np.float64(0.6802176246485789), 'nauc_ndcg_at_5_max': np.float64(0.1710880020518264), 'nauc_ndcg_at_5_std': np.float64(-0.623544324755987), 'nauc_ndcg_at_5_diff1': np.float64(0.65782040297904), 'nauc_ndcg_at_10_max': np.float64(0.16337846477607224), 'nauc_ndcg_at_10_std': np.float64(-0.6439472422010555), 'nauc_ndcg_at_10_diff1': np.float64(0.6534305228357417), 'nauc_ndcg_at_20_max': np.float64(0.15154965569273673), 'nauc_ndcg_at_20_std': np.float64(-0.62529669477198), 'nauc_ndcg_at_20_diff1': np.float64(0.6532504040101259), 'nauc_ndcg_at_100_max': np.float64(0.13930225357339482), 'nauc_ndcg_at_100_std': np.float64(-0.6349323465994774), 'nauc_ndcg_at_100_diff1': np.float64(0.6798177496497114), 'nauc_ndcg_at_1000_max': np.float64(0.13930225357339482), 'nauc_ndcg_at_1000_std': np.float64(-0.6349323465994774), 'nauc_ndcg_at_1000_diff1': np.float64(0.6798177496497114), 'nauc_map_at_1_max': np.float64(0.08574937709970755), 'nauc_map_at_1_std': np.float64(-0.6246105689080378), 'nauc_map_at_1_diff1': np.float64(0.7283217227535123), 'nauc_map_at_3_max': np.float64(0.11334045087831807), 'nauc_map_at_3_std': np.float64(-0.6298824326505806), 'nauc_map_at_3_diff1': np.float64(0.6952310170994932), 'nauc_map_at_5_max': np.float64(0.13942038403835927), 'nauc_map_at_5_std': np.float64(-0.6274947494869828), 'nauc_map_at_5_diff1': np.float64(0.6844736565258235), 'nauc_map_at_10_max': np.float64(0.13476353281143322), 'nauc_map_at_10_std': np.float64(-0.63489540113429), 'nauc_map_at_10_diff1': np.float64(0.6837187235611711), 'nauc_map_at_20_max': np.float64(0.1313812162496074), 'nauc_map_at_20_std': np.float64(-0.6315026415983667), 'nauc_map_at_20_diff1': np.float64(0.6838263576041446), 'nauc_map_at_100_max': np.float64(0.13028712605706078), 'nauc_map_at_100_std': np.float64(-0.6333480833690052), 'nauc_map_at_100_diff1': np.float64(0.6882626899425819), 'nauc_map_at_1000_max': np.float64(0.13028712605706078), 'nauc_map_at_1000_std': np.float64(-0.6333480833690052), 'nauc_map_at_1000_diff1': np.float64(0.6882626899425819), 'nauc_recall_at_1_max': np.float64(0.08574937709970755), 'nauc_recall_at_1_std': np.float64(-0.6246105689080378), 'nauc_recall_at_1_diff1': np.float64(0.7283217227535123), 'nauc_recall_at_3_max': np.float64(0.13934586595258888), 'nauc_recall_at_3_std': np.float64(-0.6267492848843966), 'nauc_recall_at_3_diff1': np.float64(0.6150080982680903), 'nauc_recall_at_5_max': np.float64(0.35829210769325465), 'nauc_recall_at_5_std': np.float64(-0.5967482390704182), 'nauc_recall_at_5_diff1': np.float64(0.5019388400138263), 'nauc_recall_at_10_max': np.float64(0.44178729100383596), 'nauc_recall_at_10_std': np.float64(-0.7449071731142182), 'nauc_recall_at_10_diff1': np.float64(0.3576107205133534), 'nauc_recall_at_20_max': np.float64(0.4593222978687574), 'nauc_recall_at_20_std': np.float64(-0.45587797040779265), 'nauc_recall_at_20_diff1': np.float64(0.13838797981732298), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.08574937709970755), 'nauc_precision_at_1_std': np.float64(-0.6246105689080378), 'nauc_precision_at_1_diff1': np.float64(0.7283217227535123), 'nauc_precision_at_3_max': np.float64(0.13934586595258922), 'nauc_precision_at_3_std': np.float64(-0.6267492848843961), 'nauc_precision_at_3_diff1': np.float64(0.6150080982680898), 'nauc_precision_at_5_max': np.float64(0.3582921076932564), 'nauc_precision_at_5_std': np.float64(-0.5967482390704195), 'nauc_precision_at_5_diff1': np.float64(0.5019388400138272), 'nauc_precision_at_10_max': np.float64(0.4417872910038361), 'nauc_precision_at_10_std': np.float64(-0.7449071731142188), 'nauc_precision_at_10_diff1': np.float64(0.3576107205133529), 'nauc_precision_at_20_max': np.float64(0.4593222978687597), 'nauc_precision_at_20_std': np.float64(-0.4558779704077904), 'nauc_precision_at_20_diff1': np.float64(0.13838797981732007), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.08574937709970755), 'nauc_mrr_at_1_std': np.float64(-0.6246105689080378), 'nauc_mrr_at_1_diff1': np.float64(0.7283217227535123), 'nauc_mrr_at_3_max': np.float64(0.11334045087831807), 'nauc_mrr_at_3_std': np.float64(-0.6298824326505806), 'nauc_mrr_at_3_diff1': np.float64(0.6952310170994932), 'nauc_mrr_at_5_max': np.float64(0.13942038403835927), 'nauc_mrr_at_5_std': np.float64(-0.6274947494869828), 'nauc_mrr_at_5_diff1': np.float64(0.6844736565258235), 'nauc_mrr_at_10_max': np.float64(0.13476353281143322), 'nauc_mrr_at_10_std': np.float64(-0.63489540113429), 'nauc_mrr_at_10_diff1': np.float64(0.6837187235611711), 'nauc_mrr_at_20_max': np.float64(0.1313812162496074), 'nauc_mrr_at_20_std': np.float64(-0.6315026415983667), 'nauc_mrr_at_20_diff1': np.float64(0.6838263576041446), 'nauc_mrr_at_100_max': np.float64(0.13028712605706078), 'nauc_mrr_at_100_std': np.float64(-0.6333480833690052), 'nauc_mrr_at_100_diff1': np.float64(0.6882626899425819), 'nauc_mrr_at_1000_max': np.float64(0.13028712605706078), 'nauc_mrr_at_1000_std': np.float64(-0.6333480833690052), 'nauc_mrr_at_1000_diff1': np.float64(0.6882626899425819), 'main_score': 0.81337}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 23.37it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.91 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 2.00 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.68831, 'ndcg_at_3': 0.79313, 'ndcg_at_5': 0.80375, 'ndcg_at_10': 0.82534, 'ndcg_at_20': 0.83183, 'ndcg_at_100': 0.83718, 'ndcg_at_1000': 0.83718, 'map_at_1': 0.68831, 'map_at_3': 0.77056, 'map_at_5': 0.77641, 'map_at_10': 0.78566, 'map_at_20': 0.78739, 'map_at_100': 0.78832, 'map_at_1000': 0.78832, 'recall_at_1': 0.68831, 'recall_at_3': 0.85714, 'recall_at_5': 0.88312, 'recall_at_10': 0.94805, 'recall_at_20': 0.97403, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.68831, 'precision_at_3': 0.28571, 'precision_at_5': 0.17662, 'precision_at_10': 0.09481, 'precision_at_20': 0.0487, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6883116883116883, 'mrr_at_3': 0.7705627705627704, 'mrr_at_5': 0.7764069264069264, 'mrr_at_10': 0.785657596371882, 'mrr_at_20': 0.7873891981034838, 'mrr_at_100': 0.7883238694927007, 'mrr_at_1000': 0.7883238694927007, 'nauc_ndcg_at_1_max': np.float64(0.2317241170179748), 'nauc_ndcg_at_1_std': np.float64(-0.192793491783307), 'nauc_ndcg_at_1_diff1': np.float64(0.8302946692246838), 'nauc_ndcg_at_3_max': np.float64(0.2165935406595234), 'nauc_ndcg_at_3_std': np.float64(-0.3575105094880901), 'nauc_ndcg_at_3_diff1': np.float64(0.7916549180462429), 'nauc_ndcg_at_5_max': np.float64(0.22129779544783112), 'nauc_ndcg_at_5_std': np.float64(-0.3642016640354031), 'nauc_ndcg_at_5_diff1': np.float64(0.7943239308426), 'nauc_ndcg_at_10_max': np.float64(0.21930105422089738), 'nauc_ndcg_at_10_std': np.float64(-0.2823488334907109), 'nauc_ndcg_at_10_diff1': np.float64(0.791163555666361), 'nauc_ndcg_at_20_max': np.float64(0.22971240795889006), 'nauc_ndcg_at_20_std': np.float64(-0.2571618122570241), 'nauc_ndcg_at_20_diff1': np.float64(0.7946105403995175), 'nauc_ndcg_at_100_max': np.float64(0.22376165537986312), 'nauc_ndcg_at_100_std': np.float64(-0.2845177705394917), 'nauc_ndcg_at_100_diff1': np.float64(0.800535416072367), 'nauc_ndcg_at_1000_max': np.float64(0.22376165537986312), 'nauc_ndcg_at_1000_std': np.float64(-0.2845177705394917), 'nauc_ndcg_at_1000_diff1': np.float64(0.800535416072367), 'nauc_map_at_1_max': np.float64(0.2317241170179748), 'nauc_map_at_1_std': np.float64(-0.192793491783307), 'nauc_map_at_1_diff1': np.float64(0.8302946692246838), 'nauc_map_at_3_max': np.float64(0.2221615156737509), 'nauc_map_at_3_std': np.float64(-0.30766923209187896), 'nauc_map_at_3_diff1': np.float64(0.8022516732629955), 'nauc_map_at_5_max': np.float64(0.2241716349857892), 'nauc_map_at_5_std': np.float64(-0.3102630334004927), 'nauc_map_at_5_diff1': np.float64(0.8036926446757969), 'nauc_map_at_10_max': np.float64(0.22230817835873698), 'nauc_map_at_10_std': np.float64(-0.2806074153409453), 'nauc_map_at_10_diff1': np.float64(0.8025655422786346), 'nauc_map_at_20_max': np.float64(0.2245496806184615), 'nauc_map_at_20_std': np.float64(-0.27523588788328135), 'nauc_map_at_20_diff1': np.float64(0.8034037360099546), 'nauc_map_at_100_max': np.float64(0.22404852716375828), 'nauc_map_at_100_std': np.float64(-0.27881068564841477), 'nauc_map_at_100_diff1': np.float64(0.8042948615488029), 'nauc_map_at_1000_max': np.float64(0.22404852716375828), 'nauc_map_at_1000_std': np.float64(-0.27881068564841477), 'nauc_map_at_1000_diff1': np.float64(0.8042948615488029), 'nauc_recall_at_1_max': np.float64(0.2317241170179748), 'nauc_recall_at_1_std': np.float64(-0.192793491783307), 'nauc_recall_at_1_diff1': np.float64(0.8302946692246838), 'nauc_recall_at_3_max': np.float64(0.19238123933939866), 'nauc_recall_at_3_std': np.float64(-0.5686316973323894), 'nauc_recall_at_3_diff1': np.float64(0.7474623592532373), 'nauc_recall_at_5_max': np.float64(0.2084956723767503), 'nauc_recall_at_5_std': np.float64(-0.6310025883818963), 'nauc_recall_at_5_diff1': np.float64(0.7498540019990096), 'nauc_recall_at_10_max': np.float64(0.1981185792546231), 'nauc_recall_at_10_std': np.float64(-0.18261458357572427), 'nauc_recall_at_10_diff1': np.float64(0.6752521641350948), 'nauc_recall_at_20_max': np.float64(0.41670903386108427), 'nauc_recall_at_20_std': np.float64(0.4971754420232289), 'nauc_recall_at_20_diff1': np.float64(0.6387246499035979), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2317241170179748), 'nauc_precision_at_1_std': np.float64(-0.192793491783307), 'nauc_precision_at_1_diff1': np.float64(0.8302946692246838), 'nauc_precision_at_3_max': np.float64(0.19238123933939982), 'nauc_precision_at_3_std': np.float64(-0.5686316973323878), 'nauc_precision_at_3_diff1': np.float64(0.7474623592532387), 'nauc_precision_at_5_max': np.float64(0.20849567237675368), 'nauc_precision_at_5_std': np.float64(-0.6310025883818912), 'nauc_precision_at_5_diff1': np.float64(0.7498540019990121), 'nauc_precision_at_10_max': np.float64(0.1981185792546289), 'nauc_precision_at_10_std': np.float64(-0.18261458357571947), 'nauc_precision_at_10_diff1': np.float64(0.6752521641350954), 'nauc_precision_at_20_max': np.float64(0.4167090338610833), 'nauc_precision_at_20_std': np.float64(0.49717544202323205), 'nauc_precision_at_20_diff1': np.float64(0.6387246499035996), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.2317241170179748), 'nauc_mrr_at_1_std': np.float64(-0.192793491783307), 'nauc_mrr_at_1_diff1': np.float64(0.8302946692246838), 'nauc_mrr_at_3_max': np.float64(0.2221615156737509), 'nauc_mrr_at_3_std': np.float64(-0.30766923209187896), 'nauc_mrr_at_3_diff1': np.float64(0.8022516732629955), 'nauc_mrr_at_5_max': np.float64(0.2241716349857892), 'nauc_mrr_at_5_std': np.float64(-0.3102630334004927), 'nauc_mrr_at_5_diff1': np.float64(0.8036926446757969), 'nauc_mrr_at_10_max': np.float64(0.22230817835873698), 'nauc_mrr_at_10_std': np.float64(-0.2806074153409453), 'nauc_mrr_at_10_diff1': np.float64(0.8025655422786346), 'nauc_mrr_at_20_max': np.float64(0.2245496806184615), 'nauc_mrr_at_20_std': np.float64(-0.27523588788328135), 'nauc_mrr_at_20_diff1': np.float64(0.8034037360099546), 'nauc_mrr_at_100_max': np.float64(0.22404852716375828), 'nauc_mrr_at_100_std': np.float64(-0.27881068564841477), 'nauc_mrr_at_100_diff1': np.float64(0.8042948615488029), 'nauc_mrr_at_1000_max': np.float64(0.22404852716375828), 'nauc_mrr_at_1000_std': np.float64(-0.27881068564841477), 'nauc_mrr_at_1000_diff1': np.float64(0.8042948615488029), 'main_score': 0.82534}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.79 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.67 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.16it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.06 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 26.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.90556, 'ndcg_at_3': 0.93872, 'ndcg_at_5': 0.94149, 'ndcg_at_10': 0.94499, 'ndcg_at_20': 0.94703, 'ndcg_at_100': 0.94834, 'ndcg_at_1000': 0.94925, 'map_at_1': 0.90556, 'map_at_3': 0.93093, 'map_at_5': 0.93248, 'map_at_10': 0.93387, 'map_at_20': 0.93447, 'map_at_100': 0.93468, 'map_at_1000': 0.93472, 'recall_at_1': 0.90556, 'recall_at_3': 0.96111, 'recall_at_5': 0.96778, 'recall_at_10': 0.97889, 'recall_at_20': 0.98667, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.90556, 'precision_at_3': 0.32037, 'precision_at_5': 0.19356, 'precision_at_10': 0.09789, 'precision_at_20': 0.04933, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.9055555555555556, 'mrr_at_3': 0.9309259259259258, 'mrr_at_5': 0.9324814814814814, 'mrr_at_10': 0.9338730158730159, 'mrr_at_20': 0.9344692159692158, 'mrr_at_100': 0.9346750637504948, 'mrr_at_1000': 0.9347165982343034, 'nauc_ndcg_at_1_max': np.float64(0.7965178228154025), 'nauc_ndcg_at_1_std': np.float64(0.18032075575328102), 'nauc_ndcg_at_1_diff1': np.float64(0.9256329982973587), 'nauc_ndcg_at_3_max': np.float64(0.8486196504258102), 'nauc_ndcg_at_3_std': np.float64(0.2244037110917959), 'nauc_ndcg_at_3_diff1': np.float64(0.93419337625773), 'nauc_ndcg_at_5_max': np.float64(0.845513221904975), 'nauc_ndcg_at_5_std': np.float64(0.23060011579652634), 'nauc_ndcg_at_5_diff1': np.float64(0.9343058150714209), 'nauc_ndcg_at_10_max': np.float64(0.8392724958204727), 'nauc_ndcg_at_10_std': np.float64(0.2174409681677675), 'nauc_ndcg_at_10_diff1': np.float64(0.9327072401603272), 'nauc_ndcg_at_20_max': np.float64(0.8337744839486585), 'nauc_ndcg_at_20_std': np.float64(0.2183668124786509), 'nauc_ndcg_at_20_diff1': np.float64(0.9328766716345652), 'nauc_ndcg_at_100_max': np.float64(0.8318347592999481), 'nauc_ndcg_at_100_std': np.float64(0.2253928671613762), 'nauc_ndcg_at_100_diff1': np.float64(0.9311689837709294), 'nauc_ndcg_at_1000_max': np.float64(0.8308367681918263), 'nauc_ndcg_at_1000_std': np.float64(0.21661583693444478), 'nauc_ndcg_at_1000_diff1': np.float64(0.9311047013723796), 'nauc_map_at_1_max': np.float64(0.7965178228154025), 'nauc_map_at_1_std': np.float64(0.18032075575328102), 'nauc_map_at_1_diff1': np.float64(0.9256329982973587), 'nauc_map_at_3_max': np.float64(0.83250476240541), 'nauc_map_at_3_std': np.float64(0.21031933774403588), 'nauc_map_at_3_diff1': np.float64(0.931054638119769), 'nauc_map_at_5_max': np.float64(0.8305281154334097), 'nauc_map_at_5_std': np.float64(0.21305404590067914), 'nauc_map_at_5_diff1': np.float64(0.9310392469293455), 'nauc_map_at_10_max': np.float64(0.8282339553413531), 'nauc_map_at_10_std': np.float64(0.2077632421187409), 'nauc_map_at_10_diff1': np.float64(0.9304875708217899), 'nauc_map_at_20_max': np.float64(0.8268189860529359), 'nauc_map_at_20_std': np.float64(0.20806536983957427), 'nauc_map_at_20_diff1': np.float64(0.9304567434737736), 'nauc_map_at_100_max': np.float64(0.8265563740476617), 'nauc_map_at_100_std': np.float64(0.20923759828213495), 'nauc_map_at_100_diff1': np.float64(0.9302376031901283), 'nauc_map_at_1000_max': np.float64(0.8265114039753071), 'nauc_map_at_1000_std': np.float64(0.20890868954346548), 'nauc_map_at_1000_diff1': np.float64(0.930227758709326), 'nauc_recall_at_1_max': np.float64(0.7965178228154025), 'nauc_recall_at_1_std': np.float64(0.18032075575328102), 'nauc_recall_at_1_diff1': np.float64(0.9256329982973587), 'nauc_recall_at_3_max': np.float64(0.9304388422035459), 'nauc_recall_at_3_std': np.float64(0.29626517273576003), 'nauc_recall_at_3_diff1': np.float64(0.9505135387488312), 'nauc_recall_at_5_max': np.float64(0.9346405228758145), 'nauc_recall_at_5_std': np.float64(0.3377603915129274), 'nauc_recall_at_5_diff1': np.float64(0.9543610547667313), 'nauc_recall_at_10_max': np.float64(0.9286205710354343), 'nauc_recall_at_10_std': np.float64(0.29566563467492946), 'nauc_recall_at_10_diff1': np.float64(0.9509803921568633), 'nauc_recall_at_20_max': np.float64(0.8978758169934619), 'nauc_recall_at_20_std': np.float64(0.349634298163714), 'nauc_recall_at_20_diff1': np.float64(0.9659586056644808), 'nauc_recall_at_100_max': np.float64(0.8856209150326758), 'nauc_recall_at_100_std': np.float64(0.7176314970432669), 'nauc_recall_at_100_diff1': np.float64(0.9319172113289615), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7965178228154025), 'nauc_precision_at_1_std': np.float64(0.18032075575328102), 'nauc_precision_at_1_diff1': np.float64(0.9256329982973587), 'nauc_precision_at_3_max': np.float64(0.9304388422035507), 'nauc_precision_at_3_std': np.float64(0.2962651727357632), 'nauc_precision_at_3_diff1': np.float64(0.9505135387488309), 'nauc_precision_at_5_max': np.float64(0.9346405228758145), 'nauc_precision_at_5_std': np.float64(0.33776039151291765), 'nauc_precision_at_5_diff1': np.float64(0.9543610547667292), 'nauc_precision_at_10_max': np.float64(0.9286205710354282), 'nauc_precision_at_10_std': np.float64(0.29566563467491047), 'nauc_precision_at_10_diff1': np.float64(0.9509803921568587), 'nauc_precision_at_20_max': np.float64(0.8978758169934673), 'nauc_precision_at_20_std': np.float64(0.3496342981637061), 'nauc_precision_at_20_diff1': np.float64(0.965958605664485), 'nauc_precision_at_100_max': np.float64(0.8856209150326616), 'nauc_precision_at_100_std': np.float64(0.7176314970432794), 'nauc_precision_at_100_diff1': np.float64(0.9319172113289566), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7965178228154025), 'nauc_mrr_at_1_std': np.float64(0.18032075575328102), 'nauc_mrr_at_1_diff1': np.float64(0.9256329982973587), 'nauc_mrr_at_3_max': np.float64(0.83250476240541), 'nauc_mrr_at_3_std': np.float64(0.21031933774403588), 'nauc_mrr_at_3_diff1': np.float64(0.931054638119769), 'nauc_mrr_at_5_max': np.float64(0.8305281154334097), 'nauc_mrr_at_5_std': np.float64(0.21305404590067914), 'nauc_mrr_at_5_diff1': np.float64(0.9310392469293455), 'nauc_mrr_at_10_max': np.float64(0.8282339553413531), 'nauc_mrr_at_10_std': np.float64(0.2077632421187409), 'nauc_mrr_at_10_diff1': np.float64(0.9304875708217899), 'nauc_mrr_at_20_max': np.float64(0.8268189860529359), 'nauc_mrr_at_20_std': np.float64(0.20806536983957427), 'nauc_mrr_at_20_diff1': np.float64(0.9304567434737736), 'nauc_mrr_at_100_max': np.float64(0.8265563740476617), 'nauc_mrr_at_100_std': np.float64(0.20923759828213495), 'nauc_mrr_at_100_diff1': np.float64(0.9302376031901283), 'nauc_mrr_at_1000_max': np.float64(0.8265114039753071), 'nauc_mrr_at_1000_std': np.float64(0.20890868954346548), 'nauc_mrr_at_1000_diff1': np.float64(0.930227758709326), 'main_score': 0.94499}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.85667, 'ndcg_at_3': 0.9045, 'ndcg_at_5': 0.91305, 'ndcg_at_10': 0.92031, 'ndcg_at_20': 0.92293, 'ndcg_at_100': 0.92405, 'ndcg_at_1000': 0.92436, 'map_at_1': 0.85667, 'map_at_3': 0.89296, 'map_at_5': 0.89763, 'map_at_10': 0.90067, 'map_at_20': 0.90143, 'map_at_100': 0.90155, 'map_at_1000': 0.90157, 'recall_at_1': 0.85667, 'recall_at_3': 0.93778, 'recall_at_5': 0.95889, 'recall_at_10': 0.98111, 'recall_at_20': 0.99111, 'recall_at_100': 0.99778, 'recall_at_1000': 1.0, 'precision_at_1': 0.85667, 'precision_at_3': 0.31259, 'precision_at_5': 0.19178, 'precision_at_10': 0.09811, 'precision_at_20': 0.04956, 'precision_at_100': 0.00998, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8566666666666667, 'mrr_at_3': 0.8929629629629634, 'mrr_at_5': 0.8976296296296301, 'mrr_at_10': 0.9006693121693128, 'mrr_at_20': 0.9014305278055285, 'mrr_at_100': 0.9015503056196907, 'mrr_at_1000': 0.9015654504046813, 'nauc_ndcg_at_1_max': np.float64(0.6200235118576627), 'nauc_ndcg_at_1_std': np.float64(0.07183550742658158), 'nauc_ndcg_at_1_diff1': np.float64(0.9290876344207575), 'nauc_ndcg_at_3_max': np.float64(0.6349271604621773), 'nauc_ndcg_at_3_std': np.float64(0.053555195873877144), 'nauc_ndcg_at_3_diff1': np.float64(0.914187763311422), 'nauc_ndcg_at_5_max': np.float64(0.6233361968663719), 'nauc_ndcg_at_5_std': np.float64(0.05898324798893133), 'nauc_ndcg_at_5_diff1': np.float64(0.9199620720983661), 'nauc_ndcg_at_10_max': np.float64(0.6140930950462312), 'nauc_ndcg_at_10_std': np.float64(0.05677801630688054), 'nauc_ndcg_at_10_diff1': np.float64(0.9213837866465251), 'nauc_ndcg_at_20_max': np.float64(0.6131029065007272), 'nauc_ndcg_at_20_std': np.float64(0.07210053998325393), 'nauc_ndcg_at_20_diff1': np.float64(0.9212579184919344), 'nauc_ndcg_at_100_max': np.float64(0.6181840377291484), 'nauc_ndcg_at_100_std': np.float64(0.07163635632943753), 'nauc_ndcg_at_100_diff1': np.float64(0.9214411175848705), 'nauc_ndcg_at_1000_max': np.float64(0.6185534050632435), 'nauc_ndcg_at_1000_std': np.float64(0.06803705027165456), 'nauc_ndcg_at_1000_diff1': np.float64(0.9214103710428968), 'nauc_map_at_1_max': np.float64(0.6200235118576627), 'nauc_map_at_1_std': np.float64(0.07183550742658158), 'nauc_map_at_1_diff1': np.float64(0.9290876344207575), 'nauc_map_at_3_max': np.float64(0.6291171775700318), 'nauc_map_at_3_std': np.float64(0.05984820578172109), 'nauc_map_at_3_diff1': np.float64(0.9181874296864884), 'nauc_map_at_5_max': np.float64(0.6236460096499931), 'nauc_map_at_5_std': np.float64(0.0627327727332104), 'nauc_map_at_5_diff1': np.float64(0.9211955728710669), 'nauc_map_at_10_max': np.float64(0.6203003887986447), 'nauc_map_at_10_std': np.float64(0.0620874618663675), 'nauc_map_at_10_diff1': np.float64(0.9218303582707491), 'nauc_map_at_20_max': np.float64(0.6202010281677299), 'nauc_map_at_20_std': np.float64(0.06578026510307823), 'nauc_map_at_20_diff1': np.float64(0.9217873327372612), 'nauc_map_at_100_max': np.float64(0.6206524888282047), 'nauc_map_at_100_std': np.float64(0.06610573144199076), 'nauc_map_at_100_diff1': np.float64(0.9218178893846458), 'nauc_map_at_1000_max': np.float64(0.6206471258944869), 'nauc_map_at_1000_std': np.float64(0.06596374693316626), 'nauc_map_at_1000_diff1': np.float64(0.92182025415712), 'nauc_recall_at_1_max': np.float64(0.6200235118576627), 'nauc_recall_at_1_std': np.float64(0.07183550742658158), 'nauc_recall_at_1_diff1': np.float64(0.9290876344207575), 'nauc_recall_at_3_max': np.float64(0.6637404961984781), 'nauc_recall_at_3_std': np.float64(0.022817460317458665), 'nauc_recall_at_3_diff1': np.float64(0.8953748165933032), 'nauc_recall_at_5_max': np.float64(0.6175965881848232), 'nauc_recall_at_5_std': np.float64(0.03401721048779963), 'nauc_recall_at_5_diff1': np.float64(0.9137582961112365), 'nauc_recall_at_10_max': np.float64(0.5008787828857026), 'nauc_recall_at_10_std': np.float64(-0.021502718734554168), 'nauc_recall_at_10_diff1': np.float64(0.9211841599384808), 'nauc_recall_at_20_max': np.float64(0.33555088702149116), 'nauc_recall_at_20_std': np.float64(0.37219887955183756), 'nauc_recall_at_20_diff1': np.float64(0.9183006535947648), 'nauc_recall_at_100_max': np.float64(0.4960317460317535), 'nauc_recall_at_100_std': np.float64(0.934640522875857), 'nauc_recall_at_100_diff1': np.float64(0.934640522875857), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6200235118576627), 'nauc_precision_at_1_std': np.float64(0.07183550742658158), 'nauc_precision_at_1_diff1': np.float64(0.9290876344207575), 'nauc_precision_at_3_max': np.float64(0.6637404961984841), 'nauc_precision_at_3_std': np.float64(0.022817460317461912), 'nauc_precision_at_3_diff1': np.float64(0.895374816593309), 'nauc_precision_at_5_max': np.float64(0.6175965881848202), 'nauc_precision_at_5_std': np.float64(0.034017210487790155), 'nauc_precision_at_5_diff1': np.float64(0.9137582961112355), 'nauc_precision_at_10_max': np.float64(0.5008787828856862), 'nauc_precision_at_10_std': np.float64(-0.021502718734557884), 'nauc_precision_at_10_diff1': np.float64(0.9211841599384868), 'nauc_precision_at_20_max': np.float64(0.3355508870214679), 'nauc_precision_at_20_std': np.float64(0.37219887955182474), 'nauc_precision_at_20_diff1': np.float64(0.9183006535947696), 'nauc_precision_at_100_max': np.float64(0.49603174603179234), 'nauc_precision_at_100_std': np.float64(0.9346405228757582), 'nauc_precision_at_100_diff1': np.float64(0.9346405228757582), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6200235118576627), 'nauc_mrr_at_1_std': np.float64(0.07183550742658158), 'nauc_mrr_at_1_diff1': np.float64(0.9290876344207575), 'nauc_mrr_at_3_max': np.float64(0.6291171775700318), 'nauc_mrr_at_3_std': np.float64(0.05984820578172109), 'nauc_mrr_at_3_diff1': np.float64(0.9181874296864884), 'nauc_mrr_at_5_max': np.float64(0.6236460096499931), 'nauc_mrr_at_5_std': np.float64(0.0627327727332104), 'nauc_mrr_at_5_diff1': np.float64(0.9211955728710669), 'nauc_mrr_at_10_max': np.float64(0.6203003887986447), 'nauc_mrr_at_10_std': np.float64(0.0620874618663675), 'nauc_mrr_at_10_diff1': np.float64(0.9218303582707491), 'nauc_mrr_at_20_max': np.float64(0.6202010281677299), 'nauc_mrr_at_20_std': np.float64(0.06578026510307823), 'nauc_mrr_at_20_diff1': np.float64(0.9217873327372612), 'nauc_mrr_at_100_max': np.float64(0.6206524888282047), 'nauc_mrr_at_100_std': np.float64(0.06610573144199076), 'nauc_mrr_at_100_diff1': np.float64(0.9218178893846458), 'nauc_mrr_at_1000_max': np.float64(0.6206471258944869), 'nauc_mrr_at_1000_std': np.float64(0.06596374693316626), 'nauc_mrr_at_1000_diff1': np.float64(0.92182025415712), 'main_score': 0.92031}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.78556, 'ndcg_at_3': 0.84078, 'ndcg_at_5': 0.85541, 'ndcg_at_10': 0.86452, 'ndcg_at_20': 0.87024, 'ndcg_at_100': 0.87494, 'ndcg_at_1000': 0.87623, 'map_at_1': 0.78556, 'map_at_3': 0.82722, 'map_at_5': 0.83533, 'map_at_10': 0.83917, 'map_at_20': 0.8408, 'map_at_100': 0.8415, 'map_at_1000': 0.84155, 'recall_at_1': 0.78556, 'recall_at_3': 0.88, 'recall_at_5': 0.91556, 'recall_at_10': 0.94333, 'recall_at_20': 0.96556, 'recall_at_100': 0.99, 'recall_at_1000': 1.0, 'precision_at_1': 0.78556, 'precision_at_3': 0.29333, 'precision_at_5': 0.18311, 'precision_at_10': 0.09433, 'precision_at_20': 0.04828, 'precision_at_100': 0.0099, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7855555555555556, 'mrr_at_3': 0.8272222222222225, 'mrr_at_5': 0.8353333333333338, 'mrr_at_10': 0.8391706349206354, 'mrr_at_20': 0.8407976750011067, 'mrr_at_100': 0.8415019369013431, 'mrr_at_1000': 0.8415523736896204, 'nauc_ndcg_at_1_max': np.float64(0.7385293491488186), 'nauc_ndcg_at_1_std': np.float64(0.14492300333008346), 'nauc_ndcg_at_1_diff1': np.float64(0.9056590384024021), 'nauc_ndcg_at_3_max': np.float64(0.7508780483627049), 'nauc_ndcg_at_3_std': np.float64(0.17629577865227775), 'nauc_ndcg_at_3_diff1': np.float64(0.8796131863096975), 'nauc_ndcg_at_5_max': np.float64(0.7639847302367411), 'nauc_ndcg_at_5_std': np.float64(0.22769495548405205), 'nauc_ndcg_at_5_diff1': np.float64(0.8887001457995483), 'nauc_ndcg_at_10_max': np.float64(0.7616020409402215), 'nauc_ndcg_at_10_std': np.float64(0.2209162854297489), 'nauc_ndcg_at_10_diff1': np.float64(0.8910240767840198), 'nauc_ndcg_at_20_max': np.float64(0.7563923945801978), 'nauc_ndcg_at_20_std': np.float64(0.2257500574997457), 'nauc_ndcg_at_20_diff1': np.float64(0.8901705655943357), 'nauc_ndcg_at_100_max': np.float64(0.7545109846083868), 'nauc_ndcg_at_100_std': np.float64(0.2122690068264438), 'nauc_ndcg_at_100_diff1': np.float64(0.8913784112846709), 'nauc_ndcg_at_1000_max': np.float64(0.7544397216354228), 'nauc_ndcg_at_1000_std': np.float64(0.20394034939099934), 'nauc_ndcg_at_1000_diff1': np.float64(0.8913558562559795), 'nauc_map_at_1_max': np.float64(0.7385293491488186), 'nauc_map_at_1_std': np.float64(0.14492300333008346), 'nauc_map_at_1_diff1': np.float64(0.9056590384024021), 'nauc_map_at_3_max': np.float64(0.7487353164254025), 'nauc_map_at_3_std': np.float64(0.16922961302361597), 'nauc_map_at_3_diff1': np.float64(0.8872650055085894), 'nauc_map_at_5_max': np.float64(0.7549879563198285), 'nauc_map_at_5_std': np.float64(0.1938393366249109), 'nauc_map_at_5_diff1': np.float64(0.8918257731962219), 'nauc_map_at_10_max': np.float64(0.7538520746576524), 'nauc_map_at_10_std': np.float64(0.19104920288263752), 'nauc_map_at_10_diff1': np.float64(0.892782216866023), 'nauc_map_at_20_max': np.float64(0.7525637807150531), 'nauc_map_at_20_std': np.float64(0.1920752367370665), 'nauc_map_at_20_diff1': np.float64(0.8926494720845148), 'nauc_map_at_100_max': np.float64(0.7523016927357646), 'nauc_map_at_100_std': np.float64(0.19022784908812126), 'nauc_map_at_100_diff1': np.float64(0.8927729415362704), 'nauc_map_at_1000_max': np.float64(0.7522985353992927), 'nauc_map_at_1000_std': np.float64(0.18996221933631463), 'nauc_map_at_1000_diff1': np.float64(0.8927705645097672), 'nauc_recall_at_1_max': np.float64(0.7385293491488186), 'nauc_recall_at_1_std': np.float64(0.14492300333008346), 'nauc_recall_at_1_diff1': np.float64(0.9056590384024021), 'nauc_recall_at_3_max': np.float64(0.7585772616396222), 'nauc_recall_at_3_std': np.float64(0.20325149361897632), 'nauc_recall_at_3_diff1': np.float64(0.8490958744299502), 'nauc_recall_at_5_max': np.float64(0.8139773453240944), 'nauc_recall_at_5_std': np.float64(0.4190562189788191), 'nauc_recall_at_5_diff1': np.float64(0.8751474273920088), 'nauc_recall_at_10_max': np.float64(0.8229252485307852), 'nauc_recall_at_10_std': np.float64(0.459255597663904), 'nauc_recall_at_10_diff1': np.float64(0.883881657238058), 'nauc_recall_at_20_max': np.float64(0.7901569229842438), 'nauc_recall_at_20_std': np.float64(0.6722237282009564), 'nauc_recall_at_20_diff1': np.float64(0.8660431914701362), 'nauc_recall_at_100_max': np.float64(0.7622159975101154), 'nauc_recall_at_100_std': np.float64(0.9564270152505469), 'nauc_recall_at_100_diff1': np.float64(0.8905488121174361), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7385293491488186), 'nauc_precision_at_1_std': np.float64(0.14492300333008346), 'nauc_precision_at_1_diff1': np.float64(0.9056590384024021), 'nauc_precision_at_3_max': np.float64(0.7585772616396241), 'nauc_precision_at_3_std': np.float64(0.20325149361897543), 'nauc_precision_at_3_diff1': np.float64(0.8490958744299489), 'nauc_precision_at_5_max': np.float64(0.8139773453240927), 'nauc_precision_at_5_std': np.float64(0.41905621897881695), 'nauc_precision_at_5_diff1': np.float64(0.8751474273920078), 'nauc_precision_at_10_max': np.float64(0.8229252485307802), 'nauc_precision_at_10_std': np.float64(0.4592555976638981), 'nauc_precision_at_10_diff1': np.float64(0.8838816572380539), 'nauc_precision_at_20_max': np.float64(0.7901569229842433), 'nauc_precision_at_20_std': np.float64(0.6722237282009511), 'nauc_precision_at_20_diff1': np.float64(0.8660431914701331), 'nauc_precision_at_100_max': np.float64(0.7622159975101201), 'nauc_precision_at_100_std': np.float64(0.956427015250545), 'nauc_precision_at_100_diff1': np.float64(0.8905488121174426), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7385293491488186), 'nauc_mrr_at_1_std': np.float64(0.14492300333008346), 'nauc_mrr_at_1_diff1': np.float64(0.9056590384024021), 'nauc_mrr_at_3_max': np.float64(0.7487353164254025), 'nauc_mrr_at_3_std': np.float64(0.16922961302361597), 'nauc_mrr_at_3_diff1': np.float64(0.8872650055085894), 'nauc_mrr_at_5_max': np.float64(0.7549879563198285), 'nauc_mrr_at_5_std': np.float64(0.1938393366249109), 'nauc_mrr_at_5_diff1': np.float64(0.8918257731962219), 'nauc_mrr_at_10_max': np.float64(0.7538520746576524), 'nauc_mrr_at_10_std': np.float64(0.19104920288263752), 'nauc_mrr_at_10_diff1': np.float64(0.892782216866023), 'nauc_mrr_at_20_max': np.float64(0.7525637807150531), 'nauc_mrr_at_20_std': np.float64(0.1920752367370665), 'nauc_mrr_at_20_diff1': np.float64(0.8926494720845148), 'nauc_mrr_at_100_max': np.float64(0.7523016927357646), 'nauc_mrr_at_100_std': np.float64(0.19022784908812126), 'nauc_mrr_at_100_diff1': np.float64(0.8927729415362704), 'nauc_mrr_at_1000_max': np.float64(0.7522985353992927), 'nauc_mrr_at_1000_std': np.float64(0.18996221933631463), 'nauc_mrr_at_1000_diff1': np.float64(0.8927705645097672), 'main_score': 0.86452}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.32 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  6.38it/s]Batches:  67%|██████▋   | 2/3 [00:10<00:06,  6.33s/it]Batches: 100%|██████████| 3/3 [00:11<00:00,  3.96s/it]Batches: 100%|██████████| 3/3 [00:11<00:00,  3.98s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 13.98 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]Batches: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.51 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 24.65 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.27982, 'ndcg_at_3': 0.30518, 'ndcg_at_5': 0.32476, 'ndcg_at_10': 0.3571, 'ndcg_at_20': 0.37717, 'ndcg_at_100': 0.42603, 'ndcg_at_1000': 0.45678, 'map_at_1': 0.19353, 'map_at_3': 0.27544, 'map_at_5': 0.29204, 'map_at_10': 0.30797, 'map_at_20': 0.31431, 'map_at_100': 0.32189, 'map_at_1000': 0.32316, 'recall_at_1': 0.19353, 'recall_at_3': 0.32531, 'recall_at_5': 0.37551, 'recall_at_10': 0.46376, 'recall_at_20': 0.53236, 'recall_at_100': 0.77339, 'recall_at_1000': 1.0, 'precision_at_1': 0.27982, 'precision_at_3': 0.1738, 'precision_at_5': 0.12141, 'precision_at_10': 0.07477, 'precision_at_20': 0.04335, 'precision_at_100': 0.0124, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.2798165137614679, 'mrr_at_3': 0.326197757390418, 'mrr_at_5': 0.3365188583078491, 'mrr_at_10': 0.34852252317848637, 'mrr_at_20': 0.353421123934445, 'mrr_at_100': 0.3588061965996376, 'mrr_at_1000': 0.35962853293378244, 'nauc_ndcg_at_1_max': np.float64(0.16265322563646364), 'nauc_ndcg_at_1_std': np.float64(-0.18833485079936244), 'nauc_ndcg_at_1_diff1': np.float64(0.5743959063219708), 'nauc_ndcg_at_3_max': np.float64(0.15115082409197186), 'nauc_ndcg_at_3_std': np.float64(-0.2326831413567524), 'nauc_ndcg_at_3_diff1': np.float64(0.5355513006467298), 'nauc_ndcg_at_5_max': np.float64(0.1578451311010888), 'nauc_ndcg_at_5_std': np.float64(-0.23854976550429074), 'nauc_ndcg_at_5_diff1': np.float64(0.5195025224339292), 'nauc_ndcg_at_10_max': np.float64(0.15079190670828926), 'nauc_ndcg_at_10_std': np.float64(-0.2242977737169114), 'nauc_ndcg_at_10_diff1': np.float64(0.4959985025680068), 'nauc_ndcg_at_20_max': np.float64(0.15109050671097862), 'nauc_ndcg_at_20_std': np.float64(-0.21482130972989494), 'nauc_ndcg_at_20_diff1': np.float64(0.48475424375330856), 'nauc_ndcg_at_100_max': np.float64(0.16115614111999935), 'nauc_ndcg_at_100_std': np.float64(-0.18904172759900084), 'nauc_ndcg_at_100_diff1': np.float64(0.485263684271266), 'nauc_ndcg_at_1000_max': np.float64(0.15640619038232137), 'nauc_ndcg_at_1000_std': np.float64(-0.20424927266549617), 'nauc_ndcg_at_1000_diff1': np.float64(0.49811933320774837), 'nauc_map_at_1_max': np.float64(0.1333788664457722), 'nauc_map_at_1_std': np.float64(-0.19186056452745517), 'nauc_map_at_1_diff1': np.float64(0.6026428255407352), 'nauc_map_at_3_max': np.float64(0.15847786314733434), 'nauc_map_at_3_std': np.float64(-0.22563259495426558), 'nauc_map_at_3_diff1': np.float64(0.5443309558055008), 'nauc_map_at_5_max': np.float64(0.16149176531535286), 'nauc_map_at_5_std': np.float64(-0.2313479654688125), 'nauc_map_at_5_diff1': np.float64(0.5307359022230224), 'nauc_map_at_10_max': np.float64(0.1576616812242588), 'nauc_map_at_10_std': np.float64(-0.22424136385398943), 'nauc_map_at_10_diff1': np.float64(0.517443829870831), 'nauc_map_at_20_max': np.float64(0.156561929005934), 'nauc_map_at_20_std': np.float64(-0.2216790685134788), 'nauc_map_at_20_diff1': np.float64(0.5129905220017826), 'nauc_map_at_100_max': np.float64(0.15722893179621295), 'nauc_map_at_100_std': np.float64(-0.21899702974943797), 'nauc_map_at_100_diff1': np.float64(0.5135039330115706), 'nauc_map_at_1000_max': np.float64(0.15707089247415382), 'nauc_map_at_1000_std': np.float64(-0.21948337190049208), 'nauc_map_at_1000_diff1': np.float64(0.5138627556879988), 'nauc_recall_at_1_max': np.float64(0.1333788664457722), 'nauc_recall_at_1_std': np.float64(-0.19186056452745517), 'nauc_recall_at_1_diff1': np.float64(0.6026428255407352), 'nauc_recall_at_3_max': np.float64(0.14378997670580718), 'nauc_recall_at_3_std': np.float64(-0.2508505427267107), 'nauc_recall_at_3_diff1': np.float64(0.5076772126959125), 'nauc_recall_at_5_max': np.float64(0.15627328191656), 'nauc_recall_at_5_std': np.float64(-0.25764388965660323), 'nauc_recall_at_5_diff1': np.float64(0.4695357175880984), 'nauc_recall_at_10_max': np.float64(0.1407876095206232), 'nauc_recall_at_10_std': np.float64(-0.22041004043085902), 'nauc_recall_at_10_diff1': np.float64(0.40650972514828604), 'nauc_recall_at_20_max': np.float64(0.14017332698852716), 'nauc_recall_at_20_std': np.float64(-0.19365573286425647), 'nauc_recall_at_20_diff1': np.float64(0.3669244580517796), 'nauc_recall_at_100_max': np.float64(0.2011530724751607), 'nauc_recall_at_100_std': np.float64(-0.010097304957252298), 'nauc_recall_at_100_diff1': np.float64(0.30827274858191983), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.16265322563646364), 'nauc_precision_at_1_std': np.float64(-0.18833485079936244), 'nauc_precision_at_1_diff1': np.float64(0.5743959063219708), 'nauc_precision_at_3_max': np.float64(0.14601652881659463), 'nauc_precision_at_3_std': np.float64(-0.20711924836563086), 'nauc_precision_at_3_diff1': np.float64(0.38339762191899696), 'nauc_precision_at_5_max': np.float64(0.13913915589491396), 'nauc_precision_at_5_std': np.float64(-0.2129621767324046), 'nauc_precision_at_5_diff1': np.float64(0.33200959009193537), 'nauc_precision_at_10_max': np.float64(0.10758428277045155), 'nauc_precision_at_10_std': np.float64(-0.16332896820174375), 'nauc_precision_at_10_diff1': np.float64(0.2548094988167048), 'nauc_precision_at_20_max': np.float64(0.10039935632406857), 'nauc_precision_at_20_std': np.float64(-0.10994045270402089), 'nauc_precision_at_20_diff1': np.float64(0.1884737665414867), 'nauc_precision_at_100_max': np.float64(0.12889529870201247), 'nauc_precision_at_100_std': np.float64(0.07228197543698799), 'nauc_precision_at_100_diff1': np.float64(0.08463744093830189), 'nauc_precision_at_1000_max': np.float64(0.0721575870675354), 'nauc_precision_at_1000_std': np.float64(0.11651396952596191), 'nauc_precision_at_1000_diff1': np.float64(-0.03589529200880238), 'nauc_mrr_at_1_max': np.float64(0.16265322563646364), 'nauc_mrr_at_1_std': np.float64(-0.18833485079936244), 'nauc_mrr_at_1_diff1': np.float64(0.5743959063219708), 'nauc_mrr_at_3_max': np.float64(0.14940886624479835), 'nauc_mrr_at_3_std': np.float64(-0.2184632519050764), 'nauc_mrr_at_3_diff1': np.float64(0.5405184183033841), 'nauc_mrr_at_5_max': np.float64(0.152270086279411), 'nauc_mrr_at_5_std': np.float64(-0.21979258971459814), 'nauc_mrr_at_5_diff1': np.float64(0.5366763341588761), 'nauc_mrr_at_10_max': np.float64(0.14834849698398808), 'nauc_mrr_at_10_std': np.float64(-0.21463548212217884), 'nauc_mrr_at_10_diff1': np.float64(0.5293818437160801), 'nauc_mrr_at_20_max': np.float64(0.14986034601971795), 'nauc_mrr_at_20_std': np.float64(-0.21164471837621995), 'nauc_mrr_at_20_diff1': np.float64(0.5275684873655814), 'nauc_mrr_at_100_max': np.float64(0.1504809730978369), 'nauc_mrr_at_100_std': np.float64(-0.2102525312939993), 'nauc_mrr_at_100_diff1': np.float64(0.5276110687785383), 'nauc_mrr_at_1000_max': np.float64(0.15033414379003274), 'nauc_mrr_at_1000_std': np.float64(-0.21092273788039365), 'nauc_mrr_at_1000_diff1': np.float64(0.5279854829088149), 'main_score': 0.3571}, 'eng-kor': {'ndcg_at_1': 0.20336, 'ndcg_at_3': 0.24829, 'ndcg_at_5': 0.27407, 'ndcg_at_10': 0.31094, 'ndcg_at_20': 0.34327, 'ndcg_at_100': 0.39884, 'ndcg_at_1000': 0.42943, 'map_at_1': 0.11333, 'map_at_3': 0.19906, 'map_at_5': 0.22564, 'map_at_10': 0.24545, 'map_at_20': 0.25597, 'map_at_100': 0.26562, 'map_at_1000': 0.26749, 'recall_at_1': 0.11333, 'recall_at_3': 0.26741, 'recall_at_5': 0.34264, 'recall_at_10': 0.43379, 'recall_at_20': 0.54123, 'recall_at_100': 0.7987, 'recall_at_1000': 0.99847, 'precision_at_1': 0.20336, 'precision_at_3': 0.1682, 'precision_at_5': 0.13272, 'precision_at_10': 0.0867, 'precision_at_20': 0.05367, 'precision_at_100': 0.0158, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.20336391437308868, 'mrr_at_3': 0.27752293577981646, 'mrr_at_5': 0.29441896024464825, 'mrr_at_10': 0.3069990534440074, 'mrr_at_20': 0.3153198691491857, 'mrr_at_100': 0.32029614486379404, 'mrr_at_1000': 0.3210234436903728, 'nauc_ndcg_at_1_max': np.float64(0.23059526255686508), 'nauc_ndcg_at_1_std': np.float64(-0.1766781943662403), 'nauc_ndcg_at_1_diff1': np.float64(0.15805964434970776), 'nauc_ndcg_at_3_max': np.float64(0.15037561069761582), 'nauc_ndcg_at_3_std': np.float64(-0.24293322987087043), 'nauc_ndcg_at_3_diff1': np.float64(0.1060598008256348), 'nauc_ndcg_at_5_max': np.float64(0.11923002425610947), 'nauc_ndcg_at_5_std': np.float64(-0.24917569135736384), 'nauc_ndcg_at_5_diff1': np.float64(0.10662261587225039), 'nauc_ndcg_at_10_max': np.float64(0.10073501229237586), 'nauc_ndcg_at_10_std': np.float64(-0.2622246009221012), 'nauc_ndcg_at_10_diff1': np.float64(0.10156045352650941), 'nauc_ndcg_at_20_max': np.float64(0.09270514139435625), 'nauc_ndcg_at_20_std': np.float64(-0.2513232750935288), 'nauc_ndcg_at_20_diff1': np.float64(0.09221995427715365), 'nauc_ndcg_at_100_max': np.float64(0.09834852768094031), 'nauc_ndcg_at_100_std': np.float64(-0.21658736652593918), 'nauc_ndcg_at_100_diff1': np.float64(0.08223322787581405), 'nauc_ndcg_at_1000_max': np.float64(0.11518617431466921), 'nauc_ndcg_at_1000_std': np.float64(-0.2210907355602964), 'nauc_ndcg_at_1000_diff1': np.float64(0.09251582953701985), 'nauc_map_at_1_max': np.float64(0.21218528961951696), 'nauc_map_at_1_std': np.float64(-0.17591883514018467), 'nauc_map_at_1_diff1': np.float64(0.1692354811812946), 'nauc_map_at_3_max': np.float64(0.16600746017544304), 'nauc_map_at_3_std': np.float64(-0.2255894882300477), 'nauc_map_at_3_diff1': np.float64(0.11677334137424876), 'nauc_map_at_5_max': np.float64(0.14770064826124832), 'nauc_map_at_5_std': np.float64(-0.23569636575078878), 'nauc_map_at_5_diff1': np.float64(0.12201030040561259), 'nauc_map_at_10_max': np.float64(0.13563441812048518), 'nauc_map_at_10_std': np.float64(-0.24270965115117196), 'nauc_map_at_10_diff1': np.float64(0.1184495655302733), 'nauc_map_at_20_max': np.float64(0.13323610200660557), 'nauc_map_at_20_std': np.float64(-0.2404168732861843), 'nauc_map_at_20_diff1': np.float64(0.11725028326714887), 'nauc_map_at_100_max': np.float64(0.13370690711946526), 'nauc_map_at_100_std': np.float64(-0.23411130471182684), 'nauc_map_at_100_diff1': np.float64(0.11413610768701515), 'nauc_map_at_1000_max': np.float64(0.13522112373677148), 'nauc_map_at_1000_std': np.float64(-0.23322284294211604), 'nauc_map_at_1000_diff1': np.float64(0.11425958191910945), 'nauc_recall_at_1_max': np.float64(0.21218528961951696), 'nauc_recall_at_1_std': np.float64(-0.17591883514018467), 'nauc_recall_at_1_diff1': np.float64(0.1692354811812946), 'nauc_recall_at_3_max': np.float64(0.10532900063127473), 'nauc_recall_at_3_std': np.float64(-0.2467354814385313), 'nauc_recall_at_3_diff1': np.float64(0.06276907993627277), 'nauc_recall_at_5_max': np.float64(0.05871797288722992), 'nauc_recall_at_5_std': np.float64(-0.2559901740274049), 'nauc_recall_at_5_diff1': np.float64(0.07359713001358666), 'nauc_recall_at_10_max': np.float64(0.028377440281751782), 'nauc_recall_at_10_std': np.float64(-0.28217277278383585), 'nauc_recall_at_10_diff1': np.float64(0.05828772902103733), 'nauc_recall_at_20_max': np.float64(-0.0017203766062452103), 'nauc_recall_at_20_std': np.float64(-0.24781992086304866), 'nauc_recall_at_20_diff1': np.float64(0.024863917911959483), 'nauc_recall_at_100_max': np.float64(-0.034624616677202624), 'nauc_recall_at_100_std': np.float64(-0.07300396774406927), 'nauc_recall_at_100_diff1': np.float64(-0.054201511406694665), 'nauc_recall_at_1000_max': np.float64(0.869369819235015), 'nauc_recall_at_1000_std': np.float64(0.7222547590617517), 'nauc_recall_at_1000_diff1': np.float64(0.7222547590617517), 'nauc_precision_at_1_max': np.float64(0.23059526255686508), 'nauc_precision_at_1_std': np.float64(-0.1766781943662403), 'nauc_precision_at_1_diff1': np.float64(0.15805964434970776), 'nauc_precision_at_3_max': np.float64(0.13180630249788944), 'nauc_precision_at_3_std': np.float64(-0.24183469944734207), 'nauc_precision_at_3_diff1': np.float64(0.08617923357508446), 'nauc_precision_at_5_max': np.float64(0.07866866827452602), 'nauc_precision_at_5_std': np.float64(-0.24266623091805606), 'nauc_precision_at_5_diff1': np.float64(0.0874821096786221), 'nauc_precision_at_10_max': np.float64(0.023002780783397795), 'nauc_precision_at_10_std': np.float64(-0.23243183541419282), 'nauc_precision_at_10_diff1': np.float64(0.07100666295380739), 'nauc_precision_at_20_max': np.float64(-0.0021771031283383964), 'nauc_precision_at_20_std': np.float64(-0.19515025526504237), 'nauc_precision_at_20_diff1': np.float64(0.04742722206087879), 'nauc_precision_at_100_max': np.float64(-0.01150201764909971), 'nauc_precision_at_100_std': np.float64(-0.028989227689994995), 'nauc_precision_at_100_diff1': np.float64(-0.012190888503449399), 'nauc_precision_at_1000_max': np.float64(0.009575450938722765), 'nauc_precision_at_1000_std': np.float64(0.013030685694043514), 'nauc_precision_at_1000_diff1': np.float64(-0.00545209595105802), 'nauc_mrr_at_1_max': np.float64(0.23059526255686508), 'nauc_mrr_at_1_std': np.float64(-0.1766781943662403), 'nauc_mrr_at_1_diff1': np.float64(0.15805964434970776), 'nauc_mrr_at_3_max': np.float64(0.14965808675341316), 'nauc_mrr_at_3_std': np.float64(-0.22720341532066826), 'nauc_mrr_at_3_diff1': np.float64(0.10760583301455022), 'nauc_mrr_at_5_max': np.float64(0.13478576285143773), 'nauc_mrr_at_5_std': np.float64(-0.23309783375879714), 'nauc_mrr_at_5_diff1': np.float64(0.10717311467446305), 'nauc_mrr_at_10_max': np.float64(0.13022159862116023), 'nauc_mrr_at_10_std': np.float64(-0.23851667054691125), 'nauc_mrr_at_10_diff1': np.float64(0.10872888873416436), 'nauc_mrr_at_20_max': np.float64(0.1295569397783808), 'nauc_mrr_at_20_std': np.float64(-0.2326885936546818), 'nauc_mrr_at_20_diff1': np.float64(0.10507892754003542), 'nauc_mrr_at_100_max': np.float64(0.13155826493042203), 'nauc_mrr_at_100_std': np.float64(-0.2285534429647367), 'nauc_mrr_at_100_diff1': np.float64(0.1053488003757654), 'nauc_mrr_at_1000_max': np.float64(0.13210736193428502), 'nauc_mrr_at_1000_std': np.float64(-0.2286682961218941), 'nauc_mrr_at_1000_diff1': np.float64(0.10556582344109193), 'main_score': 0.31094}, 'kor-eng': {'ndcg_at_1': 0.25733, 'ndcg_at_3': 0.28539, 'ndcg_at_5': 0.30887, 'ndcg_at_10': 0.34022, 'ndcg_at_20': 0.3661, 'ndcg_at_100': 0.41412, 'ndcg_at_1000': 0.44655, 'map_at_1': 0.18219, 'map_at_3': 0.25706, 'map_at_5': 0.2773, 'map_at_10': 0.29275, 'map_at_20': 0.30085, 'map_at_100': 0.30851, 'map_at_1000': 0.30996, 'recall_at_1': 0.18219, 'recall_at_3': 0.30131, 'recall_at_5': 0.35681, 'recall_at_10': 0.4428, 'recall_at_20': 0.53298, 'recall_at_100': 0.76261, 'recall_at_1000': 1.0, 'precision_at_1': 0.25733, 'precision_at_3': 0.1645, 'precision_at_5': 0.12117, 'precision_at_10': 0.07557, 'precision_at_20': 0.0456, 'precision_at_100': 0.01313, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.25895765472312704, 'mrr_at_3': 0.30646036916395225, 'mrr_at_5': 0.31720955483170465, 'mrr_at_10': 0.3285727211622976, 'mrr_at_20': 0.33488076540877026, 'mrr_at_100': 0.3401064373206317, 'mrr_at_1000': 0.3409058663480543, 'nauc_ndcg_at_1_max': np.float64(0.1971297183494224), 'nauc_ndcg_at_1_std': np.float64(-0.11120789239003809), 'nauc_ndcg_at_1_diff1': np.float64(0.505606121700976), 'nauc_ndcg_at_3_max': np.float64(0.15294276809515184), 'nauc_ndcg_at_3_std': np.float64(-0.13479945201257715), 'nauc_ndcg_at_3_diff1': np.float64(0.44538947482989755), 'nauc_ndcg_at_5_max': np.float64(0.16421233739990027), 'nauc_ndcg_at_5_std': np.float64(-0.13024612438239955), 'nauc_ndcg_at_5_diff1': np.float64(0.4332480000238585), 'nauc_ndcg_at_10_max': np.float64(0.15174365698596645), 'nauc_ndcg_at_10_std': np.float64(-0.13983430076673511), 'nauc_ndcg_at_10_diff1': np.float64(0.42789163679262), 'nauc_ndcg_at_20_max': np.float64(0.15218373164939072), 'nauc_ndcg_at_20_std': np.float64(-0.13080527628412159), 'nauc_ndcg_at_20_diff1': np.float64(0.4228156872589017), 'nauc_ndcg_at_100_max': np.float64(0.16471149939393329), 'nauc_ndcg_at_100_std': np.float64(-0.12419666085367623), 'nauc_ndcg_at_100_diff1': np.float64(0.4197482535367832), 'nauc_ndcg_at_1000_max': np.float64(0.1631876739382489), 'nauc_ndcg_at_1000_std': np.float64(-0.1267628877422666), 'nauc_ndcg_at_1000_diff1': np.float64(0.43227644470585863), 'nauc_map_at_1_max': np.float64(0.15584196650847043), 'nauc_map_at_1_std': np.float64(-0.08921387429404619), 'nauc_map_at_1_diff1': np.float64(0.5225535776695338), 'nauc_map_at_3_max': np.float64(0.15456738468260678), 'nauc_map_at_3_std': np.float64(-0.12090759593450583), 'nauc_map_at_3_diff1': np.float64(0.45188009332621976), 'nauc_map_at_5_max': np.float64(0.1624127622487365), 'nauc_map_at_5_std': np.float64(-0.12398811036745316), 'nauc_map_at_5_diff1': np.float64(0.4359700028114134), 'nauc_map_at_10_max': np.float64(0.156591838771751), 'nauc_map_at_10_std': np.float64(-0.1320605005830169), 'nauc_map_at_10_diff1': np.float64(0.4346209427682855), 'nauc_map_at_20_max': np.float64(0.1542453863285621), 'nauc_map_at_20_std': np.float64(-0.13123199270240662), 'nauc_map_at_20_diff1': np.float64(0.43355971960494083), 'nauc_map_at_100_max': np.float64(0.15545840830620714), 'nauc_map_at_100_std': np.float64(-0.13056802709857612), 'nauc_map_at_100_diff1': np.float64(0.43332117251607577), 'nauc_map_at_1000_max': np.float64(0.15534953868268594), 'nauc_map_at_1000_std': np.float64(-0.1307680270172141), 'nauc_map_at_1000_diff1': np.float64(0.4337904133813476), 'nauc_recall_at_1_max': np.float64(0.15584196650847043), 'nauc_recall_at_1_std': np.float64(-0.08921387429404619), 'nauc_recall_at_1_diff1': np.float64(0.5225535776695338), 'nauc_recall_at_3_max': np.float64(0.13077819571940505), 'nauc_recall_at_3_std': np.float64(-0.14150932434179694), 'nauc_recall_at_3_diff1': np.float64(0.4222884972688852), 'nauc_recall_at_5_max': np.float64(0.14812299412156793), 'nauc_recall_at_5_std': np.float64(-0.13082787279472374), 'nauc_recall_at_5_diff1': np.float64(0.3873390941681804), 'nauc_recall_at_10_max': np.float64(0.11894029557077423), 'nauc_recall_at_10_std': np.float64(-0.14673953529637915), 'nauc_recall_at_10_diff1': np.float64(0.36399932536981683), 'nauc_recall_at_20_max': np.float64(0.11705223183609517), 'nauc_recall_at_20_std': np.float64(-0.1150270696095652), 'nauc_recall_at_20_diff1': np.float64(0.33968994682381265), 'nauc_recall_at_100_max': np.float64(0.16776282781560076), 'nauc_recall_at_100_std': np.float64(-0.08738029961423872), 'nauc_recall_at_100_diff1': np.float64(0.2597346348531165), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1971297183494224), 'nauc_precision_at_1_std': np.float64(-0.11120789239003809), 'nauc_precision_at_1_diff1': np.float64(0.505606121700976), 'nauc_precision_at_3_max': np.float64(0.1458981532783693), 'nauc_precision_at_3_std': np.float64(-0.14357842661749431), 'nauc_precision_at_3_diff1': np.float64(0.30644575638980337), 'nauc_precision_at_5_max': np.float64(0.14297124191463026), 'nauc_precision_at_5_std': np.float64(-0.1488828633233652), 'nauc_precision_at_5_diff1': np.float64(0.2517676981179563), 'nauc_precision_at_10_max': np.float64(0.10356769209172943), 'nauc_precision_at_10_std': np.float64(-0.16004221638654986), 'nauc_precision_at_10_diff1': np.float64(0.227080207545651), 'nauc_precision_at_20_max': np.float64(0.09046124563031495), 'nauc_precision_at_20_std': np.float64(-0.1278407870889799), 'nauc_precision_at_20_diff1': np.float64(0.18498933751641064), 'nauc_precision_at_100_max': np.float64(0.1470704819648003), 'nauc_precision_at_100_std': np.float64(-0.014471486575332319), 'nauc_precision_at_100_diff1': np.float64(0.08275612190388706), 'nauc_precision_at_1000_max': np.float64(0.12181094948854453), 'nauc_precision_at_1000_std': np.float64(0.026396427608266396), 'nauc_precision_at_1000_diff1': np.float64(0.007813782679524005), 'nauc_mrr_at_1_max': np.float64(0.19217676498843742), 'nauc_mrr_at_1_std': np.float64(-0.11594293709957194), 'nauc_mrr_at_1_diff1': np.float64(0.4991151319854248), 'nauc_mrr_at_3_max': np.float64(0.1842096370604303), 'nauc_mrr_at_3_std': np.float64(-0.13501358973038904), 'nauc_mrr_at_3_diff1': np.float64(0.47782314113442886), 'nauc_mrr_at_5_max': np.float64(0.1830143101944072), 'nauc_mrr_at_5_std': np.float64(-0.1321860558529258), 'nauc_mrr_at_5_diff1': np.float64(0.47218356356734453), 'nauc_mrr_at_10_max': np.float64(0.17715953642409424), 'nauc_mrr_at_10_std': np.float64(-0.1337225175497489), 'nauc_mrr_at_10_diff1': np.float64(0.47030989278915064), 'nauc_mrr_at_20_max': np.float64(0.1811895511707218), 'nauc_mrr_at_20_std': np.float64(-0.1283478319299466), 'nauc_mrr_at_20_diff1': np.float64(0.46771303960374416), 'nauc_mrr_at_100_max': np.float64(0.18062617193141584), 'nauc_mrr_at_100_std': np.float64(-0.129790217072728), 'nauc_mrr_at_100_diff1': np.float64(0.4682769057315426), 'nauc_mrr_at_1000_max': np.float64(0.1804704551292172), 'nauc_mrr_at_1000_std': np.float64(-0.12986374835058603), 'nauc_mrr_at_1000_diff1': np.float64(0.4684131584581279), 'main_score': 0.34022}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:10,  5.87s/it]Batches:  15%|█▌        | 2/13 [00:16<01:35,  8.71s/it]Batches:  23%|██▎       | 3/13 [00:27<01:36,  9.67s/it]Batches:  31%|███       | 4/13 [00:38<01:31, 10.13s/it]Batches:  38%|███▊      | 5/13 [00:49<01:23, 10.40s/it]Batches:  46%|████▌     | 6/13 [01:00<01:14, 10.58s/it]Batches:  54%|█████▍    | 7/13 [01:10<01:04, 10.70s/it]Batches:  62%|██████▏   | 8/13 [01:21<00:53, 10.78s/it]Batches:  69%|██████▉   | 9/13 [01:32<00:43, 10.85s/it]Batches:  77%|███████▋  | 10/13 [01:43<00:32, 10.90s/it]Batches:  85%|████████▍ | 11/13 [01:54<00:21, 10.93s/it]Batches:  92%|█████████▏| 12/13 [02:05<00:10, 10.96s/it]Batches: 100%|██████████| 13/13 [02:16<00:00, 10.96s/it]Batches: 100%|██████████| 13/13 [02:16<00:00, 10.53s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 144.72 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 144.98 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.155, 'ndcg_at_3': 0.21286, 'ndcg_at_5': 0.23114, 'ndcg_at_10': 0.24596, 'ndcg_at_20': 0.25838, 'ndcg_at_100': 0.2866, 'ndcg_at_1000': 0.32479, 'map_at_1': 0.155, 'map_at_3': 0.19833, 'map_at_5': 0.20833, 'map_at_10': 0.21462, 'map_at_20': 0.2179, 'map_at_100': 0.22193, 'map_at_1000': 0.22312, 'recall_at_1': 0.155, 'recall_at_3': 0.255, 'recall_at_5': 0.3, 'recall_at_10': 0.345, 'recall_at_20': 0.395, 'recall_at_100': 0.545, 'recall_at_1000': 0.86, 'precision_at_1': 0.155, 'precision_at_3': 0.085, 'precision_at_5': 0.06, 'precision_at_10': 0.0345, 'precision_at_20': 0.01975, 'precision_at_100': 0.00545, 'precision_at_1000': 0.00086, 'mrr_at_1': 0.155, 'mrr_at_3': 0.19833333333333333, 'mrr_at_5': 0.20833333333333337, 'mrr_at_10': 0.21461706349206353, 'mrr_at_20': 0.21790329991645788, 'mrr_at_100': 0.22192636282777436, 'mrr_at_1000': 0.22311573567447404, 'nauc_ndcg_at_1_max': np.float64(0.6534024410633671), 'nauc_ndcg_at_1_std': np.float64(0.023663168661545685), 'nauc_ndcg_at_1_diff1': np.float64(0.5704239896928506), 'nauc_ndcg_at_3_max': np.float64(0.5392950770971048), 'nauc_ndcg_at_3_std': np.float64(0.06310962168128884), 'nauc_ndcg_at_3_diff1': np.float64(0.4391634377402065), 'nauc_ndcg_at_5_max': np.float64(0.512798841157178), 'nauc_ndcg_at_5_std': np.float64(0.058583454190707915), 'nauc_ndcg_at_5_diff1': np.float64(0.40367034656058765), 'nauc_ndcg_at_10_max': np.float64(0.51468292285022), 'nauc_ndcg_at_10_std': np.float64(0.08414452558367269), 'nauc_ndcg_at_10_diff1': np.float64(0.42602576993830543), 'nauc_ndcg_at_20_max': np.float64(0.5087229428962105), 'nauc_ndcg_at_20_std': np.float64(0.09178765600668244), 'nauc_ndcg_at_20_diff1': np.float64(0.42282432452418245), 'nauc_ndcg_at_100_max': np.float64(0.5117756592677707), 'nauc_ndcg_at_100_std': np.float64(0.127400673676403), 'nauc_ndcg_at_100_diff1': np.float64(0.4208279282960337), 'nauc_ndcg_at_1000_max': np.float64(0.5155838182757371), 'nauc_ndcg_at_1000_std': np.float64(0.12272578659300962), 'nauc_ndcg_at_1000_diff1': np.float64(0.42235515270965235), 'nauc_map_at_1_max': np.float64(0.6534024410633671), 'nauc_map_at_1_std': np.float64(0.023663168661545685), 'nauc_map_at_1_diff1': np.float64(0.5704239896928506), 'nauc_map_at_3_max': np.float64(0.5624322695466907), 'nauc_map_at_3_std': np.float64(0.0561734805035326), 'nauc_map_at_3_diff1': np.float64(0.46690651146077067), 'nauc_map_at_5_max': np.float64(0.546357284460649), 'nauc_map_at_5_std': np.float64(0.05302593819749632), 'nauc_map_at_5_diff1': np.float64(0.44601957495182504), 'nauc_map_at_10_max': np.float64(0.5462465519755866), 'nauc_map_at_10_std': np.float64(0.06327954999500235), 'nauc_map_at_10_diff1': np.float64(0.45678409482750154), 'nauc_map_at_20_max': np.float64(0.5449016727511192), 'nauc_map_at_20_std': np.float64(0.06628084219719646), 'nauc_map_at_20_diff1': np.float64(0.45630693262164523), 'nauc_map_at_100_max': np.float64(0.545782541881912), 'nauc_map_at_100_std': np.float64(0.07148056047352806), 'nauc_map_at_100_diff1': np.float64(0.4564613211456158), 'nauc_map_at_1000_max': np.float64(0.5455803221220351), 'nauc_map_at_1000_std': np.float64(0.07110000993450748), 'nauc_map_at_1000_diff1': np.float64(0.45630643126428766), 'nauc_recall_at_1_max': np.float64(0.6534024410633671), 'nauc_recall_at_1_std': np.float64(0.023663168661545685), 'nauc_recall_at_1_diff1': np.float64(0.5704239896928506), 'nauc_recall_at_3_max': np.float64(0.48216277696362575), 'nauc_recall_at_3_std': np.float64(0.07985009879189547), 'nauc_recall_at_3_diff1': np.float64(0.37024723492056555), 'nauc_recall_at_5_max': np.float64(0.431245777597622), 'nauc_recall_at_5_std': np.float64(0.07129441967301701), 'nauc_recall_at_5_diff1': np.float64(0.29952709093365765), 'nauc_recall_at_10_max': np.float64(0.44140018371298445), 'nauc_recall_at_10_std': np.float64(0.14219913694547434), 'nauc_recall_at_10_diff1': np.float64(0.35589434520859364), 'nauc_recall_at_20_max': np.float64(0.42071577426077317), 'nauc_recall_at_20_std': np.float64(0.16179440361822775), 'nauc_recall_at_20_diff1': np.float64(0.34385423857851627), 'nauc_recall_at_100_max': np.float64(0.4236611102187895), 'nauc_recall_at_100_std': np.float64(0.33775847259369934), 'nauc_recall_at_100_diff1': np.float64(0.32182936793368594), 'nauc_recall_at_1000_max': np.float64(0.40395940141332987), 'nauc_recall_at_1000_std': np.float64(0.5805736455590972), 'nauc_recall_at_1000_diff1': np.float64(0.23020299293335245), 'nauc_precision_at_1_max': np.float64(0.6534024410633671), 'nauc_precision_at_1_std': np.float64(0.023663168661545685), 'nauc_precision_at_1_diff1': np.float64(0.5704239896928506), 'nauc_precision_at_3_max': np.float64(0.4821627769636258), 'nauc_precision_at_3_std': np.float64(0.07985009879189534), 'nauc_precision_at_3_diff1': np.float64(0.3702472349205655), 'nauc_precision_at_5_max': np.float64(0.4312457775976221), 'nauc_precision_at_5_std': np.float64(0.07129441967301732), 'nauc_precision_at_5_diff1': np.float64(0.2995270909336579), 'nauc_precision_at_10_max': np.float64(0.441400183712985), 'nauc_precision_at_10_std': np.float64(0.14219913694547434), 'nauc_precision_at_10_diff1': np.float64(0.3558943452085937), 'nauc_precision_at_20_max': np.float64(0.4207157742607733), 'nauc_precision_at_20_std': np.float64(0.16179440361822794), 'nauc_precision_at_20_diff1': np.float64(0.3438542385785166), 'nauc_precision_at_100_max': np.float64(0.42366111021878955), 'nauc_precision_at_100_std': np.float64(0.33775847259369973), 'nauc_precision_at_100_diff1': np.float64(0.321829367933686), 'nauc_precision_at_1000_max': np.float64(0.40395940141333003), 'nauc_precision_at_1000_std': np.float64(0.5805736455590976), 'nauc_precision_at_1000_diff1': np.float64(0.2302029929333522), 'nauc_mrr_at_1_max': np.float64(0.6534024410633671), 'nauc_mrr_at_1_std': np.float64(0.023663168661545685), 'nauc_mrr_at_1_diff1': np.float64(0.5704239896928506), 'nauc_mrr_at_3_max': np.float64(0.5624322695466907), 'nauc_mrr_at_3_std': np.float64(0.0561734805035326), 'nauc_mrr_at_3_diff1': np.float64(0.46690651146077067), 'nauc_mrr_at_5_max': np.float64(0.546357284460649), 'nauc_mrr_at_5_std': np.float64(0.05302593819749632), 'nauc_mrr_at_5_diff1': np.float64(0.44601957495182504), 'nauc_mrr_at_10_max': np.float64(0.5462465519755866), 'nauc_mrr_at_10_std': np.float64(0.06327954999500235), 'nauc_mrr_at_10_diff1': np.float64(0.45678409482750154), 'nauc_mrr_at_20_max': np.float64(0.5449016727511192), 'nauc_mrr_at_20_std': np.float64(0.06628084219719646), 'nauc_mrr_at_20_diff1': np.float64(0.45630693262164523), 'nauc_mrr_at_100_max': np.float64(0.545782541881912), 'nauc_mrr_at_100_std': np.float64(0.07148056047352806), 'nauc_mrr_at_100_diff1': np.float64(0.4564613211456158), 'nauc_mrr_at_1000_max': np.float64(0.5455803221220351), 'nauc_mrr_at_1000_std': np.float64(0.07110000993450748), 'nauc_mrr_at_1000_diff1': np.float64(0.45630643126428766), 'main_score': 0.24596}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 30.42it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:09,  5.83s/it]Batches:  15%|█▌        | 2/13 [00:16<01:37,  8.82s/it]Batches:  23%|██▎       | 3/13 [00:27<01:37,  9.79s/it]Batches:  31%|███       | 4/13 [00:38<01:32, 10.25s/it]Batches:  38%|███▊      | 5/13 [00:49<01:24, 10.52s/it]Batches:  46%|████▌     | 6/13 [01:00<01:14, 10.68s/it]Batches:  54%|█████▍    | 7/13 [01:11<01:04, 10.79s/it]Batches:  62%|██████▏   | 8/13 [01:22<00:54, 10.86s/it]Batches:  69%|██████▉   | 9/13 [01:33<00:43, 10.91s/it]Batches:  77%|███████▋  | 10/13 [01:44<00:32, 10.95s/it]Batches:  85%|████████▍ | 11/13 [01:55<00:21, 10.97s/it]Batches:  92%|█████████▏| 12/13 [02:06<00:10, 10.99s/it]Batches: 100%|██████████| 13/13 [02:17<00:00, 11.00s/it]Batches: 100%|██████████| 13/13 [02:17<00:00, 10.60s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 144.15 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 144.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.19, 'ndcg_at_3': 0.23339, 'ndcg_at_5': 0.24372, 'ndcg_at_10': 0.2708, 'ndcg_at_20': 0.28444, 'ndcg_at_100': 0.31019, 'ndcg_at_1000': 0.33916, 'map_at_1': 0.19, 'map_at_3': 0.2225, 'map_at_5': 0.22825, 'map_at_10': 0.23921, 'map_at_20': 0.2428, 'map_at_100': 0.24591, 'map_at_1000': 0.24682, 'recall_at_1': 0.19, 'recall_at_3': 0.265, 'recall_at_5': 0.29, 'recall_at_10': 0.375, 'recall_at_20': 0.43, 'recall_at_100': 0.575, 'recall_at_1000': 0.815, 'precision_at_1': 0.19, 'precision_at_3': 0.08833, 'precision_at_5': 0.058, 'precision_at_10': 0.0375, 'precision_at_20': 0.0215, 'precision_at_100': 0.00575, 'precision_at_1000': 0.00082, 'mrr_at_1': 0.19, 'mrr_at_3': 0.2225, 'mrr_at_5': 0.22825000000000004, 'mrr_at_10': 0.23920634920634926, 'mrr_at_20': 0.2428042409946435, 'mrr_at_100': 0.24590719223302934, 'mrr_at_1000': 0.24682316999124865, 'nauc_ndcg_at_1_max': np.float64(0.5271047366031646), 'nauc_ndcg_at_1_std': np.float64(0.055958165890404005), 'nauc_ndcg_at_1_diff1': np.float64(0.6510265162342577), 'nauc_ndcg_at_3_max': np.float64(0.5558310317804566), 'nauc_ndcg_at_3_std': np.float64(0.10534719216179274), 'nauc_ndcg_at_3_diff1': np.float64(0.606812226397841), 'nauc_ndcg_at_5_max': np.float64(0.5423518753341231), 'nauc_ndcg_at_5_std': np.float64(0.10834330908441163), 'nauc_ndcg_at_5_diff1': np.float64(0.5734308027380774), 'nauc_ndcg_at_10_max': np.float64(0.5150527233958064), 'nauc_ndcg_at_10_std': np.float64(0.1307503383225075), 'nauc_ndcg_at_10_diff1': np.float64(0.5294774420810564), 'nauc_ndcg_at_20_max': np.float64(0.5059964177926148), 'nauc_ndcg_at_20_std': np.float64(0.13017095675485332), 'nauc_ndcg_at_20_diff1': np.float64(0.5311272743578979), 'nauc_ndcg_at_100_max': np.float64(0.49039519277894145), 'nauc_ndcg_at_100_std': np.float64(0.1449929646229025), 'nauc_ndcg_at_100_diff1': np.float64(0.5177677734480506), 'nauc_ndcg_at_1000_max': np.float64(0.5043243755008304), 'nauc_ndcg_at_1000_std': np.float64(0.14684049480460046), 'nauc_ndcg_at_1000_diff1': np.float64(0.5288524441900466), 'nauc_map_at_1_max': np.float64(0.5271047366031646), 'nauc_map_at_1_std': np.float64(0.055958165890404005), 'nauc_map_at_1_diff1': np.float64(0.6510265162342577), 'nauc_map_at_3_max': np.float64(0.5469596217147008), 'nauc_map_at_3_std': np.float64(0.09000285041565309), 'nauc_map_at_3_diff1': np.float64(0.6171579403599334), 'nauc_map_at_5_max': np.float64(0.539514391080624), 'nauc_map_at_5_std': np.float64(0.09213374119424868), 'nauc_map_at_5_diff1': np.float64(0.5979177152578171), 'nauc_map_at_10_max': np.float64(0.5268633688986352), 'nauc_map_at_10_std': np.float64(0.10257357841351267), 'nauc_map_at_10_diff1': np.float64(0.5780895156704443), 'nauc_map_at_20_max': np.float64(0.5247364919928256), 'nauc_map_at_20_std': np.float64(0.10278104143405609), 'nauc_map_at_20_diff1': np.float64(0.5787872676341045), 'nauc_map_at_100_max': np.float64(0.522536444698086), 'nauc_map_at_100_std': np.float64(0.1043256942507403), 'nauc_map_at_100_diff1': np.float64(0.5775438826446706), 'nauc_map_at_1000_max': np.float64(0.523318979040455), 'nauc_map_at_1000_std': np.float64(0.10476750567563853), 'nauc_map_at_1000_diff1': np.float64(0.578021990250392), 'nauc_recall_at_1_max': np.float64(0.5271047366031646), 'nauc_recall_at_1_std': np.float64(0.055958165890404005), 'nauc_recall_at_1_diff1': np.float64(0.6510265162342577), 'nauc_recall_at_3_max': np.float64(0.5802423139477398), 'nauc_recall_at_3_std': np.float64(0.14759513079364625), 'nauc_recall_at_3_diff1': np.float64(0.5792535698676662), 'nauc_recall_at_5_max': np.float64(0.5485831627817535), 'nauc_recall_at_5_std': np.float64(0.15158715986978555), 'nauc_recall_at_5_diff1': np.float64(0.506174196118292), 'nauc_recall_at_10_max': np.float64(0.4774857515062694), 'nauc_recall_at_10_std': np.float64(0.20782934375508869), 'nauc_recall_at_10_diff1': np.float64(0.392105520273571), 'nauc_recall_at_20_max': np.float64(0.4428411647657072), 'nauc_recall_at_20_std': np.float64(0.20331378184703022), 'nauc_recall_at_20_diff1': np.float64(0.3967304365920587), 'nauc_recall_at_100_max': np.float64(0.35553230636025834), 'nauc_recall_at_100_std': np.float64(0.2966701540459615), 'nauc_recall_at_100_diff1': np.float64(0.30535733612323657), 'nauc_recall_at_1000_max': np.float64(0.4060192767202733), 'nauc_recall_at_1000_std': np.float64(0.40615351571938707), 'nauc_recall_at_1000_diff1': np.float64(0.2733106021961501), 'nauc_precision_at_1_max': np.float64(0.5271047366031646), 'nauc_precision_at_1_std': np.float64(0.055958165890404005), 'nauc_precision_at_1_diff1': np.float64(0.6510265162342577), 'nauc_precision_at_3_max': np.float64(0.5802423139477403), 'nauc_precision_at_3_std': np.float64(0.14759513079364642), 'nauc_precision_at_3_diff1': np.float64(0.5792535698676661), 'nauc_precision_at_5_max': np.float64(0.5485831627817537), 'nauc_precision_at_5_std': np.float64(0.1515871598697858), 'nauc_precision_at_5_diff1': np.float64(0.5061741961182923), 'nauc_precision_at_10_max': np.float64(0.4774857515062697), 'nauc_precision_at_10_std': np.float64(0.20782934375508877), 'nauc_precision_at_10_diff1': np.float64(0.3921055202735711), 'nauc_precision_at_20_max': np.float64(0.44284116476570745), 'nauc_precision_at_20_std': np.float64(0.20331378184703042), 'nauc_precision_at_20_diff1': np.float64(0.396730436592059), 'nauc_precision_at_100_max': np.float64(0.3555323063602586), 'nauc_precision_at_100_std': np.float64(0.29667015404596153), 'nauc_precision_at_100_diff1': np.float64(0.3053573361232372), 'nauc_precision_at_1000_max': np.float64(0.4060192767202729), 'nauc_precision_at_1000_std': np.float64(0.4061535157193871), 'nauc_precision_at_1000_diff1': np.float64(0.2733106021961501), 'nauc_mrr_at_1_max': np.float64(0.5271047366031646), 'nauc_mrr_at_1_std': np.float64(0.055958165890404005), 'nauc_mrr_at_1_diff1': np.float64(0.6510265162342577), 'nauc_mrr_at_3_max': np.float64(0.5469596217147008), 'nauc_mrr_at_3_std': np.float64(0.09000285041565309), 'nauc_mrr_at_3_diff1': np.float64(0.6171579403599334), 'nauc_mrr_at_5_max': np.float64(0.539514391080624), 'nauc_mrr_at_5_std': np.float64(0.09213374119424868), 'nauc_mrr_at_5_diff1': np.float64(0.5979177152578171), 'nauc_mrr_at_10_max': np.float64(0.5268633688986352), 'nauc_mrr_at_10_std': np.float64(0.10257357841351267), 'nauc_mrr_at_10_diff1': np.float64(0.5780895156704443), 'nauc_mrr_at_20_max': np.float64(0.5247364919928256), 'nauc_mrr_at_20_std': np.float64(0.10278104143405609), 'nauc_mrr_at_20_diff1': np.float64(0.5787872676341045), 'nauc_mrr_at_100_max': np.float64(0.522536444698086), 'nauc_mrr_at_100_std': np.float64(0.1043256942507403), 'nauc_mrr_at_100_diff1': np.float64(0.5775438826446706), 'nauc_mrr_at_1000_max': np.float64(0.523318979040455), 'nauc_mrr_at_1000_std': np.float64(0.10476750567563853), 'nauc_mrr_at_1000_diff1': np.float64(0.578021990250392), 'main_score': 0.2708}}



==================================================
Running model: intfloat/multilingual-e5-large-instruct
--------------------------------------------------
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
##### attention 적용 모델 로딩 실패 --> attention 적용 없이 재시도
XLMRobertaModel.__init__() got an unexpected keyword argument 'model_kwargs'
Created GritLM: torch.float16 dtype, mean pool, embedding mode, cccc attn
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / intfloat/multilingual-e5-large-instruct on GPU 0 in process Process-9
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  1.36it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:05,  3.52it/s]Batches:  11%|█         | 2/19 [00:02<00:23,  1.39s/it]Batches:  16%|█▌        | 3/19 [00:04<00:28,  1.76s/it]Batches:  21%|██        | 4/19 [00:06<00:28,  1.93s/it]Batches:  26%|██▋       | 5/19 [00:09<00:28,  2.02s/it]Batches:  32%|███▏      | 6/19 [00:11<00:27,  2.08s/it]Batches:  37%|███▋      | 7/19 [00:13<00:25,  2.12s/it]Batches:  42%|████▏     | 8/19 [00:15<00:23,  2.15s/it]Batches:  47%|████▋     | 9/19 [00:17<00:21,  2.16s/it]Batches:  53%|█████▎    | 10/19 [00:20<00:19,  2.17s/it]Batches:  58%|█████▊    | 11/19 [00:22<00:17,  2.18s/it]Batches:  63%|██████▎   | 12/19 [00:24<00:15,  2.19s/it]Batches:  68%|██████▊   | 13/19 [00:26<00:13,  2.20s/it]Batches:  74%|███████▎  | 14/19 [00:28<00:11,  2.20s/it]Batches:  79%|███████▉  | 15/19 [00:31<00:08,  2.20s/it]Batches:  84%|████████▍ | 16/19 [00:33<00:06,  2.21s/it]Batches:  89%|████████▉ | 17/19 [00:35<00:04,  2.21s/it]Batches:  95%|█████████▍| 18/19 [00:37<00:02,  2.21s/it]Batches: 100%|██████████| 19/19 [00:40<00:00,  2.25s/it]Batches: 100%|██████████| 19/19 [00:40<00:00,  2.11s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 41.40 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 42.00 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.75507, 'ndcg_at_3': 0.75189, 'ndcg_at_5': 0.78331, 'ndcg_at_10': 0.79887, 'ndcg_at_20': 0.80587, 'ndcg_at_100': 0.81648, 'ndcg_at_1000': 0.82361, 'map_at_1': 0.49351, 'map_at_3': 0.7117, 'map_at_5': 0.74392, 'map_at_10': 0.75549, 'map_at_20': 0.75871, 'map_at_100': 0.76072, 'map_at_1000': 0.76102, 'recall_at_1': 0.49351, 'recall_at_3': 0.75884, 'recall_at_5': 0.8227, 'recall_at_10': 0.85782, 'recall_at_20': 0.87913, 'recall_at_100': 0.9252, 'recall_at_1000': 0.97095, 'precision_at_1': 0.75507, 'precision_at_3': 0.44538, 'precision_at_5': 0.29865, 'precision_at_10': 0.15895, 'precision_at_20': 0.08201, 'precision_at_100': 0.01743, 'precision_at_1000': 0.00185, 'mrr_at_1': 0.7550675675675675, 'mrr_at_3': 0.8063063063063062, 'mrr_at_5': 0.8104448198198196, 'mrr_at_10': 0.8120750214500213, 'mrr_at_20': 0.8127675704881586, 'mrr_at_100': 0.8137184792433931, 'mrr_at_1000': 0.8138627949241024, 'nauc_ndcg_at_1_max': np.float64(0.5727474883534197), 'nauc_ndcg_at_1_std': np.float64(0.20852184247649982), 'nauc_ndcg_at_1_diff1': np.float64(0.6158519528990565), 'nauc_ndcg_at_3_max': np.float64(0.577787275596167), 'nauc_ndcg_at_3_std': np.float64(0.237087459627351), 'nauc_ndcg_at_3_diff1': np.float64(0.5247323566406811), 'nauc_ndcg_at_5_max': np.float64(0.6436713913943135), 'nauc_ndcg_at_5_std': np.float64(0.28095025336908297), 'nauc_ndcg_at_5_diff1': np.float64(0.5452939030702649), 'nauc_ndcg_at_10_max': np.float64(0.6759063903732295), 'nauc_ndcg_at_10_std': np.float64(0.3259201698612886), 'nauc_ndcg_at_10_diff1': np.float64(0.5390662254118882), 'nauc_ndcg_at_20_max': np.float64(0.675939730380448), 'nauc_ndcg_at_20_std': np.float64(0.3451547533615087), 'nauc_ndcg_at_20_diff1': np.float64(0.5440106426401761), 'nauc_ndcg_at_100_max': np.float64(0.6669063762815851), 'nauc_ndcg_at_100_std': np.float64(0.3465536219011131), 'nauc_ndcg_at_100_diff1': np.float64(0.5427112226813036), 'nauc_ndcg_at_1000_max': np.float64(0.656338200293394), 'nauc_ndcg_at_1000_std': np.float64(0.33151420695131983), 'nauc_ndcg_at_1000_diff1': np.float64(0.5376957540444702), 'nauc_map_at_1_max': np.float64(0.23408768250714546), 'nauc_map_at_1_std': np.float64(-0.007446739597742769), 'nauc_map_at_1_diff1': np.float64(0.5763962412717073), 'nauc_map_at_3_max': np.float64(0.5232392145843742), 'nauc_map_at_3_std': np.float64(0.17947191069306864), 'nauc_map_at_3_diff1': np.float64(0.5129986916538465), 'nauc_map_at_5_max': np.float64(0.5808280881207133), 'nauc_map_at_5_std': np.float64(0.21712082676244757), 'nauc_map_at_5_diff1': np.float64(0.529431826312614), 'nauc_map_at_10_max': np.float64(0.6015021650928929), 'nauc_map_at_10_std': np.float64(0.24454806235512166), 'nauc_map_at_10_diff1': np.float64(0.5240557141766429), 'nauc_map_at_20_max': np.float64(0.6019519382315871), 'nauc_map_at_20_std': np.float64(0.25209357986571734), 'nauc_map_at_20_diff1': np.float64(0.5271123662579152), 'nauc_map_at_100_max': np.float64(0.6004573780362663), 'nauc_map_at_100_std': np.float64(0.25234854407470486), 'nauc_map_at_100_diff1': np.float64(0.5263381021917141), 'nauc_map_at_1000_max': np.float64(0.6000369370440701), 'nauc_map_at_1000_std': np.float64(0.25190800564220306), 'nauc_map_at_1000_diff1': np.float64(0.5262054518780127), 'nauc_recall_at_1_max': np.float64(0.23408768250714546), 'nauc_recall_at_1_std': np.float64(-0.007446739597742769), 'nauc_recall_at_1_diff1': np.float64(0.5763962412717073), 'nauc_recall_at_3_max': np.float64(0.5795842824553967), 'nauc_recall_at_3_std': np.float64(0.24546706094062212), 'nauc_recall_at_3_diff1': np.float64(0.49017067084176524), 'nauc_recall_at_5_max': np.float64(0.7195409453404005), 'nauc_recall_at_5_std': np.float64(0.34618966424185427), 'nauc_recall_at_5_diff1': np.float64(0.5194773654817216), 'nauc_recall_at_10_max': np.float64(0.8343898880673456), 'nauc_recall_at_10_std': np.float64(0.49474065180833804), 'nauc_recall_at_10_diff1': np.float64(0.5012816841260364), 'nauc_recall_at_20_max': np.float64(0.860889980047164), 'nauc_recall_at_20_std': np.float64(0.6144360815190124), 'nauc_recall_at_20_diff1': np.float64(0.5174784817765612), 'nauc_recall_at_100_max': np.float64(0.8821544361345515), 'nauc_recall_at_100_std': np.float64(0.7751863280665128), 'nauc_recall_at_100_diff1': np.float64(0.5039585510047164), 'nauc_recall_at_1000_max': np.float64(0.876861475892877), 'nauc_recall_at_1000_std': np.float64(0.907974334424692), 'nauc_recall_at_1000_diff1': np.float64(0.275303091358477), 'nauc_precision_at_1_max': np.float64(0.5727474883534197), 'nauc_precision_at_1_std': np.float64(0.20852184247649982), 'nauc_precision_at_1_diff1': np.float64(0.6158519528990565), 'nauc_precision_at_3_max': np.float64(0.4199582530610942), 'nauc_precision_at_3_std': np.float64(0.30634819262268315), 'nauc_precision_at_3_diff1': np.float64(-0.029013727597239115), 'nauc_precision_at_5_max': np.float64(0.3681815785470059), 'nauc_precision_at_5_std': np.float64(0.2954266706591043), 'nauc_precision_at_5_diff1': np.float64(-0.09001558966322391), 'nauc_precision_at_10_max': np.float64(0.32880522657537203), 'nauc_precision_at_10_std': np.float64(0.3191898156600829), 'nauc_precision_at_10_diff1': np.float64(-0.1512477610994067), 'nauc_precision_at_20_max': np.float64(0.2862629611332116), 'nauc_precision_at_20_std': np.float64(0.3255332095997299), 'nauc_precision_at_20_diff1': np.float64(-0.17036455107218743), 'nauc_precision_at_100_max': np.float64(0.18182050204914146), 'nauc_precision_at_100_std': np.float64(0.29041396174885464), 'nauc_precision_at_100_diff1': np.float64(-0.24957890225082507), 'nauc_precision_at_1000_max': np.float64(0.05033883591861056), 'nauc_precision_at_1000_std': np.float64(0.1988482841500978), 'nauc_precision_at_1000_diff1': np.float64(-0.3617392309967401), 'nauc_mrr_at_1_max': np.float64(0.5727474883534197), 'nauc_mrr_at_1_std': np.float64(0.20852184247649982), 'nauc_mrr_at_1_diff1': np.float64(0.6158519528990565), 'nauc_mrr_at_3_max': np.float64(0.6801763638390359), 'nauc_mrr_at_3_std': np.float64(0.33763214084668475), 'nauc_mrr_at_3_diff1': np.float64(0.6109808457751671), 'nauc_mrr_at_5_max': np.float64(0.6799573969629825), 'nauc_mrr_at_5_std': np.float64(0.3355465021439214), 'nauc_mrr_at_5_diff1': np.float64(0.6087679022041059), 'nauc_mrr_at_10_max': np.float64(0.6785089298966275), 'nauc_mrr_at_10_std': np.float64(0.33572545926343905), 'nauc_mrr_at_10_diff1': np.float64(0.6064594943104936), 'nauc_mrr_at_20_max': np.float64(0.6774187850667475), 'nauc_mrr_at_20_std': np.float64(0.33577548352505066), 'nauc_mrr_at_20_diff1': np.float64(0.60597437507358), 'nauc_mrr_at_100_max': np.float64(0.6762887550942012), 'nauc_mrr_at_100_std': np.float64(0.3351938511636513), 'nauc_mrr_at_100_diff1': np.float64(0.6060223357753235), 'nauc_mrr_at_1000_max': np.float64(0.6760592680510537), 'nauc_mrr_at_1000_std': np.float64(0.33479308173824707), 'nauc_mrr_at_1000_diff1': np.float64(0.6059813851259808), 'main_score': 0.79887}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'AutoRAGRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'AutoRAGRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.73it/s]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Batches: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3.54 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 3.70 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.63158, 'ndcg_at_3': 0.74091, 'ndcg_at_5': 0.75865, 'ndcg_at_10': 0.77996, 'ndcg_at_20': 0.78881, 'ndcg_at_100': 0.7974, 'ndcg_at_1000': 0.7974, 'map_at_1': 0.63158, 'map_at_3': 0.71491, 'map_at_5': 0.72456, 'map_at_10': 0.73422, 'map_at_20': 0.73664, 'map_at_100': 0.73798, 'map_at_1000': 0.73798, 'recall_at_1': 0.63158, 'recall_at_3': 0.81579, 'recall_at_5': 0.85965, 'recall_at_10': 0.92105, 'recall_at_20': 0.95614, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.63158, 'precision_at_3': 0.27193, 'precision_at_5': 0.17193, 'precision_at_10': 0.09211, 'precision_at_20': 0.04781, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.631578947368421, 'mrr_at_3': 0.7149122807017544, 'mrr_at_5': 0.7245614035087722, 'mrr_at_10': 0.7342209690893903, 'mrr_at_20': 0.7366366532052129, 'mrr_at_100': 0.7379801603806115, 'mrr_at_1000': 0.7379801603806115, 'nauc_ndcg_at_1_max': np.float64(0.024150951562940618), 'nauc_ndcg_at_1_std': np.float64(-0.37759464704889256), 'nauc_ndcg_at_1_diff1': np.float64(0.6755296859994486), 'nauc_ndcg_at_3_max': np.float64(0.06494448464990901), 'nauc_ndcg_at_3_std': np.float64(-0.44777161440202856), 'nauc_ndcg_at_3_diff1': np.float64(0.5783362178814786), 'nauc_ndcg_at_5_max': np.float64(0.03631279046215516), 'nauc_ndcg_at_5_std': np.float64(-0.5313356819910321), 'nauc_ndcg_at_5_diff1': np.float64(0.6242306769679065), 'nauc_ndcg_at_10_max': np.float64(0.10832580287969389), 'nauc_ndcg_at_10_std': np.float64(-0.48937782027332816), 'nauc_ndcg_at_10_diff1': np.float64(0.6468051138280505), 'nauc_ndcg_at_20_max': np.float64(0.09238377122473308), 'nauc_ndcg_at_20_std': np.float64(-0.4955340508129813), 'nauc_ndcg_at_20_diff1': np.float64(0.6410441362879792), 'nauc_ndcg_at_100_max': np.float64(0.07844222424411847), 'nauc_ndcg_at_100_std': np.float64(-0.4626464976834516), 'nauc_ndcg_at_100_diff1': np.float64(0.6386861983810836), 'nauc_ndcg_at_1000_max': np.float64(0.07844222424411847), 'nauc_ndcg_at_1000_std': np.float64(-0.4626464976834516), 'nauc_ndcg_at_1000_diff1': np.float64(0.6386861983810836), 'nauc_map_at_1_max': np.float64(0.024150951562940618), 'nauc_map_at_1_std': np.float64(-0.37759464704889256), 'nauc_map_at_1_diff1': np.float64(0.6755296859994486), 'nauc_map_at_3_max': np.float64(0.05784884520381813), 'nauc_map_at_3_std': np.float64(-0.43069080633151685), 'nauc_map_at_3_diff1': np.float64(0.6077115138203844), 'nauc_map_at_5_max': np.float64(0.045230434391050546), 'nauc_map_at_5_std': np.float64(-0.47052118506215285), 'nauc_map_at_5_diff1': np.float64(0.6327767915615091), 'nauc_map_at_10_max': np.float64(0.07409359198407652), 'nauc_map_at_10_std': np.float64(-0.4506537175901882), 'nauc_map_at_10_diff1': np.float64(0.6413402133513847), 'nauc_map_at_20_max': np.float64(0.07059215552277907), 'nauc_map_at_20_std': np.float64(-0.4524287048567066), 'nauc_map_at_20_diff1': np.float64(0.6402194895134982), 'nauc_map_at_100_max': np.float64(0.0690961457298233), 'nauc_map_at_100_std': np.float64(-0.4479754754387847), 'nauc_map_at_100_diff1': np.float64(0.639926260318653), 'nauc_map_at_1000_max': np.float64(0.0690961457298233), 'nauc_map_at_1000_std': np.float64(-0.4479754754387847), 'nauc_map_at_1000_diff1': np.float64(0.639926260318653), 'nauc_recall_at_1_max': np.float64(0.024150951562940618), 'nauc_recall_at_1_std': np.float64(-0.37759464704889256), 'nauc_recall_at_1_diff1': np.float64(0.6755296859994486), 'nauc_recall_at_3_max': np.float64(0.09068385936815089), 'nauc_recall_at_3_std': np.float64(-0.514524438603832), 'nauc_recall_at_3_diff1': np.float64(0.4595175891856197), 'nauc_recall_at_5_max': np.float64(-0.022828393192234387), 'nauc_recall_at_5_std': np.float64(-0.8547226023738652), 'nauc_recall_at_5_diff1': np.float64(0.5894327798332518), 'nauc_recall_at_10_max': np.float64(0.418051286609699), 'nauc_recall_at_10_std': np.float64(-0.8142213143329806), 'nauc_recall_at_10_diff1': np.float64(0.726063039546092), 'nauc_recall_at_20_max': np.float64(0.3904960260636177), 'nauc_recall_at_20_std': np.float64(-1.1422328878688501), 'nauc_recall_at_20_diff1': np.float64(0.6874924403711355), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.024150951562940618), 'nauc_precision_at_1_std': np.float64(-0.37759464704889256), 'nauc_precision_at_1_diff1': np.float64(0.6755296859994486), 'nauc_precision_at_3_max': np.float64(0.09068385936815057), 'nauc_precision_at_3_std': np.float64(-0.5145244386038328), 'nauc_precision_at_3_diff1': np.float64(0.45951758918561936), 'nauc_precision_at_5_max': np.float64(-0.022828393192234623), 'nauc_precision_at_5_std': np.float64(-0.8547226023738643), 'nauc_precision_at_5_diff1': np.float64(0.5894327798332507), 'nauc_precision_at_10_max': np.float64(0.4180512866096978), 'nauc_precision_at_10_std': np.float64(-0.8142213143329762), 'nauc_precision_at_10_diff1': np.float64(0.7260630395460898), 'nauc_precision_at_20_max': np.float64(0.39049602606361516), 'nauc_precision_at_20_std': np.float64(-1.142232887868855), 'nauc_precision_at_20_diff1': np.float64(0.6874924403711331), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.024150951562940618), 'nauc_mrr_at_1_std': np.float64(-0.37759464704889256), 'nauc_mrr_at_1_diff1': np.float64(0.6755296859994486), 'nauc_mrr_at_3_max': np.float64(0.05784884520381813), 'nauc_mrr_at_3_std': np.float64(-0.43069080633151685), 'nauc_mrr_at_3_diff1': np.float64(0.6077115138203844), 'nauc_mrr_at_5_max': np.float64(0.045230434391050546), 'nauc_mrr_at_5_std': np.float64(-0.47052118506215285), 'nauc_mrr_at_5_diff1': np.float64(0.6327767915615091), 'nauc_mrr_at_10_max': np.float64(0.07409359198407652), 'nauc_mrr_at_10_std': np.float64(-0.4506537175901882), 'nauc_mrr_at_10_diff1': np.float64(0.6413402133513847), 'nauc_mrr_at_20_max': np.float64(0.07059215552277907), 'nauc_mrr_at_20_std': np.float64(-0.4524287048567066), 'nauc_mrr_at_20_diff1': np.float64(0.6402194895134982), 'nauc_mrr_at_100_max': np.float64(0.0690961457298233), 'nauc_mrr_at_100_std': np.float64(-0.4479754754387847), 'nauc_mrr_at_100_diff1': np.float64(0.639926260318653), 'nauc_mrr_at_1000_max': np.float64(0.0690961457298233), 'nauc_mrr_at_1000_std': np.float64(-0.4479754754387847), 'nauc_mrr_at_1000_diff1': np.float64(0.639926260318653), 'main_score': 0.77996}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'PublicHealthQA'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'PublicHealthQA'
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.46 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.54 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.72727, 'ndcg_at_3': 0.83178, 'ndcg_at_5': 0.83738, 'ndcg_at_10': 0.84967, 'ndcg_at_20': 0.85329, 'ndcg_at_100': 0.85854, 'ndcg_at_1000': 0.85854, 'map_at_1': 0.72727, 'map_at_3': 0.80519, 'map_at_5': 0.80844, 'map_at_10': 0.81335, 'map_at_20': 0.81453, 'map_at_100': 0.8154, 'map_at_1000': 0.8154, 'recall_at_1': 0.72727, 'recall_at_3': 0.90909, 'recall_at_5': 0.92208, 'recall_at_10': 0.96104, 'recall_at_20': 0.97403, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.72727, 'precision_at_3': 0.30303, 'precision_at_5': 0.18442, 'precision_at_10': 0.0961, 'precision_at_20': 0.0487, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7272727272727273, 'mrr_at_3': 0.8051948051948052, 'mrr_at_5': 0.8084415584415584, 'mrr_at_10': 0.8133477633477633, 'mrr_at_20': 0.8145284008920373, 'mrr_at_100': 0.8153980669402747, 'mrr_at_1000': 0.8153980669402747, 'nauc_ndcg_at_1_max': np.float64(0.2578662916557108), 'nauc_ndcg_at_1_std': np.float64(-0.17339023849413804), 'nauc_ndcg_at_1_diff1': np.float64(0.8502933860364167), 'nauc_ndcg_at_3_max': np.float64(0.2789511826471411), 'nauc_ndcg_at_3_std': np.float64(-0.27327533046798197), 'nauc_ndcg_at_3_diff1': np.float64(0.8088899419035144), 'nauc_ndcg_at_5_max': np.float64(0.2686030984088624), 'nauc_ndcg_at_5_std': np.float64(-0.2398529803942681), 'nauc_ndcg_at_5_diff1': np.float64(0.8121263422915855), 'nauc_ndcg_at_10_max': np.float64(0.25653467116330825), 'nauc_ndcg_at_10_std': np.float64(-0.16801671661837783), 'nauc_ndcg_at_10_diff1': np.float64(0.8028630815222548), 'nauc_ndcg_at_20_max': np.float64(0.2600943671088392), 'nauc_ndcg_at_20_std': np.float64(-0.1573447636079357), 'nauc_ndcg_at_20_diff1': np.float64(0.801072318229471), 'nauc_ndcg_at_100_max': np.float64(0.27496694113179954), 'nauc_ndcg_at_100_std': np.float64(-0.18043690881056673), 'nauc_ndcg_at_100_diff1': np.float64(0.8152844323746344), 'nauc_ndcg_at_1000_max': np.float64(0.27496694113179954), 'nauc_ndcg_at_1000_std': np.float64(-0.18043690881056673), 'nauc_ndcg_at_1000_diff1': np.float64(0.8152844323746344), 'nauc_map_at_1_max': np.float64(0.2578662916557108), 'nauc_map_at_1_std': np.float64(-0.17339023849413804), 'nauc_map_at_1_diff1': np.float64(0.8502933860364167), 'nauc_map_at_3_max': np.float64(0.2832246049725774), 'nauc_map_at_3_std': np.float64(-0.2237173829465317), 'nauc_map_at_3_diff1': np.float64(0.8202919737719437), 'nauc_map_at_5_max': np.float64(0.27813762918636437), 'nauc_map_at_5_std': np.float64(-0.20610079524493233), 'nauc_map_at_5_diff1': np.float64(0.822121513194672), 'nauc_map_at_10_max': np.float64(0.27448093578803834), 'nauc_map_at_10_std': np.float64(-0.18103424295415874), 'nauc_map_at_10_diff1': np.float64(0.8190794622023716), 'nauc_map_at_20_max': np.float64(0.2755314745647117), 'nauc_map_at_20_std': np.float64(-0.17835635325681093), 'nauc_map_at_20_diff1': np.float64(0.8187291485858915), 'nauc_map_at_100_max': np.float64(0.27777799731256525), 'nauc_map_at_100_std': np.float64(-0.18126304477876914), 'nauc_map_at_100_diff1': np.float64(0.8206571496909262), 'nauc_map_at_1000_max': np.float64(0.27777799731256525), 'nauc_map_at_1000_std': np.float64(-0.18126304477876914), 'nauc_map_at_1000_diff1': np.float64(0.8206571496909262), 'nauc_recall_at_1_max': np.float64(0.2578662916557108), 'nauc_recall_at_1_std': np.float64(-0.17339023849413804), 'nauc_recall_at_1_diff1': np.float64(0.8502933860364167), 'nauc_recall_at_3_max': np.float64(0.24603942534806478), 'nauc_recall_at_3_std': np.float64(-0.5646971914957211), 'nauc_recall_at_3_diff1': np.float64(0.7466686222564456), 'nauc_recall_at_5_max': np.float64(0.19457155386259348), 'nauc_recall_at_5_std': np.float64(-0.4647524911636102), 'nauc_recall_at_5_diff1': np.float64(0.7506796183748019), 'nauc_recall_at_10_max': np.float64(-0.012909070638077955), 'nauc_recall_at_10_std': np.float64(0.09099141428707062), 'nauc_recall_at_10_diff1': np.float64(0.5938250215675056), 'nauc_recall_at_20_max': np.float64(-0.08218269674420323), 'nauc_recall_at_20_std': np.float64(0.41670903386108427), 'nauc_recall_at_20_diff1': np.float64(0.45638118111511516), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2578662916557108), 'nauc_precision_at_1_std': np.float64(-0.17339023849413804), 'nauc_precision_at_1_diff1': np.float64(0.8502933860364167), 'nauc_precision_at_3_max': np.float64(0.2460394253480639), 'nauc_precision_at_3_std': np.float64(-0.5646971914957185), 'nauc_precision_at_3_diff1': np.float64(0.7466686222564458), 'nauc_precision_at_5_max': np.float64(0.1945715538625944), 'nauc_precision_at_5_std': np.float64(-0.46475249116360745), 'nauc_precision_at_5_diff1': np.float64(0.7506796183748052), 'nauc_precision_at_10_max': np.float64(-0.012909070638074602), 'nauc_precision_at_10_std': np.float64(0.09099141428707733), 'nauc_precision_at_10_diff1': np.float64(0.5938250215675132), 'nauc_precision_at_20_max': np.float64(-0.08218269674418595), 'nauc_precision_at_20_std': np.float64(0.4167090338610833), 'nauc_precision_at_20_diff1': np.float64(0.4563811811151188), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.2578662916557108), 'nauc_mrr_at_1_std': np.float64(-0.17339023849413804), 'nauc_mrr_at_1_diff1': np.float64(0.8502933860364167), 'nauc_mrr_at_3_max': np.float64(0.2832246049725774), 'nauc_mrr_at_3_std': np.float64(-0.2237173829465317), 'nauc_mrr_at_3_diff1': np.float64(0.8202919737719437), 'nauc_mrr_at_5_max': np.float64(0.27813762918636437), 'nauc_mrr_at_5_std': np.float64(-0.20610079524493233), 'nauc_mrr_at_5_diff1': np.float64(0.822121513194672), 'nauc_mrr_at_10_max': np.float64(0.27448093578803834), 'nauc_mrr_at_10_std': np.float64(-0.18103424295415874), 'nauc_mrr_at_10_diff1': np.float64(0.8190794622023716), 'nauc_mrr_at_20_max': np.float64(0.2755314745647117), 'nauc_mrr_at_20_std': np.float64(-0.17835635325681093), 'nauc_mrr_at_20_diff1': np.float64(0.8187291485858915), 'nauc_mrr_at_100_max': np.float64(0.27777799731256525), 'nauc_mrr_at_100_std': np.float64(-0.18126304477876914), 'nauc_mrr_at_100_diff1': np.float64(0.8206571496909262), 'nauc_mrr_at_1000_max': np.float64(0.27777799731256525), 'nauc_mrr_at_1000_std': np.float64(-0.18126304477876914), 'nauc_mrr_at_1000_diff1': np.float64(0.8206571496909262), 'main_score': 0.84967}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.48it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.45it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.42 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.25it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.22it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.36 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.43it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.40it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.28 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 8.69 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.89222, 'ndcg_at_3': 0.9234, 'ndcg_at_5': 0.93129, 'ndcg_at_10': 0.93603, 'ndcg_at_20': 0.93791, 'ndcg_at_100': 0.9398, 'ndcg_at_1000': 0.94023, 'map_at_1': 0.89222, 'map_at_3': 0.91574, 'map_at_5': 0.92019, 'map_at_10': 0.92218, 'map_at_20': 0.92265, 'map_at_100': 0.92292, 'map_at_1000': 0.92294, 'recall_at_1': 0.89222, 'recall_at_3': 0.94556, 'recall_at_5': 0.96444, 'recall_at_10': 0.97889, 'recall_at_20': 0.98667, 'recall_at_100': 0.99667, 'recall_at_1000': 1.0, 'precision_at_1': 0.89222, 'precision_at_3': 0.31519, 'precision_at_5': 0.19289, 'precision_at_10': 0.09789, 'precision_at_20': 0.04933, 'precision_at_100': 0.00997, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8922222222222222, 'mrr_at_3': 0.9157407407407407, 'mrr_at_5': 0.9201851851851852, 'mrr_at_10': 0.9221798941798943, 'mrr_at_20': 0.9226488668566842, 'mrr_at_100': 0.9229221134897714, 'mrr_at_1000': 0.9229389832546225, 'nauc_ndcg_at_1_max': np.float64(0.7559884167257802), 'nauc_ndcg_at_1_std': np.float64(0.11310212133285405), 'nauc_ndcg_at_1_diff1': np.float64(0.9075378740027407), 'nauc_ndcg_at_3_max': np.float64(0.8046835489465721), 'nauc_ndcg_at_3_std': np.float64(0.1804182130630102), 'nauc_ndcg_at_3_diff1': np.float64(0.9058569690070104), 'nauc_ndcg_at_5_max': np.float64(0.8012419491051281), 'nauc_ndcg_at_5_std': np.float64(0.17187022513100597), 'nauc_ndcg_at_5_diff1': np.float64(0.9086374936067283), 'nauc_ndcg_at_10_max': np.float64(0.7999992577265886), 'nauc_ndcg_at_10_std': np.float64(0.1715804456824186), 'nauc_ndcg_at_10_diff1': np.float64(0.9116354452566919), 'nauc_ndcg_at_20_max': np.float64(0.796371858665518), 'nauc_ndcg_at_20_std': np.float64(0.1725063456613105), 'nauc_ndcg_at_20_diff1': np.float64(0.9089461038595327), 'nauc_ndcg_at_100_max': np.float64(0.7923452718937988), 'nauc_ndcg_at_100_std': np.float64(0.16712404488812554), 'nauc_ndcg_at_100_diff1': np.float64(0.9084066457691001), 'nauc_ndcg_at_1000_max': np.float64(0.790818551487913), 'nauc_ndcg_at_1000_std': np.float64(0.16132142181593392), 'nauc_ndcg_at_1000_diff1': np.float64(0.9080519787574791), 'nauc_map_at_1_max': np.float64(0.7559884167257802), 'nauc_map_at_1_std': np.float64(0.11310212133285405), 'nauc_map_at_1_diff1': np.float64(0.9075378740027407), 'nauc_map_at_3_max': np.float64(0.7903874144498463), 'nauc_map_at_3_std': np.float64(0.1630929154666399), 'nauc_map_at_3_diff1': np.float64(0.9053657881969174), 'nauc_map_at_5_max': np.float64(0.7877141287356025), 'nauc_map_at_5_std': np.float64(0.15697911965481995), 'nauc_map_at_5_diff1': np.float64(0.9067110567499744), 'nauc_map_at_10_max': np.float64(0.7870586930411507), 'nauc_map_at_10_std': np.float64(0.15612500293941442), 'nauc_map_at_10_diff1': np.float64(0.9078093760719279), 'nauc_map_at_20_max': np.float64(0.7862334193343802), 'nauc_map_at_20_std': np.float64(0.15589668225405653), 'nauc_map_at_20_diff1': np.float64(0.907246735277992), 'nauc_map_at_100_max': np.float64(0.7857108807647025), 'nauc_map_at_100_std': np.float64(0.15473897089718977), 'nauc_map_at_100_diff1': np.float64(0.9071667019392678), 'nauc_map_at_1000_max': np.float64(0.7856636582801596), 'nauc_map_at_1000_std': np.float64(0.15456238243226877), 'nauc_map_at_1000_diff1': np.float64(0.9071555907420865), 'nauc_recall_at_1_max': np.float64(0.7559884167257802), 'nauc_recall_at_1_std': np.float64(0.11310212133285405), 'nauc_recall_at_1_diff1': np.float64(0.9075378740027407), 'nauc_recall_at_3_max': np.float64(0.8677185159778226), 'nauc_recall_at_3_std': np.float64(0.2551877894014712), 'nauc_recall_at_3_diff1': np.float64(0.908677756817013), 'nauc_recall_at_5_max': np.float64(0.8872403127917826), 'nauc_recall_at_5_std': np.float64(0.2647788281979452), 'nauc_recall_at_5_diff1': np.float64(0.9227503501400555), 'nauc_recall_at_10_max': np.float64(0.9324291119956791), 'nauc_recall_at_10_std': np.float64(0.3330139073173117), 'nauc_recall_at_10_diff1': np.float64(0.9578603371173053), 'nauc_recall_at_20_max': np.float64(0.9410597572362199), 'nauc_recall_at_20_std': np.float64(0.45992841581076965), 'nauc_recall_at_20_diff1': np.float64(0.9332788671023909), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.9564270152505339), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7559884167257802), 'nauc_precision_at_1_std': np.float64(0.11310212133285405), 'nauc_precision_at_1_diff1': np.float64(0.9075378740027407), 'nauc_precision_at_3_max': np.float64(0.8677185159778196), 'nauc_precision_at_3_std': np.float64(0.25518778940147957), 'nauc_precision_at_3_diff1': np.float64(0.9086777568170122), 'nauc_precision_at_5_max': np.float64(0.8872403127917805), 'nauc_precision_at_5_std': np.float64(0.2647788281979385), 'nauc_precision_at_5_diff1': np.float64(0.9227503501400542), 'nauc_precision_at_10_max': np.float64(0.9324291119956715), 'nauc_precision_at_10_std': np.float64(0.33301390731730346), 'nauc_precision_at_10_diff1': np.float64(0.9578603371172977), 'nauc_precision_at_20_max': np.float64(0.941059757236231), 'nauc_precision_at_20_std': np.float64(0.45992841581075417), 'nauc_precision_at_20_diff1': np.float64(0.9332788671023994), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.9564270152505041), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505041), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7559884167257802), 'nauc_mrr_at_1_std': np.float64(0.11310212133285405), 'nauc_mrr_at_1_diff1': np.float64(0.9075378740027407), 'nauc_mrr_at_3_max': np.float64(0.7903874144498463), 'nauc_mrr_at_3_std': np.float64(0.1630929154666399), 'nauc_mrr_at_3_diff1': np.float64(0.9053657881969174), 'nauc_mrr_at_5_max': np.float64(0.7877141287356025), 'nauc_mrr_at_5_std': np.float64(0.15697911965481995), 'nauc_mrr_at_5_diff1': np.float64(0.9067110567499744), 'nauc_mrr_at_10_max': np.float64(0.7870586930411507), 'nauc_mrr_at_10_std': np.float64(0.15612500293941442), 'nauc_mrr_at_10_diff1': np.float64(0.9078093760719279), 'nauc_mrr_at_20_max': np.float64(0.7862334193343802), 'nauc_mrr_at_20_std': np.float64(0.15589668225405653), 'nauc_mrr_at_20_diff1': np.float64(0.907246735277992), 'nauc_mrr_at_100_max': np.float64(0.7857108807647025), 'nauc_mrr_at_100_std': np.float64(0.15473897089718977), 'nauc_mrr_at_100_diff1': np.float64(0.9071667019392678), 'nauc_mrr_at_1000_max': np.float64(0.7856636582801596), 'nauc_mrr_at_1000_std': np.float64(0.15456238243226877), 'nauc_mrr_at_1000_diff1': np.float64(0.9071555907420865), 'main_score': 0.93603}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.86333, 'ndcg_at_3': 0.91177, 'ndcg_at_5': 0.91928, 'ndcg_at_10': 0.92482, 'ndcg_at_20': 0.92829, 'ndcg_at_100': 0.92935, 'ndcg_at_1000': 0.92976, 'map_at_1': 0.86333, 'map_at_3': 0.90074, 'map_at_5': 0.90502, 'map_at_10': 0.9074, 'map_at_20': 0.9084, 'map_at_100': 0.90855, 'map_at_1000': 0.90856, 'recall_at_1': 0.86333, 'recall_at_3': 0.94333, 'recall_at_5': 0.96111, 'recall_at_10': 0.97778, 'recall_at_20': 0.99111, 'recall_at_100': 0.99667, 'recall_at_1000': 1.0, 'precision_at_1': 0.86333, 'precision_at_3': 0.31444, 'precision_at_5': 0.19222, 'precision_at_10': 0.09778, 'precision_at_20': 0.04956, 'precision_at_100': 0.00997, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8633333333333333, 'mrr_at_3': 0.9007407407407411, 'mrr_at_5': 0.9050185185185189, 'mrr_at_10': 0.9073955026455032, 'mrr_at_20': 0.908397048370733, 'mrr_at_100': 0.9085521299329449, 'mrr_at_1000': 0.9085648476044211, 'nauc_ndcg_at_1_max': np.float64(0.6099140135155323), 'nauc_ndcg_at_1_std': np.float64(0.00646668712090879), 'nauc_ndcg_at_1_diff1': np.float64(0.903735259178841), 'nauc_ndcg_at_3_max': np.float64(0.6481676790604936), 'nauc_ndcg_at_3_std': np.float64(0.028589359037325752), 'nauc_ndcg_at_3_diff1': np.float64(0.89658797647391), 'nauc_ndcg_at_5_max': np.float64(0.6491416873953931), 'nauc_ndcg_at_5_std': np.float64(0.019473810166820073), 'nauc_ndcg_at_5_diff1': np.float64(0.8958100284140829), 'nauc_ndcg_at_10_max': np.float64(0.6479653772824047), 'nauc_ndcg_at_10_std': np.float64(0.029215214302291608), 'nauc_ndcg_at_10_diff1': np.float64(0.8956806520742397), 'nauc_ndcg_at_20_max': np.float64(0.6413993358261516), 'nauc_ndcg_at_20_std': np.float64(0.026218032748382948), 'nauc_ndcg_at_20_diff1': np.float64(0.9000089526843404), 'nauc_ndcg_at_100_max': np.float64(0.6409812520717987), 'nauc_ndcg_at_100_std': np.float64(0.027445863539626563), 'nauc_ndcg_at_100_diff1': np.float64(0.8996789854457844), 'nauc_ndcg_at_1000_max': np.float64(0.6393593719942897), 'nauc_ndcg_at_1000_std': np.float64(0.022454698103965824), 'nauc_ndcg_at_1000_diff1': np.float64(0.8993256215537422), 'nauc_map_at_1_max': np.float64(0.6099140135155323), 'nauc_map_at_1_std': np.float64(0.00646668712090879), 'nauc_map_at_1_diff1': np.float64(0.903735259178841), 'nauc_map_at_3_max': np.float64(0.6374670650986446), 'nauc_map_at_3_std': np.float64(0.02077754928632171), 'nauc_map_at_3_diff1': np.float64(0.8988737870316825), 'nauc_map_at_5_max': np.float64(0.6373387612313168), 'nauc_map_at_5_std': np.float64(0.016254466520959136), 'nauc_map_at_5_diff1': np.float64(0.8984580242742688), 'nauc_map_at_10_max': np.float64(0.6365719801653463), 'nauc_map_at_10_std': np.float64(0.019304767126614965), 'nauc_map_at_10_diff1': np.float64(0.8984256257105865), 'nauc_map_at_20_max': np.float64(0.6350660515812196), 'nauc_map_at_20_std': np.float64(0.0186524974702766), 'nauc_map_at_20_diff1': np.float64(0.8996288037046547), 'nauc_map_at_100_max': np.float64(0.6350594488184639), 'nauc_map_at_100_std': np.float64(0.01847406737095244), 'nauc_map_at_100_diff1': np.float64(0.8995914231410215), 'nauc_map_at_1000_max': np.float64(0.6350214249075169), 'nauc_map_at_1000_std': np.float64(0.018349457469257657), 'nauc_map_at_1000_diff1': np.float64(0.8995815876496662), 'nauc_recall_at_1_max': np.float64(0.6099140135155323), 'nauc_recall_at_1_std': np.float64(0.00646668712090879), 'nauc_recall_at_1_diff1': np.float64(0.903735259178841), 'nauc_recall_at_3_max': np.float64(0.6996393328573252), 'nauc_recall_at_3_std': np.float64(0.0675106643964764), 'nauc_recall_at_3_diff1': np.float64(0.88535544936929), 'nauc_recall_at_5_max': np.float64(0.7289048952914498), 'nauc_recall_at_5_std': np.float64(0.038882219554492656), 'nauc_recall_at_5_diff1': np.float64(0.877897825796986), 'nauc_recall_at_10_max': np.float64(0.7783146591970082), 'nauc_recall_at_10_std': np.float64(0.15574229691877126), 'nauc_recall_at_10_diff1': np.float64(0.8644024276377222), 'nauc_recall_at_20_max': np.float64(0.7672152194211065), 'nauc_recall_at_20_std': np.float64(0.24358076563958803), 'nauc_recall_at_20_diff1': np.float64(0.9346405228758294), 'nauc_recall_at_100_max': np.float64(0.9128540305010676), 'nauc_recall_at_100_std': np.float64(0.8513849984438123), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6099140135155323), 'nauc_precision_at_1_std': np.float64(0.00646668712090879), 'nauc_precision_at_1_diff1': np.float64(0.903735259178841), 'nauc_precision_at_3_max': np.float64(0.6996393328573267), 'nauc_precision_at_3_std': np.float64(0.06751066439647656), 'nauc_precision_at_3_diff1': np.float64(0.8853554493692909), 'nauc_precision_at_5_max': np.float64(0.7289048952914466), 'nauc_precision_at_5_std': np.float64(0.03888221955448746), 'nauc_precision_at_5_diff1': np.float64(0.8778978257969816), 'nauc_precision_at_10_max': np.float64(0.7783146591970098), 'nauc_precision_at_10_std': np.float64(0.15574229691876484), 'nauc_precision_at_10_diff1': np.float64(0.86440242763772), 'nauc_precision_at_20_max': np.float64(0.7672152194210989), 'nauc_precision_at_20_std': np.float64(0.2435807656395918), 'nauc_precision_at_20_diff1': np.float64(0.9346405228758121), 'nauc_precision_at_100_max': np.float64(0.9128540305010695), 'nauc_precision_at_100_std': np.float64(0.8513849984438455), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505041), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6099140135155323), 'nauc_mrr_at_1_std': np.float64(0.00646668712090879), 'nauc_mrr_at_1_diff1': np.float64(0.903735259178841), 'nauc_mrr_at_3_max': np.float64(0.6374670650986446), 'nauc_mrr_at_3_std': np.float64(0.02077754928632171), 'nauc_mrr_at_3_diff1': np.float64(0.8988737870316825), 'nauc_mrr_at_5_max': np.float64(0.6373387612313168), 'nauc_mrr_at_5_std': np.float64(0.016254466520959136), 'nauc_mrr_at_5_diff1': np.float64(0.8984580242742688), 'nauc_mrr_at_10_max': np.float64(0.6365719801653463), 'nauc_mrr_at_10_std': np.float64(0.019304767126614965), 'nauc_mrr_at_10_diff1': np.float64(0.8984256257105865), 'nauc_mrr_at_20_max': np.float64(0.6350660515812196), 'nauc_mrr_at_20_std': np.float64(0.0186524974702766), 'nauc_mrr_at_20_diff1': np.float64(0.8996288037046547), 'nauc_mrr_at_100_max': np.float64(0.6350594488184639), 'nauc_mrr_at_100_std': np.float64(0.01847406737095244), 'nauc_mrr_at_100_diff1': np.float64(0.8995914231410215), 'nauc_mrr_at_1000_max': np.float64(0.6350214249075169), 'nauc_mrr_at_1000_std': np.float64(0.018349457469257657), 'nauc_mrr_at_1000_diff1': np.float64(0.8995815876496662), 'main_score': 0.92482}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.77556, 'ndcg_at_3': 0.84088, 'ndcg_at_5': 0.8504, 'ndcg_at_10': 0.86177, 'ndcg_at_20': 0.86605, 'ndcg_at_100': 0.87073, 'ndcg_at_1000': 0.87273, 'map_at_1': 0.77556, 'map_at_3': 0.82537, 'map_at_5': 0.83059, 'map_at_10': 0.83543, 'map_at_20': 0.83663, 'map_at_100': 0.83726, 'map_at_1000': 0.83736, 'recall_at_1': 0.77556, 'recall_at_3': 0.88556, 'recall_at_5': 0.90889, 'recall_at_10': 0.94333, 'recall_at_20': 0.96, 'recall_at_100': 0.98556, 'recall_at_1000': 1.0, 'precision_at_1': 0.77556, 'precision_at_3': 0.29519, 'precision_at_5': 0.18178, 'precision_at_10': 0.09433, 'precision_at_20': 0.048, 'precision_at_100': 0.00986, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7755555555555556, 'mrr_at_3': 0.8253703703703703, 'mrr_at_5': 0.8305925925925925, 'mrr_at_10': 0.8354276895943563, 'mrr_at_20': 0.8366342586244548, 'mrr_at_100': 0.8372601744078978, 'mrr_at_1000': 0.8373595118451472, 'nauc_ndcg_at_1_max': np.float64(0.6760802649127515), 'nauc_ndcg_at_1_std': np.float64(0.039787623543968066), 'nauc_ndcg_at_1_diff1': np.float64(0.8762937570044161), 'nauc_ndcg_at_3_max': np.float64(0.7200938991115078), 'nauc_ndcg_at_3_std': np.float64(0.1371129407859106), 'nauc_ndcg_at_3_diff1': np.float64(0.8440609513425971), 'nauc_ndcg_at_5_max': np.float64(0.7320543787124469), 'nauc_ndcg_at_5_std': np.float64(0.16299385867300736), 'nauc_ndcg_at_5_diff1': np.float64(0.849568358592967), 'nauc_ndcg_at_10_max': np.float64(0.7257669827316664), 'nauc_ndcg_at_10_std': np.float64(0.1531268391377476), 'nauc_ndcg_at_10_diff1': np.float64(0.8508223251399955), 'nauc_ndcg_at_20_max': np.float64(0.7255292199942737), 'nauc_ndcg_at_20_std': np.float64(0.15622394129449554), 'nauc_ndcg_at_20_diff1': np.float64(0.8529680001839732), 'nauc_ndcg_at_100_max': np.float64(0.719221257766969), 'nauc_ndcg_at_100_std': np.float64(0.14010098262195667), 'nauc_ndcg_at_100_diff1': np.float64(0.8532814457675549), 'nauc_ndcg_at_1000_max': np.float64(0.7161409407486817), 'nauc_ndcg_at_1000_std': np.float64(0.13118238564932613), 'nauc_ndcg_at_1000_diff1': np.float64(0.8544590134625465), 'nauc_map_at_1_max': np.float64(0.6760802649127515), 'nauc_map_at_1_std': np.float64(0.039787623543968066), 'nauc_map_at_1_diff1': np.float64(0.8762937570044161), 'nauc_map_at_3_max': np.float64(0.7078386195869544), 'nauc_map_at_3_std': np.float64(0.10955607768958464), 'nauc_map_at_3_diff1': np.float64(0.8530087855647857), 'nauc_map_at_5_max': np.float64(0.7133833504561998), 'nauc_map_at_5_std': np.float64(0.12167925414056359), 'nauc_map_at_5_diff1': np.float64(0.8558768280745414), 'nauc_map_at_10_max': np.float64(0.7103867572729406), 'nauc_map_at_10_std': np.float64(0.11659574990893444), 'nauc_map_at_10_diff1': np.float64(0.8565863927007449), 'nauc_map_at_20_max': np.float64(0.7101451002121112), 'nauc_map_at_20_std': np.float64(0.11702640931466465), 'nauc_map_at_20_diff1': np.float64(0.8571124043574347), 'nauc_map_at_100_max': np.float64(0.7093705485013881), 'nauc_map_at_100_std': np.float64(0.11480965523119789), 'nauc_map_at_100_diff1': np.float64(0.8571361229591467), 'nauc_map_at_1000_max': np.float64(0.7092524055868455), 'nauc_map_at_1000_std': np.float64(0.11447619182659889), 'nauc_map_at_1000_diff1': np.float64(0.8571782613197131), 'nauc_recall_at_1_max': np.float64(0.6760802649127515), 'nauc_recall_at_1_std': np.float64(0.039787623543968066), 'nauc_recall_at_1_diff1': np.float64(0.8762937570044161), 'nauc_recall_at_3_max': np.float64(0.7706994921331336), 'nauc_recall_at_3_std': np.float64(0.25120053828357475), 'nauc_recall_at_3_diff1': np.float64(0.8071304139437573), 'nauc_recall_at_5_max': np.float64(0.8277424791054628), 'nauc_recall_at_5_std': np.float64(0.37458723326729154), 'nauc_recall_at_5_diff1': np.float64(0.8201191045523909), 'nauc_recall_at_10_max': np.float64(0.8443089654162333), 'nauc_recall_at_10_std': np.float64(0.4376979549989933), 'nauc_recall_at_10_diff1': np.float64(0.8101462807345169), 'nauc_recall_at_20_max': np.float64(0.892571843552236), 'nauc_recall_at_20_std': np.float64(0.5944081336238212), 'nauc_recall_at_20_diff1': np.float64(0.8199372341529212), 'nauc_recall_at_100_max': np.float64(0.9069884364002062), 'nauc_recall_at_100_std': np.float64(0.6863463334051649), 'nauc_recall_at_100_diff1': np.float64(0.7805788982259576), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6760802649127515), 'nauc_precision_at_1_std': np.float64(0.039787623543968066), 'nauc_precision_at_1_diff1': np.float64(0.8762937570044161), 'nauc_precision_at_3_max': np.float64(0.7706994921331332), 'nauc_precision_at_3_std': np.float64(0.25120053828357747), 'nauc_precision_at_3_diff1': np.float64(0.8071304139437587), 'nauc_precision_at_5_max': np.float64(0.8277424791054608), 'nauc_precision_at_5_std': np.float64(0.3745872332672881), 'nauc_precision_at_5_diff1': np.float64(0.8201191045523888), 'nauc_precision_at_10_max': np.float64(0.8443089654162306), 'nauc_precision_at_10_std': np.float64(0.4376979549989915), 'nauc_precision_at_10_diff1': np.float64(0.8101462807345137), 'nauc_precision_at_20_max': np.float64(0.8925718435522375), 'nauc_precision_at_20_std': np.float64(0.59440813362382), 'nauc_precision_at_20_diff1': np.float64(0.819937234152921), 'nauc_precision_at_100_max': np.float64(0.9069884364002117), 'nauc_precision_at_100_std': np.float64(0.6863463334051753), 'nauc_precision_at_100_diff1': np.float64(0.7805788982259647), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6760802649127515), 'nauc_mrr_at_1_std': np.float64(0.039787623543968066), 'nauc_mrr_at_1_diff1': np.float64(0.8762937570044161), 'nauc_mrr_at_3_max': np.float64(0.7078386195869544), 'nauc_mrr_at_3_std': np.float64(0.10955607768958464), 'nauc_mrr_at_3_diff1': np.float64(0.8530087855647857), 'nauc_mrr_at_5_max': np.float64(0.7133833504561998), 'nauc_mrr_at_5_std': np.float64(0.12167925414056359), 'nauc_mrr_at_5_diff1': np.float64(0.8558768280745414), 'nauc_mrr_at_10_max': np.float64(0.7103867572729406), 'nauc_mrr_at_10_std': np.float64(0.11659574990893444), 'nauc_mrr_at_10_diff1': np.float64(0.8565863927007449), 'nauc_mrr_at_20_max': np.float64(0.7101451002121112), 'nauc_mrr_at_20_std': np.float64(0.11702640931466465), 'nauc_mrr_at_20_diff1': np.float64(0.8571124043574347), 'nauc_mrr_at_100_max': np.float64(0.7093705485013881), 'nauc_mrr_at_100_std': np.float64(0.11480965523119789), 'nauc_mrr_at_100_diff1': np.float64(0.8571361229591467), 'nauc_mrr_at_1000_max': np.float64(0.7092524055868455), 'nauc_mrr_at_1000_std': np.float64(0.11447619182659889), 'nauc_mrr_at_1000_diff1': np.float64(0.8571782613197131), 'main_score': 0.86177}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  5.21it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.25it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.72 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  5.59it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  5.57it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  7.75it/s]Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.25it/s]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.41s/it]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.76 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.78it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.35it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.34it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.67 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 10.08 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.3104, 'ndcg_at_3': 0.34404, 'ndcg_at_5': 0.36921, 'ndcg_at_10': 0.39707, 'ndcg_at_20': 0.42032, 'ndcg_at_100': 0.4715, 'ndcg_at_1000': 0.49425, 'map_at_1': 0.21888, 'map_at_3': 0.31243, 'map_at_5': 0.33255, 'map_at_10': 0.34644, 'map_at_20': 0.3543, 'map_at_100': 0.3624, 'map_at_1000': 0.36344, 'recall_at_1': 0.21888, 'recall_at_3': 0.36942, 'recall_at_5': 0.43282, 'recall_at_10': 0.50757, 'recall_at_20': 0.58723, 'recall_at_100': 0.83588, 'recall_at_1000': 1.0, 'precision_at_1': 0.3104, 'precision_at_3': 0.19419, 'precision_at_5': 0.13731, 'precision_at_10': 0.08135, 'precision_at_20': 0.04763, 'precision_at_100': 0.01338, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.3103975535168196, 'mrr_at_3': 0.36340468909276263, 'mrr_at_5': 0.37579001019367986, 'mrr_at_10': 0.3859278675792436, 'mrr_at_20': 0.390748695874807, 'mrr_at_100': 0.3967888678551078, 'mrr_at_1000': 0.3974932025086132, 'nauc_ndcg_at_1_max': np.float64(0.14834968074029853), 'nauc_ndcg_at_1_std': np.float64(-0.3323893090055653), 'nauc_ndcg_at_1_diff1': np.float64(0.5390638956654156), 'nauc_ndcg_at_3_max': np.float64(0.12533896822516902), 'nauc_ndcg_at_3_std': np.float64(-0.34682086222663394), 'nauc_ndcg_at_3_diff1': np.float64(0.49350845252301123), 'nauc_ndcg_at_5_max': np.float64(0.13637160732355455), 'nauc_ndcg_at_5_std': np.float64(-0.3492880140693769), 'nauc_ndcg_at_5_diff1': np.float64(0.4877468760647533), 'nauc_ndcg_at_10_max': np.float64(0.13804842516428034), 'nauc_ndcg_at_10_std': np.float64(-0.3623063826885174), 'nauc_ndcg_at_10_diff1': np.float64(0.493470036717251), 'nauc_ndcg_at_20_max': np.float64(0.136638217524365), 'nauc_ndcg_at_20_std': np.float64(-0.35319808840597094), 'nauc_ndcg_at_20_diff1': np.float64(0.4800543938254261), 'nauc_ndcg_at_100_max': np.float64(0.15600705651947083), 'nauc_ndcg_at_100_std': np.float64(-0.32005889573707524), 'nauc_ndcg_at_100_diff1': np.float64(0.47580485654665317), 'nauc_ndcg_at_1000_max': np.float64(0.1470129720870552), 'nauc_ndcg_at_1000_std': np.float64(-0.3359621299081911), 'nauc_ndcg_at_1000_diff1': np.float64(0.487096766754959), 'nauc_map_at_1_max': np.float64(0.10719703322248628), 'nauc_map_at_1_std': np.float64(-0.28511277812214025), 'nauc_map_at_1_diff1': np.float64(0.5781701087616348), 'nauc_map_at_3_max': np.float64(0.13328509422007276), 'nauc_map_at_3_std': np.float64(-0.33551483755589023), 'nauc_map_at_3_diff1': np.float64(0.4996576301659027), 'nauc_map_at_5_max': np.float64(0.14121622178261256), 'nauc_map_at_5_std': np.float64(-0.34331452148875213), 'nauc_map_at_5_diff1': np.float64(0.49831079971449793), 'nauc_map_at_10_max': np.float64(0.1399384905919865), 'nauc_map_at_10_std': np.float64(-0.35158569674334), 'nauc_map_at_10_diff1': np.float64(0.5005372331022767), 'nauc_map_at_20_max': np.float64(0.13785338260376398), 'nauc_map_at_20_std': np.float64(-0.3503456337310843), 'nauc_map_at_20_diff1': np.float64(0.496107922999249), 'nauc_map_at_100_max': np.float64(0.14035435407694416), 'nauc_map_at_100_std': np.float64(-0.34553073006974266), 'nauc_map_at_100_diff1': np.float64(0.49543686503087836), 'nauc_map_at_1000_max': np.float64(0.14028282686328525), 'nauc_map_at_1000_std': np.float64(-0.3459841122356278), 'nauc_map_at_1000_diff1': np.float64(0.49591048616784206), 'nauc_recall_at_1_max': np.float64(0.10719703322248628), 'nauc_recall_at_1_std': np.float64(-0.28511277812214025), 'nauc_recall_at_1_diff1': np.float64(0.5781701087616348), 'nauc_recall_at_3_max': np.float64(0.10864805299445435), 'nauc_recall_at_3_std': np.float64(-0.33129118870640384), 'nauc_recall_at_3_diff1': np.float64(0.449002186550647), 'nauc_recall_at_5_max': np.float64(0.1290461802519051), 'nauc_recall_at_5_std': np.float64(-0.34324505890807), 'nauc_recall_at_5_diff1': np.float64(0.43291512849498687), 'nauc_recall_at_10_max': np.float64(0.13565799896280048), 'nauc_recall_at_10_std': np.float64(-0.3763639323572944), 'nauc_recall_at_10_diff1': np.float64(0.4479461904649116), 'nauc_recall_at_20_max': np.float64(0.13123362735401065), 'nauc_recall_at_20_std': np.float64(-0.34386886741531253), 'nauc_recall_at_20_diff1': np.float64(0.3995124928723459), 'nauc_recall_at_100_max': np.float64(0.2946376260903222), 'nauc_recall_at_100_std': np.float64(-0.07026404396503054), 'nauc_recall_at_100_diff1': np.float64(0.29660023226530086), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.14834968074029853), 'nauc_precision_at_1_std': np.float64(-0.3323893090055653), 'nauc_precision_at_1_diff1': np.float64(0.5390638956654156), 'nauc_precision_at_3_max': np.float64(0.14161658092880383), 'nauc_precision_at_3_std': np.float64(-0.3274281750452455), 'nauc_precision_at_3_diff1': np.float64(0.3093249601252475), 'nauc_precision_at_5_max': np.float64(0.14083496728899653), 'nauc_precision_at_5_std': np.float64(-0.31740076848026383), 'nauc_precision_at_5_diff1': np.float64(0.2822771751068877), 'nauc_precision_at_10_max': np.float64(0.12545697636574826), 'nauc_precision_at_10_std': np.float64(-0.326030136947804), 'nauc_precision_at_10_diff1': np.float64(0.26597821242111674), 'nauc_precision_at_20_max': np.float64(0.10564285170277886), 'nauc_precision_at_20_std': np.float64(-0.2660391616327411), 'nauc_precision_at_20_diff1': np.float64(0.1868671840417624), 'nauc_precision_at_100_max': np.float64(0.1609741460344705), 'nauc_precision_at_100_std': np.float64(-0.0345839278424397), 'nauc_precision_at_100_diff1': np.float64(0.039208989431007195), 'nauc_precision_at_1000_max': np.float64(0.12006674175244639), 'nauc_precision_at_1000_std': np.float64(0.002945125623194666), 'nauc_precision_at_1000_diff1': np.float64(-0.045768620160346093), 'nauc_mrr_at_1_max': np.float64(0.15117718045901007), 'nauc_mrr_at_1_std': np.float64(-0.33100154279766275), 'nauc_mrr_at_1_diff1': np.float64(0.5390638956654156), 'nauc_mrr_at_3_max': np.float64(0.13248407148826533), 'nauc_mrr_at_3_std': np.float64(-0.3447206399375596), 'nauc_mrr_at_3_diff1': np.float64(0.509788966998799), 'nauc_mrr_at_5_max': np.float64(0.13431802842239943), 'nauc_mrr_at_5_std': np.float64(-0.3468864302001804), 'nauc_mrr_at_5_diff1': np.float64(0.5043761783566625), 'nauc_mrr_at_10_max': np.float64(0.13808778862439594), 'nauc_mrr_at_10_std': np.float64(-0.3495090812065351), 'nauc_mrr_at_10_diff1': np.float64(0.5079791048586596), 'nauc_mrr_at_20_max': np.float64(0.14035867408078453), 'nauc_mrr_at_20_std': np.float64(-0.3453497263971695), 'nauc_mrr_at_20_diff1': np.float64(0.5061783151248821), 'nauc_mrr_at_100_max': np.float64(0.14122605744615374), 'nauc_mrr_at_100_std': np.float64(-0.34243986457537157), 'nauc_mrr_at_100_diff1': np.float64(0.5054793341924164), 'nauc_mrr_at_1000_max': np.float64(0.1407552976122019), 'nauc_mrr_at_1000_std': np.float64(-0.3430961687881763), 'nauc_mrr_at_1000_diff1': np.float64(0.5058495426201375), 'main_score': 0.39707}, 'eng-kor': {'ndcg_at_1': 0.28746, 'ndcg_at_3': 0.30061, 'ndcg_at_5': 0.3138, 'ndcg_at_10': 0.34841, 'ndcg_at_20': 0.37634, 'ndcg_at_100': 0.43494, 'ndcg_at_1000': 0.46327, 'map_at_1': 0.16119, 'map_at_3': 0.24874, 'map_at_5': 0.27052, 'map_at_10': 0.28896, 'map_at_20': 0.29894, 'map_at_100': 0.30908, 'map_at_1000': 0.31067, 'recall_at_1': 0.16119, 'recall_at_3': 0.29924, 'recall_at_5': 0.3542, 'recall_at_10': 0.44134, 'recall_at_20': 0.53196, 'recall_at_100': 0.8066, 'recall_at_1000': 0.99694, 'precision_at_1': 0.28746, 'precision_at_3': 0.19878, 'precision_at_5': 0.14495, 'precision_at_10': 0.09174, 'precision_at_20': 0.05573, 'precision_at_100': 0.01619, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.2874617737003058, 'mrr_at_3': 0.34225280326197766, 'mrr_at_5': 0.3528797145769623, 'mrr_at_10': 0.3652978010776175, 'mrr_at_20': 0.37098345575246466, 'mrr_at_100': 0.3767028672434493, 'mrr_at_1000': 0.37742610811331717, 'nauc_ndcg_at_1_max': np.float64(0.11677365601832777), 'nauc_ndcg_at_1_std': np.float64(-0.2698572961246088), 'nauc_ndcg_at_1_diff1': np.float64(0.43740382846764175), 'nauc_ndcg_at_3_max': np.float64(0.07053393241475597), 'nauc_ndcg_at_3_std': np.float64(-0.29695610983765675), 'nauc_ndcg_at_3_diff1': np.float64(0.41145677773371586), 'nauc_ndcg_at_5_max': np.float64(0.06979206883199347), 'nauc_ndcg_at_5_std': np.float64(-0.29157023703733664), 'nauc_ndcg_at_5_diff1': np.float64(0.4024047948546219), 'nauc_ndcg_at_10_max': np.float64(0.07385113898415496), 'nauc_ndcg_at_10_std': np.float64(-0.28787037496235957), 'nauc_ndcg_at_10_diff1': np.float64(0.39027358575821325), 'nauc_ndcg_at_20_max': np.float64(0.08758670201339429), 'nauc_ndcg_at_20_std': np.float64(-0.2804659810649404), 'nauc_ndcg_at_20_diff1': np.float64(0.3874176441265369), 'nauc_ndcg_at_100_max': np.float64(0.10597859126521968), 'nauc_ndcg_at_100_std': np.float64(-0.258185304539762), 'nauc_ndcg_at_100_diff1': np.float64(0.38992425755611415), 'nauc_ndcg_at_1000_max': np.float64(0.09704818605828966), 'nauc_ndcg_at_1000_std': np.float64(-0.2649304942708969), 'nauc_ndcg_at_1000_diff1': np.float64(0.39391795387589484), 'nauc_map_at_1_max': np.float64(0.11557448945335527), 'nauc_map_at_1_std': np.float64(-0.23419923263440692), 'nauc_map_at_1_diff1': np.float64(0.4735449804969547), 'nauc_map_at_3_max': np.float64(0.08496746569192953), 'nauc_map_at_3_std': np.float64(-0.28326006526515524), 'nauc_map_at_3_diff1': np.float64(0.4305227101064009), 'nauc_map_at_5_max': np.float64(0.08322179074994965), 'nauc_map_at_5_std': np.float64(-0.28357612056660997), 'nauc_map_at_5_diff1': np.float64(0.417702302127094), 'nauc_map_at_10_max': np.float64(0.08589419699948006), 'nauc_map_at_10_std': np.float64(-0.28262282318731974), 'nauc_map_at_10_diff1': np.float64(0.4145227281510094), 'nauc_map_at_20_max': np.float64(0.08882967646757318), 'nauc_map_at_20_std': np.float64(-0.2823900101373965), 'nauc_map_at_20_diff1': np.float64(0.4126405874187155), 'nauc_map_at_100_max': np.float64(0.09069151597150764), 'nauc_map_at_100_std': np.float64(-0.280352223700918), 'nauc_map_at_100_diff1': np.float64(0.413122374133709), 'nauc_map_at_1000_max': np.float64(0.09108221009570636), 'nauc_map_at_1000_std': np.float64(-0.2795180112583092), 'nauc_map_at_1000_diff1': np.float64(0.41315199783914125), 'nauc_recall_at_1_max': np.float64(0.11557448945335527), 'nauc_recall_at_1_std': np.float64(-0.23419923263440692), 'nauc_recall_at_1_diff1': np.float64(0.4735449804969547), 'nauc_recall_at_3_max': np.float64(0.04273611887453051), 'nauc_recall_at_3_std': np.float64(-0.2853142281086032), 'nauc_recall_at_3_diff1': np.float64(0.38199046436812034), 'nauc_recall_at_5_max': np.float64(0.0396709372361749), 'nauc_recall_at_5_std': np.float64(-0.28992910337340866), 'nauc_recall_at_5_diff1': np.float64(0.3578768702518169), 'nauc_recall_at_10_max': np.float64(0.047146411828744204), 'nauc_recall_at_10_std': np.float64(-0.27583519148160984), 'nauc_recall_at_10_diff1': np.float64(0.32358193907007804), 'nauc_recall_at_20_max': np.float64(0.09511191745520513), 'nauc_recall_at_20_std': np.float64(-0.24451933307554508), 'nauc_recall_at_20_diff1': np.float64(0.3098775961160975), 'nauc_recall_at_100_max': np.float64(0.23338288447757893), 'nauc_recall_at_100_std': np.float64(-0.08434646011183694), 'nauc_recall_at_100_diff1': np.float64(0.29837835006639124), 'nauc_recall_at_1000_max': np.float64(-0.0754372826685466), 'nauc_recall_at_1000_std': np.float64(-0.4366799748609778), 'nauc_recall_at_1000_diff1': np.float64(0.6789912062843171), 'nauc_precision_at_1_max': np.float64(0.11677365601832777), 'nauc_precision_at_1_std': np.float64(-0.2698572961246088), 'nauc_precision_at_1_diff1': np.float64(0.43740382846764175), 'nauc_precision_at_3_max': np.float64(0.04448162046598827), 'nauc_precision_at_3_std': np.float64(-0.2781433279019405), 'nauc_precision_at_3_diff1': np.float64(0.29768760918340975), 'nauc_precision_at_5_max': np.float64(0.043131129659799046), 'nauc_precision_at_5_std': np.float64(-0.2500670288977752), 'nauc_precision_at_5_diff1': np.float64(0.25048787306224374), 'nauc_precision_at_10_max': np.float64(0.051045685159536135), 'nauc_precision_at_10_std': np.float64(-0.2167052980022179), 'nauc_precision_at_10_diff1': np.float64(0.20711936911283332), 'nauc_precision_at_20_max': np.float64(0.06507220082927256), 'nauc_precision_at_20_std': np.float64(-0.18406382211925656), 'nauc_precision_at_20_diff1': np.float64(0.16924980401639336), 'nauc_precision_at_100_max': np.float64(0.09762536800572956), 'nauc_precision_at_100_std': np.float64(-0.039848205836443336), 'nauc_precision_at_100_diff1': np.float64(0.06819743072956849), 'nauc_precision_at_1000_max': np.float64(0.068882805437944), 'nauc_precision_at_1000_std': np.float64(0.018982569283596245), 'nauc_precision_at_1000_diff1': np.float64(0.0009610676753889071), 'nauc_mrr_at_1_max': np.float64(0.11677365601832777), 'nauc_mrr_at_1_std': np.float64(-0.2698572961246088), 'nauc_mrr_at_1_diff1': np.float64(0.43740382846764175), 'nauc_mrr_at_3_max': np.float64(0.07698017878099053), 'nauc_mrr_at_3_std': np.float64(-0.2843971691113085), 'nauc_mrr_at_3_diff1': np.float64(0.40503515717593835), 'nauc_mrr_at_5_max': np.float64(0.07626824384362946), 'nauc_mrr_at_5_std': np.float64(-0.2857321222527295), 'nauc_mrr_at_5_diff1': np.float64(0.39839825834339876), 'nauc_mrr_at_10_max': np.float64(0.07703168320748324), 'nauc_mrr_at_10_std': np.float64(-0.28513963248866475), 'nauc_mrr_at_10_diff1': np.float64(0.3930542777013584), 'nauc_mrr_at_20_max': np.float64(0.08208527134784778), 'nauc_mrr_at_20_std': np.float64(-0.2808158367902323), 'nauc_mrr_at_20_diff1': np.float64(0.39314597108049554), 'nauc_mrr_at_100_max': np.float64(0.08451792719081944), 'nauc_mrr_at_100_std': np.float64(-0.2782149386608983), 'nauc_mrr_at_100_diff1': np.float64(0.3951511792598903), 'nauc_mrr_at_1000_max': np.float64(0.08411007678657985), 'nauc_mrr_at_1000_std': np.float64(-0.27872651010418464), 'nauc_mrr_at_1000_diff1': np.float64(0.3952980097131502), 'main_score': 0.34841}, 'kor-eng': {'ndcg_at_1': 0.27524, 'ndcg_at_3': 0.3106, 'ndcg_at_5': 0.33905, 'ndcg_at_10': 0.37362, 'ndcg_at_20': 0.39758, 'ndcg_at_100': 0.44773, 'ndcg_at_1000': 0.47333, 'map_at_1': 0.19463, 'map_at_3': 0.27894, 'map_at_5': 0.30078, 'map_at_10': 0.31843, 'map_at_20': 0.32658, 'map_at_100': 0.33451, 'map_at_1000': 0.33566, 'recall_at_1': 0.19463, 'recall_at_3': 0.33201, 'recall_at_5': 0.39986, 'recall_at_10': 0.49377, 'recall_at_20': 0.57375, 'recall_at_100': 0.81522, 'recall_at_1000': 1.0, 'precision_at_1': 0.27524, 'precision_at_3': 0.17644, 'precision_at_5': 0.1316, 'precision_at_10': 0.08274, 'precision_at_20': 0.04886, 'precision_at_100': 0.01391, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.2768729641693811, 'mrr_at_3': 0.3327904451682954, 'mrr_at_5': 0.34744842562432143, 'mrr_at_10': 0.35923297657825337, 'mrr_at_20': 0.36475101994427894, 'mrr_at_100': 0.37017895505352316, 'mrr_at_1000': 0.3708681532715571, 'nauc_ndcg_at_1_max': np.float64(0.07101697112154846), 'nauc_ndcg_at_1_std': np.float64(-0.2720158381402068), 'nauc_ndcg_at_1_diff1': np.float64(0.523765306788138), 'nauc_ndcg_at_3_max': np.float64(0.03906989286876069), 'nauc_ndcg_at_3_std': np.float64(-0.29060607655626514), 'nauc_ndcg_at_3_diff1': np.float64(0.4432800428492287), 'nauc_ndcg_at_5_max': np.float64(0.021115016659003588), 'nauc_ndcg_at_5_std': np.float64(-0.3103213106649532), 'nauc_ndcg_at_5_diff1': np.float64(0.43110058636948856), 'nauc_ndcg_at_10_max': np.float64(0.031247849028525922), 'nauc_ndcg_at_10_std': np.float64(-0.327315550021495), 'nauc_ndcg_at_10_diff1': np.float64(0.4292334638162514), 'nauc_ndcg_at_20_max': np.float64(0.04314049440438147), 'nauc_ndcg_at_20_std': np.float64(-0.3168790236091491), 'nauc_ndcg_at_20_diff1': np.float64(0.42729314120734857), 'nauc_ndcg_at_100_max': np.float64(0.06770640652471913), 'nauc_ndcg_at_100_std': np.float64(-0.26492427405578245), 'nauc_ndcg_at_100_diff1': np.float64(0.40780572219647865), 'nauc_ndcg_at_1000_max': np.float64(0.05589735523371463), 'nauc_ndcg_at_1000_std': np.float64(-0.28557391268203103), 'nauc_ndcg_at_1000_diff1': np.float64(0.42581988354892875), 'nauc_map_at_1_max': np.float64(0.0333779502484941), 'nauc_map_at_1_std': np.float64(-0.2292104531599672), 'nauc_map_at_1_diff1': np.float64(0.559219762859922), 'nauc_map_at_3_max': np.float64(0.04254275361818072), 'nauc_map_at_3_std': np.float64(-0.2798266220542301), 'nauc_map_at_3_diff1': np.float64(0.4526148932750387), 'nauc_map_at_5_max': np.float64(0.03350765226893604), 'nauc_map_at_5_std': np.float64(-0.2995804061568846), 'nauc_map_at_5_diff1': np.float64(0.4447211086874347), 'nauc_map_at_10_max': np.float64(0.03403864031236228), 'nauc_map_at_10_std': np.float64(-0.31257156025004057), 'nauc_map_at_10_diff1': np.float64(0.44069146485244526), 'nauc_map_at_20_max': np.float64(0.03772664173707162), 'nauc_map_at_20_std': np.float64(-0.3099746521842217), 'nauc_map_at_20_diff1': np.float64(0.43999334321221434), 'nauc_map_at_100_max': np.float64(0.0412427867547448), 'nauc_map_at_100_std': np.float64(-0.3009324279139346), 'nauc_map_at_100_diff1': np.float64(0.4365896389216951), 'nauc_map_at_1000_max': np.float64(0.04086724125824777), 'nauc_map_at_1000_std': np.float64(-0.3015922317750913), 'nauc_map_at_1000_diff1': np.float64(0.4372179528172179), 'nauc_recall_at_1_max': np.float64(0.0333779502484941), 'nauc_recall_at_1_std': np.float64(-0.2292104531599672), 'nauc_recall_at_1_diff1': np.float64(0.559219762859922), 'nauc_recall_at_3_max': np.float64(0.022559669627852694), 'nauc_recall_at_3_std': np.float64(-0.2846336396017293), 'nauc_recall_at_3_diff1': np.float64(0.4022223245390467), 'nauc_recall_at_5_max': np.float64(-0.012792130331053676), 'nauc_recall_at_5_std': np.float64(-0.32005091586926443), 'nauc_recall_at_5_diff1': np.float64(0.3679812375196208), 'nauc_recall_at_10_max': np.float64(0.015348344799469206), 'nauc_recall_at_10_std': np.float64(-0.3570225338139556), 'nauc_recall_at_10_diff1': np.float64(0.3555907198854983), 'nauc_recall_at_20_max': np.float64(0.05228464701534023), 'nauc_recall_at_20_std': np.float64(-0.3241105035389205), 'nauc_recall_at_20_diff1': np.float64(0.34608024569553586), 'nauc_recall_at_100_max': np.float64(0.22028163178567373), 'nauc_recall_at_100_std': np.float64(0.028221514320504418), 'nauc_recall_at_100_diff1': np.float64(0.14991060605979836), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.07101697112154846), 'nauc_precision_at_1_std': np.float64(-0.2720158381402068), 'nauc_precision_at_1_diff1': np.float64(0.523765306788138), 'nauc_precision_at_3_max': np.float64(0.06826016185057171), 'nauc_precision_at_3_std': np.float64(-0.2858467909073881), 'nauc_precision_at_3_diff1': np.float64(0.2713052716012502), 'nauc_precision_at_5_max': np.float64(0.023133283983209067), 'nauc_precision_at_5_std': np.float64(-0.3160598731040262), 'nauc_precision_at_5_diff1': np.float64(0.2280125906101646), 'nauc_precision_at_10_max': np.float64(0.041005225200070675), 'nauc_precision_at_10_std': np.float64(-0.315577687963074), 'nauc_precision_at_10_diff1': np.float64(0.1915645014143839), 'nauc_precision_at_20_max': np.float64(0.0720271579037407), 'nauc_precision_at_20_std': np.float64(-0.25184817016670064), 'nauc_precision_at_20_diff1': np.float64(0.15339608431123142), 'nauc_precision_at_100_max': np.float64(0.17990596259954394), 'nauc_precision_at_100_std': np.float64(0.042071449268137315), 'nauc_precision_at_100_diff1': np.float64(-0.0362820626027741), 'nauc_precision_at_1000_max': np.float64(0.15769782136238175), 'nauc_precision_at_1000_std': np.float64(0.0632262670206087), 'nauc_precision_at_1000_diff1': np.float64(-0.08168935692979885), 'nauc_mrr_at_1_max': np.float64(0.06728314865997019), 'nauc_mrr_at_1_std': np.float64(-0.27480276718724933), 'nauc_mrr_at_1_diff1': np.float64(0.5174212832386107), 'nauc_mrr_at_3_max': np.float64(0.04856455404051944), 'nauc_mrr_at_3_std': np.float64(-0.29686131961875006), 'nauc_mrr_at_3_diff1': np.float64(0.4699834349712395), 'nauc_mrr_at_5_max': np.float64(0.03785988557408071), 'nauc_mrr_at_5_std': np.float64(-0.3007018584582903), 'nauc_mrr_at_5_diff1': np.float64(0.46085359987480284), 'nauc_mrr_at_10_max': np.float64(0.04490348944714986), 'nauc_mrr_at_10_std': np.float64(-0.30137100809417605), 'nauc_mrr_at_10_diff1': np.float64(0.4632551634842999), 'nauc_mrr_at_20_max': np.float64(0.0480630108242807), 'nauc_mrr_at_20_std': np.float64(-0.2982881905836301), 'nauc_mrr_at_20_diff1': np.float64(0.46286367227252323), 'nauc_mrr_at_100_max': np.float64(0.049888799079959786), 'nauc_mrr_at_100_std': np.float64(-0.29380202956522344), 'nauc_mrr_at_100_diff1': np.float64(0.461135210895071), 'nauc_mrr_at_1000_max': np.float64(0.049477713482214566), 'nauc_mrr_at_1000_std': np.float64(-0.2944233554987918), 'nauc_mrr_at_1000_diff1': np.float64(0.46150164228657825), 'main_score': 0.37362}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:02<00:33,  2.82s/it]Batches:  15%|█▌        | 2/13 [00:05<00:27,  2.48s/it]Batches:  23%|██▎       | 3/13 [00:07<00:23,  2.30s/it]Batches:  31%|███       | 4/13 [00:09<00:19,  2.22s/it]Batches:  38%|███▊      | 5/13 [00:11<00:17,  2.17s/it]Batches:  46%|████▌     | 6/13 [00:13<00:15,  2.15s/it]Batches:  54%|█████▍    | 7/13 [00:15<00:12,  2.14s/it]Batches:  62%|██████▏   | 8/13 [00:18<00:11,  2.24s/it]Batches:  69%|██████▉   | 9/13 [00:20<00:09,  2.30s/it]Batches:  77%|███████▋  | 10/13 [00:23<00:07,  2.39s/it]Batches:  85%|████████▍ | 11/13 [00:25<00:04,  2.43s/it]Batches:  92%|█████████▏| 12/13 [00:28<00:02,  2.51s/it]Batches: 100%|██████████| 13/13 [00:30<00:00,  2.44s/it]Batches: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.62 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 31.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.195, 'ndcg_at_3': 0.24524, 'ndcg_at_5': 0.26374, 'ndcg_at_10': 0.27828, 'ndcg_at_20': 0.2971, 'ndcg_at_100': 0.32793, 'ndcg_at_1000': 0.36011, 'map_at_1': 0.195, 'map_at_3': 0.23167, 'map_at_5': 0.24192, 'map_at_10': 0.24793, 'map_at_20': 0.25301, 'map_at_100': 0.25733, 'map_at_1000': 0.25831, 'recall_at_1': 0.195, 'recall_at_3': 0.285, 'recall_at_5': 0.33, 'recall_at_10': 0.375, 'recall_at_20': 0.45, 'recall_at_100': 0.615, 'recall_at_1000': 0.88, 'precision_at_1': 0.195, 'precision_at_3': 0.095, 'precision_at_5': 0.066, 'precision_at_10': 0.0375, 'precision_at_20': 0.0225, 'precision_at_100': 0.00615, 'precision_at_1000': 0.00088, 'mrr_at_1': 0.195, 'mrr_at_3': 0.2316666666666667, 'mrr_at_5': 0.24191666666666667, 'mrr_at_10': 0.24793055555555552, 'mrr_at_20': 0.25301386040859725, 'mrr_at_100': 0.25732841973878956, 'mrr_at_1000': 0.25830738214181687, 'nauc_ndcg_at_1_max': np.float64(0.2943012692215825), 'nauc_ndcg_at_1_std': np.float64(-0.007264460972054072), 'nauc_ndcg_at_1_diff1': np.float64(0.4043965637946514), 'nauc_ndcg_at_3_max': np.float64(0.25729722647928605), 'nauc_ndcg_at_3_std': np.float64(-0.006994806000349935), 'nauc_ndcg_at_3_diff1': np.float64(0.38865328684778994), 'nauc_ndcg_at_5_max': np.float64(0.2673194826391847), 'nauc_ndcg_at_5_std': np.float64(0.019961780151737902), 'nauc_ndcg_at_5_diff1': np.float64(0.36569527116764655), 'nauc_ndcg_at_10_max': np.float64(0.2470029346381694), 'nauc_ndcg_at_10_std': np.float64(0.0026224207507512883), 'nauc_ndcg_at_10_diff1': np.float64(0.35737559789466666), 'nauc_ndcg_at_20_max': np.float64(0.25515519585709295), 'nauc_ndcg_at_20_std': np.float64(0.037645474464617634), 'nauc_ndcg_at_20_diff1': np.float64(0.3469171199568039), 'nauc_ndcg_at_100_max': np.float64(0.26289410196563623), 'nauc_ndcg_at_100_std': np.float64(0.0711830530847509), 'nauc_ndcg_at_100_diff1': np.float64(0.33170253659790533), 'nauc_ndcg_at_1000_max': np.float64(0.2625720695897485), 'nauc_ndcg_at_1000_std': np.float64(0.053290613653258864), 'nauc_ndcg_at_1000_diff1': np.float64(0.34071614158847124), 'nauc_map_at_1_max': np.float64(0.2943012692215825), 'nauc_map_at_1_std': np.float64(-0.007264460972054072), 'nauc_map_at_1_diff1': np.float64(0.4043965637946514), 'nauc_map_at_3_max': np.float64(0.262287901437037), 'nauc_map_at_3_std': np.float64(-0.008466116434885087), 'nauc_map_at_3_diff1': np.float64(0.38948592121380365), 'nauc_map_at_5_max': np.float64(0.2678540851429975), 'nauc_map_at_5_std': np.float64(0.007650126294619136), 'nauc_map_at_5_diff1': np.float64(0.37626056796857993), 'nauc_map_at_10_max': np.float64(0.25974642536519105), 'nauc_map_at_10_std': np.float64(0.0001995666797276549), 'nauc_map_at_10_diff1': np.float64(0.372007297756856), 'nauc_map_at_20_max': np.float64(0.2624500083633629), 'nauc_map_at_20_std': np.float64(0.009644934813633063), 'nauc_map_at_20_diff1': np.float64(0.3692359976230927), 'nauc_map_at_100_max': np.float64(0.26309352649809375), 'nauc_map_at_100_std': np.float64(0.01425853004668684), 'nauc_map_at_100_diff1': np.float64(0.3670433676629534), 'nauc_map_at_1000_max': np.float64(0.2629160244468375), 'nauc_map_at_1000_std': np.float64(0.013441533849383624), 'nauc_map_at_1000_diff1': np.float64(0.36727308033552175), 'nauc_recall_at_1_max': np.float64(0.2943012692215825), 'nauc_recall_at_1_std': np.float64(-0.007264460972054072), 'nauc_recall_at_1_diff1': np.float64(0.4043965637946514), 'nauc_recall_at_3_max': np.float64(0.24547261407627485), 'nauc_recall_at_3_std': np.float64(-0.002617746660295337), 'nauc_recall_at_3_diff1': np.float64(0.38748190776944436), 'nauc_recall_at_5_max': np.float64(0.26856918427394116), 'nauc_recall_at_5_std': np.float64(0.054492684160775344), 'nauc_recall_at_5_diff1': np.float64(0.3369346700217012), 'nauc_recall_at_10_max': np.float64(0.20927536231884059), 'nauc_recall_at_10_std': np.float64(0.005738479075069209), 'nauc_recall_at_10_diff1': np.float64(0.3174922651034034), 'nauc_recall_at_20_max': np.float64(0.23550710403980876), 'nauc_recall_at_20_std': np.float64(0.13421069861847698), 'nauc_recall_at_20_diff1': np.float64(0.27857657303738653), 'nauc_recall_at_100_max': np.float64(0.28055091883322264), 'nauc_recall_at_100_std': np.float64(0.33297509889557103), 'nauc_recall_at_100_diff1': np.float64(0.18349225222753207), 'nauc_recall_at_1000_max': np.float64(0.32661867642379955), 'nauc_recall_at_1000_std': np.float64(0.4211541520839954), 'nauc_recall_at_1000_diff1': np.float64(0.1427378300986306), 'nauc_precision_at_1_max': np.float64(0.2943012692215825), 'nauc_precision_at_1_std': np.float64(-0.007264460972054072), 'nauc_precision_at_1_diff1': np.float64(0.4043965637946514), 'nauc_precision_at_3_max': np.float64(0.24547261407627474), 'nauc_precision_at_3_std': np.float64(-0.0026177466602957254), 'nauc_precision_at_3_diff1': np.float64(0.38748190776944447), 'nauc_precision_at_5_max': np.float64(0.2685691842739411), 'nauc_precision_at_5_std': np.float64(0.05449268416077547), 'nauc_precision_at_5_diff1': np.float64(0.3369346700217014), 'nauc_precision_at_10_max': np.float64(0.20927536231884078), 'nauc_precision_at_10_std': np.float64(0.005738479075069121), 'nauc_precision_at_10_diff1': np.float64(0.3174922651034033), 'nauc_precision_at_20_max': np.float64(0.2355071040398088), 'nauc_precision_at_20_std': np.float64(0.13421069861847706), 'nauc_precision_at_20_diff1': np.float64(0.2785765730373863), 'nauc_precision_at_100_max': np.float64(0.2805509188332227), 'nauc_precision_at_100_std': np.float64(0.33297509889557114), 'nauc_precision_at_100_diff1': np.float64(0.18349225222753304), 'nauc_precision_at_1000_max': np.float64(0.3266186764237976), 'nauc_precision_at_1000_std': np.float64(0.4211541520839966), 'nauc_precision_at_1000_diff1': np.float64(0.14273783009863025), 'nauc_mrr_at_1_max': np.float64(0.2943012692215825), 'nauc_mrr_at_1_std': np.float64(-0.007264460972054072), 'nauc_mrr_at_1_diff1': np.float64(0.4043965637946514), 'nauc_mrr_at_3_max': np.float64(0.262287901437037), 'nauc_mrr_at_3_std': np.float64(-0.008466116434885087), 'nauc_mrr_at_3_diff1': np.float64(0.38948592121380365), 'nauc_mrr_at_5_max': np.float64(0.2678540851429975), 'nauc_mrr_at_5_std': np.float64(0.007650126294619136), 'nauc_mrr_at_5_diff1': np.float64(0.37626056796857993), 'nauc_mrr_at_10_max': np.float64(0.25974642536519105), 'nauc_mrr_at_10_std': np.float64(0.0001995666797276549), 'nauc_mrr_at_10_diff1': np.float64(0.372007297756856), 'nauc_mrr_at_20_max': np.float64(0.2624500083633629), 'nauc_mrr_at_20_std': np.float64(0.009644934813633063), 'nauc_mrr_at_20_diff1': np.float64(0.3692359976230927), 'nauc_mrr_at_100_max': np.float64(0.26309352649809375), 'nauc_mrr_at_100_std': np.float64(0.01425853004668684), 'nauc_mrr_at_100_diff1': np.float64(0.3670433676629534), 'nauc_mrr_at_1000_max': np.float64(0.2629160244468375), 'nauc_mrr_at_1000_std': np.float64(0.013441533849383624), 'nauc_mrr_at_1000_diff1': np.float64(0.36727308033552175), 'main_score': 0.27828}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:02<00:34,  2.83s/it]Batches:  15%|█▌        | 2/13 [00:05<00:27,  2.49s/it]Batches:  23%|██▎       | 3/13 [00:07<00:23,  2.31s/it]Batches:  31%|███       | 4/13 [00:09<00:20,  2.23s/it]Batches:  38%|███▊      | 5/13 [00:11<00:17,  2.19s/it]Batches:  46%|████▌     | 6/13 [00:13<00:15,  2.17s/it]Batches:  54%|█████▍    | 7/13 [00:15<00:12,  2.15s/it]Batches:  62%|██████▏   | 8/13 [00:18<00:11,  2.25s/it]Batches:  69%|██████▉   | 9/13 [00:20<00:09,  2.29s/it]Batches:  77%|███████▋  | 10/13 [00:23<00:07,  2.37s/it]Batches:  85%|████████▍ | 11/13 [00:25<00:04,  2.41s/it]Batches:  92%|█████████▏| 12/13 [00:28<00:02,  2.51s/it]Batches: 100%|██████████| 13/13 [00:30<00:00,  2.45s/it]Batches: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.34 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 31.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.185, 'ndcg_at_3': 0.22208, 'ndcg_at_5': 0.23456, 'ndcg_at_10': 0.25525, 'ndcg_at_20': 0.26901, 'ndcg_at_100': 0.30905, 'ndcg_at_1000': 0.33338, 'map_at_1': 0.185, 'map_at_3': 0.2125, 'map_at_5': 0.2195, 'map_at_10': 0.22783, 'map_at_20': 0.23153, 'map_at_100': 0.23678, 'map_at_1000': 0.23748, 'recall_at_1': 0.185, 'recall_at_3': 0.25, 'recall_at_5': 0.28, 'recall_at_10': 0.345, 'recall_at_20': 0.4, 'recall_at_100': 0.62, 'recall_at_1000': 0.825, 'precision_at_1': 0.185, 'precision_at_3': 0.08333, 'precision_at_5': 0.056, 'precision_at_10': 0.0345, 'precision_at_20': 0.02, 'precision_at_100': 0.0062, 'precision_at_1000': 0.00083, 'mrr_at_1': 0.185, 'mrr_at_3': 0.2125, 'mrr_at_5': 0.2195, 'mrr_at_10': 0.22783134920634926, 'mrr_at_20': 0.23152909304747543, 'mrr_at_100': 0.2367833239154172, 'mrr_at_1000': 0.2374753426113605, 'nauc_ndcg_at_1_max': np.float64(0.5621184934623409), 'nauc_ndcg_at_1_std': np.float64(-0.018363825238884145), 'nauc_ndcg_at_1_diff1': np.float64(0.6564960207419364), 'nauc_ndcg_at_3_max': np.float64(0.4983773170371353), 'nauc_ndcg_at_3_std': np.float64(-0.001382877447712404), 'nauc_ndcg_at_3_diff1': np.float64(0.5904544035625694), 'nauc_ndcg_at_5_max': np.float64(0.48658320797924554), 'nauc_ndcg_at_5_std': np.float64(0.008217040428420813), 'nauc_ndcg_at_5_diff1': np.float64(0.5739369368938925), 'nauc_ndcg_at_10_max': np.float64(0.4791257880307742), 'nauc_ndcg_at_10_std': np.float64(0.03983135140012613), 'nauc_ndcg_at_10_diff1': np.float64(0.5802120016199976), 'nauc_ndcg_at_20_max': np.float64(0.4767712801246623), 'nauc_ndcg_at_20_std': np.float64(0.05096390178348801), 'nauc_ndcg_at_20_diff1': np.float64(0.5774816004248818), 'nauc_ndcg_at_100_max': np.float64(0.48200308255441704), 'nauc_ndcg_at_100_std': np.float64(0.08379277819071321), 'nauc_ndcg_at_100_diff1': np.float64(0.550480582496986), 'nauc_ndcg_at_1000_max': np.float64(0.48308198076385994), 'nauc_ndcg_at_1000_std': np.float64(0.07843725195477907), 'nauc_ndcg_at_1000_diff1': np.float64(0.5525579807424741), 'nauc_map_at_1_max': np.float64(0.5621184934623409), 'nauc_map_at_1_std': np.float64(-0.018363825238884145), 'nauc_map_at_1_diff1': np.float64(0.6564960207419364), 'nauc_map_at_3_max': np.float64(0.5116586338153044), 'nauc_map_at_3_std': np.float64(-0.0058836469811811), 'nauc_map_at_3_diff1': np.float64(0.6054370071129067), 'nauc_map_at_5_max': np.float64(0.5048739528519287), 'nauc_map_at_5_std': np.float64(-0.0005623639967071212), 'nauc_map_at_5_diff1': np.float64(0.5954954578090191), 'nauc_map_at_10_max': np.float64(0.5009655164800644), 'nauc_map_at_10_std': np.float64(0.012362530497095294), 'nauc_map_at_10_diff1': np.float64(0.5973150557816457), 'nauc_map_at_20_max': np.float64(0.5004957064758818), 'nauc_map_at_20_std': np.float64(0.0157465032445563), 'nauc_map_at_20_diff1': np.float64(0.5961679136786554), 'nauc_map_at_100_max': np.float64(0.5009841468898677), 'nauc_map_at_100_std': np.float64(0.019519850929331166), 'nauc_map_at_100_diff1': np.float64(0.5917107373555729), 'nauc_map_at_1000_max': np.float64(0.5009634062943839), 'nauc_map_at_1000_std': np.float64(0.019494080635944797), 'nauc_map_at_1000_diff1': np.float64(0.5918863798727253), 'nauc_recall_at_1_max': np.float64(0.5621184934623409), 'nauc_recall_at_1_std': np.float64(-0.018363825238884145), 'nauc_recall_at_1_diff1': np.float64(0.6564960207419364), 'nauc_recall_at_3_max': np.float64(0.46353070981978667), 'nauc_recall_at_3_std': np.float64(0.010820154468554456), 'nauc_recall_at_3_diff1': np.float64(0.5506436189775651), 'nauc_recall_at_5_max': np.float64(0.43857897089222847), 'nauc_recall_at_5_std': np.float64(0.032376110397228736), 'nauc_recall_at_5_diff1': np.float64(0.5170330744734344), 'nauc_recall_at_10_max': np.float64(0.42305531875524555), 'nauc_recall_at_10_std': np.float64(0.12055008161350232), 'nauc_recall_at_10_diff1': np.float64(0.5401492172373002), 'nauc_recall_at_20_max': np.float64(0.41496524201853785), 'nauc_recall_at_20_std': np.float64(0.15605046343975265), 'nauc_recall_at_20_diff1': np.float64(0.5338117919670443), 'nauc_recall_at_100_max': np.float64(0.4385902839737867), 'nauc_recall_at_100_std': np.float64(0.3650355351813676), 'nauc_recall_at_100_diff1': np.float64(0.39151770605790204), 'nauc_recall_at_1000_max': np.float64(0.4270736187650142), 'nauc_recall_at_1000_std': np.float64(0.5035325702981486), 'nauc_recall_at_1000_diff1': np.float64(0.28027412745513686), 'nauc_precision_at_1_max': np.float64(0.5621184934623409), 'nauc_precision_at_1_std': np.float64(-0.018363825238884145), 'nauc_precision_at_1_diff1': np.float64(0.6564960207419364), 'nauc_precision_at_3_max': np.float64(0.46353070981978695), 'nauc_precision_at_3_std': np.float64(0.010820154468554766), 'nauc_precision_at_3_diff1': np.float64(0.5506436189775653), 'nauc_precision_at_5_max': np.float64(0.4385789708922289), 'nauc_precision_at_5_std': np.float64(0.032376110397228985), 'nauc_precision_at_5_diff1': np.float64(0.5170330744734346), 'nauc_precision_at_10_max': np.float64(0.42305531875524544), 'nauc_precision_at_10_std': np.float64(0.12055008161350217), 'nauc_precision_at_10_diff1': np.float64(0.5401492172373006), 'nauc_precision_at_20_max': np.float64(0.41496524201853774), 'nauc_precision_at_20_std': np.float64(0.15605046343975285), 'nauc_precision_at_20_diff1': np.float64(0.5338117919670442), 'nauc_precision_at_100_max': np.float64(0.4385902839737872), 'nauc_precision_at_100_std': np.float64(0.3650355351813683), 'nauc_precision_at_100_diff1': np.float64(0.39151770605790304), 'nauc_precision_at_1000_max': np.float64(0.4270736187650138), 'nauc_precision_at_1000_std': np.float64(0.5035325702981494), 'nauc_precision_at_1000_diff1': np.float64(0.2802741274551366), 'nauc_mrr_at_1_max': np.float64(0.5621184934623409), 'nauc_mrr_at_1_std': np.float64(-0.018363825238884145), 'nauc_mrr_at_1_diff1': np.float64(0.6564960207419364), 'nauc_mrr_at_3_max': np.float64(0.5116586338153044), 'nauc_mrr_at_3_std': np.float64(-0.0058836469811811), 'nauc_mrr_at_3_diff1': np.float64(0.6054370071129067), 'nauc_mrr_at_5_max': np.float64(0.5048739528519287), 'nauc_mrr_at_5_std': np.float64(-0.0005623639967071212), 'nauc_mrr_at_5_diff1': np.float64(0.5954954578090191), 'nauc_mrr_at_10_max': np.float64(0.5009655164800644), 'nauc_mrr_at_10_std': np.float64(0.012362530497095294), 'nauc_mrr_at_10_diff1': np.float64(0.5973150557816457), 'nauc_mrr_at_20_max': np.float64(0.5004957064758818), 'nauc_mrr_at_20_std': np.float64(0.0157465032445563), 'nauc_mrr_at_20_diff1': np.float64(0.5961679136786554), 'nauc_mrr_at_100_max': np.float64(0.5009841468898677), 'nauc_mrr_at_100_std': np.float64(0.019519850929331166), 'nauc_mrr_at_100_diff1': np.float64(0.5917107373555729), 'nauc_mrr_at_1000_max': np.float64(0.5009634290526249), 'nauc_mrr_at_1000_std': np.float64(0.019494044129931224), 'nauc_mrr_at_1000_diff1': np.float64(0.5918863828350728), 'main_score': 0.25525}}



==================================================
Running model: ibm-granite/granite-embedding-107m-multilingual
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ibm-granite/granite-embedding-107m-multilingual
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / ibm-granite/granite-embedding-107m-multilingual on GPU 0 in process Process-10
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.28it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  6.33it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:04,  4.06it/s]Batches:  11%|█         | 2/19 [00:00<00:08,  2.10it/s]Batches:  16%|█▌        | 3/19 [00:01<00:07,  2.01it/s]Batches:  21%|██        | 4/19 [00:01<00:06,  2.20it/s]Batches:  26%|██▋       | 5/19 [00:02<00:05,  2.45it/s]Batches:  32%|███▏      | 6/19 [00:02<00:04,  2.69it/s]Batches:  37%|███▋      | 7/19 [00:02<00:04,  2.99it/s]Batches:  42%|████▏     | 8/19 [00:02<00:03,  3.28it/s]Batches:  47%|████▋     | 9/19 [00:03<00:02,  3.56it/s]Batches:  53%|█████▎    | 10/19 [00:03<00:02,  3.82it/s]Batches:  58%|█████▊    | 11/19 [00:03<00:01,  4.23it/s]Batches:  63%|██████▎   | 12/19 [00:03<00:01,  4.58it/s]Batches:  68%|██████▊   | 13/19 [00:03<00:01,  4.96it/s]Batches:  74%|███████▎  | 14/19 [00:04<00:00,  5.34it/s]Batches:  79%|███████▉  | 15/19 [00:04<00:00,  5.79it/s]Batches:  84%|████████▍ | 16/19 [00:04<00:00,  6.44it/s]Batches:  89%|████████▉ | 17/19 [00:04<00:00,  7.12it/s]Batches: 100%|██████████| 19/19 [00:04<00:00,  8.85it/s]Batches: 100%|██████████| 19/19 [00:04<00:00,  4.16it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.55 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 6.15 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.65541, 'ndcg_at_3': 0.65614, 'ndcg_at_5': 0.68805, 'ndcg_at_10': 0.70531, 'ndcg_at_20': 0.71721, 'ndcg_at_100': 0.7329, 'ndcg_at_1000': 0.74447, 'map_at_1': 0.41881, 'map_at_3': 0.60586, 'map_at_5': 0.63556, 'map_at_10': 0.64744, 'map_at_20': 0.65245, 'map_at_100': 0.65529, 'map_at_1000': 0.65582, 'recall_at_1': 0.41881, 'recall_at_3': 0.67141, 'recall_at_5': 0.73801, 'recall_at_10': 0.77861, 'recall_at_20': 0.81554, 'recall_at_100': 0.88361, 'recall_at_1000': 0.9578, 'precision_at_1': 0.65541, 'precision_at_3': 0.38908, 'precision_at_5': 0.2625, 'precision_at_10': 0.14139, 'precision_at_20': 0.07492, 'precision_at_100': 0.01645, 'precision_at_1000': 0.00183, 'mrr_at_1': 0.6554054054054054, 'mrr_at_3': 0.7277590090090089, 'mrr_at_5': 0.7341779279279276, 'mrr_at_10': 0.7360708923208922, 'mrr_at_20': 0.7373011950314581, 'mrr_at_100': 0.7391350350525233, 'mrr_at_1000': 0.7393108252946802, 'nauc_ndcg_at_1_max': np.float64(0.5290209374429565), 'nauc_ndcg_at_1_std': np.float64(0.15862202818970883), 'nauc_ndcg_at_1_diff1': np.float64(0.6329801837811128), 'nauc_ndcg_at_3_max': np.float64(0.577419951793824), 'nauc_ndcg_at_3_std': np.float64(0.19329959597095747), 'nauc_ndcg_at_3_diff1': np.float64(0.5336358198087913), 'nauc_ndcg_at_5_max': np.float64(0.6204518920357139), 'nauc_ndcg_at_5_std': np.float64(0.2216711085553783), 'nauc_ndcg_at_5_diff1': np.float64(0.5448558672635591), 'nauc_ndcg_at_10_max': np.float64(0.6412916271989583), 'nauc_ndcg_at_10_std': np.float64(0.2561512678515764), 'nauc_ndcg_at_10_diff1': np.float64(0.5446889814041614), 'nauc_ndcg_at_20_max': np.float64(0.6531510559302534), 'nauc_ndcg_at_20_std': np.float64(0.2784438778697869), 'nauc_ndcg_at_20_diff1': np.float64(0.5533094998682067), 'nauc_ndcg_at_100_max': np.float64(0.6465714621500209), 'nauc_ndcg_at_100_std': np.float64(0.28067522910818227), 'nauc_ndcg_at_100_diff1': np.float64(0.5596390712436295), 'nauc_ndcg_at_1000_max': np.float64(0.6348718419004235), 'nauc_ndcg_at_1000_std': np.float64(0.2669536806805805), 'nauc_ndcg_at_1000_diff1': np.float64(0.5606159164971272), 'nauc_map_at_1_max': np.float64(0.3241859373955544), 'nauc_map_at_1_std': np.float64(0.02352609440485304), 'nauc_map_at_1_diff1': np.float64(0.5717229343521868), 'nauc_map_at_3_max': np.float64(0.5318344708356362), 'nauc_map_at_3_std': np.float64(0.14006274724946838), 'nauc_map_at_3_diff1': np.float64(0.5247075003873253), 'nauc_map_at_5_max': np.float64(0.5673704046024957), 'nauc_map_at_5_std': np.float64(0.167573384574432), 'nauc_map_at_5_diff1': np.float64(0.5305595171257252), 'nauc_map_at_10_max': np.float64(0.5782703658732632), 'nauc_map_at_10_std': np.float64(0.1884642969850521), 'nauc_map_at_10_diff1': np.float64(0.529545540899962), 'nauc_map_at_20_max': np.float64(0.5830409215534177), 'nauc_map_at_20_std': np.float64(0.19687150902833683), 'nauc_map_at_20_diff1': np.float64(0.5334307445425635), 'nauc_map_at_100_max': np.float64(0.582081915499496), 'nauc_map_at_100_std': np.float64(0.1969592851649685), 'nauc_map_at_100_diff1': np.float64(0.5347754173105317), 'nauc_map_at_1000_max': np.float64(0.5815508807841169), 'nauc_map_at_1000_std': np.float64(0.1965262638663795), 'nauc_map_at_1000_diff1': np.float64(0.5345659981418326), 'nauc_recall_at_1_max': np.float64(0.3241859373955544), 'nauc_recall_at_1_std': np.float64(0.02352609440485304), 'nauc_recall_at_1_diff1': np.float64(0.5717229343521868), 'nauc_recall_at_3_max': np.float64(0.5854951691932576), 'nauc_recall_at_3_std': np.float64(0.21390473001263796), 'nauc_recall_at_3_diff1': np.float64(0.46877044894858955), 'nauc_recall_at_5_max': np.float64(0.6710244527253931), 'nauc_recall_at_5_std': np.float64(0.2782143499332638), 'nauc_recall_at_5_diff1': np.float64(0.47746107190664216), 'nauc_recall_at_10_max': np.float64(0.7426255946328112), 'nauc_recall_at_10_std': np.float64(0.37958010951338617), 'nauc_recall_at_10_diff1': np.float64(0.47215461043490886), 'nauc_recall_at_20_max': np.float64(0.8179222473482651), 'nauc_recall_at_20_std': np.float64(0.49422957052489624), 'nauc_recall_at_20_diff1': np.float64(0.5052214159970494), 'nauc_recall_at_100_max': np.float64(0.8674862824788461), 'nauc_recall_at_100_std': np.float64(0.6395230196826325), 'nauc_recall_at_100_diff1': np.float64(0.5499420737958264), 'nauc_recall_at_1000_max': np.float64(0.9056725060168626), 'nauc_recall_at_1000_std': np.float64(0.8064781492114823), 'nauc_recall_at_1000_diff1': np.float64(0.6338681753690225), 'nauc_precision_at_1_max': np.float64(0.5290209374429565), 'nauc_precision_at_1_std': np.float64(0.15862202818970883), 'nauc_precision_at_1_diff1': np.float64(0.6329801837811128), 'nauc_precision_at_3_max': np.float64(0.4621273808982828), 'nauc_precision_at_3_std': np.float64(0.23853149084139028), 'nauc_precision_at_3_diff1': np.float64(0.16382572109615534), 'nauc_precision_at_5_max': np.float64(0.42050114443128705), 'nauc_precision_at_5_std': np.float64(0.24876164569281425), 'nauc_precision_at_5_diff1': np.float64(0.09965842051647535), 'nauc_precision_at_10_max': np.float64(0.3831475412068668), 'nauc_precision_at_10_std': np.float64(0.2885519959066646), 'nauc_precision_at_10_diff1': np.float64(0.04406975199570664), 'nauc_precision_at_20_max': np.float64(0.3585654778209307), 'nauc_precision_at_20_std': np.float64(0.31824872014115857), 'nauc_precision_at_20_diff1': np.float64(0.023586815930885106), 'nauc_precision_at_100_max': np.float64(0.24267526858794355), 'nauc_precision_at_100_std': np.float64(0.28541726742561685), 'nauc_precision_at_100_diff1': np.float64(-0.04833864366348033), 'nauc_precision_at_1000_max': np.float64(0.03145210847000234), 'nauc_precision_at_1000_std': np.float64(0.15030261410190632), 'nauc_precision_at_1000_diff1': np.float64(-0.18226144498501654), 'nauc_mrr_at_1_max': np.float64(0.5290209374429565), 'nauc_mrr_at_1_std': np.float64(0.15862202818970883), 'nauc_mrr_at_1_diff1': np.float64(0.6329801837811128), 'nauc_mrr_at_3_max': np.float64(0.6358134464465018), 'nauc_mrr_at_3_std': np.float64(0.2667986242452568), 'nauc_mrr_at_3_diff1': np.float64(0.6154485075062786), 'nauc_mrr_at_5_max': np.float64(0.6366136077189156), 'nauc_mrr_at_5_std': np.float64(0.26366130724932224), 'nauc_mrr_at_5_diff1': np.float64(0.6184666087057293), 'nauc_mrr_at_10_max': np.float64(0.6365461421799173), 'nauc_mrr_at_10_std': np.float64(0.2650254587580828), 'nauc_mrr_at_10_diff1': np.float64(0.6187243074428174), 'nauc_mrr_at_20_max': np.float64(0.6369290618672118), 'nauc_mrr_at_20_std': np.float64(0.266873424807331), 'nauc_mrr_at_20_diff1': np.float64(0.6189697160524228), 'nauc_mrr_at_100_max': np.float64(0.6347967813555792), 'nauc_mrr_at_100_std': np.float64(0.26575542818552067), 'nauc_mrr_at_100_diff1': np.float64(0.6188128767424593), 'nauc_mrr_at_1000_max': np.float64(0.6345819887636812), 'nauc_mrr_at_1000_std': np.float64(0.2654405565170606), 'nauc_mrr_at_1000_diff1': np.float64(0.6188451342899701), 'main_score': 0.70531}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 54.84it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.76it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.04it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.21 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 1.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.5614, 'ndcg_at_3': 0.64077, 'ndcg_at_5': 0.64755, 'ndcg_at_10': 0.68243, 'ndcg_at_20': 0.69369, 'ndcg_at_100': 0.71342, 'ndcg_at_1000': 0.71702, 'map_at_1': 0.5614, 'map_at_3': 0.61988, 'map_at_5': 0.62339, 'map_at_10': 0.63829, 'map_at_20': 0.64149, 'map_at_100': 0.64426, 'map_at_1000': 0.64443, 'recall_at_1': 0.5614, 'recall_at_3': 0.70175, 'recall_at_5': 0.7193, 'recall_at_10': 0.82456, 'recall_at_20': 0.86842, 'recall_at_100': 0.97368, 'recall_at_1000': 1.0, 'precision_at_1': 0.5614, 'precision_at_3': 0.23392, 'precision_at_5': 0.14386, 'precision_at_10': 0.08246, 'precision_at_20': 0.04342, 'precision_at_100': 0.00974, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5614035087719298, 'mrr_at_3': 0.6198830409356727, 'mrr_at_5': 0.6233918128654972, 'mrr_at_10': 0.6382866889445838, 'mrr_at_20': 0.6414897724108253, 'mrr_at_100': 0.6442617137203759, 'mrr_at_1000': 0.64442883386091, 'nauc_ndcg_at_1_max': np.float64(0.22003754680781837), 'nauc_ndcg_at_1_std': np.float64(-0.01937635170084128), 'nauc_ndcg_at_1_diff1': np.float64(0.6368579252381142), 'nauc_ndcg_at_3_max': np.float64(0.1667693688683789), 'nauc_ndcg_at_3_std': np.float64(-0.059708467056917944), 'nauc_ndcg_at_3_diff1': np.float64(0.5604184827369659), 'nauc_ndcg_at_5_max': np.float64(0.15107818199045553), 'nauc_ndcg_at_5_std': np.float64(-0.07695211726076395), 'nauc_ndcg_at_5_diff1': np.float64(0.553875624151419), 'nauc_ndcg_at_10_max': np.float64(0.23664768749905243), 'nauc_ndcg_at_10_std': np.float64(0.011563947398617434), 'nauc_ndcg_at_10_diff1': np.float64(0.5751242581515231), 'nauc_ndcg_at_20_max': np.float64(0.23199111641588666), 'nauc_ndcg_at_20_std': np.float64(-0.005152536171573853), 'nauc_ndcg_at_20_diff1': np.float64(0.5770226203914983), 'nauc_ndcg_at_100_max': np.float64(0.22265056285158513), 'nauc_ndcg_at_100_std': np.float64(-0.007936073263769248), 'nauc_ndcg_at_100_diff1': np.float64(0.5898216329751359), 'nauc_ndcg_at_1000_max': np.float64(0.2109497680905648), 'nauc_ndcg_at_1000_std': np.float64(-0.020924533539508256), 'nauc_ndcg_at_1000_diff1': np.float64(0.5893911261482505), 'nauc_map_at_1_max': np.float64(0.22003754680781837), 'nauc_map_at_1_std': np.float64(-0.01937635170084128), 'nauc_map_at_1_diff1': np.float64(0.6368579252381142), 'nauc_map_at_3_max': np.float64(0.1790956740732903), 'nauc_map_at_3_std': np.float64(-0.05045648429172705), 'nauc_map_at_3_diff1': np.float64(0.5841519912868479), 'nauc_map_at_5_max': np.float64(0.17144475281546834), 'nauc_map_at_5_std': np.float64(-0.05890100093048595), 'nauc_map_at_5_diff1': np.float64(0.5811203298359114), 'nauc_map_at_10_max': np.float64(0.20218290969368927), 'nauc_map_at_10_std': np.float64(-0.026483993946439768), 'nauc_map_at_10_diff1': np.float64(0.590928304401652), 'nauc_map_at_20_max': np.float64(0.20128024024477004), 'nauc_map_at_20_std': np.float64(-0.030962626162164365), 'nauc_map_at_20_diff1': np.float64(0.5919473505334532), 'nauc_map_at_100_max': np.float64(0.2006863410547946), 'nauc_map_at_100_std': np.float64(-0.03098827821029068), 'nauc_map_at_100_diff1': np.float64(0.5943450385661672), 'nauc_map_at_1000_max': np.float64(0.20023793613683333), 'nauc_map_at_1000_std': np.float64(-0.03148179254267458), 'nauc_map_at_1000_diff1': np.float64(0.5943410529357398), 'nauc_recall_at_1_max': np.float64(0.22003754680781837), 'nauc_recall_at_1_std': np.float64(-0.01937635170084128), 'nauc_recall_at_1_diff1': np.float64(0.6368579252381142), 'nauc_recall_at_3_max': np.float64(0.12625389642263726), 'nauc_recall_at_3_std': np.float64(-0.09007450584246267), 'nauc_recall_at_3_diff1': np.float64(0.4790903097870967), 'nauc_recall_at_5_max': np.float64(0.07713473726145936), 'nauc_recall_at_5_std': np.float64(-0.14332129345492883), 'nauc_recall_at_5_diff1': np.float64(0.45527668914812214), 'nauc_recall_at_10_max': np.float64(0.4720306997321954), 'nauc_recall_at_10_std': np.float64(0.26297931464273205), 'nauc_recall_at_10_diff1': np.float64(0.5027405019222593), 'nauc_recall_at_20_max': np.float64(0.49743406642036386), 'nauc_recall_at_20_std': np.float64(0.21051943695979244), 'nauc_recall_at_20_diff1': np.float64(0.4889591043824069), 'nauc_recall_at_100_max': np.float64(0.9565962307252979), 'nauc_recall_at_100_std': np.float64(0.8081827652644304), 'nauc_recall_at_100_diff1': np.float64(0.6206036788040356), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.22003754680781837), 'nauc_precision_at_1_std': np.float64(-0.01937635170084128), 'nauc_precision_at_1_diff1': np.float64(0.6368579252381142), 'nauc_precision_at_3_max': np.float64(0.12625389642263704), 'nauc_precision_at_3_std': np.float64(-0.0900745058424627), 'nauc_precision_at_3_diff1': np.float64(0.4790903097870966), 'nauc_precision_at_5_max': np.float64(0.07713473726145907), 'nauc_precision_at_5_std': np.float64(-0.14332129345492858), 'nauc_precision_at_5_diff1': np.float64(0.45527668914812275), 'nauc_precision_at_10_max': np.float64(0.47203069973219663), 'nauc_precision_at_10_std': np.float64(0.2629793146427312), 'nauc_precision_at_10_diff1': np.float64(0.5027405019222593), 'nauc_precision_at_20_max': np.float64(0.49743406642036386), 'nauc_precision_at_20_std': np.float64(0.2105194369597922), 'nauc_precision_at_20_diff1': np.float64(0.48895910438240564), 'nauc_precision_at_100_max': np.float64(0.9565962307253074), 'nauc_precision_at_100_std': np.float64(0.8081827652644381), 'nauc_precision_at_100_diff1': np.float64(0.6206036788040415), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.22003754680781837), 'nauc_mrr_at_1_std': np.float64(-0.01937635170084128), 'nauc_mrr_at_1_diff1': np.float64(0.6368579252381142), 'nauc_mrr_at_3_max': np.float64(0.1790956740732903), 'nauc_mrr_at_3_std': np.float64(-0.05045648429172705), 'nauc_mrr_at_3_diff1': np.float64(0.5841519912868479), 'nauc_mrr_at_5_max': np.float64(0.17144475281546834), 'nauc_mrr_at_5_std': np.float64(-0.05890100093048595), 'nauc_mrr_at_5_diff1': np.float64(0.5811203298359114), 'nauc_mrr_at_10_max': np.float64(0.20218290969368927), 'nauc_mrr_at_10_std': np.float64(-0.026483993946439768), 'nauc_mrr_at_10_diff1': np.float64(0.590928304401652), 'nauc_mrr_at_20_max': np.float64(0.20128024024477004), 'nauc_mrr_at_20_std': np.float64(-0.030962626162164365), 'nauc_mrr_at_20_diff1': np.float64(0.5919473505334532), 'nauc_mrr_at_100_max': np.float64(0.2006863410547946), 'nauc_mrr_at_100_std': np.float64(-0.03098827821029068), 'nauc_mrr_at_100_diff1': np.float64(0.5943450385661672), 'nauc_mrr_at_1000_max': np.float64(0.20023793613683333), 'nauc_mrr_at_1000_std': np.float64(-0.03148179254267458), 'nauc_mrr_at_1000_diff1': np.float64(0.5943410529357398), 'main_score': 0.68243}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 44.00it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 16.96it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.20 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.53247, 'ndcg_at_3': 0.67486, 'ndcg_at_5': 0.69609, 'ndcg_at_10': 0.73209, 'ndcg_at_20': 0.73896, 'ndcg_at_100': 0.74576, 'ndcg_at_1000': 0.74576, 'map_at_1': 0.53247, 'map_at_3': 0.64286, 'map_at_5': 0.65455, 'map_at_10': 0.6684, 'map_at_20': 0.67044, 'map_at_100': 0.6712, 'map_at_1000': 0.6712, 'recall_at_1': 0.53247, 'recall_at_3': 0.76623, 'recall_at_5': 0.81818, 'recall_at_10': 0.93506, 'recall_at_20': 0.96104, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.53247, 'precision_at_3': 0.25541, 'precision_at_5': 0.16364, 'precision_at_10': 0.09351, 'precision_at_20': 0.04805, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5324675324675324, 'mrr_at_3': 0.6428571428571429, 'mrr_at_5': 0.6545454545454544, 'mrr_at_10': 0.6683982683982683, 'mrr_at_20': 0.6704447068083432, 'mrr_at_100': 0.6712005128094375, 'mrr_at_1000': 0.6712005128094375, 'nauc_ndcg_at_1_max': np.float64(0.2481431828589085), 'nauc_ndcg_at_1_std': np.float64(0.04695265701155958), 'nauc_ndcg_at_1_diff1': np.float64(0.455388466921803), 'nauc_ndcg_at_3_max': np.float64(0.2894127450013274), 'nauc_ndcg_at_3_std': np.float64(0.1553171879938942), 'nauc_ndcg_at_3_diff1': np.float64(0.4028879881284699), 'nauc_ndcg_at_5_max': np.float64(0.2577811456202509), 'nauc_ndcg_at_5_std': np.float64(0.12938084294974606), 'nauc_ndcg_at_5_diff1': np.float64(0.3956061696843109), 'nauc_ndcg_at_10_max': np.float64(0.23427810204278163), 'nauc_ndcg_at_10_std': np.float64(0.1424398067573142), 'nauc_ndcg_at_10_diff1': np.float64(0.38405107191357446), 'nauc_ndcg_at_20_max': np.float64(0.27226111070112236), 'nauc_ndcg_at_20_std': np.float64(0.14626208832425003), 'nauc_ndcg_at_20_diff1': np.float64(0.4199275199037704), 'nauc_ndcg_at_100_max': np.float64(0.26533618020099864), 'nauc_ndcg_at_100_std': np.float64(0.12719585140274392), 'nauc_ndcg_at_100_diff1': np.float64(0.41588965700421987), 'nauc_ndcg_at_1000_max': np.float64(0.26533618020099864), 'nauc_ndcg_at_1000_std': np.float64(0.12719585140274392), 'nauc_ndcg_at_1000_diff1': np.float64(0.41588965700421987), 'nauc_map_at_1_max': np.float64(0.2481431828589085), 'nauc_map_at_1_std': np.float64(0.04695265701155958), 'nauc_map_at_1_diff1': np.float64(0.455388466921803), 'nauc_map_at_3_max': np.float64(0.28279048836648346), 'nauc_map_at_3_std': np.float64(0.13011769372228885), 'nauc_map_at_3_diff1': np.float64(0.4204273362840516), 'nauc_map_at_5_max': np.float64(0.2660202216894175), 'nauc_map_at_5_std': np.float64(0.1153326544614391), 'nauc_map_at_5_diff1': np.float64(0.41589476617650367), 'nauc_map_at_10_max': np.float64(0.2582636522162112), 'nauc_map_at_10_std': np.float64(0.11880721103177881), 'nauc_map_at_10_diff1': np.float64(0.4116146407877393), 'nauc_map_at_20_max': np.float64(0.26694231165800525), 'nauc_map_at_20_std': np.float64(0.11909327954260485), 'nauc_map_at_20_diff1': np.float64(0.42083102277891143), 'nauc_map_at_100_max': np.float64(0.2662053456200643), 'nauc_map_at_100_std': np.float64(0.11725336719888715), 'nauc_map_at_100_diff1': np.float64(0.42054543700113073), 'nauc_map_at_1000_max': np.float64(0.2662053456200643), 'nauc_map_at_1000_std': np.float64(0.11725336719888715), 'nauc_map_at_1000_diff1': np.float64(0.42054543700113073), 'nauc_recall_at_1_max': np.float64(0.2481431828589085), 'nauc_recall_at_1_std': np.float64(0.04695265701155958), 'nauc_recall_at_1_diff1': np.float64(0.455388466921803), 'nauc_recall_at_3_max': np.float64(0.3117594953481499), 'nauc_recall_at_3_std': np.float64(0.2481374560999426), 'nauc_recall_at_3_diff1': np.float64(0.3346171949717651), 'nauc_recall_at_5_max': np.float64(0.21094725110701112), 'nauc_recall_at_5_std': np.float64(0.18514727506662912), 'nauc_recall_at_5_diff1': np.float64(0.3029924367803543), 'nauc_recall_at_10_max': np.float64(-0.10177181487427948), 'nauc_recall_at_10_std': np.float64(0.41498423658311495), 'nauc_recall_at_10_diff1': np.float64(0.06088353640206052), 'nauc_recall_at_20_max': np.float64(0.4627549073276888), 'nauc_recall_at_20_std': np.float64(0.6935061178385437), 'nauc_recall_at_20_diff1': np.float64(0.5451216692588444), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2481431828589085), 'nauc_precision_at_1_std': np.float64(0.04695265701155958), 'nauc_precision_at_1_diff1': np.float64(0.455388466921803), 'nauc_precision_at_3_max': np.float64(0.31175949534815184), 'nauc_precision_at_3_std': np.float64(0.2481374560999438), 'nauc_precision_at_3_diff1': np.float64(0.3346171949717672), 'nauc_precision_at_5_max': np.float64(0.21094725110701287), 'nauc_precision_at_5_std': np.float64(0.1851472750666311), 'nauc_precision_at_5_diff1': np.float64(0.3029924367803557), 'nauc_precision_at_10_max': np.float64(-0.101771814874275), 'nauc_precision_at_10_std': np.float64(0.4149842365831161), 'nauc_precision_at_10_diff1': np.float64(0.060883536402064765), 'nauc_precision_at_20_max': np.float64(0.4627549073276905), 'nauc_precision_at_20_std': np.float64(0.6935061178385504), 'nauc_precision_at_20_diff1': np.float64(0.5451216692588461), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.2481431828589085), 'nauc_mrr_at_1_std': np.float64(0.04695265701155958), 'nauc_mrr_at_1_diff1': np.float64(0.455388466921803), 'nauc_mrr_at_3_max': np.float64(0.28279048836648346), 'nauc_mrr_at_3_std': np.float64(0.13011769372228885), 'nauc_mrr_at_3_diff1': np.float64(0.4204273362840516), 'nauc_mrr_at_5_max': np.float64(0.2660202216894175), 'nauc_mrr_at_5_std': np.float64(0.1153326544614391), 'nauc_mrr_at_5_diff1': np.float64(0.41589476617650367), 'nauc_mrr_at_10_max': np.float64(0.2582636522162112), 'nauc_mrr_at_10_std': np.float64(0.11880721103177881), 'nauc_mrr_at_10_diff1': np.float64(0.4116146407877393), 'nauc_mrr_at_20_max': np.float64(0.26694231165800525), 'nauc_mrr_at_20_std': np.float64(0.11909327954260485), 'nauc_mrr_at_20_diff1': np.float64(0.42083102277891143), 'nauc_mrr_at_100_max': np.float64(0.2662053456200643), 'nauc_mrr_at_100_std': np.float64(0.11725336719888715), 'nauc_mrr_at_100_diff1': np.float64(0.42054543700113073), 'nauc_mrr_at_1000_max': np.float64(0.2662053456200643), 'nauc_mrr_at_1000_std': np.float64(0.11725336719888715), 'nauc_mrr_at_1000_diff1': np.float64(0.42054543700113073), 'main_score': 0.73209}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 28.81it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.92 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 25.21it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.94 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 28.38it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.97 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 4.44 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.73111, 'ndcg_at_3': 0.79241, 'ndcg_at_5': 0.80909, 'ndcg_at_10': 0.82063, 'ndcg_at_20': 0.82944, 'ndcg_at_100': 0.83581, 'ndcg_at_1000': 0.83867, 'map_at_1': 0.73111, 'map_at_3': 0.77815, 'map_at_5': 0.78726, 'map_at_10': 0.79205, 'map_at_20': 0.79452, 'map_at_100': 0.7954, 'map_at_1000': 0.79554, 'recall_at_1': 0.73111, 'recall_at_3': 0.83333, 'recall_at_5': 0.87444, 'recall_at_10': 0.91, 'recall_at_20': 0.94444, 'recall_at_100': 0.97889, 'recall_at_1000': 1.0, 'precision_at_1': 0.73111, 'precision_at_3': 0.27778, 'precision_at_5': 0.17489, 'precision_at_10': 0.091, 'precision_at_20': 0.04722, 'precision_at_100': 0.00979, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7311111111111112, 'mrr_at_3': 0.7781481481481485, 'mrr_at_5': 0.7872592592592597, 'mrr_at_10': 0.7920515873015875, 'mrr_at_20': 0.7945202798959253, 'mrr_at_100': 0.7954044716182472, 'mrr_at_1000': 0.7955397737465332, 'nauc_ndcg_at_1_max': np.float64(0.7581803916067977), 'nauc_ndcg_at_1_std': np.float64(0.06118691838675863), 'nauc_ndcg_at_1_diff1': np.float64(0.8728987406689837), 'nauc_ndcg_at_3_max': np.float64(0.7785993783791882), 'nauc_ndcg_at_3_std': np.float64(0.13435087257209802), 'nauc_ndcg_at_3_diff1': np.float64(0.8397423319921407), 'nauc_ndcg_at_5_max': np.float64(0.7697947439431878), 'nauc_ndcg_at_5_std': np.float64(0.13532624128728335), 'nauc_ndcg_at_5_diff1': np.float64(0.8334557572145351), 'nauc_ndcg_at_10_max': np.float64(0.7654902938455237), 'nauc_ndcg_at_10_std': np.float64(0.1302319605427718), 'nauc_ndcg_at_10_diff1': np.float64(0.8305303665334354), 'nauc_ndcg_at_20_max': np.float64(0.7690554332814783), 'nauc_ndcg_at_20_std': np.float64(0.1363395113588387), 'nauc_ndcg_at_20_diff1': np.float64(0.8366043510255086), 'nauc_ndcg_at_100_max': np.float64(0.7666578450662977), 'nauc_ndcg_at_100_std': np.float64(0.11937654596651773), 'nauc_ndcg_at_100_diff1': np.float64(0.8403659218386048), 'nauc_ndcg_at_1000_max': np.float64(0.767439967216144), 'nauc_ndcg_at_1000_std': np.float64(0.11829860114881247), 'nauc_ndcg_at_1000_diff1': np.float64(0.8414983389758781), 'nauc_map_at_1_max': np.float64(0.7581803916067977), 'nauc_map_at_1_std': np.float64(0.06118691838675863), 'nauc_map_at_1_diff1': np.float64(0.8728987406689837), 'nauc_map_at_3_max': np.float64(0.7718412627631724), 'nauc_map_at_3_std': np.float64(0.11103755628880912), 'nauc_map_at_3_diff1': np.float64(0.8474531331915228), 'nauc_map_at_5_max': np.float64(0.7671643226282532), 'nauc_map_at_5_std': np.float64(0.11026288946296608), 'nauc_map_at_5_diff1': np.float64(0.8446996507915395), 'nauc_map_at_10_max': np.float64(0.7655152089541306), 'nauc_map_at_10_std': np.float64(0.10803865057837064), 'nauc_map_at_10_diff1': np.float64(0.8438314222445563), 'nauc_map_at_20_max': np.float64(0.7662892494178841), 'nauc_map_at_20_std': np.float64(0.10916594199797619), 'nauc_map_at_20_diff1': np.float64(0.8452694277192461), 'nauc_map_at_100_max': np.float64(0.7661477834737442), 'nauc_map_at_100_std': np.float64(0.10717175956268933), 'nauc_map_at_100_diff1': np.float64(0.8458839683443172), 'nauc_map_at_1000_max': np.float64(0.7662076258176415), 'nauc_map_at_1000_std': np.float64(0.10720744323139188), 'nauc_map_at_1000_diff1': np.float64(0.8459231427778572), 'nauc_recall_at_1_max': np.float64(0.7581803916067977), 'nauc_recall_at_1_std': np.float64(0.06118691838675863), 'nauc_recall_at_1_diff1': np.float64(0.8728987406689837), 'nauc_recall_at_3_max': np.float64(0.8039014778325125), 'nauc_recall_at_3_std': np.float64(0.22122824302134647), 'nauc_recall_at_3_diff1': np.float64(0.8123448275862064), 'nauc_recall_at_5_max': np.float64(0.7803833518671001), 'nauc_recall_at_5_std': np.float64(0.2520521548687211), 'nauc_recall_at_5_diff1': np.float64(0.7817924840623752), 'nauc_recall_at_10_max': np.float64(0.7602044933199603), 'nauc_recall_at_10_std': np.float64(0.262607923827968), 'nauc_recall_at_10_diff1': np.float64(0.7475648695692264), 'nauc_recall_at_20_max': np.float64(0.7976003734827274), 'nauc_recall_at_20_std': np.float64(0.4117647058823557), 'nauc_recall_at_20_diff1': np.float64(0.7669934640522895), 'nauc_recall_at_100_max': np.float64(0.7368912477271651), 'nauc_recall_at_100_std': np.float64(0.2060789227971914), 'nauc_recall_at_100_diff1': np.float64(0.7794731927858821), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7581803916067977), 'nauc_precision_at_1_std': np.float64(0.06118691838675863), 'nauc_precision_at_1_diff1': np.float64(0.8728987406689837), 'nauc_precision_at_3_max': np.float64(0.8039014778325128), 'nauc_precision_at_3_std': np.float64(0.22122824302134625), 'nauc_precision_at_3_diff1': np.float64(0.8123448275862066), 'nauc_precision_at_5_max': np.float64(0.7803833518670984), 'nauc_precision_at_5_std': np.float64(0.25205215486872007), 'nauc_precision_at_5_diff1': np.float64(0.781792484062375), 'nauc_precision_at_10_max': np.float64(0.7602044933199599), 'nauc_precision_at_10_std': np.float64(0.26260792382796655), 'nauc_precision_at_10_diff1': np.float64(0.7475648695692249), 'nauc_precision_at_20_max': np.float64(0.7976003734827243), 'nauc_precision_at_20_std': np.float64(0.4117647058823524), 'nauc_precision_at_20_diff1': np.float64(0.7669934640522865), 'nauc_precision_at_100_max': np.float64(0.7368912477271683), 'nauc_precision_at_100_std': np.float64(0.2060789227971919), 'nauc_precision_at_100_diff1': np.float64(0.7794731927858854), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7581803916067977), 'nauc_mrr_at_1_std': np.float64(0.06118691838675863), 'nauc_mrr_at_1_diff1': np.float64(0.8728987406689837), 'nauc_mrr_at_3_max': np.float64(0.7718412627631724), 'nauc_mrr_at_3_std': np.float64(0.11103755628880912), 'nauc_mrr_at_3_diff1': np.float64(0.8474531331915228), 'nauc_mrr_at_5_max': np.float64(0.7671643226282532), 'nauc_mrr_at_5_std': np.float64(0.11026288946296608), 'nauc_mrr_at_5_diff1': np.float64(0.8446996507915395), 'nauc_mrr_at_10_max': np.float64(0.7655152089541306), 'nauc_mrr_at_10_std': np.float64(0.10803865057837064), 'nauc_mrr_at_10_diff1': np.float64(0.8438314222445563), 'nauc_mrr_at_20_max': np.float64(0.7662892494178841), 'nauc_mrr_at_20_std': np.float64(0.10916594199797619), 'nauc_mrr_at_20_diff1': np.float64(0.8452694277192461), 'nauc_mrr_at_100_max': np.float64(0.7661477834737442), 'nauc_mrr_at_100_std': np.float64(0.10717175956268933), 'nauc_mrr_at_100_diff1': np.float64(0.8458839683443172), 'nauc_mrr_at_1000_max': np.float64(0.7662076258176415), 'nauc_mrr_at_1000_std': np.float64(0.10720744323139188), 'nauc_mrr_at_1000_diff1': np.float64(0.8459231427778572), 'main_score': 0.82063}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.67556, 'ndcg_at_3': 0.76128, 'ndcg_at_5': 0.78026, 'ndcg_at_10': 0.79616, 'ndcg_at_20': 0.80733, 'ndcg_at_100': 0.81334, 'ndcg_at_1000': 0.81426, 'map_at_1': 0.67556, 'map_at_3': 0.74056, 'map_at_5': 0.75094, 'map_at_10': 0.75755, 'map_at_20': 0.76058, 'map_at_100': 0.76142, 'map_at_1000': 0.76147, 'recall_at_1': 0.67556, 'recall_at_3': 0.82111, 'recall_at_5': 0.86778, 'recall_at_10': 0.91667, 'recall_at_20': 0.96111, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.67556, 'precision_at_3': 0.2737, 'precision_at_5': 0.17356, 'precision_at_10': 0.09167, 'precision_at_20': 0.04806, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6755555555555556, 'mrr_at_3': 0.7405555555555555, 'mrr_at_5': 0.7509444444444447, 'mrr_at_10': 0.7575507054673726, 'mrr_at_20': 0.7605819038632509, 'mrr_at_100': 0.7614241850323177, 'mrr_at_1000': 0.7614699461456035, 'nauc_ndcg_at_1_max': np.float64(0.6286731696924507), 'nauc_ndcg_at_1_std': np.float64(-0.03772845555673889), 'nauc_ndcg_at_1_diff1': np.float64(0.8175551260785536), 'nauc_ndcg_at_3_max': np.float64(0.6462121573460321), 'nauc_ndcg_at_3_std': np.float64(0.013044646666122676), 'nauc_ndcg_at_3_diff1': np.float64(0.7692618964832233), 'nauc_ndcg_at_5_max': np.float64(0.6460846355287525), 'nauc_ndcg_at_5_std': np.float64(0.02465515885666536), 'nauc_ndcg_at_5_diff1': np.float64(0.7681195141042853), 'nauc_ndcg_at_10_max': np.float64(0.6383814487221928), 'nauc_ndcg_at_10_std': np.float64(0.004208672169417173), 'nauc_ndcg_at_10_diff1': np.float64(0.7673672924697353), 'nauc_ndcg_at_20_max': np.float64(0.6389311426323754), 'nauc_ndcg_at_20_std': np.float64(0.001076599980471204), 'nauc_ndcg_at_20_diff1': np.float64(0.7763092429355204), 'nauc_ndcg_at_100_max': np.float64(0.6372669591749286), 'nauc_ndcg_at_100_std': np.float64(-0.0006765100308548718), 'nauc_ndcg_at_100_diff1': np.float64(0.7782385177236363), 'nauc_ndcg_at_1000_max': np.float64(0.6377842040425654), 'nauc_ndcg_at_1000_std': np.float64(-0.002156585150020439), 'nauc_ndcg_at_1000_diff1': np.float64(0.7784672926320134), 'nauc_map_at_1_max': np.float64(0.6286731696924507), 'nauc_map_at_1_std': np.float64(-0.03772845555673889), 'nauc_map_at_1_diff1': np.float64(0.8175551260785536), 'nauc_map_at_3_max': np.float64(0.6405219638302005), 'nauc_map_at_3_std': np.float64(-0.003093384450043042), 'nauc_map_at_3_diff1': np.float64(0.7809167839933935), 'nauc_map_at_5_max': np.float64(0.6401661537542822), 'nauc_map_at_5_std': np.float64(0.0019175649184766997), 'nauc_map_at_5_diff1': np.float64(0.7807511581623584), 'nauc_map_at_10_max': np.float64(0.637142753323764), 'nauc_map_at_10_std': np.float64(-0.00570200220467743), 'nauc_map_at_10_diff1': np.float64(0.780596391308588), 'nauc_map_at_20_max': np.float64(0.6371558692364602), 'nauc_map_at_20_std': np.float64(-0.006712292464523269), 'nauc_map_at_20_diff1': np.float64(0.7827270068226065), 'nauc_map_at_100_max': np.float64(0.6369612768507121), 'nauc_map_at_100_std': np.float64(-0.006980633355829309), 'nauc_map_at_100_diff1': np.float64(0.782917415082556), 'nauc_map_at_1000_max': np.float64(0.636979790303072), 'nauc_map_at_1000_std': np.float64(-0.007025916301661925), 'nauc_map_at_1000_diff1': np.float64(0.7829267480446284), 'nauc_recall_at_1_max': np.float64(0.6286731696924507), 'nauc_recall_at_1_std': np.float64(-0.03772845555673889), 'nauc_recall_at_1_diff1': np.float64(0.8175551260785536), 'nauc_recall_at_3_max': np.float64(0.6686370322048601), 'nauc_recall_at_3_std': np.float64(0.07647808186299564), 'nauc_recall_at_3_diff1': np.float64(0.7253232486722337), 'nauc_recall_at_5_max': np.float64(0.6756680093039086), 'nauc_recall_at_5_std': np.float64(0.14029208438353555), 'nauc_recall_at_5_diff1': np.float64(0.7077332663365444), 'nauc_recall_at_10_max': np.float64(0.6416495487083712), 'nauc_recall_at_10_std': np.float64(0.06191721132897721), 'nauc_recall_at_10_diff1': np.float64(0.6736134453781504), 'nauc_recall_at_20_max': np.float64(0.658530078698146), 'nauc_recall_at_20_std': np.float64(0.08085901027077388), 'nauc_recall_at_20_diff1': np.float64(0.7229024943310656), 'nauc_recall_at_100_max': np.float64(0.5414721444133208), 'nauc_recall_at_100_std': np.float64(0.27380952380952706), 'nauc_recall_at_100_diff1': np.float64(0.737005913476488), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6286731696924507), 'nauc_precision_at_1_std': np.float64(-0.03772845555673889), 'nauc_precision_at_1_diff1': np.float64(0.8175551260785536), 'nauc_precision_at_3_max': np.float64(0.668637032204861), 'nauc_precision_at_3_std': np.float64(0.07647808186299533), 'nauc_precision_at_3_diff1': np.float64(0.7253232486722343), 'nauc_precision_at_5_max': np.float64(0.6756680093039061), 'nauc_precision_at_5_std': np.float64(0.1402920843835324), 'nauc_precision_at_5_diff1': np.float64(0.7077332663365439), 'nauc_precision_at_10_max': np.float64(0.6416495487083709), 'nauc_precision_at_10_std': np.float64(0.061917211328974056), 'nauc_precision_at_10_diff1': np.float64(0.6736134453781494), 'nauc_precision_at_20_max': np.float64(0.6585300786981414), 'nauc_precision_at_20_std': np.float64(0.08085901027077942), 'nauc_precision_at_20_diff1': np.float64(0.7229024943310633), 'nauc_precision_at_100_max': np.float64(0.5414721444133205), 'nauc_precision_at_100_std': np.float64(0.27380952380954604), 'nauc_precision_at_100_diff1': np.float64(0.7370059134765026), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6286731696924507), 'nauc_mrr_at_1_std': np.float64(-0.03772845555673889), 'nauc_mrr_at_1_diff1': np.float64(0.8175551260785536), 'nauc_mrr_at_3_max': np.float64(0.6405219638302005), 'nauc_mrr_at_3_std': np.float64(-0.003093384450043042), 'nauc_mrr_at_3_diff1': np.float64(0.7809167839933935), 'nauc_mrr_at_5_max': np.float64(0.6401661537542822), 'nauc_mrr_at_5_std': np.float64(0.0019175649184766997), 'nauc_mrr_at_5_diff1': np.float64(0.7807511581623584), 'nauc_mrr_at_10_max': np.float64(0.637142753323764), 'nauc_mrr_at_10_std': np.float64(-0.00570200220467743), 'nauc_mrr_at_10_diff1': np.float64(0.780596391308588), 'nauc_mrr_at_20_max': np.float64(0.6371558692364602), 'nauc_mrr_at_20_std': np.float64(-0.006712292464523269), 'nauc_mrr_at_20_diff1': np.float64(0.7827270068226065), 'nauc_mrr_at_100_max': np.float64(0.6369612768507121), 'nauc_mrr_at_100_std': np.float64(-0.006980633355829309), 'nauc_mrr_at_100_diff1': np.float64(0.782917415082556), 'nauc_mrr_at_1000_max': np.float64(0.636979790303072), 'nauc_mrr_at_1000_std': np.float64(-0.007025916301661925), 'nauc_mrr_at_1000_diff1': np.float64(0.7829267480446284), 'main_score': 0.79616}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.61667, 'ndcg_at_3': 0.69584, 'ndcg_at_5': 0.71622, 'ndcg_at_10': 0.73451, 'ndcg_at_20': 0.746, 'ndcg_at_100': 0.75855, 'ndcg_at_1000': 0.76285, 'map_at_1': 0.61667, 'map_at_3': 0.67704, 'map_at_5': 0.68848, 'map_at_10': 0.69622, 'map_at_20': 0.69936, 'map_at_100': 0.70107, 'map_at_1000': 0.70126, 'recall_at_1': 0.61667, 'recall_at_3': 0.75, 'recall_at_5': 0.79889, 'recall_at_10': 0.85444, 'recall_at_20': 0.9, 'recall_at_100': 0.96778, 'recall_at_1000': 1.0, 'precision_at_1': 0.61667, 'precision_at_3': 0.25, 'precision_at_5': 0.15978, 'precision_at_10': 0.08544, 'precision_at_20': 0.045, 'precision_at_100': 0.00968, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6166666666666667, 'mrr_at_3': 0.6770370370370369, 'mrr_at_5': 0.6884814814814811, 'mrr_at_10': 0.6962235449735444, 'mrr_at_20': 0.6993563973674908, 'mrr_at_100': 0.7010721603816695, 'mrr_at_1000': 0.7012620319561371, 'nauc_ndcg_at_1_max': np.float64(0.5929257664177772), 'nauc_ndcg_at_1_std': np.float64(0.028137237413249715), 'nauc_ndcg_at_1_diff1': np.float64(0.7444815371677581), 'nauc_ndcg_at_3_max': np.float64(0.6146283303125285), 'nauc_ndcg_at_3_std': np.float64(0.08240760771912414), 'nauc_ndcg_at_3_diff1': np.float64(0.6931502955315826), 'nauc_ndcg_at_5_max': np.float64(0.6297411624280014), 'nauc_ndcg_at_5_std': np.float64(0.10875821404877699), 'nauc_ndcg_at_5_diff1': np.float64(0.684192790063988), 'nauc_ndcg_at_10_max': np.float64(0.6338309104220816), 'nauc_ndcg_at_10_std': np.float64(0.11371998698161825), 'nauc_ndcg_at_10_diff1': np.float64(0.6908743920650521), 'nauc_ndcg_at_20_max': np.float64(0.6285052807875923), 'nauc_ndcg_at_20_std': np.float64(0.11180741490727626), 'nauc_ndcg_at_20_diff1': np.float64(0.6899225236299047), 'nauc_ndcg_at_100_max': np.float64(0.6262349336986199), 'nauc_ndcg_at_100_std': np.float64(0.10220022634800095), 'nauc_ndcg_at_100_diff1': np.float64(0.6989430169224646), 'nauc_ndcg_at_1000_max': np.float64(0.6224771425605469), 'nauc_ndcg_at_1000_std': np.float64(0.09312728210530942), 'nauc_ndcg_at_1000_diff1': np.float64(0.6994184016786514), 'nauc_map_at_1_max': np.float64(0.5929257664177772), 'nauc_map_at_1_std': np.float64(0.028137237413249715), 'nauc_map_at_1_diff1': np.float64(0.7444815371677581), 'nauc_map_at_3_max': np.float64(0.6094892882696004), 'nauc_map_at_3_std': np.float64(0.06682027353260662), 'nauc_map_at_3_diff1': np.float64(0.7062368419698053), 'nauc_map_at_5_max': np.float64(0.6173430014451181), 'nauc_map_at_5_std': np.float64(0.08014412947262935), 'nauc_map_at_5_diff1': np.float64(0.7018088775242026), 'nauc_map_at_10_max': np.float64(0.6187643350220358), 'nauc_map_at_10_std': np.float64(0.08146621692877815), 'nauc_map_at_10_diff1': np.float64(0.7051979964569536), 'nauc_map_at_20_max': np.float64(0.6172610131414443), 'nauc_map_at_20_std': np.float64(0.08047185512484588), 'nauc_map_at_20_diff1': np.float64(0.7050409082970811), 'nauc_map_at_100_max': np.float64(0.6168916392910191), 'nauc_map_at_100_std': np.float64(0.07913063190764082), 'nauc_map_at_100_diff1': np.float64(0.7060897944825868), 'nauc_map_at_1000_max': np.float64(0.6167465179019074), 'nauc_map_at_1000_std': np.float64(0.07881909619280986), 'nauc_map_at_1000_diff1': np.float64(0.7060854385234963), 'nauc_recall_at_1_max': np.float64(0.5929257664177772), 'nauc_recall_at_1_std': np.float64(0.028137237413249715), 'nauc_recall_at_1_diff1': np.float64(0.7444815371677581), 'nauc_recall_at_3_max': np.float64(0.6320948892377461), 'nauc_recall_at_3_std': np.float64(0.13696145124716613), 'nauc_recall_at_3_diff1': np.float64(0.6481353567067856), 'nauc_recall_at_5_max': np.float64(0.6814872329079028), 'nauc_recall_at_5_std': np.float64(0.22853108671564804), 'nauc_recall_at_5_diff1': np.float64(0.6128673941095368), 'nauc_recall_at_10_max': np.float64(0.717481291012998), 'nauc_recall_at_10_std': np.float64(0.29228751272657), 'nauc_recall_at_10_diff1': np.float64(0.6173854237111792), 'nauc_recall_at_20_max': np.float64(0.706494449631704), 'nauc_recall_at_20_std': np.float64(0.3499377528789288), 'nauc_recall_at_20_diff1': np.float64(0.5818445896877263), 'nauc_recall_at_100_max': np.float64(0.798432016484753), 'nauc_recall_at_100_std': np.float64(0.5333236742973074), 'nauc_recall_at_100_diff1': np.float64(0.6670369297144113), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.5929257664177772), 'nauc_precision_at_1_std': np.float64(0.028137237413249715), 'nauc_precision_at_1_diff1': np.float64(0.7444815371677581), 'nauc_precision_at_3_max': np.float64(0.6320948892377466), 'nauc_precision_at_3_std': np.float64(0.13696145124716563), 'nauc_precision_at_3_diff1': np.float64(0.648135356706785), 'nauc_precision_at_5_max': np.float64(0.6814872329079007), 'nauc_precision_at_5_std': np.float64(0.2285310867156477), 'nauc_precision_at_5_diff1': np.float64(0.6128673941095351), 'nauc_precision_at_10_max': np.float64(0.7174812910129975), 'nauc_precision_at_10_std': np.float64(0.2922875127265687), 'nauc_precision_at_10_diff1': np.float64(0.6173854237111777), 'nauc_precision_at_20_max': np.float64(0.7064944496317025), 'nauc_precision_at_20_std': np.float64(0.3499377528789283), 'nauc_precision_at_20_diff1': np.float64(0.5818445896877259), 'nauc_precision_at_100_max': np.float64(0.7984320164847518), 'nauc_precision_at_100_std': np.float64(0.5333236742973105), 'nauc_precision_at_100_diff1': np.float64(0.6670369297144179), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.5929257664177772), 'nauc_mrr_at_1_std': np.float64(0.028137237413249715), 'nauc_mrr_at_1_diff1': np.float64(0.7444815371677581), 'nauc_mrr_at_3_max': np.float64(0.6094892882696004), 'nauc_mrr_at_3_std': np.float64(0.06682027353260662), 'nauc_mrr_at_3_diff1': np.float64(0.7062368419698053), 'nauc_mrr_at_5_max': np.float64(0.6173430014451181), 'nauc_mrr_at_5_std': np.float64(0.08014412947262935), 'nauc_mrr_at_5_diff1': np.float64(0.7018088775242026), 'nauc_mrr_at_10_max': np.float64(0.6187643350220358), 'nauc_mrr_at_10_std': np.float64(0.08146621692877815), 'nauc_mrr_at_10_diff1': np.float64(0.7051979964569536), 'nauc_mrr_at_20_max': np.float64(0.6172610131414443), 'nauc_mrr_at_20_std': np.float64(0.08047185512484588), 'nauc_mrr_at_20_diff1': np.float64(0.7050409082970811), 'nauc_mrr_at_100_max': np.float64(0.6168916392910191), 'nauc_mrr_at_100_std': np.float64(0.07913063190764082), 'nauc_mrr_at_100_diff1': np.float64(0.7060897944825868), 'nauc_mrr_at_1000_max': np.float64(0.6167465179019074), 'nauc_mrr_at_1000_std': np.float64(0.07881909619280986), 'nauc_mrr_at_1000_diff1': np.float64(0.7060854385234963), 'main_score': 0.73451}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 18.36it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 18.19it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 13.21it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 13.07it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.73 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 21.17it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  6.97it/s]Batches:  67%|██████▋   | 2/3 [00:00<00:00,  2.34it/s]Batches: 100%|██████████| 3/3 [00:00<00:00,  3.65it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.44 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 18.04it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 17.87it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 14.00it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 13.91it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.66 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 4.96 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.18654, 'ndcg_at_3': 0.1935, 'ndcg_at_5': 0.20878, 'ndcg_at_10': 0.23, 'ndcg_at_20': 0.2526, 'ndcg_at_100': 0.30094, 'ndcg_at_1000': 0.35266, 'map_at_1': 0.13132, 'map_at_3': 0.1724, 'map_at_5': 0.18386, 'map_at_10': 0.19317, 'map_at_20': 0.19974, 'map_at_100': 0.20662, 'map_at_1000': 0.20871, 'recall_at_1': 0.13132, 'recall_at_3': 0.20466, 'recall_at_5': 0.24146, 'recall_at_10': 0.30069, 'recall_at_20': 0.38254, 'recall_at_100': 0.62439, 'recall_at_1000': 1.0, 'precision_at_1': 0.18654, 'precision_at_3': 0.10398, 'precision_at_5': 0.07462, 'precision_at_10': 0.04709, 'precision_at_20': 0.02966, 'precision_at_100': 0.00969, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.18807339449541285, 'mrr_at_3': 0.21814475025484198, 'mrr_at_5': 0.22647808358817534, 'mrr_at_10': 0.2348563176544827, 'mrr_at_20': 0.24096254923398674, 'mrr_at_100': 0.24639456342901297, 'mrr_at_1000': 0.24764689227202194, 'nauc_ndcg_at_1_max': np.float64(0.13166963769363144), 'nauc_ndcg_at_1_std': np.float64(-0.2538867867004861), 'nauc_ndcg_at_1_diff1': np.float64(0.5119113716147425), 'nauc_ndcg_at_3_max': np.float64(0.1243499082887724), 'nauc_ndcg_at_3_std': np.float64(-0.2444510969717285), 'nauc_ndcg_at_3_diff1': np.float64(0.420406170889805), 'nauc_ndcg_at_5_max': np.float64(0.12071083866691591), 'nauc_ndcg_at_5_std': np.float64(-0.2320707970983439), 'nauc_ndcg_at_5_diff1': np.float64(0.41319458818606486), 'nauc_ndcg_at_10_max': np.float64(0.12969987314706613), 'nauc_ndcg_at_10_std': np.float64(-0.22613090962113971), 'nauc_ndcg_at_10_diff1': np.float64(0.38925208688073204), 'nauc_ndcg_at_20_max': np.float64(0.14006340722584748), 'nauc_ndcg_at_20_std': np.float64(-0.2108804264022621), 'nauc_ndcg_at_20_diff1': np.float64(0.38287020604804395), 'nauc_ndcg_at_100_max': np.float64(0.1597686009307856), 'nauc_ndcg_at_100_std': np.float64(-0.18397412271184263), 'nauc_ndcg_at_100_diff1': np.float64(0.3707506404571579), 'nauc_ndcg_at_1000_max': np.float64(0.14212604529366352), 'nauc_ndcg_at_1000_std': np.float64(-0.20796314764401783), 'nauc_ndcg_at_1000_diff1': np.float64(0.39301621732359604), 'nauc_map_at_1_max': np.float64(0.11084360322647732), 'nauc_map_at_1_std': np.float64(-0.2096794806066227), 'nauc_map_at_1_diff1': np.float64(0.5055981546572169), 'nauc_map_at_3_max': np.float64(0.12578068087519143), 'nauc_map_at_3_std': np.float64(-0.23501882336910765), 'nauc_map_at_3_diff1': np.float64(0.4319203218184404), 'nauc_map_at_5_max': np.float64(0.12079365624681022), 'nauc_map_at_5_std': np.float64(-0.23181377766250708), 'nauc_map_at_5_diff1': np.float64(0.4246615998807844), 'nauc_map_at_10_max': np.float64(0.12299567501438936), 'nauc_map_at_10_std': np.float64(-0.22951683494144537), 'nauc_map_at_10_diff1': np.float64(0.4126301002733342), 'nauc_map_at_20_max': np.float64(0.1264912279176413), 'nauc_map_at_20_std': np.float64(-0.22635972139092475), 'nauc_map_at_20_diff1': np.float64(0.4123467643844084), 'nauc_map_at_100_max': np.float64(0.1287431055107584), 'nauc_map_at_100_std': np.float64(-0.22320957790121052), 'nauc_map_at_100_diff1': np.float64(0.4104560735418924), 'nauc_map_at_1000_max': np.float64(0.1285714165784984), 'nauc_map_at_1000_std': np.float64(-0.22360820337896228), 'nauc_map_at_1000_diff1': np.float64(0.4113280166728395), 'nauc_recall_at_1_max': np.float64(0.11084360322647732), 'nauc_recall_at_1_std': np.float64(-0.2096794806066227), 'nauc_recall_at_1_diff1': np.float64(0.5055981546572169), 'nauc_recall_at_3_max': np.float64(0.1343509928216314), 'nauc_recall_at_3_std': np.float64(-0.2226032590347836), 'nauc_recall_at_3_diff1': np.float64(0.37297238533253985), 'nauc_recall_at_5_max': np.float64(0.1200562156220723), 'nauc_recall_at_5_std': np.float64(-0.19814614106401954), 'nauc_recall_at_5_diff1': np.float64(0.3507627348098198), 'nauc_recall_at_10_max': np.float64(0.1504685051861712), 'nauc_recall_at_10_std': np.float64(-0.17764683149615784), 'nauc_recall_at_10_diff1': np.float64(0.2915188693690384), 'nauc_recall_at_20_max': np.float64(0.17439321721184248), 'nauc_recall_at_20_std': np.float64(-0.12751924117911542), 'nauc_recall_at_20_diff1': np.float64(0.2639265619263124), 'nauc_recall_at_100_max': np.float64(0.26411587844842715), 'nauc_recall_at_100_std': np.float64(0.006117695067727386), 'nauc_recall_at_100_diff1': np.float64(0.1816423189585701), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.13166963769363144), 'nauc_precision_at_1_std': np.float64(-0.2538867867004861), 'nauc_precision_at_1_diff1': np.float64(0.5119113716147425), 'nauc_precision_at_3_max': np.float64(0.12480265317758628), 'nauc_precision_at_3_std': np.float64(-0.2752741932527593), 'nauc_precision_at_3_diff1': np.float64(0.3387411106838598), 'nauc_precision_at_5_max': np.float64(0.10110889665552694), 'nauc_precision_at_5_std': np.float64(-0.25870886969808415), 'nauc_precision_at_5_diff1': np.float64(0.3121556966096832), 'nauc_precision_at_10_max': np.float64(0.10044643367716861), 'nauc_precision_at_10_std': np.float64(-0.24233539435746332), 'nauc_precision_at_10_diff1': np.float64(0.24954937578360373), 'nauc_precision_at_20_max': np.float64(0.13592110622391074), 'nauc_precision_at_20_std': np.float64(-0.19051679895073126), 'nauc_precision_at_20_diff1': np.float64(0.2438863229848143), 'nauc_precision_at_100_max': np.float64(0.1913456362861458), 'nauc_precision_at_100_std': np.float64(-0.03510456874331373), 'nauc_precision_at_100_diff1': np.float64(0.1467976026273262), 'nauc_precision_at_1000_max': np.float64(0.03779497684458051), 'nauc_precision_at_1000_std': np.float64(-0.01802905457391492), 'nauc_precision_at_1000_diff1': np.float64(0.025705565447767045), 'nauc_mrr_at_1_max': np.float64(0.12883942685182012), 'nauc_mrr_at_1_std': np.float64(-0.2529452476069238), 'nauc_mrr_at_1_diff1': np.float64(0.5030841649193402), 'nauc_mrr_at_3_max': np.float64(0.12202599831472413), 'nauc_mrr_at_3_std': np.float64(-0.25951628788350894), 'nauc_mrr_at_3_diff1': np.float64(0.45167061803955616), 'nauc_mrr_at_5_max': np.float64(0.1190503892060898), 'nauc_mrr_at_5_std': np.float64(-0.2527976908693103), 'nauc_mrr_at_5_diff1': np.float64(0.44713933608078993), 'nauc_mrr_at_10_max': np.float64(0.12224303232777668), 'nauc_mrr_at_10_std': np.float64(-0.25136024688594627), 'nauc_mrr_at_10_diff1': np.float64(0.43771796943525193), 'nauc_mrr_at_20_max': np.float64(0.12433135712638407), 'nauc_mrr_at_20_std': np.float64(-0.24613655381327673), 'nauc_mrr_at_20_diff1': np.float64(0.4344542168508507), 'nauc_mrr_at_100_max': np.float64(0.12616179961079155), 'nauc_mrr_at_100_std': np.float64(-0.24296901883435304), 'nauc_mrr_at_100_diff1': np.float64(0.43246339075790824), 'nauc_mrr_at_1000_max': np.float64(0.12568241437143798), 'nauc_mrr_at_1000_std': np.float64(-0.24376112770404995), 'nauc_mrr_at_1000_diff1': np.float64(0.4332506657641551), 'main_score': 0.23}, 'eng-kor': {'ndcg_at_1': 0.20031, 'ndcg_at_3': 0.19881, 'ndcg_at_5': 0.21469, 'ndcg_at_10': 0.24378, 'ndcg_at_20': 0.2688, 'ndcg_at_100': 0.31906, 'ndcg_at_1000': 0.36968, 'map_at_1': 0.10691, 'map_at_3': 0.16067, 'map_at_5': 0.17875, 'map_at_10': 0.19351, 'map_at_20': 0.20164, 'map_at_100': 0.20959, 'map_at_1000': 0.21208, 'recall_at_1': 0.10691, 'recall_at_3': 0.19574, 'recall_at_5': 0.24786, 'recall_at_10': 0.32146, 'recall_at_20': 0.40339, 'recall_at_100': 0.64151, 'recall_at_1000': 0.98703, 'precision_at_1': 0.20031, 'precision_at_3': 0.13201, 'precision_at_5': 0.10122, 'precision_at_10': 0.06651, 'precision_at_20': 0.04151, 'precision_at_100': 0.01289, 'precision_at_1000': 0.00193, 'mrr_at_1': 0.20030581039755352, 'mrr_at_3': 0.24108053007135566, 'mrr_at_5': 0.2523955147808359, 'mrr_at_10': 0.26243932333381864, 'mrr_at_20': 0.26862914679133754, 'mrr_at_100': 0.273413546744893, 'mrr_at_1000': 0.2746074898644071, 'nauc_ndcg_at_1_max': np.float64(0.1761542395280546), 'nauc_ndcg_at_1_std': np.float64(-0.2035798668391982), 'nauc_ndcg_at_1_diff1': np.float64(0.46267016345201123), 'nauc_ndcg_at_3_max': np.float64(0.1755500923990418), 'nauc_ndcg_at_3_std': np.float64(-0.19075774975023474), 'nauc_ndcg_at_3_diff1': np.float64(0.3879196327554034), 'nauc_ndcg_at_5_max': np.float64(0.16959309778784676), 'nauc_ndcg_at_5_std': np.float64(-0.17287164843745254), 'nauc_ndcg_at_5_diff1': np.float64(0.3781666617496654), 'nauc_ndcg_at_10_max': np.float64(0.17052173018624187), 'nauc_ndcg_at_10_std': np.float64(-0.16621175639553118), 'nauc_ndcg_at_10_diff1': np.float64(0.36719933092594115), 'nauc_ndcg_at_20_max': np.float64(0.17408832226409912), 'nauc_ndcg_at_20_std': np.float64(-0.15856131307940946), 'nauc_ndcg_at_20_diff1': np.float64(0.3581109260021207), 'nauc_ndcg_at_100_max': np.float64(0.20213881273558684), 'nauc_ndcg_at_100_std': np.float64(-0.10731903851212933), 'nauc_ndcg_at_100_diff1': np.float64(0.353420474065198), 'nauc_ndcg_at_1000_max': np.float64(0.18884702683499324), 'nauc_ndcg_at_1000_std': np.float64(-0.14153677989310104), 'nauc_ndcg_at_1000_diff1': np.float64(0.3594972266085901), 'nauc_map_at_1_max': np.float64(0.14292614092399), 'nauc_map_at_1_std': np.float64(-0.21812894129139734), 'nauc_map_at_1_diff1': np.float64(0.49240283558602477), 'nauc_map_at_3_max': np.float64(0.17554563744892823), 'nauc_map_at_3_std': np.float64(-0.18718348213672592), 'nauc_map_at_3_diff1': np.float64(0.40995978139355166), 'nauc_map_at_5_max': np.float64(0.17113921880510216), 'nauc_map_at_5_std': np.float64(-0.1830023134766823), 'nauc_map_at_5_diff1': np.float64(0.39867963555641417), 'nauc_map_at_10_max': np.float64(0.17235950631320954), 'nauc_map_at_10_std': np.float64(-0.18141834215415664), 'nauc_map_at_10_diff1': np.float64(0.3932652295461363), 'nauc_map_at_20_max': np.float64(0.17165228209109903), 'nauc_map_at_20_std': np.float64(-0.18130364165916973), 'nauc_map_at_20_diff1': np.float64(0.3893812959559676), 'nauc_map_at_100_max': np.float64(0.174925849844972), 'nauc_map_at_100_std': np.float64(-0.1731076575829106), 'nauc_map_at_100_diff1': np.float64(0.3873267938737459), 'nauc_map_at_1000_max': np.float64(0.17534915514409005), 'nauc_map_at_1000_std': np.float64(-0.17362121236425146), 'nauc_map_at_1000_diff1': np.float64(0.3872563729044403), 'nauc_recall_at_1_max': np.float64(0.14292614092399), 'nauc_recall_at_1_std': np.float64(-0.21812894129139734), 'nauc_recall_at_1_diff1': np.float64(0.49240283558602477), 'nauc_recall_at_3_max': np.float64(0.1719145488951957), 'nauc_recall_at_3_std': np.float64(-0.1523810877490871), 'nauc_recall_at_3_diff1': np.float64(0.3265829270356077), 'nauc_recall_at_5_max': np.float64(0.15463244403938858), 'nauc_recall_at_5_std': np.float64(-0.130945841953787), 'nauc_recall_at_5_diff1': np.float64(0.30472335765087044), 'nauc_recall_at_10_max': np.float64(0.15783379421200902), 'nauc_recall_at_10_std': np.float64(-0.10749425579497099), 'nauc_recall_at_10_diff1': np.float64(0.28158262614326846), 'nauc_recall_at_20_max': np.float64(0.16390504245381562), 'nauc_recall_at_20_std': np.float64(-0.08650567192718621), 'nauc_recall_at_20_diff1': np.float64(0.25316017963704235), 'nauc_recall_at_100_max': np.float64(0.28677947304961515), 'nauc_recall_at_100_std': np.float64(0.15596161130719932), 'nauc_recall_at_100_diff1': np.float64(0.22326479758457185), 'nauc_recall_at_1000_max': np.float64(0.36681643709719236), 'nauc_recall_at_1000_std': np.float64(0.2714081152831406), 'nauc_recall_at_1000_diff1': np.float64(-0.20217447352136342), 'nauc_precision_at_1_max': np.float64(0.1761542395280546), 'nauc_precision_at_1_std': np.float64(-0.2035798668391982), 'nauc_precision_at_1_diff1': np.float64(0.46267016345201123), 'nauc_precision_at_3_max': np.float64(0.19111938611681392), 'nauc_precision_at_3_std': np.float64(-0.18488268307266364), 'nauc_precision_at_3_diff1': np.float64(0.3183081407822036), 'nauc_precision_at_5_max': np.float64(0.17863280372948384), 'nauc_precision_at_5_std': np.float64(-0.15901770759566794), 'nauc_precision_at_5_diff1': np.float64(0.29553855637017135), 'nauc_precision_at_10_max': np.float64(0.16270492177985402), 'nauc_precision_at_10_std': np.float64(-0.14774640312102325), 'nauc_precision_at_10_diff1': np.float64(0.25334754606116067), 'nauc_precision_at_20_max': np.float64(0.1611642329104922), 'nauc_precision_at_20_std': np.float64(-0.10932127751188718), 'nauc_precision_at_20_diff1': np.float64(0.2156660591669846), 'nauc_precision_at_100_max': np.float64(0.21488903145287253), 'nauc_precision_at_100_std': np.float64(0.06123376026325016), 'nauc_precision_at_100_diff1': np.float64(0.1453885457811606), 'nauc_precision_at_1000_max': np.float64(0.10138809847562301), 'nauc_precision_at_1000_std': np.float64(-0.010913294914940214), 'nauc_precision_at_1000_diff1': np.float64(0.047321950772366464), 'nauc_mrr_at_1_max': np.float64(0.1761542395280546), 'nauc_mrr_at_1_std': np.float64(-0.2035798668391982), 'nauc_mrr_at_1_diff1': np.float64(0.46267016345201123), 'nauc_mrr_at_3_max': np.float64(0.16710245025636347), 'nauc_mrr_at_3_std': np.float64(-0.19280217159888793), 'nauc_mrr_at_3_diff1': np.float64(0.40425035846628493), 'nauc_mrr_at_5_max': np.float64(0.1649468781946775), 'nauc_mrr_at_5_std': np.float64(-0.18400313419307326), 'nauc_mrr_at_5_diff1': np.float64(0.3967490658281464), 'nauc_mrr_at_10_max': np.float64(0.16567081334116843), 'nauc_mrr_at_10_std': np.float64(-0.1800861992045503), 'nauc_mrr_at_10_diff1': np.float64(0.3910316518365303), 'nauc_mrr_at_20_max': np.float64(0.1692821767948285), 'nauc_mrr_at_20_std': np.float64(-0.17517428703356083), 'nauc_mrr_at_20_diff1': np.float64(0.38804768411071044), 'nauc_mrr_at_100_max': np.float64(0.17086226635900711), 'nauc_mrr_at_100_std': np.float64(-0.17193240717880917), 'nauc_mrr_at_100_diff1': np.float64(0.38837662434178727), 'nauc_mrr_at_1000_max': np.float64(0.17032830283461814), 'nauc_mrr_at_1000_std': np.float64(-0.17297991407949712), 'nauc_mrr_at_1000_diff1': np.float64(0.388588961671458), 'main_score': 0.24378}, 'kor-eng': {'ndcg_at_1': 0.14658, 'ndcg_at_3': 0.15846, 'ndcg_at_5': 0.17621, 'ndcg_at_10': 0.19953, 'ndcg_at_20': 0.21608, 'ndcg_at_100': 0.26391, 'ndcg_at_1000': 0.3242, 'map_at_1': 0.10562, 'map_at_3': 0.13978, 'map_at_5': 0.15215, 'map_at_10': 0.16248, 'map_at_20': 0.1678, 'map_at_100': 0.17453, 'map_at_1000': 0.17696, 'recall_at_1': 0.10562, 'recall_at_3': 0.16963, 'recall_at_5': 0.21046, 'recall_at_10': 0.27589, 'recall_at_20': 0.33139, 'recall_at_100': 0.56393, 'recall_at_1000': 1.0, 'precision_at_1': 0.14658, 'precision_at_3': 0.08523, 'precision_at_5': 0.06547, 'precision_at_10': 0.04332, 'precision_at_20': 0.02687, 'precision_at_100': 0.00948, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.1465798045602606, 'mrr_at_3': 0.17752442996742668, 'mrr_at_5': 0.18762214983713354, 'mrr_at_10': 0.19731722765110385, 'mrr_at_20': 0.2015662951246875, 'mrr_at_100': 0.20707710534700252, 'mrr_at_1000': 0.20855553565448004, 'nauc_ndcg_at_1_max': np.float64(0.19085798747833288), 'nauc_ndcg_at_1_std': np.float64(-0.14435925114799905), 'nauc_ndcg_at_1_diff1': np.float64(0.4121735549178938), 'nauc_ndcg_at_3_max': np.float64(0.12758992196189967), 'nauc_ndcg_at_3_std': np.float64(-0.15710210840877897), 'nauc_ndcg_at_3_diff1': np.float64(0.3210013038678148), 'nauc_ndcg_at_5_max': np.float64(0.12016953405982943), 'nauc_ndcg_at_5_std': np.float64(-0.14360346859755233), 'nauc_ndcg_at_5_diff1': np.float64(0.28988757849097235), 'nauc_ndcg_at_10_max': np.float64(0.1066127896899873), 'nauc_ndcg_at_10_std': np.float64(-0.14695456582459368), 'nauc_ndcg_at_10_diff1': np.float64(0.27414120118490526), 'nauc_ndcg_at_20_max': np.float64(0.12491664888923172), 'nauc_ndcg_at_20_std': np.float64(-0.13624765030430214), 'nauc_ndcg_at_20_diff1': np.float64(0.27330858228773236), 'nauc_ndcg_at_100_max': np.float64(0.1541821284034578), 'nauc_ndcg_at_100_std': np.float64(-0.09419332925963188), 'nauc_ndcg_at_100_diff1': np.float64(0.2684528961917265), 'nauc_ndcg_at_1000_max': np.float64(0.14818751258096086), 'nauc_ndcg_at_1000_std': np.float64(-0.11254235753557018), 'nauc_ndcg_at_1000_diff1': np.float64(0.28352447736529235), 'nauc_map_at_1_max': np.float64(0.14393457002042248), 'nauc_map_at_1_std': np.float64(-0.12143702610431029), 'nauc_map_at_1_diff1': np.float64(0.40644829209482053), 'nauc_map_at_3_max': np.float64(0.136632526296263), 'nauc_map_at_3_std': np.float64(-0.14723422116468743), 'nauc_map_at_3_diff1': np.float64(0.3353006506260329), 'nauc_map_at_5_max': np.float64(0.13150111786243118), 'nauc_map_at_5_std': np.float64(-0.14418367807295407), 'nauc_map_at_5_diff1': np.float64(0.3175259737085804), 'nauc_map_at_10_max': np.float64(0.12282453527643532), 'nauc_map_at_10_std': np.float64(-0.1476675205836964), 'nauc_map_at_10_diff1': np.float64(0.3088053346453597), 'nauc_map_at_20_max': np.float64(0.12817104341755534), 'nauc_map_at_20_std': np.float64(-0.14480399498102442), 'nauc_map_at_20_diff1': np.float64(0.3081413643549043), 'nauc_map_at_100_max': np.float64(0.13308355794105098), 'nauc_map_at_100_std': np.float64(-0.13828361177976684), 'nauc_map_at_100_diff1': np.float64(0.3073047058653097), 'nauc_map_at_1000_max': np.float64(0.1338160534299897), 'nauc_map_at_1000_std': np.float64(-0.13794839607750214), 'nauc_map_at_1000_diff1': np.float64(0.30763143217672223), 'nauc_recall_at_1_max': np.float64(0.14393457002042248), 'nauc_recall_at_1_std': np.float64(-0.12143702610431029), 'nauc_recall_at_1_diff1': np.float64(0.40644829209482053), 'nauc_recall_at_3_max': np.float64(0.10444708912552092), 'nauc_recall_at_3_std': np.float64(-0.15328861618743703), 'nauc_recall_at_3_diff1': np.float64(0.2728191711624), 'nauc_recall_at_5_max': np.float64(0.08069507033602297), 'nauc_recall_at_5_std': np.float64(-0.13042911550176775), 'nauc_recall_at_5_diff1': np.float64(0.2184075677515039), 'nauc_recall_at_10_max': np.float64(0.06115108040645413), 'nauc_recall_at_10_std': np.float64(-0.12718866932476441), 'nauc_recall_at_10_diff1': np.float64(0.1829965989677518), 'nauc_recall_at_20_max': np.float64(0.10623684355332534), 'nauc_recall_at_20_std': np.float64(-0.10348366630113714), 'nauc_recall_at_20_diff1': np.float64(0.18531834190541685), 'nauc_recall_at_100_max': np.float64(0.1883912953679181), 'nauc_recall_at_100_std': np.float64(0.04473047987537684), 'nauc_recall_at_100_diff1': np.float64(0.1622926951080695), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.19085798747833288), 'nauc_precision_at_1_std': np.float64(-0.14435925114799905), 'nauc_precision_at_1_diff1': np.float64(0.4121735549178938), 'nauc_precision_at_3_max': np.float64(0.12115124075350804), 'nauc_precision_at_3_std': np.float64(-0.1994336002541869), 'nauc_precision_at_3_diff1': np.float64(0.26080711637820647), 'nauc_precision_at_5_max': np.float64(0.11312164115214461), 'nauc_precision_at_5_std': np.float64(-0.16609069120023418), 'nauc_precision_at_5_diff1': np.float64(0.19895958009479262), 'nauc_precision_at_10_max': np.float64(0.07324766398775928), 'nauc_precision_at_10_std': np.float64(-0.16595402080585206), 'nauc_precision_at_10_diff1': np.float64(0.16283737067498513), 'nauc_precision_at_20_max': np.float64(0.12496747708942148), 'nauc_precision_at_20_std': np.float64(-0.10949585296598857), 'nauc_precision_at_20_diff1': np.float64(0.14262870898486948), 'nauc_precision_at_100_max': np.float64(0.22688797234101188), 'nauc_precision_at_100_std': np.float64(0.09383792805725592), 'nauc_precision_at_100_diff1': np.float64(0.0753632022312742), 'nauc_precision_at_1000_max': np.float64(0.1443604360846416), 'nauc_precision_at_1000_std': np.float64(0.10391667529789628), 'nauc_precision_at_1000_diff1': np.float64(0.013333452388665757), 'nauc_mrr_at_1_max': np.float64(0.19085798747833288), 'nauc_mrr_at_1_std': np.float64(-0.14435925114799905), 'nauc_mrr_at_1_diff1': np.float64(0.4121735549178938), 'nauc_mrr_at_3_max': np.float64(0.1463016652847567), 'nauc_mrr_at_3_std': np.float64(-0.16152968192762507), 'nauc_mrr_at_3_diff1': np.float64(0.34195141227555), 'nauc_mrr_at_5_max': np.float64(0.14011445892693827), 'nauc_mrr_at_5_std': np.float64(-0.15073175009402276), 'nauc_mrr_at_5_diff1': np.float64(0.32249872270393876), 'nauc_mrr_at_10_max': np.float64(0.13341937872629456), 'nauc_mrr_at_10_std': np.float64(-0.15328223131178528), 'nauc_mrr_at_10_diff1': np.float64(0.317891274150289), 'nauc_mrr_at_20_max': np.float64(0.14197298455729837), 'nauc_mrr_at_20_std': np.float64(-0.14664087739778192), 'nauc_mrr_at_20_diff1': np.float64(0.3177157441337964), 'nauc_mrr_at_100_max': np.float64(0.1459584513749848), 'nauc_mrr_at_100_std': np.float64(-0.14252077791050125), 'nauc_mrr_at_100_diff1': np.float64(0.3179424768755013), 'nauc_mrr_at_1000_max': np.float64(0.14538219773553393), 'nauc_mrr_at_1000_std': np.float64(-0.14343059867159388), 'nauc_mrr_at_1000_diff1': np.float64(0.3181861601686971), 'main_score': 0.19953}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 23.08it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:01,  5.15s/it]Batches:  15%|█▌        | 2/13 [00:07<00:38,  3.53s/it]Batches:  23%|██▎       | 3/13 [00:09<00:28,  2.84s/it]Batches:  31%|███       | 4/13 [00:11<00:22,  2.47s/it]Batches:  38%|███▊      | 5/13 [00:13<00:17,  2.18s/it]Batches:  46%|████▌     | 6/13 [00:14<00:13,  1.94s/it]Batches:  54%|█████▍    | 7/13 [00:15<00:10,  1.74s/it]Batches:  62%|██████▏   | 8/13 [00:16<00:07,  1.48s/it]Batches:  69%|██████▉   | 9/13 [00:17<00:04,  1.21s/it]Batches:  77%|███████▋  | 10/13 [00:18<00:03,  1.02s/it]Batches:  85%|████████▍ | 11/13 [00:18<00:01,  1.12it/s]Batches:  92%|█████████▏| 12/13 [00:19<00:00,  1.24it/s]Batches: 100%|██████████| 13/13 [00:19<00:00,  1.35it/s]Batches: 100%|██████████| 13/13 [00:19<00:00,  1.53s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 24.06 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 24.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.15, 'ndcg_at_3': 0.18393, 'ndcg_at_5': 0.19382, 'ndcg_at_10': 0.21136, 'ndcg_at_20': 0.22377, 'ndcg_at_100': 0.24586, 'ndcg_at_1000': 0.28698, 'map_at_1': 0.15, 'map_at_3': 0.175, 'map_at_5': 0.18025, 'map_at_10': 0.18735, 'map_at_20': 0.19064, 'map_at_100': 0.19327, 'map_at_1000': 0.19464, 'recall_at_1': 0.15, 'recall_at_3': 0.21, 'recall_at_5': 0.235, 'recall_at_10': 0.29, 'recall_at_20': 0.34, 'recall_at_100': 0.465, 'recall_at_1000': 0.8, 'precision_at_1': 0.15, 'precision_at_3': 0.07, 'precision_at_5': 0.047, 'precision_at_10': 0.029, 'precision_at_20': 0.017, 'precision_at_100': 0.00465, 'precision_at_1000': 0.0008, 'mrr_at_1': 0.15, 'mrr_at_3': 0.17499999999999996, 'mrr_at_5': 0.18025, 'mrr_at_10': 0.1873511904761905, 'mrr_at_20': 0.19064376544078562, 'mrr_at_100': 0.1932656643541595, 'mrr_at_1000': 0.194637575636994, 'nauc_ndcg_at_1_max': np.float64(0.43441185364378593), 'nauc_ndcg_at_1_std': np.float64(0.04886604172966431), 'nauc_ndcg_at_1_diff1': np.float64(0.47386352182239694), 'nauc_ndcg_at_3_max': np.float64(0.4148008587092167), 'nauc_ndcg_at_3_std': np.float64(0.0765450997846883), 'nauc_ndcg_at_3_diff1': np.float64(0.4173710345301199), 'nauc_ndcg_at_5_max': np.float64(0.3947365399898461), 'nauc_ndcg_at_5_std': np.float64(0.06532036169510255), 'nauc_ndcg_at_5_diff1': np.float64(0.40607152758343384), 'nauc_ndcg_at_10_max': np.float64(0.36723757477418867), 'nauc_ndcg_at_10_std': np.float64(0.09756589754942517), 'nauc_ndcg_at_10_diff1': np.float64(0.40017226159039093), 'nauc_ndcg_at_20_max': np.float64(0.3827760165049992), 'nauc_ndcg_at_20_std': np.float64(0.10333993614473298), 'nauc_ndcg_at_20_diff1': np.float64(0.4101575188843452), 'nauc_ndcg_at_100_max': np.float64(0.3857059030820315), 'nauc_ndcg_at_100_std': np.float64(0.11677959597214504), 'nauc_ndcg_at_100_diff1': np.float64(0.3891755926132448), 'nauc_ndcg_at_1000_max': np.float64(0.3919672345060052), 'nauc_ndcg_at_1000_std': np.float64(0.12183031996562628), 'nauc_ndcg_at_1000_diff1': np.float64(0.3930884829726909), 'nauc_map_at_1_max': np.float64(0.43441185364378593), 'nauc_map_at_1_std': np.float64(0.04886604172966431), 'nauc_map_at_1_diff1': np.float64(0.47386352182239694), 'nauc_map_at_3_max': np.float64(0.4205365611309337), 'nauc_map_at_3_std': np.float64(0.06762567183054063), 'nauc_map_at_3_diff1': np.float64(0.42882435301025235), 'nauc_map_at_5_max': np.float64(0.4091255564431754), 'nauc_map_at_5_std': np.float64(0.06111330163205471), 'nauc_map_at_5_diff1': np.float64(0.42239936912996834), 'nauc_map_at_10_max': np.float64(0.39669223211581367), 'nauc_map_at_10_std': np.float64(0.07550123839325398), 'nauc_map_at_10_diff1': np.float64(0.4193940786974634), 'nauc_map_at_20_max': np.float64(0.4022637165994432), 'nauc_map_at_20_std': np.float64(0.07711481929642598), 'nauc_map_at_20_diff1': np.float64(0.4226021052334953), 'nauc_map_at_100_max': np.float64(0.4037289047072941), 'nauc_map_at_100_std': np.float64(0.079882429894484), 'nauc_map_at_100_diff1': np.float64(0.4202866537928211), 'nauc_map_at_1000_max': np.float64(0.4038842169875267), 'nauc_map_at_1000_std': np.float64(0.07983366724544608), 'nauc_map_at_1000_diff1': np.float64(0.4207049076362108), 'nauc_recall_at_1_max': np.float64(0.43441185364378593), 'nauc_recall_at_1_std': np.float64(0.04886604172966431), 'nauc_recall_at_1_diff1': np.float64(0.47386352182239694), 'nauc_recall_at_3_max': np.float64(0.39974979017213813), 'nauc_recall_at_3_std': np.float64(0.10017102950258919), 'nauc_recall_at_3_diff1': np.float64(0.3886724626664764), 'nauc_recall_at_5_max': np.float64(0.3563013398423628), 'nauc_recall_at_5_std': np.float64(0.07533496059064908), 'nauc_recall_at_5_diff1': np.float64(0.36479532075357635), 'nauc_recall_at_10_max': np.float64(0.2892875293600539), 'nauc_recall_at_10_std': np.float64(0.15705396755628195), 'nauc_recall_at_10_diff1': np.float64(0.35383157287474426), 'nauc_recall_at_20_max': np.float64(0.3359323246508915), 'nauc_recall_at_20_std': np.float64(0.1746270436418558), 'nauc_recall_at_20_diff1': np.float64(0.38568854500649197), 'nauc_recall_at_100_max': np.float64(0.3374796796124813), 'nauc_recall_at_100_std': np.float64(0.2227311917125726), 'nauc_recall_at_100_diff1': np.float64(0.2858280516779541), 'nauc_recall_at_1000_max': np.float64(0.37482517482517436), 'nauc_recall_at_1000_std': np.float64(0.3865259740259733), 'nauc_recall_at_1000_diff1': np.float64(0.22000499500499474), 'nauc_precision_at_1_max': np.float64(0.43441185364378593), 'nauc_precision_at_1_std': np.float64(0.04886604172966431), 'nauc_precision_at_1_diff1': np.float64(0.47386352182239694), 'nauc_precision_at_3_max': np.float64(0.3997497901721378), 'nauc_precision_at_3_std': np.float64(0.10017102950258906), 'nauc_precision_at_3_diff1': np.float64(0.38867246266647654), 'nauc_precision_at_5_max': np.float64(0.35630133984236295), 'nauc_precision_at_5_std': np.float64(0.07533496059064919), 'nauc_precision_at_5_diff1': np.float64(0.3647953207535766), 'nauc_precision_at_10_max': np.float64(0.2892875293600539), 'nauc_precision_at_10_std': np.float64(0.1570539675562823), 'nauc_precision_at_10_diff1': np.float64(0.3538315728747443), 'nauc_precision_at_20_max': np.float64(0.33593232465089196), 'nauc_precision_at_20_std': np.float64(0.17462704364185613), 'nauc_precision_at_20_diff1': np.float64(0.385688545006492), 'nauc_precision_at_100_max': np.float64(0.33747967961248115), 'nauc_precision_at_100_std': np.float64(0.22273119171257286), 'nauc_precision_at_100_diff1': np.float64(0.28582805167795394), 'nauc_precision_at_1000_max': np.float64(0.3748251748251741), 'nauc_precision_at_1000_std': np.float64(0.38652597402597466), 'nauc_precision_at_1000_diff1': np.float64(0.22000499500499443), 'nauc_mrr_at_1_max': np.float64(0.43441185364378593), 'nauc_mrr_at_1_std': np.float64(0.04886604172966431), 'nauc_mrr_at_1_diff1': np.float64(0.47386352182239694), 'nauc_mrr_at_3_max': np.float64(0.4205365611309337), 'nauc_mrr_at_3_std': np.float64(0.06762567183054063), 'nauc_mrr_at_3_diff1': np.float64(0.42882435301025235), 'nauc_mrr_at_5_max': np.float64(0.4091255564431754), 'nauc_mrr_at_5_std': np.float64(0.06111330163205471), 'nauc_mrr_at_5_diff1': np.float64(0.42239936912996834), 'nauc_mrr_at_10_max': np.float64(0.39669223211581367), 'nauc_mrr_at_10_std': np.float64(0.07550123839325398), 'nauc_mrr_at_10_diff1': np.float64(0.4193940786974634), 'nauc_mrr_at_20_max': np.float64(0.4022637165994432), 'nauc_mrr_at_20_std': np.float64(0.07711481929642598), 'nauc_mrr_at_20_diff1': np.float64(0.4226021052334953), 'nauc_mrr_at_100_max': np.float64(0.4037289047072941), 'nauc_mrr_at_100_std': np.float64(0.079882429894484), 'nauc_mrr_at_100_diff1': np.float64(0.4202866537928211), 'nauc_mrr_at_1000_max': np.float64(0.4038842169875267), 'nauc_mrr_at_1000_std': np.float64(0.07983366724544608), 'nauc_mrr_at_1000_diff1': np.float64(0.4207049076362108), 'main_score': 0.21136}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 46.27it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:03,  5.27s/it]Batches:  15%|█▌        | 2/13 [00:07<00:40,  3.71s/it]Batches:  23%|██▎       | 3/13 [00:10<00:30,  3.00s/it]Batches:  31%|███       | 4/13 [00:11<00:22,  2.55s/it]Batches:  38%|███▊      | 5/13 [00:13<00:17,  2.23s/it]Batches:  46%|████▌     | 6/13 [00:15<00:13,  1.98s/it]Batches:  54%|█████▍    | 7/13 [00:16<00:10,  1.77s/it]Batches:  62%|██████▏   | 8/13 [00:17<00:07,  1.50s/it]Batches:  69%|██████▉   | 9/13 [00:17<00:04,  1.22s/it]Batches:  77%|███████▋  | 10/13 [00:18<00:03,  1.03s/it]Batches:  85%|████████▍ | 11/13 [00:19<00:01,  1.11it/s]Batches:  92%|█████████▏| 12/13 [00:19<00:00,  1.24it/s]Batches: 100%|██████████| 13/13 [00:20<00:00,  1.34it/s]Batches: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 24.35 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 24.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.15, 'ndcg_at_3': 0.19024, 'ndcg_at_5': 0.20078, 'ndcg_at_10': 0.21009, 'ndcg_at_20': 0.22551, 'ndcg_at_100': 0.24701, 'ndcg_at_1000': 0.28357, 'map_at_1': 0.15, 'map_at_3': 0.18, 'map_at_5': 0.186, 'map_at_10': 0.18961, 'map_at_20': 0.19397, 'map_at_100': 0.19668, 'map_at_1000': 0.19786, 'recall_at_1': 0.15, 'recall_at_3': 0.22, 'recall_at_5': 0.245, 'recall_at_10': 0.275, 'recall_at_20': 0.335, 'recall_at_100': 0.455, 'recall_at_1000': 0.755, 'precision_at_1': 0.15, 'precision_at_3': 0.07333, 'precision_at_5': 0.049, 'precision_at_10': 0.0275, 'precision_at_20': 0.01675, 'precision_at_100': 0.00455, 'precision_at_1000': 0.00076, 'mrr_at_1': 0.15, 'mrr_at_3': 0.18000000000000005, 'mrr_at_5': 0.18599999999999997, 'mrr_at_10': 0.189609126984127, 'mrr_at_20': 0.19396976838520957, 'mrr_at_100': 0.19668076914101235, 'mrr_at_1000': 0.1978610917854651, 'nauc_ndcg_at_1_max': np.float64(0.45248462856566873), 'nauc_ndcg_at_1_std': np.float64(-0.02942243725430905), 'nauc_ndcg_at_1_diff1': np.float64(0.5749319625037798), 'nauc_ndcg_at_3_max': np.float64(0.3797385527951651), 'nauc_ndcg_at_3_std': np.float64(-0.008302044500692019), 'nauc_ndcg_at_3_diff1': np.float64(0.5235997659008191), 'nauc_ndcg_at_5_max': np.float64(0.37507182819845286), 'nauc_ndcg_at_5_std': np.float64(-0.0037929497373215483), 'nauc_ndcg_at_5_diff1': np.float64(0.5042307565175209), 'nauc_ndcg_at_10_max': np.float64(0.35639768060580845), 'nauc_ndcg_at_10_std': np.float64(0.004613511923644173), 'nauc_ndcg_at_10_diff1': np.float64(0.47954881077865175), 'nauc_ndcg_at_20_max': np.float64(0.37244317386582676), 'nauc_ndcg_at_20_std': np.float64(0.02920391095763764), 'nauc_ndcg_at_20_diff1': np.float64(0.47327403289780434), 'nauc_ndcg_at_100_max': np.float64(0.351755568534936), 'nauc_ndcg_at_100_std': np.float64(0.03926834774185948), 'nauc_ndcg_at_100_diff1': np.float64(0.4481348187534295), 'nauc_ndcg_at_1000_max': np.float64(0.3698201618957176), 'nauc_ndcg_at_1000_std': np.float64(0.06362706774681896), 'nauc_ndcg_at_1000_diff1': np.float64(0.46100358473240094), 'nauc_map_at_1_max': np.float64(0.45248462856566873), 'nauc_map_at_1_std': np.float64(-0.02942243725430905), 'nauc_map_at_1_diff1': np.float64(0.5749319625037798), 'nauc_map_at_3_max': np.float64(0.39584446106185245), 'nauc_map_at_3_std': np.float64(-0.016703462355636342), 'nauc_map_at_3_diff1': np.float64(0.5351814264857744), 'nauc_map_at_5_max': np.float64(0.3928238079669256), 'nauc_map_at_5_std': np.float64(-0.014663626892973852), 'nauc_map_at_5_diff1': np.float64(0.5234592249631748), 'nauc_map_at_10_max': np.float64(0.3849688799031845), 'nauc_map_at_10_std': np.float64(-0.011617963885986744), 'nauc_map_at_10_diff1': np.float64(0.5129554885861102), 'nauc_map_at_20_max': np.float64(0.3888801333620479), 'nauc_map_at_20_std': np.float64(-0.004779008262295349), 'nauc_map_at_20_diff1': np.float64(0.5106215421535113), 'nauc_map_at_100_max': np.float64(0.385798453127722), 'nauc_map_at_100_std': np.float64(-0.004096212332051559), 'nauc_map_at_100_diff1': np.float64(0.5069575615988758), 'nauc_map_at_1000_max': np.float64(0.3868510005703684), 'nauc_map_at_1000_std': np.float64(-0.0026675605391628023), 'nauc_map_at_1000_diff1': np.float64(0.5074359477197378), 'nauc_recall_at_1_max': np.float64(0.45248462856566873), 'nauc_recall_at_1_std': np.float64(-0.02942243725430905), 'nauc_recall_at_1_diff1': np.float64(0.5749319625037798), 'nauc_recall_at_3_max': np.float64(0.338953289616807), 'nauc_recall_at_3_std': np.float64(0.014264847561922998), 'nauc_recall_at_3_diff1': np.float64(0.4941961649625509), 'nauc_recall_at_5_max': np.float64(0.3311340848875267), 'nauc_recall_at_5_std': np.float64(0.025329701728475762), 'nauc_recall_at_5_diff1': np.float64(0.45508857602992353), 'nauc_recall_at_10_max': np.float64(0.282163608831919), 'nauc_recall_at_10_std': np.float64(0.049138993555657234), 'nauc_recall_at_10_diff1': np.float64(0.3906468993203506), 'nauc_recall_at_20_max': np.float64(0.3419904508297416), 'nauc_recall_at_20_std': np.float64(0.12899348557995577), 'nauc_recall_at_20_diff1': np.float64(0.37698636686610576), 'nauc_recall_at_100_max': np.float64(0.2510248119265153), 'nauc_recall_at_100_std': np.float64(0.18310847593249688), 'nauc_recall_at_100_diff1': np.float64(0.265755868483016), 'nauc_recall_at_1000_max': np.float64(0.34670170100954245), 'nauc_recall_at_1000_std': np.float64(0.47346361286341904), 'nauc_recall_at_1000_diff1': np.float64(0.28788442922034413), 'nauc_precision_at_1_max': np.float64(0.45248462856566873), 'nauc_precision_at_1_std': np.float64(-0.02942243725430905), 'nauc_precision_at_1_diff1': np.float64(0.5749319625037798), 'nauc_precision_at_3_max': np.float64(0.33895328961680704), 'nauc_precision_at_3_std': np.float64(0.01426484756192322), 'nauc_precision_at_3_diff1': np.float64(0.49419616496255103), 'nauc_precision_at_5_max': np.float64(0.33113408488752677), 'nauc_precision_at_5_std': np.float64(0.025329701728475713), 'nauc_precision_at_5_diff1': np.float64(0.455088576029924), 'nauc_precision_at_10_max': np.float64(0.28216360883191893), 'nauc_precision_at_10_std': np.float64(0.04913899355565734), 'nauc_precision_at_10_diff1': np.float64(0.390646899320351), 'nauc_precision_at_20_max': np.float64(0.34199045082974217), 'nauc_precision_at_20_std': np.float64(0.12899348557995627), 'nauc_precision_at_20_diff1': np.float64(0.37698636686610626), 'nauc_precision_at_100_max': np.float64(0.25102481192651527), 'nauc_precision_at_100_std': np.float64(0.18310847593249713), 'nauc_precision_at_100_diff1': np.float64(0.2657558684830164), 'nauc_precision_at_1000_max': np.float64(0.34670170100954223), 'nauc_precision_at_1000_std': np.float64(0.47346361286341937), 'nauc_precision_at_1000_diff1': np.float64(0.2878844292203446), 'nauc_mrr_at_1_max': np.float64(0.45248462856566873), 'nauc_mrr_at_1_std': np.float64(-0.02942243725430905), 'nauc_mrr_at_1_diff1': np.float64(0.5749319625037798), 'nauc_mrr_at_3_max': np.float64(0.39584446106185245), 'nauc_mrr_at_3_std': np.float64(-0.016703462355636342), 'nauc_mrr_at_3_diff1': np.float64(0.5351814264857744), 'nauc_mrr_at_5_max': np.float64(0.3928238079669256), 'nauc_mrr_at_5_std': np.float64(-0.014663626892973852), 'nauc_mrr_at_5_diff1': np.float64(0.5234592249631748), 'nauc_mrr_at_10_max': np.float64(0.3849688799031845), 'nauc_mrr_at_10_std': np.float64(-0.011617963885986744), 'nauc_mrr_at_10_diff1': np.float64(0.5129554885861102), 'nauc_mrr_at_20_max': np.float64(0.3888801333620479), 'nauc_mrr_at_20_std': np.float64(-0.004779008262295349), 'nauc_mrr_at_20_diff1': np.float64(0.5106215421535113), 'nauc_mrr_at_100_max': np.float64(0.385798453127722), 'nauc_mrr_at_100_std': np.float64(-0.004096212332051559), 'nauc_mrr_at_100_diff1': np.float64(0.5069575615988758), 'nauc_mrr_at_1000_max': np.float64(0.3868510005703684), 'nauc_mrr_at_1000_std': np.float64(-0.0026675605391628023), 'nauc_mrr_at_1000_diff1': np.float64(0.5074359477197378), 'main_score': 0.21009}}



==================================================
Running model: intfloat/e5-mistral-7b-instruct
--------------------------------------------------
##### attention 적용 모델 로딩 실패 --> attention 적용 없이 재시도
MistralModel.__init__() got an unexpected keyword argument 'model_kwargs'
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Created GritLM: torch.float16 dtype, lasttoken pool, embedding mode, cccc attn
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / intfloat/e5-mistral-7b-instruct on GPU 0 in process Process-11
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  10%|█         | 1/10 [00:01<00:14,  1.60s/it]Batches:  20%|██        | 2/10 [00:01<00:06,  1.24it/s]Batches:  30%|███       | 3/10 [00:02<00:05,  1.27it/s]Batches:  40%|████      | 4/10 [00:03<00:04,  1.44it/s]Batches:  50%|█████     | 5/10 [00:03<00:03,  1.47it/s]Batches:  60%|██████    | 6/10 [00:04<00:02,  1.41it/s]Batches:  70%|███████   | 7/10 [00:05<00:02,  1.37it/s]Batches:  80%|████████  | 8/10 [00:06<00:01,  1.39it/s]Batches:  90%|█████████ | 9/10 [00:06<00:00,  1.37it/s]Batches: 100%|██████████| 10/10 [00:07<00:00,  1.46it/s]Batches: 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/145 [00:00<?, ?it/s]Batches:   1%|          | 1/145 [00:01<03:17,  1.37s/it]Batches:   1%|▏         | 2/145 [00:06<08:41,  3.65s/it]Batches:   2%|▏         | 3/145 [00:11<10:22,  4.38s/it]Batches:   3%|▎         | 4/145 [00:17<11:07,  4.74s/it]Batches:   3%|▎         | 5/145 [00:22<11:30,  4.93s/it]Batches:   4%|▍         | 6/145 [00:27<11:42,  5.06s/it]Batches:   5%|▍         | 7/145 [00:33<11:49,  5.14s/it]Batches:   6%|▌         | 8/145 [00:38<11:51,  5.20s/it]Batches:   6%|▌         | 9/145 [00:43<11:51,  5.23s/it]Batches:   7%|▋         | 10/145 [00:49<11:50,  5.26s/it]Batches:   8%|▊         | 11/145 [00:54<11:47,  5.28s/it]Batches:   8%|▊         | 12/145 [00:59<11:44,  5.30s/it]Batches:   9%|▉         | 13/145 [01:05<11:41,  5.31s/it]Batches:  10%|▉         | 14/145 [01:10<11:37,  5.32s/it]Batches:  10%|█         | 15/145 [01:15<11:32,  5.33s/it]Batches:  11%|█         | 16/145 [01:21<11:28,  5.34s/it]Batches:  12%|█▏        | 17/145 [01:26<11:23,  5.34s/it]Batches:  12%|█▏        | 18/145 [01:31<11:19,  5.35s/it]Batches:  13%|█▎        | 19/145 [01:37<11:14,  5.35s/it]Batches:  14%|█▍        | 20/145 [01:42<11:09,  5.36s/it]Batches:  14%|█▍        | 21/145 [01:47<11:04,  5.36s/it]Batches:  15%|█▌        | 22/145 [01:53<10:59,  5.36s/it]Batches:  16%|█▌        | 23/145 [01:58<10:53,  5.36s/it]Batches:  17%|█▋        | 24/145 [02:03<10:48,  5.36s/it]Batches:  17%|█▋        | 25/145 [02:09<10:43,  5.37s/it]Batches:  18%|█▊        | 26/145 [02:14<10:38,  5.37s/it]Batches:  19%|█▊        | 27/145 [02:20<10:33,  5.37s/it]Batches:  19%|█▉        | 28/145 [02:25<10:27,  5.37s/it]Batches:  20%|██        | 29/145 [02:30<10:22,  5.37s/it]Batches:  21%|██        | 30/145 [02:36<10:17,  5.37s/it]Batches:  21%|██▏       | 31/145 [02:41<10:12,  5.37s/it]Batches:  22%|██▏       | 32/145 [02:46<10:06,  5.37s/it]Batches:  23%|██▎       | 33/145 [02:52<10:01,  5.37s/it]Batches:  23%|██▎       | 34/145 [02:57<09:56,  5.37s/it]Batches:  24%|██▍       | 35/145 [03:03<09:50,  5.37s/it]Batches:  25%|██▍       | 36/145 [03:08<09:45,  5.37s/it]Batches:  26%|██▌       | 37/145 [03:13<09:40,  5.37s/it]Batches:  26%|██▌       | 38/145 [03:19<09:34,  5.37s/it]Batches:  27%|██▋       | 39/145 [03:24<09:29,  5.37s/it]Batches:  28%|██▊       | 40/145 [03:29<09:24,  5.37s/it]Batches:  28%|██▊       | 41/145 [03:35<09:18,  5.37s/it]Batches:  29%|██▉       | 42/145 [03:40<09:13,  5.37s/it]Batches:  30%|██▉       | 43/145 [03:46<09:08,  5.37s/it]Batches:  30%|███       | 44/145 [03:51<09:02,  5.37s/it]Batches:  31%|███       | 45/145 [03:56<08:57,  5.38s/it]Batches:  32%|███▏      | 46/145 [04:02<08:52,  5.38s/it]Batches:  32%|███▏      | 47/145 [04:07<08:47,  5.38s/it]Batches:  33%|███▎      | 48/145 [04:12<08:41,  5.38s/it]Batches:  34%|███▍      | 49/145 [04:18<08:36,  5.38s/it]Batches:  34%|███▍      | 50/145 [04:23<08:31,  5.38s/it]Batches:  35%|███▌      | 51/145 [04:29<08:25,  5.38s/it]Batches:  36%|███▌      | 52/145 [04:34<08:20,  5.38s/it]Batches:  37%|███▋      | 53/145 [04:39<08:14,  5.38s/it]Batches:  37%|███▋      | 54/145 [04:45<08:09,  5.38s/it]Batches:  38%|███▊      | 55/145 [04:50<08:04,  5.38s/it]Batches:  39%|███▊      | 56/145 [04:55<07:58,  5.38s/it]Batches:  39%|███▉      | 57/145 [05:01<07:53,  5.38s/it]Batches:  40%|████      | 58/145 [05:06<07:48,  5.38s/it]Batches:  41%|████      | 59/145 [05:12<07:42,  5.38s/it]Batches:  41%|████▏     | 60/145 [05:17<07:37,  5.38s/it]Batches:  42%|████▏     | 61/145 [05:22<07:31,  5.38s/it]Batches:  43%|████▎     | 62/145 [05:28<07:26,  5.38s/it]Batches:  43%|████▎     | 63/145 [05:33<07:21,  5.38s/it]Batches:  44%|████▍     | 64/145 [05:38<07:15,  5.38s/it]Batches:  45%|████▍     | 65/145 [05:44<07:10,  5.38s/it]Batches:  46%|████▌     | 66/145 [05:49<07:04,  5.38s/it]Batches:  46%|████▌     | 67/145 [05:55<06:59,  5.38s/it]Batches:  47%|████▋     | 68/145 [06:00<06:54,  5.38s/it]Batches:  48%|████▊     | 69/145 [06:05<06:48,  5.38s/it]Batches:  48%|████▊     | 70/145 [06:11<06:43,  5.38s/it]Batches:  49%|████▉     | 71/145 [06:16<06:38,  5.38s/it]Batches:  50%|████▉     | 72/145 [06:22<06:32,  5.38s/it]Batches:  50%|█████     | 73/145 [06:27<06:27,  5.38s/it]Batches:  51%|█████     | 74/145 [06:32<06:22,  5.38s/it]Batches:  52%|█████▏    | 75/145 [06:38<06:16,  5.38s/it]Batches:  52%|█████▏    | 76/145 [06:43<06:11,  5.38s/it]Batches:  53%|█████▎    | 77/145 [06:48<06:05,  5.38s/it]Batches:  54%|█████▍    | 78/145 [06:54<06:00,  5.38s/it]Batches:  54%|█████▍    | 79/145 [06:59<05:54,  5.38s/it]Batches:  55%|█████▌    | 80/145 [07:05<05:49,  5.38s/it]Batches:  56%|█████▌    | 81/145 [07:10<05:44,  5.38s/it]Batches:  57%|█████▋    | 82/145 [07:15<05:38,  5.38s/it]Batches:  57%|█████▋    | 83/145 [07:21<05:33,  5.38s/it]Batches:  58%|█████▊    | 84/145 [07:26<05:28,  5.38s/it]Batches:  59%|█████▊    | 85/145 [07:31<05:22,  5.38s/it]Batches:  59%|█████▉    | 86/145 [07:37<05:17,  5.38s/it]Batches:  60%|██████    | 87/145 [07:42<05:11,  5.38s/it]Batches:  61%|██████    | 88/145 [07:48<05:06,  5.38s/it]Batches:  61%|██████▏   | 89/145 [07:53<05:01,  5.38s/it]Batches:  62%|██████▏   | 90/145 [07:58<04:56,  5.38s/it]Batches:  63%|██████▎   | 91/145 [08:04<04:50,  5.38s/it]Batches:  63%|██████▎   | 92/145 [08:09<04:45,  5.38s/it]Batches:  64%|██████▍   | 93/145 [08:15<04:39,  5.38s/it]Batches:  65%|██████▍   | 94/145 [08:20<04:34,  5.39s/it]Batches:  66%|██████▌   | 95/145 [08:25<04:29,  5.38s/it]Batches:  66%|██████▌   | 96/145 [08:31<04:23,  5.38s/it]Batches:  67%|██████▋   | 97/145 [08:36<04:18,  5.38s/it]Batches:  68%|██████▊   | 98/145 [08:41<04:12,  5.38s/it]Batches:  68%|██████▊   | 99/145 [08:47<04:07,  5.38s/it]Batches:  69%|██████▉   | 100/145 [08:52<04:02,  5.38s/it]Batches:  70%|██████▉   | 101/145 [08:58<03:56,  5.38s/it]Batches:  70%|███████   | 102/145 [09:03<03:51,  5.38s/it]Batches:  71%|███████   | 103/145 [09:08<03:45,  5.38s/it]Batches:  72%|███████▏  | 104/145 [09:14<03:40,  5.38s/it]Batches:  72%|███████▏  | 105/145 [09:19<03:35,  5.38s/it]Batches:  73%|███████▎  | 106/145 [09:24<03:29,  5.38s/it]Batches:  74%|███████▍  | 107/145 [09:30<03:24,  5.38s/it]Batches:  74%|███████▍  | 108/145 [09:35<03:19,  5.38s/it]Batches:  75%|███████▌  | 109/145 [09:41<03:13,  5.38s/it]Batches:  76%|███████▌  | 110/145 [09:46<03:08,  5.38s/it]Batches:  77%|███████▋  | 111/145 [09:51<03:03,  5.38s/it]Batches:  77%|███████▋  | 112/145 [09:57<02:57,  5.38s/it]Batches:  78%|███████▊  | 113/145 [10:02<02:52,  5.38s/it]Batches:  79%|███████▊  | 114/145 [10:08<02:46,  5.38s/it]Batches:  79%|███████▉  | 115/145 [10:13<02:41,  5.38s/it]Batches:  80%|████████  | 116/145 [10:18<02:36,  5.38s/it]Batches:  81%|████████  | 117/145 [10:24<02:30,  5.38s/it]Batches:  81%|████████▏ | 118/145 [10:29<02:25,  5.38s/it]Batches:  82%|████████▏ | 119/145 [10:34<02:19,  5.38s/it]Batches:  83%|████████▎ | 120/145 [10:40<02:14,  5.38s/it]Batches:  83%|████████▎ | 121/145 [10:45<02:09,  5.38s/it]Batches:  84%|████████▍ | 122/145 [10:51<02:03,  5.38s/it]Batches:  85%|████████▍ | 123/145 [10:56<01:58,  5.38s/it]Batches:  86%|████████▌ | 124/145 [11:01<01:53,  5.38s/it]Batches:  86%|████████▌ | 125/145 [11:07<01:47,  5.38s/it]Batches:  87%|████████▋ | 126/145 [11:12<01:42,  5.38s/it]Batches:  88%|████████▊ | 127/145 [11:18<01:36,  5.38s/it]Batches:  88%|████████▊ | 128/145 [11:23<01:31,  5.38s/it]Batches:  89%|████████▉ | 129/145 [11:28<01:26,  5.38s/it]Batches:  90%|████████▉ | 130/145 [11:34<01:20,  5.38s/it]Batches:  90%|█████████ | 131/145 [11:39<01:15,  5.38s/it]Batches:  91%|█████████ | 132/145 [11:44<01:09,  5.38s/it]Batches:  92%|█████████▏| 133/145 [11:50<01:04,  5.38s/it]Batches:  92%|█████████▏| 134/145 [11:55<00:59,  5.38s/it]Batches:  93%|█████████▎| 135/145 [12:01<00:53,  5.38s/it]Batches:  94%|█████████▍| 136/145 [12:06<00:48,  5.38s/it]Batches:  94%|█████████▍| 137/145 [12:11<00:43,  5.38s/it]Batches:  95%|█████████▌| 138/145 [12:17<00:37,  5.38s/it]Batches:  96%|█████████▌| 139/145 [12:22<00:32,  5.38s/it]Batches:  97%|█████████▋| 140/145 [12:27<00:26,  5.38s/it]Batches:  97%|█████████▋| 141/145 [12:33<00:21,  5.38s/it]Batches:  98%|█████████▊| 142/145 [12:38<00:16,  5.38s/it]Batches:  99%|█████████▊| 143/145 [12:44<00:10,  5.38s/it]Batches:  99%|█████████▉| 144/145 [12:49<00:05,  5.38s/it]Batches: 100%|██████████| 145/145 [12:54<00:00,  5.19s/it]Batches: 100%|██████████| 145/145 [12:54<00:00,  5.34s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 784.71 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 785.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.75845, 'ndcg_at_3': 0.74868, 'ndcg_at_5': 0.77519, 'ndcg_at_10': 0.79317, 'ndcg_at_20': 0.79982, 'ndcg_at_100': 0.81137, 'ndcg_at_1000': 0.81813, 'map_at_1': 0.49126, 'map_at_3': 0.70867, 'map_at_5': 0.73638, 'map_at_10': 0.7495, 'map_at_20': 0.7525, 'map_at_100': 0.75455, 'map_at_1000': 0.75486, 'recall_at_1': 0.49126, 'recall_at_3': 0.7543, 'recall_at_5': 0.81055, 'recall_at_10': 0.85157, 'recall_at_20': 0.87176, 'recall_at_100': 0.92359, 'recall_at_1000': 0.96523, 'precision_at_1': 0.75845, 'precision_at_3': 0.44764, 'precision_at_5': 0.29493, 'precision_at_10': 0.15828, 'precision_at_20': 0.08167, 'precision_at_100': 0.0174, 'precision_at_1000': 0.00185, 'mrr_at_1': 0.7584459459459459, 'mrr_at_3': 0.8037725225225222, 'mrr_at_5': 0.8077421171171169, 'mrr_at_10': 0.8100875429000428, 'mrr_at_20': 0.8106196684321683, 'mrr_at_100': 0.8117741696188778, 'mrr_at_1000': 0.8119308658579883, 'nauc_ndcg_at_1_max': np.float64(0.6301506150713375), 'nauc_ndcg_at_1_std': np.float64(0.2455626983258168), 'nauc_ndcg_at_1_diff1': np.float64(0.66972023486555), 'nauc_ndcg_at_3_max': np.float64(0.6641512405060968), 'nauc_ndcg_at_3_std': np.float64(0.2543432449264493), 'nauc_ndcg_at_3_diff1': np.float64(0.5897731159714351), 'nauc_ndcg_at_5_max': np.float64(0.701438209773727), 'nauc_ndcg_at_5_std': np.float64(0.293997577682127), 'nauc_ndcg_at_5_diff1': np.float64(0.6029444534112921), 'nauc_ndcg_at_10_max': np.float64(0.7149696137089852), 'nauc_ndcg_at_10_std': np.float64(0.34075062854849214), 'nauc_ndcg_at_10_diff1': np.float64(0.6003430346464026), 'nauc_ndcg_at_20_max': np.float64(0.7223368250879699), 'nauc_ndcg_at_20_std': np.float64(0.35960801191696007), 'nauc_ndcg_at_20_diff1': np.float64(0.6067158228790073), 'nauc_ndcg_at_100_max': np.float64(0.7139940512075619), 'nauc_ndcg_at_100_std': np.float64(0.3561157989568849), 'nauc_ndcg_at_100_diff1': np.float64(0.6043094579814945), 'nauc_ndcg_at_1000_max': np.float64(0.7071575615169982), 'nauc_ndcg_at_1000_std': np.float64(0.34814519146246253), 'nauc_ndcg_at_1000_diff1': np.float64(0.6071658736271631), 'nauc_map_at_1_max': np.float64(0.2926955664199994), 'nauc_map_at_1_std': np.float64(0.03482491000695274), 'nauc_map_at_1_diff1': np.float64(0.5799128004036584), 'nauc_map_at_3_max': np.float64(0.6100850559439003), 'nauc_map_at_3_std': np.float64(0.2032967213655951), 'nauc_map_at_3_diff1': np.float64(0.5707875594000664), 'nauc_map_at_5_max': np.float64(0.6511298048964124), 'nauc_map_at_5_std': np.float64(0.23763912270562051), 'nauc_map_at_5_diff1': np.float64(0.5803415355739513), 'nauc_map_at_10_max': np.float64(0.6599751607798277), 'nauc_map_at_10_std': np.float64(0.2680503647538944), 'nauc_map_at_10_diff1': np.float64(0.5791686751116271), 'nauc_map_at_20_max': np.float64(0.663291897775564), 'nauc_map_at_20_std': np.float64(0.2750654700270136), 'nauc_map_at_20_diff1': np.float64(0.5818294363558444), 'nauc_map_at_100_max': np.float64(0.6616682027785941), 'nauc_map_at_100_std': np.float64(0.2742860218168251), 'nauc_map_at_100_diff1': np.float64(0.5814545381777197), 'nauc_map_at_1000_max': np.float64(0.6613783736243776), 'nauc_map_at_1000_std': np.float64(0.2740502174662923), 'nauc_map_at_1000_diff1': np.float64(0.5815239898744718), 'nauc_recall_at_1_max': np.float64(0.2926955664199994), 'nauc_recall_at_1_std': np.float64(0.03482491000695274), 'nauc_recall_at_1_diff1': np.float64(0.5799128004036584), 'nauc_recall_at_3_max': np.float64(0.6744103858240265), 'nauc_recall_at_3_std': np.float64(0.25640288050963517), 'nauc_recall_at_3_diff1': np.float64(0.5572367507889452), 'nauc_recall_at_5_max': np.float64(0.7635092315346151), 'nauc_recall_at_5_std': np.float64(0.3351164969852482), 'nauc_recall_at_5_diff1': np.float64(0.5761474687351439), 'nauc_recall_at_10_max': np.float64(0.8248338917311779), 'nauc_recall_at_10_std': np.float64(0.4849807476605251), 'nauc_recall_at_10_diff1': np.float64(0.5688992428586632), 'nauc_recall_at_20_max': np.float64(0.87467624395276), 'nauc_recall_at_20_std': np.float64(0.5901505366736927), 'nauc_recall_at_20_diff1': np.float64(0.5974109466534318), 'nauc_recall_at_100_max': np.float64(0.8878032034318802), 'nauc_recall_at_100_std': np.float64(0.6909240094984084), 'nauc_recall_at_100_diff1': np.float64(0.5680963222825306), 'nauc_recall_at_1000_max': np.float64(0.9304343829172986), 'nauc_recall_at_1000_std': np.float64(0.8702336162445697), 'nauc_recall_at_1000_diff1': np.float64(0.632396735941214), 'nauc_precision_at_1_max': np.float64(0.6301506150713375), 'nauc_precision_at_1_std': np.float64(0.2455626983258168), 'nauc_precision_at_1_diff1': np.float64(0.66972023486555), 'nauc_precision_at_3_max': np.float64(0.4367172452112966), 'nauc_precision_at_3_std': np.float64(0.2764742828725262), 'nauc_precision_at_3_diff1': np.float64(0.05541188752867729), 'nauc_precision_at_5_max': np.float64(0.3808051604355799), 'nauc_precision_at_5_std': np.float64(0.28187720011150214), 'nauc_precision_at_5_diff1': np.float64(-0.01066638924522623), 'nauc_precision_at_10_max': np.float64(0.30131088075776663), 'nauc_precision_at_10_std': np.float64(0.30266327719783204), 'nauc_precision_at_10_diff1': np.float64(-0.08250164688420138), 'nauc_precision_at_20_max': np.float64(0.27224197167520786), 'nauc_precision_at_20_std': np.float64(0.3105317173548736), 'nauc_precision_at_20_diff1': np.float64(-0.10259875414901941), 'nauc_precision_at_100_max': np.float64(0.1684305637439278), 'nauc_precision_at_100_std': np.float64(0.271797207506889), 'nauc_precision_at_100_diff1': np.float64(-0.19627142564642316), 'nauc_precision_at_1000_max': np.float64(0.03955606783883199), 'nauc_precision_at_1000_std': np.float64(0.19379188361125566), 'nauc_precision_at_1000_diff1': np.float64(-0.2806280085418007), 'nauc_mrr_at_1_max': np.float64(0.6301506150713375), 'nauc_mrr_at_1_std': np.float64(0.2455626983258168), 'nauc_mrr_at_1_diff1': np.float64(0.66972023486555), 'nauc_mrr_at_3_max': np.float64(0.7240735657936037), 'nauc_mrr_at_3_std': np.float64(0.35119546746688735), 'nauc_mrr_at_3_diff1': np.float64(0.6743708966504051), 'nauc_mrr_at_5_max': np.float64(0.720000059937184), 'nauc_mrr_at_5_std': np.float64(0.3557423062678047), 'nauc_mrr_at_5_diff1': np.float64(0.6745833502417148), 'nauc_mrr_at_10_max': np.float64(0.7169363494428644), 'nauc_mrr_at_10_std': np.float64(0.35223055736252545), 'nauc_mrr_at_10_diff1': np.float64(0.6734370672138152), 'nauc_mrr_at_20_max': np.float64(0.716476673430364), 'nauc_mrr_at_20_std': np.float64(0.35288033831367044), 'nauc_mrr_at_20_diff1': np.float64(0.6736684272381803), 'nauc_mrr_at_100_max': np.float64(0.7154988092257505), 'nauc_mrr_at_100_std': np.float64(0.35196093105828524), 'nauc_mrr_at_100_diff1': np.float64(0.6731687899237588), 'nauc_mrr_at_1000_max': np.float64(0.7153223211268397), 'nauc_mrr_at_1000_std': np.float64(0.35163857931518755), 'nauc_mrr_at_1000_diff1': np.float64(0.6731581410879456), 'main_score': 0.79317}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'AutoRAGRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'AutoRAGRetrieval'
Batches:   0%|          | 0/12 [00:00<?, ?it/s]Batches:   8%|▊         | 1/12 [00:01<00:15,  1.42s/it]Batches:  17%|█▋        | 2/12 [00:06<00:37,  3.74s/it]Batches:  25%|██▌       | 3/12 [00:12<00:40,  4.48s/it]Batches:  33%|███▎      | 4/12 [00:17<00:38,  4.84s/it]Batches:  42%|████▏     | 5/12 [00:22<00:35,  5.03s/it]Batches:  50%|█████     | 6/12 [00:28<00:30,  5.15s/it]Batches:  58%|█████▊    | 7/12 [00:33<00:26,  5.22s/it]Batches:  67%|██████▋   | 8/12 [00:39<00:21,  5.27s/it]Batches:  75%|███████▌  | 9/12 [00:44<00:15,  5.30s/it]Batches:  83%|████████▎ | 10/12 [00:49<00:10,  5.33s/it]Batches:  92%|█████████▏| 11/12 [00:55<00:05,  5.35s/it]Batches: 100%|██████████| 12/12 [00:59<00:00,  5.06s/it]Batches: 100%|██████████| 12/12 [00:59<00:00,  4.97s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 63.81 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 63.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.50877, 'ndcg_at_3': 0.62343, 'ndcg_at_5': 0.64872, 'ndcg_at_10': 0.67829, 'ndcg_at_20': 0.68706, 'ndcg_at_100': 0.70302, 'ndcg_at_1000': 0.70674, 'map_at_1': 0.50877, 'map_at_3': 0.59357, 'map_at_5': 0.6076, 'map_at_10': 0.62052, 'map_at_20': 0.62289, 'map_at_100': 0.62562, 'map_at_1000': 0.62581, 'recall_at_1': 0.50877, 'recall_at_3': 0.71053, 'recall_at_5': 0.77193, 'recall_at_10': 0.85965, 'recall_at_20': 0.89474, 'recall_at_100': 0.97368, 'recall_at_1000': 1.0, 'precision_at_1': 0.50877, 'precision_at_3': 0.23684, 'precision_at_5': 0.15439, 'precision_at_10': 0.08596, 'precision_at_20': 0.04474, 'precision_at_100': 0.00974, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5087719298245614, 'mrr_at_3': 0.5935672514619883, 'mrr_at_5': 0.6076023391812866, 'mrr_at_10': 0.6205235310498469, 'mrr_at_20': 0.6228857963622506, 'mrr_at_100': 0.62561690136791, 'mrr_at_1000': 0.62581310777515, 'nauc_ndcg_at_1_max': np.float64(0.21248155213502273), 'nauc_ndcg_at_1_std': np.float64(-0.35903170112785254), 'nauc_ndcg_at_1_diff1': np.float64(0.6090728823575914), 'nauc_ndcg_at_3_max': np.float64(0.23675676717529345), 'nauc_ndcg_at_3_std': np.float64(-0.40301874051380876), 'nauc_ndcg_at_3_diff1': np.float64(0.5438811101297), 'nauc_ndcg_at_5_max': np.float64(0.2502845900216014), 'nauc_ndcg_at_5_std': np.float64(-0.3985522286869084), 'nauc_ndcg_at_5_diff1': np.float64(0.5668612106583857), 'nauc_ndcg_at_10_max': np.float64(0.24055704202750025), 'nauc_ndcg_at_10_std': np.float64(-0.4451507572019333), 'nauc_ndcg_at_10_diff1': np.float64(0.5754744548404779), 'nauc_ndcg_at_20_max': np.float64(0.2223841813964752), 'nauc_ndcg_at_20_std': np.float64(-0.44723521613253037), 'nauc_ndcg_at_20_diff1': np.float64(0.565609250529538), 'nauc_ndcg_at_100_max': np.float64(0.23112388880127163), 'nauc_ndcg_at_100_std': np.float64(-0.42606681005869856), 'nauc_ndcg_at_100_diff1': np.float64(0.5615526320809672), 'nauc_ndcg_at_1000_max': np.float64(0.2308851436800659), 'nauc_ndcg_at_1000_std': np.float64(-0.4245147175992623), 'nauc_ndcg_at_1000_diff1': np.float64(0.5733726093538275), 'nauc_map_at_1_max': np.float64(0.21248155213502273), 'nauc_map_at_1_std': np.float64(-0.35903170112785254), 'nauc_map_at_1_diff1': np.float64(0.6090728823575914), 'nauc_map_at_3_max': np.float64(0.23142735508369172), 'nauc_map_at_3_std': np.float64(-0.39674000031475426), 'nauc_map_at_3_diff1': np.float64(0.5671123042755822), 'nauc_map_at_5_max': np.float64(0.23881979426157995), 'nauc_map_at_5_std': np.float64(-0.39372881376091706), 'nauc_map_at_5_diff1': np.float64(0.5794706593498045), 'nauc_map_at_10_max': np.float64(0.23450242458346957), 'nauc_map_at_10_std': np.float64(-0.41389502747531987), 'nauc_map_at_10_diff1': np.float64(0.5847181610222602), 'nauc_map_at_20_max': np.float64(0.22997773995468693), 'nauc_map_at_20_std': np.float64(-0.41433921997824863), 'nauc_map_at_20_diff1': np.float64(0.5827053075949674), 'nauc_map_at_100_max': np.float64(0.23096040525198402), 'nauc_map_at_100_std': np.float64(-0.4120142573241007), 'nauc_map_at_100_diff1': np.float64(0.5818277396664252), 'nauc_map_at_1000_max': np.float64(0.23093774996611405), 'nauc_map_at_1000_std': np.float64(-0.41194777020643186), 'nauc_map_at_1000_diff1': np.float64(0.5823238769716048), 'nauc_recall_at_1_max': np.float64(0.21248155213502273), 'nauc_recall_at_1_std': np.float64(-0.35903170112785254), 'nauc_recall_at_1_diff1': np.float64(0.6090728823575914), 'nauc_recall_at_3_max': np.float64(0.2549962571692935), 'nauc_recall_at_3_std': np.float64(-0.4223888138155778), 'nauc_recall_at_3_diff1': np.float64(0.45878133440822066), 'nauc_recall_at_5_max': np.float64(0.29884838966647986), 'nauc_recall_at_5_std': np.float64(-0.4151258375967945), 'nauc_recall_at_5_diff1': np.float64(0.5161458610560639), 'nauc_recall_at_10_max': np.float64(0.2734245435140122), 'nauc_recall_at_10_std': np.float64(-0.6530978486978949), 'nauc_recall_at_10_diff1': np.float64(0.520047672512716), 'nauc_recall_at_20_max': np.float64(0.11918508664313392), 'nauc_recall_at_20_std': np.float64(-0.729670309017987), 'nauc_recall_at_20_diff1': np.float64(0.40735580805348587), 'nauc_recall_at_100_max': np.float64(0.24095945650358844), 'nauc_recall_at_100_std': np.float64(-0.5227782238828191), 'nauc_recall_at_100_diff1': np.float64(-0.1566390223291421), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.21248155213502273), 'nauc_precision_at_1_std': np.float64(-0.35903170112785254), 'nauc_precision_at_1_diff1': np.float64(0.6090728823575914), 'nauc_precision_at_3_max': np.float64(0.25499625716929286), 'nauc_precision_at_3_std': np.float64(-0.42238881381557775), 'nauc_precision_at_3_diff1': np.float64(0.45878133440822144), 'nauc_precision_at_5_max': np.float64(0.2988483896664812), 'nauc_precision_at_5_std': np.float64(-0.41512583759679444), 'nauc_precision_at_5_diff1': np.float64(0.5161458610560639), 'nauc_precision_at_10_max': np.float64(0.2734245435140121), 'nauc_precision_at_10_std': np.float64(-0.6530978486978932), 'nauc_precision_at_10_diff1': np.float64(0.5200476725127159), 'nauc_precision_at_20_max': np.float64(0.11918508664313493), 'nauc_precision_at_20_std': np.float64(-0.7296703090179871), 'nauc_precision_at_20_diff1': np.float64(0.4073558080534852), 'nauc_precision_at_100_max': np.float64(0.24095945650359982), 'nauc_precision_at_100_std': np.float64(-0.5227782238828026), 'nauc_precision_at_100_diff1': np.float64(-0.15663902232913457), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.21248155213502273), 'nauc_mrr_at_1_std': np.float64(-0.35903170112785254), 'nauc_mrr_at_1_diff1': np.float64(0.6090728823575914), 'nauc_mrr_at_3_max': np.float64(0.23142735508369172), 'nauc_mrr_at_3_std': np.float64(-0.39674000031475426), 'nauc_mrr_at_3_diff1': np.float64(0.5671123042755822), 'nauc_mrr_at_5_max': np.float64(0.23881979426157995), 'nauc_mrr_at_5_std': np.float64(-0.39372881376091706), 'nauc_mrr_at_5_diff1': np.float64(0.5794706593498045), 'nauc_mrr_at_10_max': np.float64(0.23450242458346957), 'nauc_mrr_at_10_std': np.float64(-0.41389502747531987), 'nauc_mrr_at_10_diff1': np.float64(0.5847181610222602), 'nauc_mrr_at_20_max': np.float64(0.22997773995468693), 'nauc_mrr_at_20_std': np.float64(-0.41433921997824863), 'nauc_mrr_at_20_diff1': np.float64(0.5827053075949674), 'nauc_mrr_at_100_max': np.float64(0.23096040525198402), 'nauc_mrr_at_100_std': np.float64(-0.4120142573241007), 'nauc_mrr_at_100_diff1': np.float64(0.5818277396664252), 'nauc_mrr_at_1000_max': np.float64(0.23093774996611405), 'nauc_mrr_at_1000_std': np.float64(-0.41194777020643186), 'nauc_mrr_at_1000_diff1': np.float64(0.5823238769716048), 'main_score': 0.67829}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'PublicHealthQA'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'PublicHealthQA'
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.06 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 8.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.77922, 'ndcg_at_3': 0.86905, 'ndcg_at_5': 0.87966, 'ndcg_at_10': 0.88733, 'ndcg_at_20': 0.8905, 'ndcg_at_100': 0.8905, 'ndcg_at_1000': 0.8905, 'map_at_1': 0.77922, 'map_at_3': 0.84632, 'map_at_5': 0.85216, 'map_at_10': 0.85491, 'map_at_20': 0.85572, 'map_at_100': 0.85572, 'map_at_1000': 0.85572, 'recall_at_1': 0.77922, 'recall_at_3': 0.93506, 'recall_at_5': 0.96104, 'recall_at_10': 0.98701, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.77922, 'precision_at_3': 0.31169, 'precision_at_5': 0.19221, 'precision_at_10': 0.0987, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7792207792207793, 'mrr_at_3': 0.8463203463203463, 'mrr_at_5': 0.8521645021645022, 'mrr_at_10': 0.854906204906205, 'mrr_at_20': 0.8557178932178933, 'mrr_at_100': 0.8557178932178933, 'mrr_at_1000': 0.8557178932178933, 'nauc_ndcg_at_1_max': np.float64(0.4139400142694634), 'nauc_ndcg_at_1_std': np.float64(-0.14021417297508898), 'nauc_ndcg_at_1_diff1': np.float64(0.78246273000063), 'nauc_ndcg_at_3_max': np.float64(0.4465068871741506), 'nauc_ndcg_at_3_std': np.float64(-0.13050839506151526), 'nauc_ndcg_at_3_diff1': np.float64(0.8117962912647465), 'nauc_ndcg_at_5_max': np.float64(0.4295215718616793), 'nauc_ndcg_at_5_std': np.float64(-0.17119373043019556), 'nauc_ndcg_at_5_diff1': np.float64(0.7999319493116879), 'nauc_ndcg_at_10_max': np.float64(0.4436533826919126), 'nauc_ndcg_at_10_std': np.float64(-0.18428922374139559), 'nauc_ndcg_at_10_diff1': np.float64(0.8012433401285308), 'nauc_ndcg_at_20_max': np.float64(0.4304110150291181), 'nauc_ndcg_at_20_std': np.float64(-0.1537557702365057), 'nauc_ndcg_at_20_diff1': np.float64(0.7950512425953983), 'nauc_ndcg_at_100_max': np.float64(0.4304110150291181), 'nauc_ndcg_at_100_std': np.float64(-0.1537557702365057), 'nauc_ndcg_at_100_diff1': np.float64(0.7950512425953983), 'nauc_ndcg_at_1000_max': np.float64(0.4304110150291181), 'nauc_ndcg_at_1000_std': np.float64(-0.1537557702365057), 'nauc_ndcg_at_1000_diff1': np.float64(0.7950512425953983), 'nauc_map_at_1_max': np.float64(0.4139400142694634), 'nauc_map_at_1_std': np.float64(-0.14021417297508898), 'nauc_map_at_1_diff1': np.float64(0.78246273000063), 'nauc_map_at_3_max': np.float64(0.4368327376511254), 'nauc_map_at_3_std': np.float64(-0.13197873310791935), 'nauc_map_at_3_diff1': np.float64(0.8005529129446742), 'nauc_map_at_5_max': np.float64(0.42813807841768853), 'nauc_map_at_5_std': np.float64(-0.15147615627835584), 'nauc_map_at_5_diff1': np.float64(0.7945644457362998), 'nauc_map_at_10_max': np.float64(0.4315367969330446), 'nauc_map_at_10_std': np.float64(-0.15509289492565895), 'nauc_map_at_10_diff1': np.float64(0.7946746897029425), 'nauc_map_at_20_max': np.float64(0.42889149307066504), 'nauc_map_at_20_std': np.float64(-0.14898589679329766), 'nauc_map_at_20_diff1': np.float64(0.7934322885790674), 'nauc_map_at_100_max': np.float64(0.42889149307066504), 'nauc_map_at_100_std': np.float64(-0.14898589679329766), 'nauc_map_at_100_diff1': np.float64(0.7934322885790674), 'nauc_map_at_1000_max': np.float64(0.42889149307066504), 'nauc_map_at_1000_std': np.float64(-0.14898589679329766), 'nauc_map_at_1000_diff1': np.float64(0.7934322885790674), 'nauc_recall_at_1_max': np.float64(0.4139400142694634), 'nauc_recall_at_1_std': np.float64(-0.14021417297508898), 'nauc_recall_at_1_diff1': np.float64(0.78246273000063), 'nauc_recall_at_3_max': np.float64(0.5069794576105937), 'nauc_recall_at_3_std': np.float64(-0.12278837016399707), 'nauc_recall_at_3_diff1': np.float64(0.8847118713466364), 'nauc_recall_at_5_max': np.float64(0.4360896258704462), 'nauc_recall_at_5_std': np.float64(-0.3899875213628153), 'nauc_recall_at_5_diff1': np.float64(0.8516155514202973), 'nauc_recall_at_10_max': np.float64(0.868712702472291), 'nauc_recall_at_10_std': np.float64(-1.1643653934883855), 'nauc_recall_at_10_diff1': np.float64(1.0), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.4139400142694634), 'nauc_precision_at_1_std': np.float64(-0.14021417297508898), 'nauc_precision_at_1_diff1': np.float64(0.78246273000063), 'nauc_precision_at_3_max': np.float64(0.5069794576105962), 'nauc_precision_at_3_std': np.float64(-0.12278837016399671), 'nauc_precision_at_3_diff1': np.float64(0.8847118713466388), 'nauc_precision_at_5_max': np.float64(0.43608962587044786), 'nauc_precision_at_5_std': np.float64(-0.3899875213628128), 'nauc_precision_at_5_diff1': np.float64(0.8516155514202957), 'nauc_precision_at_10_max': np.float64(0.868712702472296), 'nauc_precision_at_10_std': np.float64(-1.1643653934883855), 'nauc_precision_at_10_diff1': np.float64(1.0), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.4139400142694634), 'nauc_mrr_at_1_std': np.float64(-0.14021417297508898), 'nauc_mrr_at_1_diff1': np.float64(0.78246273000063), 'nauc_mrr_at_3_max': np.float64(0.4368327376511254), 'nauc_mrr_at_3_std': np.float64(-0.13197873310791935), 'nauc_mrr_at_3_diff1': np.float64(0.8005529129446742), 'nauc_mrr_at_5_max': np.float64(0.42813807841768853), 'nauc_mrr_at_5_std': np.float64(-0.15147615627835584), 'nauc_mrr_at_5_diff1': np.float64(0.7945644457362998), 'nauc_mrr_at_10_max': np.float64(0.4315367969330446), 'nauc_mrr_at_10_std': np.float64(-0.15509289492565895), 'nauc_mrr_at_10_diff1': np.float64(0.7946746897029425), 'nauc_mrr_at_20_max': np.float64(0.42889149307066504), 'nauc_mrr_at_20_std': np.float64(-0.14898589679329766), 'nauc_mrr_at_20_diff1': np.float64(0.7934322885790674), 'nauc_mrr_at_100_max': np.float64(0.42889149307066504), 'nauc_mrr_at_100_std': np.float64(-0.14898589679329766), 'nauc_mrr_at_100_diff1': np.float64(0.7934322885790674), 'nauc_mrr_at_1000_max': np.float64(0.42889149307066504), 'nauc_mrr_at_1000_std': np.float64(-0.14898589679329766), 'nauc_mrr_at_1000_diff1': np.float64(0.7934322885790674), 'main_score': 0.88733}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:   7%|▋         | 1/15 [00:00<00:03,  4.51it/s]Batches:  13%|█▎        | 2/15 [00:01<00:08,  1.59it/s]Batches:  20%|██        | 3/15 [00:01<00:08,  1.36it/s]Batches:  27%|██▋       | 4/15 [00:02<00:08,  1.22it/s]Batches:  33%|███▎      | 5/15 [00:03<00:08,  1.25it/s]Batches:  40%|████      | 6/15 [00:04<00:07,  1.22it/s]Batches:  47%|████▋     | 7/15 [00:05<00:06,  1.18it/s]Batches:  53%|█████▎    | 8/15 [00:06<00:05,  1.21it/s]Batches:  60%|██████    | 9/15 [00:07<00:04,  1.22it/s]Batches:  67%|██████▋   | 10/15 [00:07<00:04,  1.22it/s]Batches:  73%|███████▎  | 11/15 [00:08<00:03,  1.20it/s]Batches:  80%|████████  | 12/15 [00:09<00:02,  1.16it/s]Batches:  87%|████████▋ | 13/15 [00:10<00:01,  1.13it/s]Batches:  93%|█████████▎| 14/15 [00:11<00:00,  1.07it/s]Batches: 100%|██████████| 15/15 [00:12<00:00,  1.14it/s]Batches: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  12%|█▎        | 1/8 [00:01<00:09,  1.40s/it]Batches:  25%|██▌       | 2/8 [00:06<00:22,  3.73s/it]Batches:  38%|███▊      | 3/8 [00:12<00:22,  4.54s/it]Batches:  50%|█████     | 4/8 [00:17<00:19,  4.77s/it]Batches:  62%|██████▎   | 5/8 [00:22<00:14,  4.99s/it]Batches:  75%|███████▌  | 6/8 [00:28<00:10,  5.12s/it]Batches:  88%|████████▊ | 7/8 [00:33<00:05,  5.16s/it]Batches: 100%|██████████| 8/8 [00:37<00:00,  4.97s/it]Batches: 100%|██████████| 8/8 [00:37<00:00,  4.74s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 52.92 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:   7%|▋         | 1/15 [00:00<00:02,  6.41it/s]Batches:  13%|█▎        | 2/15 [00:00<00:04,  2.80it/s]Batches:  20%|██        | 3/15 [00:01<00:05,  2.27it/s]Batches:  27%|██▋       | 4/15 [00:01<00:04,  2.20it/s]Batches:  33%|███▎      | 5/15 [00:02<00:04,  2.17it/s]Batches:  40%|████      | 6/15 [00:02<00:04,  2.13it/s]Batches:  47%|████▋     | 7/15 [00:03<00:03,  2.14it/s]Batches:  53%|█████▎    | 8/15 [00:03<00:03,  2.10it/s]Batches:  60%|██████    | 9/15 [00:04<00:02,  2.09it/s]Batches:  67%|██████▋   | 10/15 [00:04<00:02,  2.09it/s]Batches:  73%|███████▎  | 11/15 [00:05<00:01,  2.09it/s]Batches:  80%|████████  | 12/15 [00:05<00:01,  2.10it/s]Batches:  87%|████████▋ | 13/15 [00:06<00:00,  2.03it/s]Batches:  93%|█████████▎| 14/15 [00:06<00:00,  2.04it/s]Batches: 100%|██████████| 15/15 [00:06<00:00,  2.21it/s]Batches: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  12%|█▎        | 1/8 [00:01<00:09,  1.40s/it]Batches:  25%|██▌       | 2/8 [00:06<00:22,  3.74s/it]Batches:  38%|███▊      | 3/8 [00:12<00:22,  4.55s/it]Batches:  50%|█████     | 4/8 [00:17<00:19,  4.78s/it]Batches:  62%|██████▎   | 5/8 [00:22<00:14,  4.99s/it]Batches:  75%|███████▌  | 6/8 [00:28<00:10,  5.13s/it]Batches:  88%|████████▊ | 7/8 [00:33<00:05,  5.17s/it]Batches: 100%|██████████| 8/8 [00:37<00:00,  4.97s/it]Batches: 100%|██████████| 8/8 [00:37<00:00,  4.75s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 47.48 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:   7%|▋         | 1/15 [00:00<00:03,  4.51it/s]Batches:  13%|█▎        | 2/15 [00:01<00:08,  1.58it/s]Batches:  20%|██        | 3/15 [00:02<00:08,  1.36it/s]Batches:  27%|██▋       | 4/15 [00:02<00:09,  1.22it/s]Batches:  33%|███▎      | 5/15 [00:03<00:08,  1.24it/s]Batches:  40%|████      | 6/15 [00:04<00:07,  1.21it/s]Batches:  47%|████▋     | 7/15 [00:05<00:06,  1.18it/s]Batches:  53%|█████▎    | 8/15 [00:06<00:05,  1.21it/s]Batches:  60%|██████    | 9/15 [00:07<00:04,  1.21it/s]Batches:  67%|██████▋   | 10/15 [00:07<00:04,  1.21it/s]Batches:  73%|███████▎  | 11/15 [00:08<00:03,  1.20it/s]Batches:  80%|████████  | 12/15 [00:09<00:02,  1.16it/s]Batches:  87%|████████▋ | 13/15 [00:10<00:01,  1.13it/s]Batches:  93%|█████████▎| 14/15 [00:11<00:00,  1.07it/s]Batches: 100%|██████████| 15/15 [00:12<00:00,  1.14it/s]Batches: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  12%|█▎        | 1/8 [00:00<00:04,  1.70it/s]Batches:  25%|██▌       | 2/8 [00:02<00:09,  1.56s/it]Batches:  38%|███▊      | 3/8 [00:05<00:10,  2.05s/it]Batches:  50%|█████     | 4/8 [00:08<00:09,  2.41s/it]Batches:  62%|██████▎   | 5/8 [00:10<00:07,  2.37s/it]Batches:  75%|███████▌  | 6/8 [00:13<00:04,  2.39s/it]Batches:  88%|████████▊ | 7/8 [00:15<00:02,  2.32s/it]Batches: 100%|██████████| 8/8 [00:17<00:00,  2.26s/it]Batches: 100%|██████████| 8/8 [00:17<00:00,  2.18s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.41 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 133.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.87, 'ndcg_at_3': 0.91213, 'ndcg_at_5': 0.91901, 'ndcg_at_10': 0.92401, 'ndcg_at_20': 0.92714, 'ndcg_at_100': 0.92917, 'ndcg_at_1000': 0.92977, 'map_at_1': 0.87, 'map_at_3': 0.90241, 'map_at_5': 0.90624, 'map_at_10': 0.90828, 'map_at_20': 0.90916, 'map_at_100': 0.90943, 'map_at_1000': 0.90945, 'recall_at_1': 0.87, 'recall_at_3': 0.94, 'recall_at_5': 0.95667, 'recall_at_10': 0.97222, 'recall_at_20': 0.98444, 'recall_at_100': 0.99556, 'recall_at_1000': 1.0, 'precision_at_1': 0.87, 'precision_at_3': 0.31333, 'precision_at_5': 0.19133, 'precision_at_10': 0.09722, 'precision_at_20': 0.04922, 'precision_at_100': 0.00996, 'precision_at_1000': 0.001, 'mrr_at_1': 0.87, 'mrr_at_3': 0.9024074074074075, 'mrr_at_5': 0.9062407407407409, 'mrr_at_10': 0.9082830687830689, 'mrr_at_20': 0.9091617023804848, 'mrr_at_100': 0.9094274067491804, 'mrr_at_1000': 0.9094540876757962, 'nauc_ndcg_at_1_max': np.float64(0.7576958206818232), 'nauc_ndcg_at_1_std': np.float64(-0.1504110197733845), 'nauc_ndcg_at_1_diff1': np.float64(0.9120154368987957), 'nauc_ndcg_at_3_max': np.float64(0.7633185143220046), 'nauc_ndcg_at_3_std': np.float64(-0.1918571927274191), 'nauc_ndcg_at_3_diff1': np.float64(0.9013487734702595), 'nauc_ndcg_at_5_max': np.float64(0.7665885728237049), 'nauc_ndcg_at_5_std': np.float64(-0.19472790384402736), 'nauc_ndcg_at_5_diff1': np.float64(0.9092867089203742), 'nauc_ndcg_at_10_max': np.float64(0.7694325036676215), 'nauc_ndcg_at_10_std': np.float64(-0.16391688440773586), 'nauc_ndcg_at_10_diff1': np.float64(0.9084989140218339), 'nauc_ndcg_at_20_max': np.float64(0.7723812863928085), 'nauc_ndcg_at_20_std': np.float64(-0.15538800093057173), 'nauc_ndcg_at_20_diff1': np.float64(0.9102626993934786), 'nauc_ndcg_at_100_max': np.float64(0.7704521510072088), 'nauc_ndcg_at_100_std': np.float64(-0.160863017816179), 'nauc_ndcg_at_100_diff1': np.float64(0.9094916840763209), 'nauc_ndcg_at_1000_max': np.float64(0.7684631591942682), 'nauc_ndcg_at_1000_std': np.float64(-0.16342949946774943), 'nauc_ndcg_at_1000_diff1': np.float64(0.9090086214137436), 'nauc_map_at_1_max': np.float64(0.7576958206818232), 'nauc_map_at_1_std': np.float64(-0.1504110197733845), 'nauc_map_at_1_diff1': np.float64(0.9120154368987957), 'nauc_map_at_3_max': np.float64(0.763024859106417), 'nauc_map_at_3_std': np.float64(-0.1770295998568004), 'nauc_map_at_3_diff1': np.float64(0.9045838102108751), 'nauc_map_at_5_max': np.float64(0.7647866209411698), 'nauc_map_at_5_std': np.float64(-0.17732191665098596), 'nauc_map_at_5_diff1': np.float64(0.9085555990659762), 'nauc_map_at_10_max': np.float64(0.7657808134048363), 'nauc_map_at_10_std': np.float64(-0.166081528209262), 'nauc_map_at_10_diff1': np.float64(0.9083723868257834), 'nauc_map_at_20_max': np.float64(0.7664501056309141), 'nauc_map_at_20_std': np.float64(-0.16437912983948938), 'nauc_map_at_20_diff1': np.float64(0.9088643482984291), 'nauc_map_at_100_max': np.float64(0.7662342037196137), 'nauc_map_at_100_std': np.float64(-0.16481851543163192), 'nauc_map_at_100_diff1': np.float64(0.9087357976649129), 'nauc_map_at_1000_max': np.float64(0.7661637958735574), 'nauc_map_at_1000_std': np.float64(-0.1648525640015763), 'nauc_map_at_1000_diff1': np.float64(0.9087211191249609), 'nauc_recall_at_1_max': np.float64(0.7576958206818232), 'nauc_recall_at_1_std': np.float64(-0.1504110197733845), 'nauc_recall_at_1_diff1': np.float64(0.9120154368987957), 'nauc_recall_at_3_max': np.float64(0.7636857212020612), 'nauc_recall_at_3_std': np.float64(-0.2611439637583427), 'nauc_recall_at_3_diff1': np.float64(0.8865719127157022), 'nauc_recall_at_5_max': np.float64(0.7766286001580116), 'nauc_recall_at_5_std': np.float64(-0.3046996576408323), 'nauc_recall_at_5_diff1': np.float64(0.9160860925566815), 'nauc_recall_at_10_max': np.float64(0.8047619047619022), 'nauc_recall_at_10_std': np.float64(-0.1159103641456544), 'nauc_recall_at_10_diff1': np.float64(0.9115779645191382), 'nauc_recall_at_20_max': np.float64(0.8837868480725666), 'nauc_recall_at_20_std': np.float64(0.08346672002134754), 'nauc_recall_at_20_diff1': np.float64(0.9416433239962608), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.18557422969189222), 'nauc_recall_at_100_diff1': np.float64(0.9673202614379001), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7576958206818232), 'nauc_precision_at_1_std': np.float64(-0.1504110197733845), 'nauc_precision_at_1_diff1': np.float64(0.9120154368987957), 'nauc_precision_at_3_max': np.float64(0.763685721202064), 'nauc_precision_at_3_std': np.float64(-0.2611439637583455), 'nauc_precision_at_3_diff1': np.float64(0.8865719127157048), 'nauc_precision_at_5_max': np.float64(0.776628600158008), 'nauc_precision_at_5_std': np.float64(-0.30469965764083523), 'nauc_precision_at_5_diff1': np.float64(0.9160860925566805), 'nauc_precision_at_10_max': np.float64(0.8047619047619075), 'nauc_precision_at_10_std': np.float64(-0.11591036414566304), 'nauc_precision_at_10_diff1': np.float64(0.9115779645191425), 'nauc_precision_at_20_max': np.float64(0.8837868480725527), 'nauc_precision_at_20_std': np.float64(0.08346672002133163), 'nauc_precision_at_20_diff1': np.float64(0.9416433239962602), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.18557422969188173), 'nauc_precision_at_100_diff1': np.float64(0.9673202614378776), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7576958206818232), 'nauc_mrr_at_1_std': np.float64(-0.1504110197733845), 'nauc_mrr_at_1_diff1': np.float64(0.9120154368987957), 'nauc_mrr_at_3_max': np.float64(0.763024859106417), 'nauc_mrr_at_3_std': np.float64(-0.1770295998568004), 'nauc_mrr_at_3_diff1': np.float64(0.9045838102108751), 'nauc_mrr_at_5_max': np.float64(0.7647866209411698), 'nauc_mrr_at_5_std': np.float64(-0.17732191665098596), 'nauc_mrr_at_5_diff1': np.float64(0.9085555990659762), 'nauc_mrr_at_10_max': np.float64(0.7657808134048363), 'nauc_mrr_at_10_std': np.float64(-0.166081528209262), 'nauc_mrr_at_10_diff1': np.float64(0.9083723868257834), 'nauc_mrr_at_20_max': np.float64(0.7664501056309141), 'nauc_mrr_at_20_std': np.float64(-0.16437912983948938), 'nauc_mrr_at_20_diff1': np.float64(0.9088643482984291), 'nauc_mrr_at_100_max': np.float64(0.7662342037196137), 'nauc_mrr_at_100_std': np.float64(-0.16481851543163192), 'nauc_mrr_at_100_diff1': np.float64(0.9087357976649129), 'nauc_mrr_at_1000_max': np.float64(0.7661637958735574), 'nauc_mrr_at_1000_std': np.float64(-0.1648525640015763), 'nauc_mrr_at_1000_diff1': np.float64(0.9087211191249609), 'main_score': 0.92401}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.86556, 'ndcg_at_3': 0.91245, 'ndcg_at_5': 0.91976, 'ndcg_at_10': 0.92483, 'ndcg_at_20': 0.92773, 'ndcg_at_100': 0.92956, 'ndcg_at_1000': 0.92984, 'map_at_1': 0.86556, 'map_at_3': 0.90167, 'map_at_5': 0.90572, 'map_at_10': 0.90783, 'map_at_20': 0.90868, 'map_at_100': 0.90891, 'map_at_1000': 0.90892, 'recall_at_1': 0.86556, 'recall_at_3': 0.94333, 'recall_at_5': 0.96111, 'recall_at_10': 0.97667, 'recall_at_20': 0.98778, 'recall_at_100': 0.99778, 'recall_at_1000': 1.0, 'precision_at_1': 0.86556, 'precision_at_3': 0.31444, 'precision_at_5': 0.19222, 'precision_at_10': 0.09767, 'precision_at_20': 0.04939, 'precision_at_100': 0.00998, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8655555555555555, 'mrr_at_3': 0.9016666666666668, 'mrr_at_5': 0.9057222222222224, 'mrr_at_10': 0.9078293650793653, 'mrr_at_20': 0.9086785518403167, 'mrr_at_100': 0.9089148046669823, 'mrr_at_1000': 0.9089248259846959, 'nauc_ndcg_at_1_max': np.float64(0.6266975912367964), 'nauc_ndcg_at_1_std': np.float64(-0.3639052782013713), 'nauc_ndcg_at_1_diff1': np.float64(0.8942004455054253), 'nauc_ndcg_at_3_max': np.float64(0.6970050368317691), 'nauc_ndcg_at_3_std': np.float64(-0.2711580447806635), 'nauc_ndcg_at_3_diff1': np.float64(0.8933950544996908), 'nauc_ndcg_at_5_max': np.float64(0.6876593267266466), 'nauc_ndcg_at_5_std': np.float64(-0.28664735777263556), 'nauc_ndcg_at_5_diff1': np.float64(0.8912467426056183), 'nauc_ndcg_at_10_max': np.float64(0.6757781989269076), 'nauc_ndcg_at_10_std': np.float64(-0.29776916499596634), 'nauc_ndcg_at_10_diff1': np.float64(0.8881725537365418), 'nauc_ndcg_at_20_max': np.float64(0.670550841767049), 'nauc_ndcg_at_20_std': np.float64(-0.3099312789253565), 'nauc_ndcg_at_20_diff1': np.float64(0.889443704373209), 'nauc_ndcg_at_100_max': np.float64(0.6693968945666423), 'nauc_ndcg_at_100_std': np.float64(-0.30406076611436983), 'nauc_ndcg_at_100_diff1': np.float64(0.8905743385809914), 'nauc_ndcg_at_1000_max': np.float64(0.6680317387291397), 'nauc_ndcg_at_1000_std': np.float64(-0.3089095356446938), 'nauc_ndcg_at_1000_diff1': np.float64(0.8903747587427282), 'nauc_map_at_1_max': np.float64(0.6266975912367964), 'nauc_map_at_1_std': np.float64(-0.3639052782013713), 'nauc_map_at_1_diff1': np.float64(0.8942004455054253), 'nauc_map_at_3_max': np.float64(0.6738326485879481), 'nauc_map_at_3_std': np.float64(-0.3032972154887417), 'nauc_map_at_3_diff1': np.float64(0.8925822549268371), 'nauc_map_at_5_max': np.float64(0.6684705992434418), 'nauc_map_at_5_std': np.float64(-0.3110940068516004), 'nauc_map_at_5_diff1': np.float64(0.8914108120590107), 'nauc_map_at_10_max': np.float64(0.6641504162230696), 'nauc_map_at_10_std': np.float64(-0.31476180298395123), 'nauc_map_at_10_diff1': np.float64(0.8902912979808356), 'nauc_map_at_20_max': np.float64(0.6628294016804293), 'nauc_map_at_20_std': np.float64(-0.31777391869714944), 'nauc_map_at_20_diff1': np.float64(0.8906500361351591), 'nauc_map_at_100_max': np.float64(0.6626664950965993), 'nauc_map_at_100_std': np.float64(-0.31707504566125083), 'nauc_map_at_100_diff1': np.float64(0.8907906241678464), 'nauc_map_at_1000_max': np.float64(0.6626284363521765), 'nauc_map_at_1000_std': np.float64(-0.31721336074438417), 'nauc_map_at_1000_diff1': np.float64(0.8907831407317943), 'nauc_recall_at_1_max': np.float64(0.6266975912367964), 'nauc_recall_at_1_std': np.float64(-0.3639052782013713), 'nauc_recall_at_1_diff1': np.float64(0.8942004455054253), 'nauc_recall_at_3_max': np.float64(0.8105582102121894), 'nauc_recall_at_3_std': np.float64(-0.11257574925395204), 'nauc_recall_at_3_diff1': np.float64(0.8981252631771675), 'nauc_recall_at_5_max': np.float64(0.8157663065226111), 'nauc_recall_at_5_std': np.float64(-0.1254635187408309), 'nauc_recall_at_5_diff1': np.float64(0.8909030278778138), 'nauc_recall_at_10_max': np.float64(0.7828687030367684), 'nauc_recall_at_10_std': np.float64(-0.1394113200835888), 'nauc_recall_at_10_diff1': np.float64(0.8625227868925333), 'nauc_recall_at_20_max': np.float64(0.764748323571863), 'nauc_recall_at_20_std': np.float64(-0.26215940921823416), 'nauc_recall_at_20_diff1': np.float64(0.8648247177658958), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.8611111111111373), 'nauc_recall_at_100_diff1': np.float64(0.934640522875857), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6266975912367964), 'nauc_precision_at_1_std': np.float64(-0.3639052782013713), 'nauc_precision_at_1_diff1': np.float64(0.8942004455054253), 'nauc_precision_at_3_max': np.float64(0.8105582102121879), 'nauc_precision_at_3_std': np.float64(-0.11257574925395346), 'nauc_precision_at_3_diff1': np.float64(0.8981252631771672), 'nauc_precision_at_5_max': np.float64(0.8157663065226051), 'nauc_precision_at_5_std': np.float64(-0.12546351874082617), 'nauc_precision_at_5_diff1': np.float64(0.8909030278778126), 'nauc_precision_at_10_max': np.float64(0.7828687030367641), 'nauc_precision_at_10_std': np.float64(-0.13941132008360238), 'nauc_precision_at_10_diff1': np.float64(0.862522786892528), 'nauc_precision_at_20_max': np.float64(0.7647483235718557), 'nauc_precision_at_20_std': np.float64(-0.26215940921825764), 'nauc_precision_at_20_diff1': np.float64(0.8648247177658893), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.8611111111111238), 'nauc_precision_at_100_diff1': np.float64(0.9346405228757582), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6266975912367964), 'nauc_mrr_at_1_std': np.float64(-0.3639052782013713), 'nauc_mrr_at_1_diff1': np.float64(0.8942004455054253), 'nauc_mrr_at_3_max': np.float64(0.6738326485879481), 'nauc_mrr_at_3_std': np.float64(-0.3032972154887417), 'nauc_mrr_at_3_diff1': np.float64(0.8925822549268371), 'nauc_mrr_at_5_max': np.float64(0.6684705992434418), 'nauc_mrr_at_5_std': np.float64(-0.3110940068516004), 'nauc_mrr_at_5_diff1': np.float64(0.8914108120590107), 'nauc_mrr_at_10_max': np.float64(0.6641504162230696), 'nauc_mrr_at_10_std': np.float64(-0.31476180298395123), 'nauc_mrr_at_10_diff1': np.float64(0.8902912979808356), 'nauc_mrr_at_20_max': np.float64(0.6628294016804293), 'nauc_mrr_at_20_std': np.float64(-0.31777391869714944), 'nauc_mrr_at_20_diff1': np.float64(0.8906500361351591), 'nauc_mrr_at_100_max': np.float64(0.6626664950965993), 'nauc_mrr_at_100_std': np.float64(-0.31707504566125083), 'nauc_mrr_at_100_diff1': np.float64(0.8907906241678464), 'nauc_mrr_at_1000_max': np.float64(0.6626284363521765), 'nauc_mrr_at_1000_std': np.float64(-0.31721336074438417), 'nauc_mrr_at_1000_diff1': np.float64(0.8907831407317943), 'main_score': 0.92483}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.74333, 'ndcg_at_3': 0.81915, 'ndcg_at_5': 0.83086, 'ndcg_at_10': 0.84232, 'ndcg_at_20': 0.84832, 'ndcg_at_100': 0.85458, 'ndcg_at_1000': 0.85573, 'map_at_1': 0.74333, 'map_at_3': 0.80111, 'map_at_5': 0.8075, 'map_at_10': 0.81242, 'map_at_20': 0.81411, 'map_at_100': 0.81501, 'map_at_1000': 0.81505, 'recall_at_1': 0.74333, 'recall_at_3': 0.87111, 'recall_at_5': 0.9, 'recall_at_10': 0.93444, 'recall_at_20': 0.95778, 'recall_at_100': 0.99111, 'recall_at_1000': 1.0, 'precision_at_1': 0.74333, 'precision_at_3': 0.29037, 'precision_at_5': 0.18, 'precision_at_10': 0.09344, 'precision_at_20': 0.04789, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7433333333333333, 'mrr_at_3': 0.8011111111111111, 'mrr_at_5': 0.8074999999999999, 'mrr_at_10': 0.8124166666666669, 'mrr_at_20': 0.8141131871033833, 'mrr_at_100': 0.8150089527173032, 'mrr_at_1000': 0.8150510405209199, 'nauc_ndcg_at_1_max': np.float64(0.7824143952173789), 'nauc_ndcg_at_1_std': np.float64(0.20291765412958715), 'nauc_ndcg_at_1_diff1': np.float64(0.7728414117475649), 'nauc_ndcg_at_3_max': np.float64(0.790041513571183), 'nauc_ndcg_at_3_std': np.float64(0.22162252846875843), 'nauc_ndcg_at_3_diff1': np.float64(0.7323076351270531), 'nauc_ndcg_at_5_max': np.float64(0.7894674352242129), 'nauc_ndcg_at_5_std': np.float64(0.23197738125909093), 'nauc_ndcg_at_5_diff1': np.float64(0.7346534345848433), 'nauc_ndcg_at_10_max': np.float64(0.7885551001577478), 'nauc_ndcg_at_10_std': np.float64(0.23925341582305582), 'nauc_ndcg_at_10_diff1': np.float64(0.7401224795143246), 'nauc_ndcg_at_20_max': np.float64(0.786989571378506), 'nauc_ndcg_at_20_std': np.float64(0.24971235211534967), 'nauc_ndcg_at_20_diff1': np.float64(0.7392675661337992), 'nauc_ndcg_at_100_max': np.float64(0.7872625054780676), 'nauc_ndcg_at_100_std': np.float64(0.24167542529596883), 'nauc_ndcg_at_100_diff1': np.float64(0.7430328736714062), 'nauc_ndcg_at_1000_max': np.float64(0.7874335980370746), 'nauc_ndcg_at_1000_std': np.float64(0.2357335760255637), 'nauc_ndcg_at_1000_diff1': np.float64(0.7436085167742466), 'nauc_map_at_1_max': np.float64(0.7824143952173789), 'nauc_map_at_1_std': np.float64(0.20291765412958715), 'nauc_map_at_1_diff1': np.float64(0.7728414117475649), 'nauc_map_at_3_max': np.float64(0.7883167767821174), 'nauc_map_at_3_std': np.float64(0.21816460298279464), 'nauc_map_at_3_diff1': np.float64(0.7431154659540903), 'nauc_map_at_5_max': np.float64(0.7882987156582553), 'nauc_map_at_5_std': np.float64(0.22307140257260838), 'nauc_map_at_5_diff1': np.float64(0.7447128209505363), 'nauc_map_at_10_max': np.float64(0.7878434225511316), 'nauc_map_at_10_std': np.float64(0.2262877269367202), 'nauc_map_at_10_diff1': np.float64(0.7470236033199076), 'nauc_map_at_20_max': np.float64(0.7874927418891358), 'nauc_map_at_20_std': np.float64(0.22883274656257493), 'nauc_map_at_20_diff1': np.float64(0.7468797363436885), 'nauc_map_at_100_max': np.float64(0.7874607828790072), 'nauc_map_at_100_std': np.float64(0.2277580918203967), 'nauc_map_at_100_diff1': np.float64(0.7473088691309715), 'nauc_map_at_1000_max': np.float64(0.7874584111482307), 'nauc_map_at_1000_std': np.float64(0.22758742153743658), 'nauc_map_at_1000_diff1': np.float64(0.7473146961942588), 'nauc_recall_at_1_max': np.float64(0.7824143952173789), 'nauc_recall_at_1_std': np.float64(0.20291765412958715), 'nauc_recall_at_1_diff1': np.float64(0.7728414117475649), 'nauc_recall_at_3_max': np.float64(0.7969252711532728), 'nauc_recall_at_3_std': np.float64(0.23480463696971768), 'nauc_recall_at_3_diff1': np.float64(0.6878544893694643), 'nauc_recall_at_5_max': np.float64(0.7941280215790028), 'nauc_recall_at_5_std': np.float64(0.27834837638759324), 'nauc_recall_at_5_diff1': np.float64(0.6849258221807234), 'nauc_recall_at_10_max': np.float64(0.7916726012438876), 'nauc_recall_at_10_std': np.float64(0.34007501305606896), 'nauc_recall_at_10_diff1': np.float64(0.6949706436246803), 'nauc_recall_at_20_max': np.float64(0.7726792471374523), 'nauc_recall_at_20_std': np.float64(0.5227775320654581), 'nauc_recall_at_20_diff1': np.float64(0.6595041525382099), 'nauc_recall_at_100_max': np.float64(0.7610877684407182), 'nauc_recall_at_100_std': np.float64(0.9305555555555559), 'nauc_recall_at_100_diff1': np.float64(0.6659663865546264), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7824143952173789), 'nauc_precision_at_1_std': np.float64(0.20291765412958715), 'nauc_precision_at_1_diff1': np.float64(0.7728414117475649), 'nauc_precision_at_3_max': np.float64(0.7969252711532735), 'nauc_precision_at_3_std': np.float64(0.23480463696971818), 'nauc_precision_at_3_diff1': np.float64(0.6878544893694668), 'nauc_precision_at_5_max': np.float64(0.7941280215790011), 'nauc_precision_at_5_std': np.float64(0.2783483763875909), 'nauc_precision_at_5_diff1': np.float64(0.6849258221807228), 'nauc_precision_at_10_max': np.float64(0.7916726012438878), 'nauc_precision_at_10_std': np.float64(0.3400750130560682), 'nauc_precision_at_10_diff1': np.float64(0.6949706436246802), 'nauc_precision_at_20_max': np.float64(0.7726792471374495), 'nauc_precision_at_20_std': np.float64(0.5227775320654573), 'nauc_precision_at_20_diff1': np.float64(0.6595041525382113), 'nauc_precision_at_100_max': np.float64(0.7610877684407207), 'nauc_precision_at_100_std': np.float64(0.9305555555555604), 'nauc_precision_at_100_diff1': np.float64(0.6659663865546206), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7824143952173789), 'nauc_mrr_at_1_std': np.float64(0.20291765412958715), 'nauc_mrr_at_1_diff1': np.float64(0.7728414117475649), 'nauc_mrr_at_3_max': np.float64(0.7883167767821174), 'nauc_mrr_at_3_std': np.float64(0.21816460298279464), 'nauc_mrr_at_3_diff1': np.float64(0.7431154659540903), 'nauc_mrr_at_5_max': np.float64(0.7882987156582553), 'nauc_mrr_at_5_std': np.float64(0.22307140257260838), 'nauc_mrr_at_5_diff1': np.float64(0.7447128209505363), 'nauc_mrr_at_10_max': np.float64(0.7878434225511316), 'nauc_mrr_at_10_std': np.float64(0.2262877269367202), 'nauc_mrr_at_10_diff1': np.float64(0.7470236033199076), 'nauc_mrr_at_20_max': np.float64(0.7874927418891358), 'nauc_mrr_at_20_std': np.float64(0.22883274656257493), 'nauc_mrr_at_20_diff1': np.float64(0.7468797363436885), 'nauc_mrr_at_100_max': np.float64(0.7874607828790072), 'nauc_mrr_at_100_std': np.float64(0.2277580918203967), 'nauc_mrr_at_100_diff1': np.float64(0.7473088691309715), 'nauc_mrr_at_1000_max': np.float64(0.7874584111482307), 'nauc_mrr_at_1000_std': np.float64(0.22758742153743658), 'nauc_mrr_at_1000_diff1': np.float64(0.7473146961942588), 'main_score': 0.84232}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:   9%|▉         | 1/11 [00:00<00:03,  2.72it/s]Batches:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s]Batches:  27%|██▋       | 3/11 [00:02<00:08,  1.06s/it]Batches:  36%|███▋      | 4/11 [00:03<00:07,  1.04s/it]Batches:  45%|████▌     | 5/11 [00:04<00:06,  1.04s/it]Batches:  55%|█████▍    | 6/11 [00:06<00:06,  1.22s/it]Batches:  64%|██████▎   | 7/11 [00:07<00:04,  1.22s/it]Batches:  73%|███████▎  | 8/11 [00:08<00:03,  1.14s/it]Batches:  82%|████████▏ | 9/11 [00:10<00:02,  1.30s/it]Batches:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it]Batches: 100%|██████████| 11/11 [00:12<00:00,  1.29s/it]Batches: 100%|██████████| 11/11 [00:12<00:00,  1.17s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:   7%|▋         | 1/14 [00:00<00:04,  3.18it/s]Batches:  14%|█▍        | 2/14 [00:01<00:09,  1.30it/s]Batches:  21%|██▏       | 3/14 [00:02<00:10,  1.03it/s]Batches:  29%|██▊       | 4/14 [00:03<00:10,  1.06s/it]Batches:  36%|███▌      | 5/14 [00:05<00:10,  1.13s/it]Batches:  43%|████▎     | 6/14 [00:06<00:09,  1.15s/it]Batches:  50%|█████     | 7/14 [00:07<00:09,  1.31s/it]Batches:  57%|█████▋    | 8/14 [00:08<00:07,  1.19s/it]Batches:  64%|██████▍   | 9/14 [00:09<00:05,  1.12s/it]Batches:  71%|███████▏  | 10/14 [00:10<00:04,  1.09s/it]Batches:  79%|███████▊  | 11/14 [00:12<00:03,  1.19s/it]Batches:  86%|████████▌ | 12/14 [00:13<00:02,  1.12s/it]Batches:  93%|█████████▎| 13/14 [00:14<00:01,  1.29s/it]Batches: 100%|██████████| 14/14 [00:16<00:00,  1.36s/it]Batches: 100%|██████████| 14/14 [00:16<00:00,  1.17s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 30.37 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:   9%|▉         | 1/11 [00:00<00:03,  2.71it/s]Batches:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s]Batches:  27%|██▋       | 3/11 [00:02<00:08,  1.07s/it]Batches:  36%|███▋      | 4/11 [00:03<00:07,  1.05s/it]Batches:  45%|████▌     | 5/11 [00:04<00:06,  1.05s/it]Batches:  55%|█████▍    | 6/11 [00:06<00:06,  1.23s/it]Batches:  64%|██████▎   | 7/11 [00:07<00:04,  1.22s/it]Batches:  73%|███████▎  | 8/11 [00:08<00:03,  1.14s/it]Batches:  82%|████████▏ | 9/11 [00:10<00:02,  1.31s/it]Batches:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it]Batches: 100%|██████████| 11/11 [00:12<00:00,  1.30s/it]Batches: 100%|██████████| 11/11 [00:12<00:00,  1.18s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:08,  2.06it/s]Batches:  11%|█         | 2/19 [00:02<00:25,  1.50s/it]Batches:  16%|█▌        | 3/19 [00:05<00:31,  1.98s/it]Batches:  21%|██        | 4/19 [00:07<00:34,  2.28s/it]Batches:  26%|██▋       | 5/19 [00:11<00:37,  2.69s/it]Batches:  32%|███▏      | 6/19 [00:12<00:28,  2.16s/it]Batches:  37%|███▋      | 7/19 [00:14<00:24,  2.01s/it]Batches:  42%|████▏     | 8/19 [00:15<00:19,  1.76s/it]Batches:  47%|████▋     | 9/19 [00:16<00:16,  1.64s/it]Batches:  53%|█████▎    | 10/19 [00:18<00:13,  1.53s/it]Batches:  58%|█████▊    | 11/19 [00:19<00:12,  1.59s/it]Batches:  63%|██████▎   | 12/19 [00:22<00:14,  2.06s/it]Batches:  68%|██████▊   | 13/19 [00:27<00:16,  2.75s/it]Batches:  74%|███████▎  | 14/19 [00:29<00:12,  2.48s/it]Batches:  79%|███████▉  | 15/19 [00:31<00:09,  2.44s/it]Batches:  84%|████████▍ | 16/19 [00:32<00:06,  2.04s/it]Batches:  89%|████████▉ | 17/19 [00:33<00:03,  1.79s/it]Batches:  95%|█████████▍| 18/19 [00:36<00:01,  1.99s/it]Batches: 100%|██████████| 19/19 [00:38<00:00,  2.09s/it]Batches: 100%|██████████| 19/19 [00:38<00:00,  2.03s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 52.59 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  10%|█         | 1/10 [00:00<00:01,  5.72it/s]Batches:  20%|██        | 2/10 [00:00<00:03,  2.31it/s]Batches:  30%|███       | 3/10 [00:01<00:03,  1.76it/s]Batches:  40%|████      | 4/10 [00:02<00:03,  1.53it/s]Batches:  50%|█████     | 5/10 [00:02<00:03,  1.56it/s]Batches:  60%|██████    | 6/10 [00:03<00:02,  1.40it/s]Batches:  70%|███████   | 7/10 [00:04<00:02,  1.25it/s]Batches:  80%|████████  | 8/10 [00:05<00:01,  1.13it/s]Batches:  90%|█████████ | 9/10 [00:06<00:00,  1.16it/s]Batches: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]Batches: 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'XPQARetrieval'
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:   7%|▋         | 1/14 [00:00<00:04,  3.16it/s]Batches:  14%|█▍        | 2/14 [00:01<00:09,  1.30it/s]Batches:  21%|██▏       | 3/14 [00:02<00:10,  1.03it/s]Batches:  29%|██▊       | 4/14 [00:03<00:10,  1.07s/it]Batches:  36%|███▌      | 5/14 [00:05<00:10,  1.14s/it]Batches:  43%|████▎     | 6/14 [00:06<00:09,  1.15s/it]Batches:  50%|█████     | 7/14 [00:07<00:09,  1.31s/it]Batches:  57%|█████▋    | 8/14 [00:08<00:07,  1.19s/it]Batches:  64%|██████▍   | 9/14 [00:09<00:05,  1.13s/it]Batches:  71%|███████▏  | 10/14 [00:10<00:04,  1.09s/it]Batches:  79%|███████▊  | 11/14 [00:12<00:03,  1.20s/it]Batches:  86%|████████▌ | 12/14 [00:13<00:02,  1.13s/it]Batches:  93%|█████████▎| 13/14 [00:14<00:01,  1.29s/it]Batches: 100%|██████████| 14/14 [00:16<00:00,  1.36s/it]Batches: 100%|██████████| 14/14 [00:16<00:00,  1.17s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 24.74 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 109.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.30428, 'ndcg_at_3': 0.32681, 'ndcg_at_5': 0.35888, 'ndcg_at_10': 0.39132, 'ndcg_at_20': 0.41539, 'ndcg_at_100': 0.46272, 'ndcg_at_1000': 0.48656, 'map_at_1': 0.21735, 'map_at_3': 0.29862, 'map_at_5': 0.32435, 'map_at_10': 0.33931, 'map_at_20': 0.34711, 'map_at_100': 0.35451, 'map_at_1000': 0.35552, 'recall_at_1': 0.21735, 'recall_at_3': 0.34207, 'recall_at_5': 0.41835, 'recall_at_10': 0.50917, 'recall_at_20': 0.59286, 'recall_at_100': 0.82378, 'recall_at_1000': 1.0, 'precision_at_1': 0.30428, 'precision_at_3': 0.18145, 'precision_at_5': 0.13517, 'precision_at_10': 0.08135, 'precision_at_20': 0.04771, 'precision_at_100': 0.01321, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.30428134556574926, 'mrr_at_3': 0.34964322120285424, 'mrr_at_5': 0.3652395514780835, 'mrr_at_10': 0.37764368234551704, 'mrr_at_20': 0.3830260669795419, 'mrr_at_100': 0.38832410102685366, 'mrr_at_1000': 0.3889598856268576, 'nauc_ndcg_at_1_max': np.float64(0.11249725870947681), 'nauc_ndcg_at_1_std': np.float64(-0.3728799569971848), 'nauc_ndcg_at_1_diff1': np.float64(0.4467339947356412), 'nauc_ndcg_at_3_max': np.float64(0.09547977173950917), 'nauc_ndcg_at_3_std': np.float64(-0.38379916914378265), 'nauc_ndcg_at_3_diff1': np.float64(0.3946747072940416), 'nauc_ndcg_at_5_max': np.float64(0.10546612152309434), 'nauc_ndcg_at_5_std': np.float64(-0.39299243796593114), 'nauc_ndcg_at_5_diff1': np.float64(0.39057382894111503), 'nauc_ndcg_at_10_max': np.float64(0.106588463861301), 'nauc_ndcg_at_10_std': np.float64(-0.38665602187072373), 'nauc_ndcg_at_10_diff1': np.float64(0.38451224330173733), 'nauc_ndcg_at_20_max': np.float64(0.10836777493784458), 'nauc_ndcg_at_20_std': np.float64(-0.3804369180495682), 'nauc_ndcg_at_20_diff1': np.float64(0.3826323635685051), 'nauc_ndcg_at_100_max': np.float64(0.13222631489674724), 'nauc_ndcg_at_100_std': np.float64(-0.34470598334880453), 'nauc_ndcg_at_100_diff1': np.float64(0.3881436082865315), 'nauc_ndcg_at_1000_max': np.float64(0.11986007212536637), 'nauc_ndcg_at_1000_std': np.float64(-0.3666906413031075), 'nauc_ndcg_at_1000_diff1': np.float64(0.3946494755216197), 'nauc_map_at_1_max': np.float64(0.08344061958550404), 'nauc_map_at_1_std': np.float64(-0.31946365656800246), 'nauc_map_at_1_diff1': np.float64(0.4463964627282165), 'nauc_map_at_3_max': np.float64(0.1008303151487732), 'nauc_map_at_3_std': np.float64(-0.3657621146348587), 'nauc_map_at_3_diff1': np.float64(0.39462292511600694), 'nauc_map_at_5_max': np.float64(0.10531323884277709), 'nauc_map_at_5_std': np.float64(-0.3802022472076196), 'nauc_map_at_5_diff1': np.float64(0.3896493318258246), 'nauc_map_at_10_max': np.float64(0.10643659567327048), 'nauc_map_at_10_std': np.float64(-0.3800158826888215), 'nauc_map_at_10_diff1': np.float64(0.38793492390256795), 'nauc_map_at_20_max': np.float64(0.10601887670901818), 'nauc_map_at_20_std': np.float64(-0.3788233740044132), 'nauc_map_at_20_diff1': np.float64(0.3875017568686949), 'nauc_map_at_100_max': np.float64(0.10813297241561629), 'nauc_map_at_100_std': np.float64(-0.37501459348461086), 'nauc_map_at_100_diff1': np.float64(0.38783039947762304), 'nauc_map_at_1000_max': np.float64(0.10787447883278398), 'nauc_map_at_1000_std': np.float64(-0.3756395113593219), 'nauc_map_at_1000_diff1': np.float64(0.38826255092354406), 'nauc_recall_at_1_max': np.float64(0.08344061958550404), 'nauc_recall_at_1_std': np.float64(-0.31946365656800246), 'nauc_recall_at_1_diff1': np.float64(0.4463964627282165), 'nauc_recall_at_3_max': np.float64(0.08633837741190495), 'nauc_recall_at_3_std': np.float64(-0.3754342858887135), 'nauc_recall_at_3_diff1': np.float64(0.36718763034155105), 'nauc_recall_at_5_max': np.float64(0.10042862490071737), 'nauc_recall_at_5_std': np.float64(-0.3955110398043606), 'nauc_recall_at_5_diff1': np.float64(0.346994636238638), 'nauc_recall_at_10_max': np.float64(0.10343069956132564), 'nauc_recall_at_10_std': np.float64(-0.36680101649720925), 'nauc_recall_at_10_diff1': np.float64(0.3205273712950965), 'nauc_recall_at_20_max': np.float64(0.10513295799184674), 'nauc_recall_at_20_std': np.float64(-0.34592535147068054), 'nauc_recall_at_20_diff1': np.float64(0.30761933958382265), 'nauc_recall_at_100_max': np.float64(0.3113812040722389), 'nauc_recall_at_100_std': np.float64(-0.010631717203961884), 'nauc_recall_at_100_diff1': np.float64(0.30446393761455715), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.11249725870947681), 'nauc_precision_at_1_std': np.float64(-0.3728799569971848), 'nauc_precision_at_1_diff1': np.float64(0.4467339947356412), 'nauc_precision_at_3_max': np.float64(0.09392870266560792), 'nauc_precision_at_3_std': np.float64(-0.3644519667869421), 'nauc_precision_at_3_diff1': np.float64(0.2568365626230938), 'nauc_precision_at_5_max': np.float64(0.09831551395216515), 'nauc_precision_at_5_std': np.float64(-0.3586627477229429), 'nauc_precision_at_5_diff1': np.float64(0.22914733516961203), 'nauc_precision_at_10_max': np.float64(0.09487429897232018), 'nauc_precision_at_10_std': np.float64(-0.332359842403277), 'nauc_precision_at_10_diff1': np.float64(0.20898554433803154), 'nauc_precision_at_20_max': np.float64(0.09453559326766833), 'nauc_precision_at_20_std': np.float64(-0.26571320819070043), 'nauc_precision_at_20_diff1': np.float64(0.1641438708885957), 'nauc_precision_at_100_max': np.float64(0.17074458774590445), 'nauc_precision_at_100_std': np.float64(-0.021180430234989018), 'nauc_precision_at_100_diff1': np.float64(0.08622395023620015), 'nauc_precision_at_1000_max': np.float64(0.12304493138177759), 'nauc_precision_at_1000_std': np.float64(0.0008839679888642927), 'nauc_precision_at_1000_diff1': np.float64(0.025465995748927075), 'nauc_mrr_at_1_max': np.float64(0.11249725870947681), 'nauc_mrr_at_1_std': np.float64(-0.3728799569971848), 'nauc_mrr_at_1_diff1': np.float64(0.4467339947356412), 'nauc_mrr_at_3_max': np.float64(0.10526705047655018), 'nauc_mrr_at_3_std': np.float64(-0.39264018017179614), 'nauc_mrr_at_3_diff1': np.float64(0.42812743568828254), 'nauc_mrr_at_5_max': np.float64(0.10671511974992179), 'nauc_mrr_at_5_std': np.float64(-0.3965840911463643), 'nauc_mrr_at_5_diff1': np.float64(0.42618440641929495), 'nauc_mrr_at_10_max': np.float64(0.10569883750831614), 'nauc_mrr_at_10_std': np.float64(-0.39145315432468686), 'nauc_mrr_at_10_diff1': np.float64(0.42291122168492873), 'nauc_mrr_at_20_max': np.float64(0.10857579979225021), 'nauc_mrr_at_20_std': np.float64(-0.3889868299840338), 'nauc_mrr_at_20_diff1': np.float64(0.42359218862871356), 'nauc_mrr_at_100_max': np.float64(0.11070649966573799), 'nauc_mrr_at_100_std': np.float64(-0.386235238580988), 'nauc_mrr_at_100_diff1': np.float64(0.424388600075125), 'nauc_mrr_at_1000_max': np.float64(0.11027027819746668), 'nauc_mrr_at_1000_std': np.float64(-0.3868802919094269), 'nauc_mrr_at_1000_diff1': np.float64(0.42450789913132536), 'main_score': 0.39132}, 'eng-kor': {'ndcg_at_1': 0.25535, 'ndcg_at_3': 0.25616, 'ndcg_at_5': 0.26694, 'ndcg_at_10': 0.30285, 'ndcg_at_20': 0.33437, 'ndcg_at_100': 0.39273, 'ndcg_at_1000': 0.42736, 'map_at_1': 0.1449, 'map_at_3': 0.21433, 'map_at_5': 0.23317, 'map_at_10': 0.2503, 'map_at_20': 0.26129, 'map_at_100': 0.27182, 'map_at_1000': 0.27372, 'recall_at_1': 0.1449, 'recall_at_3': 0.24873, 'recall_at_5': 0.29317, 'recall_at_10': 0.38914, 'recall_at_20': 0.4923, 'recall_at_100': 0.75882, 'recall_at_1000': 0.9949, 'precision_at_1': 0.25535, 'precision_at_3': 0.16871, 'precision_at_5': 0.12385, 'precision_at_10': 0.08073, 'precision_at_20': 0.05115, 'precision_at_100': 0.0155, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.25535168195718655, 'mrr_at_3': 0.29332313965341494, 'mrr_at_5': 0.3036442405708461, 'mrr_at_10': 0.3164876705014319, 'mrr_at_20': 0.32345196829088535, 'mrr_at_100': 0.32890072544781823, 'mrr_at_1000': 0.3298307295678346, 'nauc_ndcg_at_1_max': np.float64(0.22527311571264705), 'nauc_ndcg_at_1_std': np.float64(-0.27988538657714074), 'nauc_ndcg_at_1_diff1': np.float64(0.49270414720254924), 'nauc_ndcg_at_3_max': np.float64(0.2310562006619422), 'nauc_ndcg_at_3_std': np.float64(-0.275943597231683), 'nauc_ndcg_at_3_diff1': np.float64(0.4363456085400352), 'nauc_ndcg_at_5_max': np.float64(0.2456545583304813), 'nauc_ndcg_at_5_std': np.float64(-0.24511448793418664), 'nauc_ndcg_at_5_diff1': np.float64(0.4168681994574911), 'nauc_ndcg_at_10_max': np.float64(0.236860626877749), 'nauc_ndcg_at_10_std': np.float64(-0.24362356300971014), 'nauc_ndcg_at_10_diff1': np.float64(0.4133610363170538), 'nauc_ndcg_at_20_max': np.float64(0.22544792847661466), 'nauc_ndcg_at_20_std': np.float64(-0.2452951768445013), 'nauc_ndcg_at_20_diff1': np.float64(0.40315966000938086), 'nauc_ndcg_at_100_max': np.float64(0.22543825941130227), 'nauc_ndcg_at_100_std': np.float64(-0.23481724008754576), 'nauc_ndcg_at_100_diff1': np.float64(0.41148105286699216), 'nauc_ndcg_at_1000_max': np.float64(0.23047993417516785), 'nauc_ndcg_at_1000_std': np.float64(-0.23810750905166228), 'nauc_ndcg_at_1000_diff1': np.float64(0.4139056967099916), 'nauc_map_at_1_max': np.float64(0.2434239350948928), 'nauc_map_at_1_std': np.float64(-0.24997815873894727), 'nauc_map_at_1_diff1': np.float64(0.5138953212789059), 'nauc_map_at_3_max': np.float64(0.24783284042661483), 'nauc_map_at_3_std': np.float64(-0.2680891538294646), 'nauc_map_at_3_diff1': np.float64(0.4590936939985688), 'nauc_map_at_5_max': np.float64(0.2605342784895587), 'nauc_map_at_5_std': np.float64(-0.2542335645618029), 'nauc_map_at_5_diff1': np.float64(0.44221554322228235), 'nauc_map_at_10_max': np.float64(0.25383247471735637), 'nauc_map_at_10_std': np.float64(-0.25415840990531396), 'nauc_map_at_10_diff1': np.float64(0.43746978404483516), 'nauc_map_at_20_max': np.float64(0.2497800607095804), 'nauc_map_at_20_std': np.float64(-0.25460737774008413), 'nauc_map_at_20_diff1': np.float64(0.43471466211797305), 'nauc_map_at_100_max': np.float64(0.2481915996427973), 'nauc_map_at_100_std': np.float64(-0.25452037584312803), 'nauc_map_at_100_diff1': np.float64(0.43487200722235975), 'nauc_map_at_1000_max': np.float64(0.24886569352430946), 'nauc_map_at_1000_std': np.float64(-0.2536576743151846), 'nauc_map_at_1000_diff1': np.float64(0.43492390238490897), 'nauc_recall_at_1_max': np.float64(0.2434239350948928), 'nauc_recall_at_1_std': np.float64(-0.24997815873894727), 'nauc_recall_at_1_diff1': np.float64(0.5138953212789059), 'nauc_recall_at_3_max': np.float64(0.2199436219680488), 'nauc_recall_at_3_std': np.float64(-0.2627217888076737), 'nauc_recall_at_3_diff1': np.float64(0.3975953352884943), 'nauc_recall_at_5_max': np.float64(0.23550084902040916), 'nauc_recall_at_5_std': np.float64(-0.2107627410732165), 'nauc_recall_at_5_diff1': np.float64(0.35356369054654546), 'nauc_recall_at_10_max': np.float64(0.20870405519395338), 'nauc_recall_at_10_std': np.float64(-0.2031678427789475), 'nauc_recall_at_10_diff1': np.float64(0.3388918192442233), 'nauc_recall_at_20_max': np.float64(0.17148491529260954), 'nauc_recall_at_20_std': np.float64(-0.2105692448514342), 'nauc_recall_at_20_diff1': np.float64(0.3004603887120195), 'nauc_recall_at_100_max': np.float64(0.16759304995845375), 'nauc_recall_at_100_std': np.float64(-0.12914544330636796), 'nauc_recall_at_100_diff1': np.float64(0.33880348832813556), 'nauc_recall_at_1000_max': np.float64(0.052355064645871356), 'nauc_recall_at_1000_std': np.float64(-0.5072703545177019), 'nauc_recall_at_1000_diff1': np.float64(0.024871490534182097), 'nauc_precision_at_1_max': np.float64(0.22527311571264705), 'nauc_precision_at_1_std': np.float64(-0.27988538657714074), 'nauc_precision_at_1_diff1': np.float64(0.49270414720254924), 'nauc_precision_at_3_max': np.float64(0.1917119993799527), 'nauc_precision_at_3_std': np.float64(-0.26513642202436344), 'nauc_precision_at_3_diff1': np.float64(0.32321030790059374), 'nauc_precision_at_5_max': np.float64(0.21171898557791388), 'nauc_precision_at_5_std': np.float64(-0.19800775012552696), 'nauc_precision_at_5_diff1': np.float64(0.27237187581032446), 'nauc_precision_at_10_max': np.float64(0.1770064321431902), 'nauc_precision_at_10_std': np.float64(-0.18802949109663442), 'nauc_precision_at_10_diff1': np.float64(0.2506843164887571), 'nauc_precision_at_20_max': np.float64(0.1336333980150719), 'nauc_precision_at_20_std': np.float64(-0.17010022340172778), 'nauc_precision_at_20_diff1': np.float64(0.20631144077167363), 'nauc_precision_at_100_max': np.float64(0.08051685366675573), 'nauc_precision_at_100_std': np.float64(-0.0663314119337897), 'nauc_precision_at_100_diff1': np.float64(0.12751672028562433), 'nauc_precision_at_1000_max': np.float64(0.03408459453546067), 'nauc_precision_at_1000_std': np.float64(-0.0014912651423470648), 'nauc_precision_at_1000_diff1': np.float64(0.030158828936747907), 'nauc_mrr_at_1_max': np.float64(0.22527311571264705), 'nauc_mrr_at_1_std': np.float64(-0.27988538657714074), 'nauc_mrr_at_1_diff1': np.float64(0.49270414720254924), 'nauc_mrr_at_3_max': np.float64(0.20974364212482557), 'nauc_mrr_at_3_std': np.float64(-0.2774844513650661), 'nauc_mrr_at_3_diff1': np.float64(0.43761835924292725), 'nauc_mrr_at_5_max': np.float64(0.21297216075604236), 'nauc_mrr_at_5_std': np.float64(-0.25665096900549267), 'nauc_mrr_at_5_diff1': np.float64(0.4266930509438262), 'nauc_mrr_at_10_max': np.float64(0.21306073443717444), 'nauc_mrr_at_10_std': np.float64(-0.2551483483582661), 'nauc_mrr_at_10_diff1': np.float64(0.4294254672172667), 'nauc_mrr_at_20_max': np.float64(0.2111081933407038), 'nauc_mrr_at_20_std': np.float64(-0.2538036832281101), 'nauc_mrr_at_20_diff1': np.float64(0.42707133241002754), 'nauc_mrr_at_100_max': np.float64(0.21114367199477724), 'nauc_mrr_at_100_std': np.float64(-0.2541721157964939), 'nauc_mrr_at_100_diff1': np.float64(0.4277302244730743), 'nauc_mrr_at_1000_max': np.float64(0.21131822076296092), 'nauc_mrr_at_1000_std': np.float64(-0.25441910267558), 'nauc_mrr_at_1000_diff1': np.float64(0.4280296777231909), 'main_score': 0.30285}, 'kor-eng': {'ndcg_at_1': 0.25081, 'ndcg_at_3': 0.2775, 'ndcg_at_5': 0.30615, 'ndcg_at_10': 0.33381, 'ndcg_at_20': 0.35821, 'ndcg_at_100': 0.41209, 'ndcg_at_1000': 0.44401, 'map_at_1': 0.17545, 'map_at_3': 0.24908, 'map_at_5': 0.27052, 'map_at_10': 0.28438, 'map_at_20': 0.29274, 'map_at_100': 0.30138, 'map_at_1000': 0.30289, 'recall_at_1': 0.17545, 'recall_at_3': 0.29657, 'recall_at_5': 0.36346, 'recall_at_10': 0.43661, 'recall_at_20': 0.51961, 'recall_at_100': 0.7735, 'recall_at_1000': 1.0, 'precision_at_1': 0.25081, 'precision_at_3': 0.15581, 'precision_at_5': 0.11694, 'precision_at_10': 0.07248, 'precision_at_20': 0.04357, 'precision_at_100': 0.01322, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.250814332247557, 'mrr_at_3': 0.3002171552660153, 'mrr_at_5': 0.3144679695982628, 'mrr_at_10': 0.3249431260017577, 'mrr_at_20': 0.3304958503890037, 'mrr_at_100': 0.33683405184187465, 'mrr_at_1000': 0.3377258668091609, 'nauc_ndcg_at_1_max': np.float64(0.1452965693714822), 'nauc_ndcg_at_1_std': np.float64(-0.2735274167796163), 'nauc_ndcg_at_1_diff1': np.float64(0.46151275106045525), 'nauc_ndcg_at_3_max': np.float64(0.1389305000031038), 'nauc_ndcg_at_3_std': np.float64(-0.2640831020481174), 'nauc_ndcg_at_3_diff1': np.float64(0.388377821727517), 'nauc_ndcg_at_5_max': np.float64(0.11442111550907663), 'nauc_ndcg_at_5_std': np.float64(-0.28618757200574674), 'nauc_ndcg_at_5_diff1': np.float64(0.35805088917287287), 'nauc_ndcg_at_10_max': np.float64(0.0993209183454152), 'nauc_ndcg_at_10_std': np.float64(-0.293931959159637), 'nauc_ndcg_at_10_diff1': np.float64(0.34252946742354756), 'nauc_ndcg_at_20_max': np.float64(0.106369505330079), 'nauc_ndcg_at_20_std': np.float64(-0.2888920793656817), 'nauc_ndcg_at_20_diff1': np.float64(0.3497130440518054), 'nauc_ndcg_at_100_max': np.float64(0.13132230624838512), 'nauc_ndcg_at_100_std': np.float64(-0.23399334437197195), 'nauc_ndcg_at_100_diff1': np.float64(0.34932167034079964), 'nauc_ndcg_at_1000_max': np.float64(0.1235552255785018), 'nauc_ndcg_at_1000_std': np.float64(-0.25880727681937943), 'nauc_ndcg_at_1000_diff1': np.float64(0.3632375320237333), 'nauc_map_at_1_max': np.float64(0.12279151581805818), 'nauc_map_at_1_std': np.float64(-0.24296102378471773), 'nauc_map_at_1_diff1': np.float64(0.49285595864965237), 'nauc_map_at_3_max': np.float64(0.1458856116039988), 'nauc_map_at_3_std': np.float64(-0.2560454304768273), 'nauc_map_at_3_diff1': np.float64(0.3978368400055779), 'nauc_map_at_5_max': np.float64(0.12818443680213576), 'nauc_map_at_5_std': np.float64(-0.2751859071621296), 'nauc_map_at_5_diff1': np.float64(0.3729941740895826), 'nauc_map_at_10_max': np.float64(0.1198307759611729), 'nauc_map_at_10_std': np.float64(-0.2804191879182208), 'nauc_map_at_10_diff1': np.float64(0.36467250575959625), 'nauc_map_at_20_max': np.float64(0.12121576125275813), 'nauc_map_at_20_std': np.float64(-0.28057529960857996), 'nauc_map_at_20_diff1': np.float64(0.3671120414142595), 'nauc_map_at_100_max': np.float64(0.12481818490563086), 'nauc_map_at_100_std': np.float64(-0.27127199862094636), 'nauc_map_at_100_diff1': np.float64(0.36752867668723704), 'nauc_map_at_1000_max': np.float64(0.12446067050706414), 'nauc_map_at_1000_std': np.float64(-0.2723059247057557), 'nauc_map_at_1000_diff1': np.float64(0.36810288281987463), 'nauc_recall_at_1_max': np.float64(0.12279151581805818), 'nauc_recall_at_1_std': np.float64(-0.24296102378471773), 'nauc_recall_at_1_diff1': np.float64(0.49285595864965237), 'nauc_recall_at_3_max': np.float64(0.1389734471478611), 'nauc_recall_at_3_std': np.float64(-0.24629596287328326), 'nauc_recall_at_3_diff1': np.float64(0.34498462678292463), 'nauc_recall_at_5_max': np.float64(0.08079219233962603), 'nauc_recall_at_5_std': np.float64(-0.29348593553811914), 'nauc_recall_at_5_diff1': np.float64(0.27916266258832306), 'nauc_recall_at_10_max': np.float64(0.041563450403469454), 'nauc_recall_at_10_std': np.float64(-0.3073773129649994), 'nauc_recall_at_10_diff1': np.float64(0.2374091060786093), 'nauc_recall_at_20_max': np.float64(0.06612287299191151), 'nauc_recall_at_20_std': np.float64(-0.2827481665049045), 'nauc_recall_at_20_diff1': np.float64(0.25065399194987886), 'nauc_recall_at_100_max': np.float64(0.19270042996351033), 'nauc_recall_at_100_std': np.float64(0.027761018698510043), 'nauc_recall_at_100_diff1': np.float64(0.19229581784725727), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1452965693714822), 'nauc_precision_at_1_std': np.float64(-0.2735274167796163), 'nauc_precision_at_1_diff1': np.float64(0.46151275106045525), 'nauc_precision_at_3_max': np.float64(0.15684465227131578), 'nauc_precision_at_3_std': np.float64(-0.25427462127207884), 'nauc_precision_at_3_diff1': np.float64(0.25747697569101485), 'nauc_precision_at_5_max': np.float64(0.0966461844616506), 'nauc_precision_at_5_std': np.float64(-0.2854262606252807), 'nauc_precision_at_5_diff1': np.float64(0.18598368745514446), 'nauc_precision_at_10_max': np.float64(0.05416385213283609), 'nauc_precision_at_10_std': np.float64(-0.2777515295313864), 'nauc_precision_at_10_diff1': np.float64(0.13578146950204548), 'nauc_precision_at_20_max': np.float64(0.054823029947450225), 'nauc_precision_at_20_std': np.float64(-0.23818889843069824), 'nauc_precision_at_20_diff1': np.float64(0.13053008363256624), 'nauc_precision_at_100_max': np.float64(0.12987720902595515), 'nauc_precision_at_100_std': np.float64(0.06644339107714407), 'nauc_precision_at_100_diff1': np.float64(0.016673809647930405), 'nauc_precision_at_1000_max': np.float64(0.07400369711516375), 'nauc_precision_at_1000_std': np.float64(0.06700364217691929), 'nauc_precision_at_1000_diff1': np.float64(-0.030084398715852344), 'nauc_mrr_at_1_max': np.float64(0.1452965693714822), 'nauc_mrr_at_1_std': np.float64(-0.2735274167796163), 'nauc_mrr_at_1_diff1': np.float64(0.46151275106045525), 'nauc_mrr_at_3_max': np.float64(0.13350141996774087), 'nauc_mrr_at_3_std': np.float64(-0.2743921662907825), 'nauc_mrr_at_3_diff1': np.float64(0.4228025084988608), 'nauc_mrr_at_5_max': np.float64(0.12205810707697962), 'nauc_mrr_at_5_std': np.float64(-0.28372014894287384), 'nauc_mrr_at_5_diff1': np.float64(0.4109513181959187), 'nauc_mrr_at_10_max': np.float64(0.11646030230984167), 'nauc_mrr_at_10_std': np.float64(-0.2860324669946639), 'nauc_mrr_at_10_diff1': np.float64(0.4049783149251119), 'nauc_mrr_at_20_max': np.float64(0.11938624789354077), 'nauc_mrr_at_20_std': np.float64(-0.2833024582507733), 'nauc_mrr_at_20_diff1': np.float64(0.40733910083719116), 'nauc_mrr_at_100_max': np.float64(0.12183801989999128), 'nauc_mrr_at_100_std': np.float64(-0.27674514849443993), 'nauc_mrr_at_100_diff1': np.float64(0.40802163108685313), 'nauc_mrr_at_1000_max': np.float64(0.12160433513445545), 'nauc_mrr_at_1000_std': np.float64(-0.27755874395858954), 'nauc_mrr_at_1000_diff1': np.float64(0.4083367135509132), 'main_score': 0.33381}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/97 [00:00<?, ?it/s]Batches:   1%|          | 1/97 [00:01<02:47,  1.74s/it]Batches:   2%|▏         | 2/97 [00:06<05:57,  3.76s/it]Batches:   3%|▎         | 3/97 [00:12<06:55,  4.42s/it]Batches:   4%|▍         | 4/97 [00:17<07:19,  4.73s/it]Batches:   5%|▌         | 5/97 [00:22<07:31,  4.90s/it]Batches:   6%|▌         | 6/97 [00:27<07:36,  5.02s/it]Batches:   7%|▋         | 7/97 [00:33<07:37,  5.09s/it]Batches:   8%|▊         | 8/97 [00:38<07:37,  5.14s/it]Batches:   9%|▉         | 9/97 [00:43<07:35,  5.17s/it]Batches:  10%|█         | 10/97 [00:48<07:31,  5.19s/it]Batches:  11%|█▏        | 11/97 [00:53<07:27,  5.20s/it]Batches:  12%|█▏        | 12/97 [00:59<07:23,  5.21s/it]Batches:  13%|█▎        | 13/97 [01:04<07:18,  5.22s/it]Batches:  14%|█▍        | 14/97 [01:09<07:14,  5.23s/it]Batches:  15%|█▌        | 15/97 [01:14<07:09,  5.24s/it]Batches:  16%|█▋        | 16/97 [01:20<07:04,  5.24s/it]Batches:  18%|█▊        | 17/97 [01:25<06:59,  5.25s/it]Batches:  19%|█▊        | 18/97 [01:30<06:54,  5.25s/it]Batches:  20%|█▉        | 19/97 [01:35<06:49,  5.25s/it]Batches:  21%|██        | 20/97 [01:41<06:44,  5.26s/it]Batches:  22%|██▏       | 21/97 [01:46<06:39,  5.26s/it]Batches:  23%|██▎       | 22/97 [01:51<06:34,  5.26s/it]Batches:  24%|██▎       | 23/97 [01:57<06:29,  5.26s/it]Batches:  25%|██▍       | 24/97 [02:02<06:24,  5.26s/it]Batches:  26%|██▌       | 25/97 [02:07<06:19,  5.27s/it]Batches:  27%|██▋       | 26/97 [02:12<06:13,  5.26s/it]Batches:  28%|██▊       | 27/97 [02:18<06:08,  5.27s/it]Batches:  29%|██▉       | 28/97 [02:23<06:03,  5.27s/it]Batches:  30%|██▉       | 29/97 [02:28<05:58,  5.27s/it]Batches:  31%|███       | 30/97 [02:33<05:53,  5.27s/it]Batches:  32%|███▏      | 31/97 [02:39<05:47,  5.27s/it]Batches:  33%|███▎      | 32/97 [02:44<05:42,  5.27s/it]Batches:  34%|███▍      | 33/97 [02:49<05:37,  5.27s/it]Batches:  35%|███▌      | 34/97 [02:55<05:32,  5.27s/it]Batches:  36%|███▌      | 35/97 [03:00<05:26,  5.27s/it]Batches:  37%|███▋      | 36/97 [03:05<05:21,  5.27s/it]Batches:  38%|███▊      | 37/97 [03:10<05:16,  5.27s/it]Batches:  39%|███▉      | 38/97 [03:16<05:11,  5.27s/it]Batches:  40%|████      | 39/97 [03:21<05:05,  5.27s/it]Batches:  41%|████      | 40/97 [03:26<05:00,  5.27s/it]Batches:  42%|████▏     | 41/97 [03:31<04:55,  5.27s/it]Batches:  43%|████▎     | 42/97 [03:37<04:50,  5.27s/it]Batches:  44%|████▍     | 43/97 [03:42<04:44,  5.27s/it]Batches:  45%|████▌     | 44/97 [03:47<04:39,  5.28s/it]Batches:  46%|████▋     | 45/97 [03:53<04:34,  5.28s/it]Batches:  47%|████▋     | 46/97 [03:58<04:29,  5.28s/it]Batches:  48%|████▊     | 47/97 [04:03<04:23,  5.28s/it]Batches:  49%|████▉     | 48/97 [04:08<04:18,  5.28s/it]Batches:  51%|█████     | 49/97 [04:14<04:13,  5.28s/it]Batches:  52%|█████▏    | 50/97 [04:19<04:08,  5.28s/it]Batches:  53%|█████▎    | 51/97 [04:24<04:02,  5.28s/it]Batches:  54%|█████▎    | 52/97 [04:29<03:57,  5.28s/it]Batches:  55%|█████▍    | 53/97 [04:35<03:52,  5.28s/it]Batches:  56%|█████▌    | 54/97 [04:40<03:46,  5.28s/it]Batches:  57%|█████▋    | 55/97 [04:45<03:41,  5.28s/it]Batches:  58%|█████▊    | 56/97 [04:51<03:36,  5.29s/it]Batches:  59%|█████▉    | 57/97 [04:56<03:31,  5.29s/it]Batches:  60%|█████▉    | 58/97 [05:01<03:26,  5.29s/it]Batches:  61%|██████    | 59/97 [05:07<03:21,  5.29s/it]Batches:  62%|██████▏   | 60/97 [05:12<03:15,  5.29s/it]Batches:  63%|██████▎   | 61/97 [05:17<03:10,  5.29s/it]Batches:  64%|██████▍   | 62/97 [05:22<03:05,  5.30s/it]Batches:  65%|██████▍   | 63/97 [05:28<03:00,  5.30s/it]Batches:  66%|██████▌   | 64/97 [05:33<02:54,  5.30s/it]Batches:  67%|██████▋   | 65/97 [05:38<02:49,  5.30s/it]Batches:  68%|██████▊   | 66/97 [05:44<02:44,  5.30s/it]Batches:  69%|██████▉   | 67/97 [05:49<02:39,  5.30s/it]Batches:  70%|███████   | 68/97 [05:54<02:33,  5.30s/it]Batches:  71%|███████   | 69/97 [06:00<02:28,  5.30s/it]Batches:  72%|███████▏  | 70/97 [06:05<02:23,  5.30s/it]Batches:  73%|███████▎  | 71/97 [06:10<02:17,  5.30s/it]Batches:  74%|███████▍  | 72/97 [06:15<02:12,  5.30s/it]Batches:  75%|███████▌  | 73/97 [06:21<02:07,  5.30s/it]Batches:  76%|███████▋  | 74/97 [06:26<02:01,  5.30s/it]Batches:  77%|███████▋  | 75/97 [06:31<01:56,  5.30s/it]Batches:  78%|███████▊  | 76/97 [06:37<01:51,  5.30s/it]Batches:  79%|███████▉  | 77/97 [06:42<01:46,  5.30s/it]Batches:  80%|████████  | 78/97 [06:47<01:40,  5.30s/it]Batches:  81%|████████▏ | 79/97 [06:53<01:35,  5.30s/it]Batches:  82%|████████▏ | 80/97 [06:58<01:30,  5.30s/it]Batches:  84%|████████▎ | 81/97 [07:03<01:24,  5.30s/it]Batches:  85%|████████▍ | 82/97 [07:08<01:19,  5.30s/it]Batches:  86%|████████▌ | 83/97 [07:14<01:14,  5.30s/it]Batches:  87%|████████▋ | 84/97 [07:19<01:08,  5.30s/it]Batches:  88%|████████▊ | 85/97 [07:24<01:03,  5.30s/it]Batches:  89%|████████▊ | 86/97 [07:30<00:58,  5.30s/it]Batches:  90%|████████▉ | 87/97 [07:35<00:53,  5.30s/it]Batches:  91%|█████████ | 88/97 [07:40<00:47,  5.30s/it]Batches:  92%|█████████▏| 89/97 [07:46<00:42,  5.30s/it]Batches:  93%|█████████▎| 90/97 [07:51<00:37,  5.30s/it]Batches:  94%|█████████▍| 91/97 [07:56<00:31,  5.30s/it]Batches:  95%|█████████▍| 92/97 [08:01<00:26,  5.31s/it]Batches:  96%|█████████▌| 93/97 [08:07<00:21,  5.31s/it]Batches:  97%|█████████▋| 94/97 [08:12<00:15,  5.30s/it]Batches:  98%|█████████▊| 95/97 [08:17<00:10,  5.30s/it]Batches:  99%|█████████▉| 96/97 [08:23<00:05,  5.30s/it]Batches: 100%|██████████| 97/97 [08:27<00:00,  5.05s/it]Batches: 100%|██████████| 97/97 [08:27<00:00,  5.23s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 520.83 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 521.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.185, 'ndcg_at_3': 0.22589, 'ndcg_at_5': 0.23837, 'ndcg_at_10': 0.25818, 'ndcg_at_20': 0.27555, 'ndcg_at_100': 0.3047, 'ndcg_at_1000': 0.33958, 'map_at_1': 0.185, 'map_at_3': 0.21583, 'map_at_5': 0.22283, 'map_at_10': 0.23124, 'map_at_20': 0.23583, 'map_at_100': 0.24003, 'map_at_1000': 0.24126, 'recall_at_1': 0.185, 'recall_at_3': 0.255, 'recall_at_5': 0.285, 'recall_at_10': 0.345, 'recall_at_20': 0.415, 'recall_at_100': 0.57, 'recall_at_1000': 0.85, 'precision_at_1': 0.185, 'precision_at_3': 0.085, 'precision_at_5': 0.057, 'precision_at_10': 0.0345, 'precision_at_20': 0.02075, 'precision_at_100': 0.0057, 'precision_at_1000': 0.00085, 'mrr_at_1': 0.185, 'mrr_at_3': 0.21583333333333335, 'mrr_at_5': 0.22283333333333336, 'mrr_at_10': 0.2312440476190477, 'mrr_at_20': 0.23582784780578903, 'mrr_at_100': 0.24002501185635805, 'mrr_at_1000': 0.24126282406384691, 'nauc_ndcg_at_1_max': np.float64(0.39765107873522265), 'nauc_ndcg_at_1_std': np.float64(0.09491839730766913), 'nauc_ndcg_at_1_diff1': np.float64(0.4786871453223328), 'nauc_ndcg_at_3_max': np.float64(0.3572166067198363), 'nauc_ndcg_at_3_std': np.float64(0.10554574009628236), 'nauc_ndcg_at_3_diff1': np.float64(0.4042077528893338), 'nauc_ndcg_at_5_max': np.float64(0.35306166566876707), 'nauc_ndcg_at_5_std': np.float64(0.09459482118303365), 'nauc_ndcg_at_5_diff1': np.float64(0.39520031266736133), 'nauc_ndcg_at_10_max': np.float64(0.3413200435627079), 'nauc_ndcg_at_10_std': np.float64(0.11205968895960523), 'nauc_ndcg_at_10_diff1': np.float64(0.3790941368699965), 'nauc_ndcg_at_20_max': np.float64(0.3194766843952747), 'nauc_ndcg_at_20_std': np.float64(0.09604488547372245), 'nauc_ndcg_at_20_diff1': np.float64(0.36262170766276697), 'nauc_ndcg_at_100_max': np.float64(0.31565704417582807), 'nauc_ndcg_at_100_std': np.float64(0.12172383099536616), 'nauc_ndcg_at_100_diff1': np.float64(0.35651140661161795), 'nauc_ndcg_at_1000_max': np.float64(0.32736964983302813), 'nauc_ndcg_at_1000_std': np.float64(0.13498808605942275), 'nauc_ndcg_at_1000_diff1': np.float64(0.3597319780575336), 'nauc_map_at_1_max': np.float64(0.39765107873522265), 'nauc_map_at_1_std': np.float64(0.09491839730766913), 'nauc_map_at_1_diff1': np.float64(0.4786871453223328), 'nauc_map_at_3_max': np.float64(0.3675095015982821), 'nauc_map_at_3_std': np.float64(0.10361345550841002), 'nauc_map_at_3_diff1': np.float64(0.4213053056606874), 'nauc_map_at_5_max': np.float64(0.3653956710210222), 'nauc_map_at_5_std': np.float64(0.0970030789067568), 'nauc_map_at_5_diff1': np.float64(0.416370309582153), 'nauc_map_at_10_max': np.float64(0.36084351366174117), 'nauc_map_at_10_std': np.float64(0.10457307470218721), 'nauc_map_at_10_diff1': np.float64(0.4096093243587333), 'nauc_map_at_20_max': np.float64(0.3545675321351549), 'nauc_map_at_20_std': np.float64(0.10020880263250684), 'nauc_map_at_20_diff1': np.float64(0.4047598896661347), 'nauc_map_at_100_max': np.float64(0.3553376798684589), 'nauc_map_at_100_std': np.float64(0.10544692763141132), 'nauc_map_at_100_diff1': np.float64(0.4047808451819473), 'nauc_map_at_1000_max': np.float64(0.35592420511573286), 'nauc_map_at_1000_std': np.float64(0.10619267717823076), 'nauc_map_at_1000_diff1': np.float64(0.4050784900626276), 'nauc_recall_at_1_max': np.float64(0.39765107873522265), 'nauc_recall_at_1_std': np.float64(0.09491839730766913), 'nauc_recall_at_1_diff1': np.float64(0.4786871453223328), 'nauc_recall_at_3_max': np.float64(0.3294910212384348), 'nauc_recall_at_3_std': np.float64(0.11049381365879964), 'nauc_recall_at_3_diff1': np.float64(0.3587713350394076), 'nauc_recall_at_5_max': np.float64(0.3201961232418505), 'nauc_recall_at_5_std': np.float64(0.08729284828842285), 'nauc_recall_at_5_diff1': np.float64(0.3394275583625924), 'nauc_recall_at_10_max': np.float64(0.28692267533686217), 'nauc_recall_at_10_std': np.float64(0.1353528544900643), 'nauc_recall_at_10_diff1': np.float64(0.29627353409594054), 'nauc_recall_at_20_max': np.float64(0.2125301641316934), 'nauc_recall_at_20_std': np.float64(0.0782035440024324), 'nauc_recall_at_20_diff1': np.float64(0.24163005997243978), 'nauc_recall_at_100_max': np.float64(0.16706132231167747), 'nauc_recall_at_100_std': np.float64(0.18926249623283256), 'nauc_recall_at_100_diff1': np.float64(0.18768387365278916), 'nauc_recall_at_1000_max': np.float64(0.1568662544744541), 'nauc_recall_at_1000_std': np.float64(0.4483403839895864), 'nauc_recall_at_1000_diff1': np.float64(0.0205824926781645), 'nauc_precision_at_1_max': np.float64(0.39765107873522265), 'nauc_precision_at_1_std': np.float64(0.09491839730766913), 'nauc_precision_at_1_diff1': np.float64(0.4786871453223328), 'nauc_precision_at_3_max': np.float64(0.3294910212384349), 'nauc_precision_at_3_std': np.float64(0.11049381365879976), 'nauc_precision_at_3_diff1': np.float64(0.3587713350394073), 'nauc_precision_at_5_max': np.float64(0.3201961232418507), 'nauc_precision_at_5_std': np.float64(0.08729284828842304), 'nauc_precision_at_5_diff1': np.float64(0.33942755836259286), 'nauc_precision_at_10_max': np.float64(0.28692267533686233), 'nauc_precision_at_10_std': np.float64(0.13535285449006437), 'nauc_precision_at_10_diff1': np.float64(0.2962735340959405), 'nauc_precision_at_20_max': np.float64(0.21253016413169376), 'nauc_precision_at_20_std': np.float64(0.07820354400243278), 'nauc_precision_at_20_diff1': np.float64(0.24163005997244016), 'nauc_precision_at_100_max': np.float64(0.16706132231167783), 'nauc_precision_at_100_std': np.float64(0.18926249623283273), 'nauc_precision_at_100_diff1': np.float64(0.18768387365278957), 'nauc_precision_at_1000_max': np.float64(0.15686625447445454), 'nauc_precision_at_1000_std': np.float64(0.4483403839895867), 'nauc_precision_at_1000_diff1': np.float64(0.020582492678163988), 'nauc_mrr_at_1_max': np.float64(0.39765107873522265), 'nauc_mrr_at_1_std': np.float64(0.09491839730766913), 'nauc_mrr_at_1_diff1': np.float64(0.4786871453223328), 'nauc_mrr_at_3_max': np.float64(0.3675095015982821), 'nauc_mrr_at_3_std': np.float64(0.10361345550841002), 'nauc_mrr_at_3_diff1': np.float64(0.4213053056606874), 'nauc_mrr_at_5_max': np.float64(0.3653956710210222), 'nauc_mrr_at_5_std': np.float64(0.0970030789067568), 'nauc_mrr_at_5_diff1': np.float64(0.416370309582153), 'nauc_mrr_at_10_max': np.float64(0.36084351366174117), 'nauc_mrr_at_10_std': np.float64(0.10457307470218721), 'nauc_mrr_at_10_diff1': np.float64(0.4096093243587333), 'nauc_mrr_at_20_max': np.float64(0.3545675321351549), 'nauc_mrr_at_20_std': np.float64(0.10020880263250684), 'nauc_mrr_at_20_diff1': np.float64(0.4047598896661347), 'nauc_mrr_at_100_max': np.float64(0.3553376798684589), 'nauc_mrr_at_100_std': np.float64(0.10544692763141132), 'nauc_mrr_at_100_diff1': np.float64(0.4047808451819473), 'nauc_mrr_at_1000_max': np.float64(0.35592420511573286), 'nauc_mrr_at_1000_std': np.float64(0.10619267717823076), 'nauc_mrr_at_1000_diff1': np.float64(0.4050784900626276), 'main_score': 0.25818}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: 'Instruct: Retrieve text based on user query.
Query: ' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/97 [00:00<?, ?it/s]Batches:   1%|          | 1/97 [00:01<02:47,  1.75s/it]Batches:   2%|▏         | 2/97 [00:07<06:04,  3.84s/it]Batches:   3%|▎         | 3/97 [00:12<07:03,  4.50s/it]Batches:   4%|▍         | 4/97 [00:17<07:27,  4.82s/it]Batches:   5%|▌         | 5/97 [00:22<07:39,  5.00s/it]Batches:   6%|▌         | 6/97 [00:28<07:44,  5.10s/it]Batches:   7%|▋         | 7/97 [00:33<07:45,  5.17s/it]Batches:   8%|▊         | 8/97 [00:38<07:43,  5.21s/it]Batches:   9%|▉         | 9/97 [00:44<07:41,  5.24s/it]Batches:  10%|█         | 10/97 [00:49<07:37,  5.25s/it]Batches:  11%|█▏        | 11/97 [00:54<07:32,  5.26s/it]Batches:  12%|█▏        | 12/97 [01:00<07:27,  5.27s/it]Batches:  13%|█▎        | 13/97 [01:05<07:22,  5.27s/it]Batches:  14%|█▍        | 14/97 [01:10<07:17,  5.27s/it]Batches:  15%|█▌        | 15/97 [01:15<07:12,  5.27s/it]Batches:  16%|█▋        | 16/97 [01:21<07:07,  5.27s/it]Batches:  18%|█▊        | 17/97 [01:26<07:02,  5.28s/it]Batches:  19%|█▊        | 18/97 [01:31<06:57,  5.28s/it]Batches:  20%|█▉        | 19/97 [01:36<06:51,  5.28s/it]Batches:  21%|██        | 20/97 [01:42<06:46,  5.28s/it]Batches:  22%|██▏       | 21/97 [01:47<06:41,  5.28s/it]Batches:  23%|██▎       | 22/97 [01:52<06:35,  5.28s/it]Batches:  24%|██▎       | 23/97 [01:58<06:30,  5.28s/it]Batches:  25%|██▍       | 24/97 [02:03<06:25,  5.28s/it]Batches:  26%|██▌       | 25/97 [02:08<06:20,  5.28s/it]Batches:  27%|██▋       | 26/97 [02:13<06:15,  5.28s/it]Batches:  28%|██▊       | 27/97 [02:19<06:09,  5.28s/it]Batches:  29%|██▉       | 28/97 [02:24<06:04,  5.29s/it]Batches:  30%|██▉       | 29/97 [02:29<05:59,  5.29s/it]Batches:  31%|███       | 30/97 [02:35<05:54,  5.28s/it]Batches:  32%|███▏      | 31/97 [02:40<05:48,  5.29s/it]Batches:  33%|███▎      | 32/97 [02:45<05:43,  5.29s/it]Batches:  34%|███▍      | 33/97 [02:50<05:38,  5.28s/it]Batches:  35%|███▌      | 34/97 [02:56<05:32,  5.28s/it]Batches:  36%|███▌      | 35/97 [03:01<05:27,  5.28s/it]Batches:  37%|███▋      | 36/97 [03:06<05:22,  5.28s/it]Batches:  38%|███▊      | 37/97 [03:12<05:16,  5.28s/it]Batches:  39%|███▉      | 38/97 [03:17<05:11,  5.28s/it]Batches:  40%|████      | 39/97 [03:22<05:06,  5.28s/it]Batches:  41%|████      | 40/97 [03:27<05:00,  5.28s/it]Batches:  42%|████▏     | 41/97 [03:33<04:55,  5.28s/it]Batches:  43%|████▎     | 42/97 [03:38<04:50,  5.28s/it]Batches:  44%|████▍     | 43/97 [03:43<04:45,  5.28s/it]Batches:  45%|████▌     | 44/97 [03:49<04:39,  5.28s/it]Batches:  46%|████▋     | 45/97 [03:54<04:34,  5.28s/it]Batches:  47%|████▋     | 46/97 [03:59<04:29,  5.28s/it]Batches:  48%|████▊     | 47/97 [04:04<04:23,  5.28s/it]Batches:  49%|████▉     | 48/97 [04:10<04:18,  5.28s/it]Batches:  51%|█████     | 49/97 [04:15<04:13,  5.28s/it]Batches:  52%|█████▏    | 50/97 [04:20<04:08,  5.28s/it]Batches:  53%|█████▎    | 51/97 [04:25<04:02,  5.28s/it]Batches:  54%|█████▎    | 52/97 [04:31<03:57,  5.28s/it]Batches:  55%|█████▍    | 53/97 [04:36<03:52,  5.28s/it]Batches:  56%|█████▌    | 54/97 [04:41<03:47,  5.28s/it]Batches:  57%|█████▋    | 55/97 [04:47<03:41,  5.28s/it]Batches:  58%|█████▊    | 56/97 [04:52<03:36,  5.29s/it]Batches:  59%|█████▉    | 57/97 [04:57<03:31,  5.29s/it]Batches:  60%|█████▉    | 58/97 [05:03<03:26,  5.30s/it]Batches:  61%|██████    | 59/97 [05:08<03:21,  5.30s/it]Batches:  62%|██████▏   | 60/97 [05:13<03:16,  5.30s/it]Batches:  63%|██████▎   | 61/97 [05:18<03:10,  5.30s/it]Batches:  64%|██████▍   | 62/97 [05:24<03:05,  5.30s/it]Batches:  65%|██████▍   | 63/97 [05:29<03:00,  5.30s/it]Batches:  66%|██████▌   | 64/97 [05:34<02:55,  5.30s/it]Batches:  67%|██████▋   | 65/97 [05:40<02:49,  5.30s/it]Batches:  68%|██████▊   | 66/97 [05:45<02:44,  5.31s/it]Batches:  69%|██████▉   | 67/97 [05:50<02:39,  5.30s/it]Batches:  70%|███████   | 68/97 [05:56<02:33,  5.30s/it]Batches:  71%|███████   | 69/97 [06:01<02:28,  5.30s/it]Batches:  72%|███████▏  | 70/97 [06:06<02:23,  5.30s/it]Batches:  73%|███████▎  | 71/97 [06:11<02:17,  5.31s/it]Batches:  74%|███████▍  | 72/97 [06:17<02:12,  5.30s/it]Batches:  75%|███████▌  | 73/97 [06:22<02:07,  5.30s/it]Batches:  76%|███████▋  | 74/97 [06:27<02:01,  5.30s/it]Batches:  77%|███████▋  | 75/97 [06:33<01:56,  5.30s/it]Batches:  78%|███████▊  | 76/97 [06:38<01:51,  5.31s/it]Batches:  79%|███████▉  | 77/97 [06:43<01:46,  5.30s/it]Batches:  80%|████████  | 78/97 [06:49<01:40,  5.30s/it]Batches:  81%|████████▏ | 79/97 [06:54<01:35,  5.30s/it]Batches:  82%|████████▏ | 80/97 [06:59<01:30,  5.30s/it]Batches:  84%|████████▎ | 81/97 [07:05<01:24,  5.31s/it]Batches:  85%|████████▍ | 82/97 [07:10<01:19,  5.31s/it]Batches:  86%|████████▌ | 83/97 [07:15<01:14,  5.31s/it]Batches:  87%|████████▋ | 84/97 [07:20<01:08,  5.31s/it]Batches:  88%|████████▊ | 85/97 [07:26<01:03,  5.31s/it]Batches:  89%|████████▊ | 86/97 [07:31<00:58,  5.31s/it]Batches:  90%|████████▉ | 87/97 [07:36<00:53,  5.31s/it]Batches:  91%|█████████ | 88/97 [07:42<00:47,  5.31s/it]Batches:  92%|█████████▏| 89/97 [07:47<00:42,  5.31s/it]Batches:  93%|█████████▎| 90/97 [07:52<00:37,  5.31s/it]Batches:  94%|█████████▍| 91/97 [07:58<00:31,  5.31s/it]Batches:  95%|█████████▍| 92/97 [08:03<00:26,  5.31s/it]Batches:  96%|█████████▌| 93/97 [08:08<00:21,  5.31s/it]Batches:  97%|█████████▋| 94/97 [08:14<00:15,  5.31s/it]Batches:  98%|█████████▊| 95/97 [08:19<00:10,  5.31s/it]Batches:  99%|█████████▉| 96/97 [08:24<00:05,  5.31s/it]Batches: 100%|██████████| 97/97 [08:29<00:00,  5.06s/it]Batches: 100%|██████████| 97/97 [08:29<00:00,  5.25s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 520.60 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 521.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.19, 'ndcg_at_3': 0.23405, 'ndcg_at_5': 0.25084, 'ndcg_at_10': 0.262, 'ndcg_at_20': 0.26709, 'ndcg_at_100': 0.29472, 'ndcg_at_1000': 0.32618, 'map_at_1': 0.19, 'map_at_3': 0.22333, 'map_at_5': 0.23283, 'map_at_10': 0.23734, 'map_at_20': 0.23875, 'map_at_100': 0.2422, 'map_at_1000': 0.24317, 'recall_at_1': 0.19, 'recall_at_3': 0.265, 'recall_at_5': 0.305, 'recall_at_10': 0.34, 'recall_at_20': 0.36, 'recall_at_100': 0.515, 'recall_at_1000': 0.775, 'precision_at_1': 0.19, 'precision_at_3': 0.08833, 'precision_at_5': 0.061, 'precision_at_10': 0.034, 'precision_at_20': 0.018, 'precision_at_100': 0.00515, 'precision_at_1000': 0.00078, 'mrr_at_1': 0.19, 'mrr_at_3': 0.22333333333333333, 'mrr_at_5': 0.23283333333333334, 'mrr_at_10': 0.2373373015873016, 'mrr_at_20': 0.2387452012856425, 'mrr_at_100': 0.2422016632458065, 'mrr_at_1000': 0.24317023876168428, 'nauc_ndcg_at_1_max': np.float64(0.5408925058429875), 'nauc_ndcg_at_1_std': np.float64(0.03177071948615341), 'nauc_ndcg_at_1_diff1': np.float64(0.7819094378961884), 'nauc_ndcg_at_3_max': np.float64(0.4791906386500155), 'nauc_ndcg_at_3_std': np.float64(0.05919088934514917), 'nauc_ndcg_at_3_diff1': np.float64(0.6689642367882729), 'nauc_ndcg_at_5_max': np.float64(0.46454468055007997), 'nauc_ndcg_at_5_std': np.float64(0.07152468247904728), 'nauc_ndcg_at_5_diff1': np.float64(0.6384655879090094), 'nauc_ndcg_at_10_max': np.float64(0.4561414104999494), 'nauc_ndcg_at_10_std': np.float64(0.07359792403386788), 'nauc_ndcg_at_10_diff1': np.float64(0.6249174784837656), 'nauc_ndcg_at_20_max': np.float64(0.4550690627632039), 'nauc_ndcg_at_20_std': np.float64(0.06706061260245715), 'nauc_ndcg_at_20_diff1': np.float64(0.622497275989241), 'nauc_ndcg_at_100_max': np.float64(0.4728130812694981), 'nauc_ndcg_at_100_std': np.float64(0.11250544150070621), 'nauc_ndcg_at_100_diff1': np.float64(0.6087071670716578), 'nauc_ndcg_at_1000_max': np.float64(0.47626307200082674), 'nauc_ndcg_at_1000_std': np.float64(0.11566882942493431), 'nauc_ndcg_at_1000_diff1': np.float64(0.6075617906964333), 'nauc_map_at_1_max': np.float64(0.5408925058429875), 'nauc_map_at_1_std': np.float64(0.03177071948615341), 'nauc_map_at_1_diff1': np.float64(0.7819094378961884), 'nauc_map_at_3_max': np.float64(0.49526585542081), 'nauc_map_at_3_std': np.float64(0.05582859875558135), 'nauc_map_at_3_diff1': np.float64(0.6926691582761113), 'nauc_map_at_5_max': np.float64(0.48617621740278727), 'nauc_map_at_5_std': np.float64(0.06283014589121534), 'nauc_map_at_5_diff1': np.float64(0.6742869896984127), 'nauc_map_at_10_max': np.float64(0.4824597717800422), 'nauc_map_at_10_std': np.float64(0.06351395494968351), 'nauc_map_at_10_diff1': np.float64(0.6683277979460702), 'nauc_map_at_20_max': np.float64(0.48210253583423107), 'nauc_map_at_20_std': np.float64(0.061702407291196304), 'nauc_map_at_20_diff1': np.float64(0.6677766525749401), 'nauc_map_at_100_max': np.float64(0.48336938534468843), 'nauc_map_at_100_std': np.float64(0.0676229989736742), 'nauc_map_at_100_diff1': np.float64(0.6656572903565171), 'nauc_map_at_1000_max': np.float64(0.48359208789567604), 'nauc_map_at_1000_std': np.float64(0.06774062843226236), 'nauc_map_at_1000_diff1': np.float64(0.6657551731379999), 'nauc_recall_at_1_max': np.float64(0.5408925058429875), 'nauc_recall_at_1_std': np.float64(0.03177071948615341), 'nauc_recall_at_1_diff1': np.float64(0.7819094378961884), 'nauc_recall_at_3_max': np.float64(0.4356993931404088), 'nauc_recall_at_3_std': np.float64(0.06705547714066677), 'nauc_recall_at_3_diff1': np.float64(0.606694800495805), 'nauc_recall_at_5_max': np.float64(0.40748178748812197), 'nauc_recall_at_5_std': np.float64(0.0943007136743786), 'nauc_recall_at_5_diff1': np.float64(0.5448455727253735), 'nauc_recall_at_10_max': np.float64(0.38546331381329646), 'nauc_recall_at_10_std': np.float64(0.10073133893319892), 'nauc_recall_at_10_diff1': np.float64(0.5091682344524231), 'nauc_recall_at_20_max': np.float64(0.38256442554978215), 'nauc_recall_at_20_std': np.float64(0.07713352227995594), 'nauc_recall_at_20_diff1': np.float64(0.5006495040151159), 'nauc_recall_at_100_max': np.float64(0.4844146442127485), 'nauc_recall_at_100_std': np.float64(0.31219426383128435), 'nauc_recall_at_100_diff1': np.float64(0.43059831257315667), 'nauc_recall_at_1000_max': np.float64(0.5260376928770707), 'nauc_recall_at_1000_std': np.float64(0.47865398849854796), 'nauc_recall_at_1000_diff1': np.float64(0.2949154472470533), 'nauc_precision_at_1_max': np.float64(0.5408925058429875), 'nauc_precision_at_1_std': np.float64(0.03177071948615341), 'nauc_precision_at_1_diff1': np.float64(0.7819094378961884), 'nauc_precision_at_3_max': np.float64(0.4356993931404091), 'nauc_precision_at_3_std': np.float64(0.06705547714066692), 'nauc_precision_at_3_diff1': np.float64(0.6066948004958052), 'nauc_precision_at_5_max': np.float64(0.4074817874881226), 'nauc_precision_at_5_std': np.float64(0.09430071367437858), 'nauc_precision_at_5_diff1': np.float64(0.5448455727253736), 'nauc_precision_at_10_max': np.float64(0.3854633138132969), 'nauc_precision_at_10_std': np.float64(0.10073133893319942), 'nauc_precision_at_10_diff1': np.float64(0.5091682344524237), 'nauc_precision_at_20_max': np.float64(0.3825644255497824), 'nauc_precision_at_20_std': np.float64(0.07713352227995598), 'nauc_precision_at_20_diff1': np.float64(0.500649504015116), 'nauc_precision_at_100_max': np.float64(0.48441464421274844), 'nauc_precision_at_100_std': np.float64(0.3121942638312848), 'nauc_precision_at_100_diff1': np.float64(0.43059831257315706), 'nauc_precision_at_1000_max': np.float64(0.5260376928770715), 'nauc_precision_at_1000_std': np.float64(0.47865398849854834), 'nauc_precision_at_1000_diff1': np.float64(0.2949154472470535), 'nauc_mrr_at_1_max': np.float64(0.5408925058429875), 'nauc_mrr_at_1_std': np.float64(0.03177071948615341), 'nauc_mrr_at_1_diff1': np.float64(0.7819094378961884), 'nauc_mrr_at_3_max': np.float64(0.49526585542081), 'nauc_mrr_at_3_std': np.float64(0.05582859875558135), 'nauc_mrr_at_3_diff1': np.float64(0.6926691582761113), 'nauc_mrr_at_5_max': np.float64(0.48617621740278727), 'nauc_mrr_at_5_std': np.float64(0.06283014589121534), 'nauc_mrr_at_5_diff1': np.float64(0.6742869896984127), 'nauc_mrr_at_10_max': np.float64(0.4824597717800422), 'nauc_mrr_at_10_std': np.float64(0.06351395494968351), 'nauc_mrr_at_10_diff1': np.float64(0.6683277979460702), 'nauc_mrr_at_20_max': np.float64(0.48210253583423107), 'nauc_mrr_at_20_std': np.float64(0.061702407291196304), 'nauc_mrr_at_20_diff1': np.float64(0.6677766525749401), 'nauc_mrr_at_100_max': np.float64(0.48336938534468843), 'nauc_mrr_at_100_std': np.float64(0.0676229989736742), 'nauc_mrr_at_100_diff1': np.float64(0.6656572903565171), 'nauc_mrr_at_1000_max': np.float64(0.4835919912901167), 'nauc_mrr_at_1000_std': np.float64(0.06774050141423948), 'nauc_mrr_at_1000_diff1': np.float64(0.6657551265134893), 'main_score': 0.262}}



==================================================
Running model: ibm-granite/granite-embedding-278m-multilingual
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ibm-granite/granite-embedding-278m-multilingual
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / ibm-granite/granite-embedding-278m-multilingual on GPU 0 in process Process-12
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  2.20it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.22it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:05,  3.17it/s]Batches:  11%|█         | 2/19 [00:03<00:35,  2.07s/it]Batches:  16%|█▌        | 3/19 [00:06<00:37,  2.35s/it]Batches:  21%|██        | 4/19 [00:08<00:33,  2.24s/it]Batches:  26%|██▋       | 5/19 [00:10<00:29,  2.08s/it]Batches:  32%|███▏      | 6/19 [00:11<00:25,  1.94s/it]Batches:  37%|███▋      | 7/19 [00:13<00:21,  1.79s/it]Batches:  42%|████▏     | 8/19 [00:14<00:18,  1.65s/it]Batches:  47%|████▋     | 9/19 [00:15<00:15,  1.54s/it]Batches:  53%|█████▎    | 10/19 [00:17<00:13,  1.45s/it]Batches:  58%|█████▊    | 11/19 [00:18<00:10,  1.33s/it]Batches:  63%|██████▎   | 12/19 [00:19<00:08,  1.24s/it]Batches:  68%|██████▊   | 13/19 [00:20<00:06,  1.16s/it]Batches:  74%|███████▎  | 14/19 [00:21<00:05,  1.08s/it]Batches:  79%|███████▉  | 15/19 [00:22<00:03,  1.00it/s]Batches:  84%|████████▍ | 16/19 [00:22<00:02,  1.10it/s]Batches:  89%|████████▉ | 17/19 [00:23<00:01,  1.21it/s]Batches:  95%|█████████▍| 18/19 [00:23<00:00,  1.35it/s]Batches: 100%|██████████| 19/19 [00:24<00:00,  1.54it/s]Batches: 100%|██████████| 19/19 [00:24<00:00,  1.28s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 25.69 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 26.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.66723, 'ndcg_at_3': 0.6682, 'ndcg_at_5': 0.6974, 'ndcg_at_10': 0.71762, 'ndcg_at_20': 0.73177, 'ndcg_at_100': 0.74452, 'ndcg_at_1000': 0.75494, 'map_at_1': 0.42862, 'map_at_3': 0.62045, 'map_at_5': 0.64746, 'map_at_10': 0.66085, 'map_at_20': 0.66704, 'map_at_100': 0.66936, 'map_at_1000': 0.66986, 'recall_at_1': 0.42862, 'recall_at_3': 0.68517, 'recall_at_5': 0.74516, 'recall_at_10': 0.79378, 'recall_at_20': 0.83641, 'recall_at_100': 0.89352, 'recall_at_1000': 0.95907, 'precision_at_1': 0.66723, 'precision_at_3': 0.39583, 'precision_at_5': 0.26588, 'precision_at_10': 0.14426, 'precision_at_20': 0.07711, 'precision_at_100': 0.01666, 'precision_at_1000': 0.00183, 'mrr_at_1': 0.6672297297297297, 'mrr_at_3': 0.7317004504504501, 'mrr_at_5': 0.7389639639639636, 'mrr_at_10': 0.741757829257829, 'mrr_at_20': 0.7436569670944667, 'mrr_at_100': 0.7447023064552839, 'mrr_at_1000': 0.7448718339994695, 'nauc_ndcg_at_1_max': np.float64(0.578281569389985), 'nauc_ndcg_at_1_std': np.float64(0.217385453394406), 'nauc_ndcg_at_1_diff1': np.float64(0.6206315047766061), 'nauc_ndcg_at_3_max': np.float64(0.5842284461325705), 'nauc_ndcg_at_3_std': np.float64(0.1914214514398678), 'nauc_ndcg_at_3_diff1': np.float64(0.5267683080402249), 'nauc_ndcg_at_5_max': np.float64(0.6293373913976505), 'nauc_ndcg_at_5_std': np.float64(0.22209490666173287), 'nauc_ndcg_at_5_diff1': np.float64(0.5297818692776709), 'nauc_ndcg_at_10_max': np.float64(0.6564191885747132), 'nauc_ndcg_at_10_std': np.float64(0.2683165738603249), 'nauc_ndcg_at_10_diff1': np.float64(0.5354838951309238), 'nauc_ndcg_at_20_max': np.float64(0.6692293596208281), 'nauc_ndcg_at_20_std': np.float64(0.289780229877756), 'nauc_ndcg_at_20_diff1': np.float64(0.5459584913980672), 'nauc_ndcg_at_100_max': np.float64(0.6666041046134634), 'nauc_ndcg_at_100_std': np.float64(0.2984835354275725), 'nauc_ndcg_at_100_diff1': np.float64(0.5512423235519665), 'nauc_ndcg_at_1000_max': np.float64(0.6565008840790238), 'nauc_ndcg_at_1000_std': np.float64(0.2872147689244455), 'nauc_ndcg_at_1000_diff1': np.float64(0.5515874974685835), 'nauc_map_at_1_max': np.float64(0.34499808659993536), 'nauc_map_at_1_std': np.float64(0.06537232846666335), 'nauc_map_at_1_diff1': np.float64(0.5669494297567521), 'nauc_map_at_3_max': np.float64(0.539948831238462), 'nauc_map_at_3_std': np.float64(0.14953361029175047), 'nauc_map_at_3_diff1': np.float64(0.5181191401272204), 'nauc_map_at_5_max': np.float64(0.5797181482321155), 'nauc_map_at_5_std': np.float64(0.17688993001390074), 'nauc_map_at_5_diff1': np.float64(0.5179753792203693), 'nauc_map_at_10_max': np.float64(0.5962395534192608), 'nauc_map_at_10_std': np.float64(0.20419463574772734), 'nauc_map_at_10_diff1': np.float64(0.5215205663736341), 'nauc_map_at_20_max': np.float64(0.6022713970485896), 'nauc_map_at_20_std': np.float64(0.21319287385687236), 'nauc_map_at_20_diff1': np.float64(0.526621164282697), 'nauc_map_at_100_max': np.float64(0.6023424541060065), 'nauc_map_at_100_std': np.float64(0.21554904865058044), 'nauc_map_at_100_diff1': np.float64(0.5277623663680581), 'nauc_map_at_1000_max': np.float64(0.6019001157415714), 'nauc_map_at_1000_std': np.float64(0.21514656580175912), 'nauc_map_at_1000_diff1': np.float64(0.5277064031525432), 'nauc_recall_at_1_max': np.float64(0.34499808659993536), 'nauc_recall_at_1_std': np.float64(0.06537232846666335), 'nauc_recall_at_1_diff1': np.float64(0.5669494297567521), 'nauc_recall_at_3_max': np.float64(0.5743502296639333), 'nauc_recall_at_3_std': np.float64(0.17669574038991076), 'nauc_recall_at_3_diff1': np.float64(0.46736508420637296), 'nauc_recall_at_5_max': np.float64(0.6572058059691339), 'nauc_recall_at_5_std': np.float64(0.23759002944375757), 'nauc_recall_at_5_diff1': np.float64(0.4568820621235609), 'nauc_recall_at_10_max': np.float64(0.7378862148888881), 'nauc_recall_at_10_std': np.float64(0.3679251825841799), 'nauc_recall_at_10_diff1': np.float64(0.4584820446223682), 'nauc_recall_at_20_max': np.float64(0.8185238409991384), 'nauc_recall_at_20_std': np.float64(0.4806061932383557), 'nauc_recall_at_20_diff1': np.float64(0.49325175785543446), 'nauc_recall_at_100_max': np.float64(0.8798233015976671), 'nauc_recall_at_100_std': np.float64(0.6484763791692478), 'nauc_recall_at_100_diff1': np.float64(0.5317769824875331), 'nauc_recall_at_1000_max': np.float64(0.9276434906800632), 'nauc_recall_at_1000_std': np.float64(0.8427306784045016), 'nauc_recall_at_1000_diff1': np.float64(0.5478905462295677), 'nauc_precision_at_1_max': np.float64(0.578281569389985), 'nauc_precision_at_1_std': np.float64(0.217385453394406), 'nauc_precision_at_1_diff1': np.float64(0.6206315047766061), 'nauc_precision_at_3_max': np.float64(0.4464132729776947), 'nauc_precision_at_3_std': np.float64(0.2133603272989073), 'nauc_precision_at_3_diff1': np.float64(0.14174388836840987), 'nauc_precision_at_5_max': np.float64(0.41217067920066885), 'nauc_precision_at_5_std': np.float64(0.23241074515394705), 'nauc_precision_at_5_diff1': np.float64(0.06437316093434073), 'nauc_precision_at_10_max': np.float64(0.37484935357255234), 'nauc_precision_at_10_std': np.float64(0.28885998919297873), 'nauc_precision_at_10_diff1': np.float64(0.010543495696650728), 'nauc_precision_at_20_max': np.float64(0.33182400849545685), 'nauc_precision_at_20_std': np.float64(0.30561646777557605), 'nauc_precision_at_20_diff1': np.float64(-0.016117821234718964), 'nauc_precision_at_100_max': np.float64(0.23290302399509435), 'nauc_precision_at_100_std': np.float64(0.287513353387931), 'nauc_precision_at_100_diff1': np.float64(-0.07687463876050478), 'nauc_precision_at_1000_max': np.float64(0.04130443364423892), 'nauc_precision_at_1000_std': np.float64(0.16939930607441087), 'nauc_precision_at_1000_diff1': np.float64(-0.19765864671925434), 'nauc_mrr_at_1_max': np.float64(0.578281569389985), 'nauc_mrr_at_1_std': np.float64(0.217385453394406), 'nauc_mrr_at_1_diff1': np.float64(0.6206315047766061), 'nauc_mrr_at_3_max': np.float64(0.6712603961134999), 'nauc_mrr_at_3_std': np.float64(0.28887698316300997), 'nauc_mrr_at_3_diff1': np.float64(0.6098450617785515), 'nauc_mrr_at_5_max': np.float64(0.6708548071396309), 'nauc_mrr_at_5_std': np.float64(0.29343639669027516), 'nauc_mrr_at_5_diff1': np.float64(0.610565654599056), 'nauc_mrr_at_10_max': np.float64(0.6704038939252405), 'nauc_mrr_at_10_std': np.float64(0.29546979814561364), 'nauc_mrr_at_10_diff1': np.float64(0.6118302761257071), 'nauc_mrr_at_20_max': np.float64(0.6695100548461419), 'nauc_mrr_at_20_std': np.float64(0.29632309738484097), 'nauc_mrr_at_20_diff1': np.float64(0.6119720625408926), 'nauc_mrr_at_100_max': np.float64(0.6685844954554838), 'nauc_mrr_at_100_std': np.float64(0.29615778797801595), 'nauc_mrr_at_100_diff1': np.float64(0.6117127411777435), 'nauc_mrr_at_1000_max': np.float64(0.668409081374803), 'nauc_mrr_at_1000_std': np.float64(0.295887763601981), 'nauc_mrr_at_1000_diff1': np.float64(0.6116987690469595), 'main_score': 0.71762}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 41.92it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  3.45it/s]Batches: 100%|██████████| 2/2 [00:03<00:00,  2.09s/it]Batches: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.82 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 4.99 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.57895, 'ndcg_at_3': 0.644, 'ndcg_at_5': 0.6693, 'ndcg_at_10': 0.70226, 'ndcg_at_20': 0.72245, 'ndcg_at_100': 0.73304, 'ndcg_at_1000': 0.73423, 'map_at_1': 0.57895, 'map_at_3': 0.62719, 'map_at_5': 0.64123, 'map_at_10': 0.6542, 'map_at_20': 0.65986, 'map_at_100': 0.66162, 'map_at_1000': 0.66167, 'recall_at_1': 0.57895, 'recall_at_3': 0.69298, 'recall_at_5': 0.75439, 'recall_at_10': 0.85965, 'recall_at_20': 0.9386, 'recall_at_100': 0.99123, 'recall_at_1000': 1.0, 'precision_at_1': 0.57895, 'precision_at_3': 0.23099, 'precision_at_5': 0.15088, 'precision_at_10': 0.08596, 'precision_at_20': 0.04693, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5789473684210527, 'mrr_at_3': 0.6271929824561403, 'mrr_at_5': 0.6412280701754388, 'mrr_at_10': 0.6541979949874689, 'mrr_at_20': 0.6598564767539838, 'mrr_at_100': 0.661617803447586, 'mrr_at_1000': 0.6616706463983365, 'nauc_ndcg_at_1_max': np.float64(0.21452168490468498), 'nauc_ndcg_at_1_std': np.float64(-0.30449868522561824), 'nauc_ndcg_at_1_diff1': np.float64(0.7241158587898895), 'nauc_ndcg_at_3_max': np.float64(0.2630027404292297), 'nauc_ndcg_at_3_std': np.float64(-0.211728754961798), 'nauc_ndcg_at_3_diff1': np.float64(0.6965579294251412), 'nauc_ndcg_at_5_max': np.float64(0.2731634464546027), 'nauc_ndcg_at_5_std': np.float64(-0.20887113006324445), 'nauc_ndcg_at_5_diff1': np.float64(0.6855240714301853), 'nauc_ndcg_at_10_max': np.float64(0.3094605754213661), 'nauc_ndcg_at_10_std': np.float64(-0.18271651524387833), 'nauc_ndcg_at_10_diff1': np.float64(0.7007731247127267), 'nauc_ndcg_at_20_max': np.float64(0.2892237245511305), 'nauc_ndcg_at_20_std': np.float64(-0.2034200399369965), 'nauc_ndcg_at_20_diff1': np.float64(0.7064356000111408), 'nauc_ndcg_at_100_max': np.float64(0.2738391352206202), 'nauc_ndcg_at_100_std': np.float64(-0.22356896537430557), 'nauc_ndcg_at_100_diff1': np.float64(0.7039471605774164), 'nauc_ndcg_at_1000_max': np.float64(0.27052927643875635), 'nauc_ndcg_at_1000_std': np.float64(-0.22548952696672447), 'nauc_ndcg_at_1000_diff1': np.float64(0.705871147682864), 'nauc_map_at_1_max': np.float64(0.21452168490468498), 'nauc_map_at_1_std': np.float64(-0.30449868522561824), 'nauc_map_at_1_diff1': np.float64(0.7241158587898895), 'nauc_map_at_3_max': np.float64(0.24888427161928267), 'nauc_map_at_3_std': np.float64(-0.2431669474126701), 'nauc_map_at_3_diff1': np.float64(0.7061360666773708), 'nauc_map_at_5_max': np.float64(0.253283794227395), 'nauc_map_at_5_std': np.float64(-0.24323052635732675), 'nauc_map_at_5_diff1': np.float64(0.7014481882729072), 'nauc_map_at_10_max': np.float64(0.265586194108177), 'nauc_map_at_10_std': np.float64(-0.23420295718551126), 'nauc_map_at_10_diff1': np.float64(0.707558476151447), 'nauc_map_at_20_max': np.float64(0.2606217305422679), 'nauc_map_at_20_std': np.float64(-0.23893665866541192), 'nauc_map_at_20_diff1': np.float64(0.7089314703855758), 'nauc_map_at_100_max': np.float64(0.25860077425144146), 'nauc_map_at_100_std': np.float64(-0.24146181439780132), 'nauc_map_at_100_diff1': np.float64(0.7087187715691337), 'nauc_map_at_1000_max': np.float64(0.2584812635899041), 'nauc_map_at_1000_std': np.float64(-0.2415329308000073), 'nauc_map_at_1000_diff1': np.float64(0.7087874428692816), 'nauc_recall_at_1_max': np.float64(0.21452168490468498), 'nauc_recall_at_1_std': np.float64(-0.30449868522561824), 'nauc_recall_at_1_diff1': np.float64(0.7241158587898895), 'nauc_recall_at_3_max': np.float64(0.3098142113446936), 'nauc_recall_at_3_std': np.float64(-0.10563484222312473), 'nauc_recall_at_3_diff1': np.float64(0.6641484427292864), 'nauc_recall_at_5_max': np.float64(0.3516986318003035), 'nauc_recall_at_5_std': np.float64(-0.07372301459575906), 'nauc_recall_at_5_diff1': np.float64(0.6207143584142163), 'nauc_recall_at_10_max': np.float64(0.6067881420079767), 'nauc_recall_at_10_std': np.float64(0.1501943937954405), 'nauc_recall_at_10_diff1': np.float64(0.6653247240849005), 'nauc_recall_at_20_max': np.float64(0.6517533254780735), 'nauc_recall_at_20_std': np.float64(0.21476758286482395), 'nauc_recall_at_20_diff1': np.float64(0.7059636383657704), 'nauc_recall_at_100_max': np.float64(0.8697886921759079), 'nauc_recall_at_100_std': np.float64(0.12223365206031499), 'nauc_recall_at_100_diff1': np.float64(0.35752776970737554), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.21452168490468498), 'nauc_precision_at_1_std': np.float64(-0.30449868522561824), 'nauc_precision_at_1_diff1': np.float64(0.7241158587898895), 'nauc_precision_at_3_max': np.float64(0.30981421134469367), 'nauc_precision_at_3_std': np.float64(-0.10563484222312422), 'nauc_precision_at_3_diff1': np.float64(0.6641484427292865), 'nauc_precision_at_5_max': np.float64(0.3516986318003045), 'nauc_precision_at_5_std': np.float64(-0.07372301459575911), 'nauc_precision_at_5_diff1': np.float64(0.6207143584142158), 'nauc_precision_at_10_max': np.float64(0.606788142007977), 'nauc_precision_at_10_std': np.float64(0.15019439379544117), 'nauc_precision_at_10_diff1': np.float64(0.6653247240848993), 'nauc_precision_at_20_max': np.float64(0.6517533254780741), 'nauc_precision_at_20_std': np.float64(0.2147675828648243), 'nauc_precision_at_20_diff1': np.float64(0.7059636383657704), 'nauc_precision_at_100_max': np.float64(0.8697886921759251), 'nauc_precision_at_100_std': np.float64(0.12223365206034731), 'nauc_precision_at_100_diff1': np.float64(0.35752776970742256), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.21452168490468498), 'nauc_mrr_at_1_std': np.float64(-0.30449868522561824), 'nauc_mrr_at_1_diff1': np.float64(0.7241158587898895), 'nauc_mrr_at_3_max': np.float64(0.24888427161928267), 'nauc_mrr_at_3_std': np.float64(-0.2431669474126701), 'nauc_mrr_at_3_diff1': np.float64(0.7061360666773708), 'nauc_mrr_at_5_max': np.float64(0.253283794227395), 'nauc_mrr_at_5_std': np.float64(-0.24323052635732675), 'nauc_mrr_at_5_diff1': np.float64(0.7014481882729072), 'nauc_mrr_at_10_max': np.float64(0.265586194108177), 'nauc_mrr_at_10_std': np.float64(-0.23420295718551126), 'nauc_mrr_at_10_diff1': np.float64(0.707558476151447), 'nauc_mrr_at_20_max': np.float64(0.2606217305422679), 'nauc_mrr_at_20_std': np.float64(-0.23893665866541192), 'nauc_mrr_at_20_diff1': np.float64(0.7089314703855758), 'nauc_mrr_at_100_max': np.float64(0.25860077425144146), 'nauc_mrr_at_100_std': np.float64(-0.24146181439780132), 'nauc_mrr_at_100_diff1': np.float64(0.7087187715691337), 'nauc_mrr_at_1000_max': np.float64(0.2584812635899041), 'nauc_mrr_at_1000_std': np.float64(-0.2415329308000073), 'nauc_mrr_at_1000_diff1': np.float64(0.7087874428692816), 'main_score': 0.70226}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 30.13it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.66 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 0.76 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.63636, 'ndcg_at_3': 0.74258, 'ndcg_at_5': 0.76381, 'ndcg_at_10': 0.77668, 'ndcg_at_20': 0.79046, 'ndcg_at_100': 0.79808, 'ndcg_at_1000': 0.79808, 'map_at_1': 0.63636, 'map_at_3': 0.71645, 'map_at_5': 0.72814, 'map_at_10': 0.7336, 'map_at_20': 0.73772, 'map_at_100': 0.73893, 'map_at_1000': 0.73893, 'recall_at_1': 0.63636, 'recall_at_3': 0.81818, 'recall_at_5': 0.87013, 'recall_at_10': 0.90909, 'recall_at_20': 0.96104, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.63636, 'precision_at_3': 0.27273, 'precision_at_5': 0.17403, 'precision_at_10': 0.09091, 'precision_at_20': 0.04805, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6363636363636364, 'mrr_at_3': 0.7164502164502166, 'mrr_at_5': 0.7281385281385282, 'mrr_at_10': 0.7336013193156052, 'mrr_at_20': 0.7377194955117035, 'mrr_at_100': 0.7389261195754704, 'mrr_at_1000': 0.7389261195754704, 'nauc_ndcg_at_1_max': np.float64(0.3380114637037834), 'nauc_ndcg_at_1_std': np.float64(0.14329973353239706), 'nauc_ndcg_at_1_diff1': np.float64(0.45937814049806025), 'nauc_ndcg_at_3_max': np.float64(0.28222315453049995), 'nauc_ndcg_at_3_std': np.float64(0.1918532103834529), 'nauc_ndcg_at_3_diff1': np.float64(0.3817879872323738), 'nauc_ndcg_at_5_max': np.float64(0.2934415902789186), 'nauc_ndcg_at_5_std': np.float64(0.2114869862530737), 'nauc_ndcg_at_5_diff1': np.float64(0.41180375180453893), 'nauc_ndcg_at_10_max': np.float64(0.2887744358518272), 'nauc_ndcg_at_10_std': np.float64(0.17829695305056045), 'nauc_ndcg_at_10_diff1': np.float64(0.4467438084863242), 'nauc_ndcg_at_20_max': np.float64(0.25736981490205063), 'nauc_ndcg_at_20_std': np.float64(0.17387315783401738), 'nauc_ndcg_at_20_diff1': np.float64(0.42733437171327604), 'nauc_ndcg_at_100_max': np.float64(0.2901820119191121), 'nauc_ndcg_at_100_std': np.float64(0.17473632926536659), 'nauc_ndcg_at_100_diff1': np.float64(0.42766620307163267), 'nauc_ndcg_at_1000_max': np.float64(0.2901820119191121), 'nauc_ndcg_at_1000_std': np.float64(0.17473632926536659), 'nauc_ndcg_at_1000_diff1': np.float64(0.42766620307163267), 'nauc_map_at_1_max': np.float64(0.3380114637037834), 'nauc_map_at_1_std': np.float64(0.14329973353239706), 'nauc_map_at_1_diff1': np.float64(0.45937814049806025), 'nauc_map_at_3_max': np.float64(0.2946498610278931), 'nauc_map_at_3_std': np.float64(0.17476969257605832), 'nauc_map_at_3_diff1': np.float64(0.4059313436356904), 'nauc_map_at_5_max': np.float64(0.30001556897999604), 'nauc_map_at_5_std': np.float64(0.1818274595741129), 'nauc_map_at_5_diff1': np.float64(0.42130543779788465), 'nauc_map_at_10_max': np.float64(0.2989589485776121), 'nauc_map_at_10_std': np.float64(0.1695347928159486), 'nauc_map_at_10_diff1': np.float64(0.4323949040119045), 'nauc_map_at_20_max': np.float64(0.2914960114625936), 'nauc_map_at_20_std': np.float64(0.16931835449622934), 'nauc_map_at_20_diff1': np.float64(0.4276218898141522), 'nauc_map_at_100_max': np.float64(0.29655938226853895), 'nauc_map_at_100_std': np.float64(0.16965435334338097), 'nauc_map_at_100_diff1': np.float64(0.42820913623880263), 'nauc_map_at_1000_max': np.float64(0.29655938226853895), 'nauc_map_at_1000_std': np.float64(0.16965435334338097), 'nauc_map_at_1000_diff1': np.float64(0.42820913623880263), 'nauc_recall_at_1_max': np.float64(0.3380114637037834), 'nauc_recall_at_1_std': np.float64(0.14329973353239706), 'nauc_recall_at_1_diff1': np.float64(0.45937814049806025), 'nauc_recall_at_3_max': np.float64(0.23418646199374452), 'nauc_recall_at_3_std': np.float64(0.2626933300855841), 'nauc_recall_at_3_diff1': np.float64(0.28320383433592566), 'nauc_recall_at_5_max': np.float64(0.26644964766720547), 'nauc_recall_at_5_std': np.float64(0.3791588331197811), 'nauc_recall_at_5_diff1': np.float64(0.3694882015112925), 'nauc_recall_at_10_max': np.float64(0.21921244145276816), 'nauc_recall_at_10_std': np.float64(0.22604822080113), 'nauc_recall_at_10_diff1': np.float64(0.6008869257776108), 'nauc_recall_at_20_max': np.float64(-0.415662658177714), 'nauc_recall_at_20_std': np.float64(0.1733581762182262), 'nauc_recall_at_20_diff1': np.float64(0.4627549073276888), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.3380114637037834), 'nauc_precision_at_1_std': np.float64(0.14329973353239706), 'nauc_precision_at_1_diff1': np.float64(0.45937814049806025), 'nauc_precision_at_3_max': np.float64(0.23418646199374446), 'nauc_precision_at_3_std': np.float64(0.26269333008558554), 'nauc_precision_at_3_diff1': np.float64(0.2832038343359279), 'nauc_precision_at_5_max': np.float64(0.26644964766720663), 'nauc_precision_at_5_std': np.float64(0.37915883311978194), 'nauc_precision_at_5_diff1': np.float64(0.3694882015112947), 'nauc_precision_at_10_max': np.float64(0.21921244145277002), 'nauc_precision_at_10_std': np.float64(0.22604822080113116), 'nauc_precision_at_10_diff1': np.float64(0.6008869257776103), 'nauc_precision_at_20_max': np.float64(-0.4156626581777089), 'nauc_precision_at_20_std': np.float64(0.17335817621822872), 'nauc_precision_at_20_diff1': np.float64(0.4627549073276905), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.3380114637037834), 'nauc_mrr_at_1_std': np.float64(0.14329973353239706), 'nauc_mrr_at_1_diff1': np.float64(0.45937814049806025), 'nauc_mrr_at_3_max': np.float64(0.2946498610278931), 'nauc_mrr_at_3_std': np.float64(0.17476969257605832), 'nauc_mrr_at_3_diff1': np.float64(0.4059313436356904), 'nauc_mrr_at_5_max': np.float64(0.30001556897999604), 'nauc_mrr_at_5_std': np.float64(0.1818274595741129), 'nauc_mrr_at_5_diff1': np.float64(0.42130543779788465), 'nauc_mrr_at_10_max': np.float64(0.2989589485776121), 'nauc_mrr_at_10_std': np.float64(0.1695347928159486), 'nauc_mrr_at_10_diff1': np.float64(0.4323949040119045), 'nauc_mrr_at_20_max': np.float64(0.2914960114625936), 'nauc_mrr_at_20_std': np.float64(0.16931835449622934), 'nauc_mrr_at_20_diff1': np.float64(0.4276218898141522), 'nauc_mrr_at_100_max': np.float64(0.29655938226853895), 'nauc_mrr_at_100_std': np.float64(0.16965435334338097), 'nauc_mrr_at_100_diff1': np.float64(0.42820913623880263), 'nauc_mrr_at_1000_max': np.float64(0.29655938226853895), 'nauc_mrr_at_1000_std': np.float64(0.16965435334338097), 'nauc_mrr_at_1000_diff1': np.float64(0.42820913623880263), 'main_score': 0.77668}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.08it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.05it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.94 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.47it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.44it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.95 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.32it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.29it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.77 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 10.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.74889, 'ndcg_at_3': 0.81059, 'ndcg_at_5': 0.82006, 'ndcg_at_10': 0.83231, 'ndcg_at_20': 0.83986, 'ndcg_at_100': 0.84798, 'ndcg_at_1000': 0.84959, 'map_at_1': 0.74889, 'map_at_3': 0.79611, 'map_at_5': 0.80128, 'map_at_10': 0.80635, 'map_at_20': 0.8084, 'map_at_100': 0.80948, 'map_at_1000': 0.80955, 'recall_at_1': 0.74889, 'recall_at_3': 0.85222, 'recall_at_5': 0.87556, 'recall_at_10': 0.91333, 'recall_at_20': 0.94333, 'recall_at_100': 0.98778, 'recall_at_1000': 1.0, 'precision_at_1': 0.74889, 'precision_at_3': 0.28407, 'precision_at_5': 0.17511, 'precision_at_10': 0.09133, 'precision_at_20': 0.04717, 'precision_at_100': 0.00988, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7488888888888889, 'mrr_at_3': 0.7961111111111112, 'mrr_at_5': 0.801277777777778, 'mrr_at_10': 0.8063514109347443, 'mrr_at_20': 0.8084048977958936, 'mrr_at_100': 0.809484302609092, 'mrr_at_1000': 0.8095513016399172, 'nauc_ndcg_at_1_max': np.float64(0.769724370947484), 'nauc_ndcg_at_1_std': np.float64(0.12039478867821318), 'nauc_ndcg_at_1_diff1': np.float64(0.8987050486417844), 'nauc_ndcg_at_3_max': np.float64(0.7887082503888294), 'nauc_ndcg_at_3_std': np.float64(0.1734622059226956), 'nauc_ndcg_at_3_diff1': np.float64(0.8643545554164997), 'nauc_ndcg_at_5_max': np.float64(0.792057712606042), 'nauc_ndcg_at_5_std': np.float64(0.18925999456380532), 'nauc_ndcg_at_5_diff1': np.float64(0.8664656932856943), 'nauc_ndcg_at_10_max': np.float64(0.7910644280597394), 'nauc_ndcg_at_10_std': np.float64(0.1855225032681675), 'nauc_ndcg_at_10_diff1': np.float64(0.865107027002684), 'nauc_ndcg_at_20_max': np.float64(0.7899402004864259), 'nauc_ndcg_at_20_std': np.float64(0.18951512086408007), 'nauc_ndcg_at_20_diff1': np.float64(0.8675145109128968), 'nauc_ndcg_at_100_max': np.float64(0.7875332857794105), 'nauc_ndcg_at_100_std': np.float64(0.17974934106771445), 'nauc_ndcg_at_100_diff1': np.float64(0.8706169772934337), 'nauc_ndcg_at_1000_max': np.float64(0.787151252028159), 'nauc_ndcg_at_1000_std': np.float64(0.1762320375564522), 'nauc_ndcg_at_1000_diff1': np.float64(0.8713631724953789), 'nauc_map_at_1_max': np.float64(0.769724370947484), 'nauc_map_at_1_std': np.float64(0.12039478867821318), 'nauc_map_at_1_diff1': np.float64(0.8987050486417844), 'nauc_map_at_3_max': np.float64(0.7845079599887295), 'nauc_map_at_3_std': np.float64(0.16061835431774726), 'nauc_map_at_3_diff1': np.float64(0.8732811132861749), 'nauc_map_at_5_max': np.float64(0.786256681531028), 'nauc_map_at_5_std': np.float64(0.16857502428244714), 'nauc_map_at_5_diff1': np.float64(0.8746788814470525), 'nauc_map_at_10_max': np.float64(0.7856952163938661), 'nauc_map_at_10_std': np.float64(0.16657420731674685), 'nauc_map_at_10_diff1': np.float64(0.8742554639101419), 'nauc_map_at_20_max': np.float64(0.7853789695250392), 'nauc_map_at_20_std': np.float64(0.1674603316514243), 'nauc_map_at_20_diff1': np.float64(0.8748833738964502), 'nauc_map_at_100_max': np.float64(0.7850150772243881), 'nauc_map_at_100_std': np.float64(0.16638093016415736), 'nauc_map_at_100_diff1': np.float64(0.875220398609825), 'nauc_map_at_1000_max': np.float64(0.7850052859210338), 'nauc_map_at_1000_std': np.float64(0.16627966890558082), 'nauc_map_at_1000_diff1': np.float64(0.8752384197193381), 'nauc_recall_at_1_max': np.float64(0.769724370947484), 'nauc_recall_at_1_std': np.float64(0.12039478867821318), 'nauc_recall_at_1_diff1': np.float64(0.8987050486417844), 'nauc_recall_at_3_max': np.float64(0.8039810002712153), 'nauc_recall_at_3_std': np.float64(0.2209488136164729), 'nauc_recall_at_3_diff1': np.float64(0.8309522587833428), 'nauc_recall_at_5_max': np.float64(0.8167824628653568), 'nauc_recall_at_5_std': np.float64(0.2801013074132378), 'nauc_recall_at_5_diff1': np.float64(0.8317603874324048), 'nauc_recall_at_10_max': np.float64(0.8217398070339238), 'nauc_recall_at_10_std': np.float64(0.2968409586056635), 'nauc_recall_at_10_diff1': np.float64(0.8119717972659146), 'nauc_recall_at_20_max': np.float64(0.8261840683986019), 'nauc_recall_at_20_std': np.float64(0.39284341187455274), 'nauc_recall_at_20_diff1': np.float64(0.8095512714889888), 'nauc_recall_at_100_max': np.float64(0.8223834988540899), 'nauc_recall_at_100_std': np.float64(0.49337916984975977), 'nauc_recall_at_100_diff1': np.float64(0.8007384772090669), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.769724370947484), 'nauc_precision_at_1_std': np.float64(0.12039478867821318), 'nauc_precision_at_1_diff1': np.float64(0.8987050486417844), 'nauc_precision_at_3_max': np.float64(0.8039810002712149), 'nauc_precision_at_3_std': np.float64(0.22094881361647148), 'nauc_precision_at_3_diff1': np.float64(0.8309522587833434), 'nauc_precision_at_5_max': np.float64(0.8167824628653552), 'nauc_precision_at_5_std': np.float64(0.28010130741323624), 'nauc_precision_at_5_diff1': np.float64(0.8317603874324037), 'nauc_precision_at_10_max': np.float64(0.8217398070339236), 'nauc_precision_at_10_std': np.float64(0.2968409586056634), 'nauc_precision_at_10_diff1': np.float64(0.8119717972659144), 'nauc_precision_at_20_max': np.float64(0.8261840683985986), 'nauc_precision_at_20_std': np.float64(0.3928434118745523), 'nauc_precision_at_20_diff1': np.float64(0.809551271488986), 'nauc_precision_at_100_max': np.float64(0.8223834988540969), 'nauc_precision_at_100_std': np.float64(0.4933791698497789), 'nauc_precision_at_100_diff1': np.float64(0.800738477209076), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.769724370947484), 'nauc_mrr_at_1_std': np.float64(0.12039478867821318), 'nauc_mrr_at_1_diff1': np.float64(0.8987050486417844), 'nauc_mrr_at_3_max': np.float64(0.7845079599887295), 'nauc_mrr_at_3_std': np.float64(0.16061835431774726), 'nauc_mrr_at_3_diff1': np.float64(0.8732811132861749), 'nauc_mrr_at_5_max': np.float64(0.786256681531028), 'nauc_mrr_at_5_std': np.float64(0.16857502428244714), 'nauc_mrr_at_5_diff1': np.float64(0.8746788814470525), 'nauc_mrr_at_10_max': np.float64(0.7856952163938661), 'nauc_mrr_at_10_std': np.float64(0.16657420731674685), 'nauc_mrr_at_10_diff1': np.float64(0.8742554639101419), 'nauc_mrr_at_20_max': np.float64(0.7853789695250392), 'nauc_mrr_at_20_std': np.float64(0.1674603316514243), 'nauc_mrr_at_20_diff1': np.float64(0.8748833738964502), 'nauc_mrr_at_100_max': np.float64(0.7850150772243881), 'nauc_mrr_at_100_std': np.float64(0.16638093016415736), 'nauc_mrr_at_100_diff1': np.float64(0.875220398609825), 'nauc_mrr_at_1000_max': np.float64(0.7850052859210338), 'nauc_mrr_at_1000_std': np.float64(0.16627966890558082), 'nauc_mrr_at_1000_diff1': np.float64(0.8752384197193381), 'main_score': 0.83231}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.69889, 'ndcg_at_3': 0.7762, 'ndcg_at_5': 0.79657, 'ndcg_at_10': 0.81364, 'ndcg_at_20': 0.81932, 'ndcg_at_100': 0.82716, 'ndcg_at_1000': 0.82761, 'map_at_1': 0.69889, 'map_at_3': 0.75722, 'map_at_5': 0.76839, 'map_at_10': 0.77555, 'map_at_20': 0.77714, 'map_at_100': 0.77831, 'map_at_1000': 0.77833, 'recall_at_1': 0.69889, 'recall_at_3': 0.83111, 'recall_at_5': 0.88111, 'recall_at_10': 0.93333, 'recall_at_20': 0.95556, 'recall_at_100': 0.99667, 'recall_at_1000': 1.0, 'precision_at_1': 0.69889, 'precision_at_3': 0.27704, 'precision_at_5': 0.17622, 'precision_at_10': 0.09333, 'precision_at_20': 0.04778, 'precision_at_100': 0.00997, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6988888888888889, 'mrr_at_3': 0.7572222222222225, 'mrr_at_5': 0.7683888888888893, 'mrr_at_10': 0.7755454144620817, 'mrr_at_20': 0.7771402314527965, 'mrr_at_100': 0.7783058301327498, 'mrr_at_1000': 0.7783271729167978, 'nauc_ndcg_at_1_max': np.float64(0.6170930374198497), 'nauc_ndcg_at_1_std': np.float64(-0.08394554861744855), 'nauc_ndcg_at_1_diff1': np.float64(0.7848024170439133), 'nauc_ndcg_at_3_max': np.float64(0.6527497138609692), 'nauc_ndcg_at_3_std': np.float64(-0.03535693740605097), 'nauc_ndcg_at_3_diff1': np.float64(0.7480911116553409), 'nauc_ndcg_at_5_max': np.float64(0.6520463578255307), 'nauc_ndcg_at_5_std': np.float64(-0.02931187388613967), 'nauc_ndcg_at_5_diff1': np.float64(0.7466323401837486), 'nauc_ndcg_at_10_max': np.float64(0.6467087097920128), 'nauc_ndcg_at_10_std': np.float64(-0.03338964776710021), 'nauc_ndcg_at_10_diff1': np.float64(0.7502289298972602), 'nauc_ndcg_at_20_max': np.float64(0.6456495169816096), 'nauc_ndcg_at_20_std': np.float64(-0.03748132098441082), 'nauc_ndcg_at_20_diff1': np.float64(0.7536168863409384), 'nauc_ndcg_at_100_max': np.float64(0.6458105435652317), 'nauc_ndcg_at_100_std': np.float64(-0.03970456154786897), 'nauc_ndcg_at_100_diff1': np.float64(0.7585770536715946), 'nauc_ndcg_at_1000_max': np.float64(0.6450298921969536), 'nauc_ndcg_at_1000_std': np.float64(-0.04165764186072046), 'nauc_ndcg_at_1000_diff1': np.float64(0.7584605188659838), 'nauc_map_at_1_max': np.float64(0.6170930374198497), 'nauc_map_at_1_std': np.float64(-0.08394554861744855), 'nauc_map_at_1_diff1': np.float64(0.7848024170439133), 'nauc_map_at_3_max': np.float64(0.6451571239088979), 'nauc_map_at_3_std': np.float64(-0.04679988019819276), 'nauc_map_at_3_diff1': np.float64(0.7587721034534187), 'nauc_map_at_5_max': np.float64(0.6448380720031306), 'nauc_map_at_5_std': np.float64(-0.04393849341918354), 'nauc_map_at_5_diff1': np.float64(0.7587890049329321), 'nauc_map_at_10_max': np.float64(0.6428281638861976), 'nauc_map_at_10_std': np.float64(-0.04525870883823384), 'nauc_map_at_10_diff1': np.float64(0.7603466586496285), 'nauc_map_at_20_max': np.float64(0.6425519824938378), 'nauc_map_at_20_std': np.float64(-0.0462468304959706), 'nauc_map_at_20_diff1': np.float64(0.761203865960089), 'nauc_map_at_100_max': np.float64(0.6425510967771912), 'nauc_map_at_100_std': np.float64(-0.04670675471599345), 'nauc_map_at_100_diff1': np.float64(0.7619159748738072), 'nauc_map_at_1000_max': np.float64(0.6425205260336119), 'nauc_map_at_1000_std': np.float64(-0.04678575796320399), 'nauc_map_at_1000_diff1': np.float64(0.761906711751256), 'nauc_recall_at_1_max': np.float64(0.6170930374198497), 'nauc_recall_at_1_std': np.float64(-0.08394554861744855), 'nauc_recall_at_1_diff1': np.float64(0.7848024170439133), 'nauc_recall_at_3_max': np.float64(0.6808489929401992), 'nauc_recall_at_3_std': np.float64(0.007825477574751912), 'nauc_recall_at_3_diff1': np.float64(0.7063856156561462), 'nauc_recall_at_5_max': np.float64(0.6858051810331764), 'nauc_recall_at_5_std': np.float64(0.044142153149702185), 'nauc_recall_at_5_diff1': np.float64(0.6834793302262586), 'nauc_recall_at_10_max': np.float64(0.6679349517584809), 'nauc_recall_at_10_std': np.float64(0.05727513227513247), 'nauc_recall_at_10_diff1': np.float64(0.6659819483348884), 'nauc_recall_at_20_max': np.float64(0.6633520074696536), 'nauc_recall_at_20_std': np.float64(0.04241363211951366), 'nauc_recall_at_20_diff1': np.float64(0.6721638655462191), 'nauc_recall_at_100_max': np.float64(0.9074074074073892), 'nauc_recall_at_100_std': np.float64(0.6095549330843201), 'nauc_recall_at_100_diff1': np.float64(0.7860255213196327), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6170930374198497), 'nauc_precision_at_1_std': np.float64(-0.08394554861744855), 'nauc_precision_at_1_diff1': np.float64(0.7848024170439133), 'nauc_precision_at_3_max': np.float64(0.6808489929401994), 'nauc_precision_at_3_std': np.float64(0.007825477574750283), 'nauc_precision_at_3_diff1': np.float64(0.7063856156561461), 'nauc_precision_at_5_max': np.float64(0.6858051810331761), 'nauc_precision_at_5_std': np.float64(0.04414215314970055), 'nauc_precision_at_5_diff1': np.float64(0.6834793302262564), 'nauc_precision_at_10_max': np.float64(0.6679349517584791), 'nauc_precision_at_10_std': np.float64(0.057275132275129995), 'nauc_precision_at_10_diff1': np.float64(0.6659819483348887), 'nauc_precision_at_20_max': np.float64(0.6633520074696505), 'nauc_precision_at_20_std': np.float64(0.04241363211950837), 'nauc_precision_at_20_diff1': np.float64(0.6721638655462181), 'nauc_precision_at_100_max': np.float64(0.9074074074074131), 'nauc_precision_at_100_std': np.float64(0.6095549330843759), 'nauc_precision_at_100_diff1': np.float64(0.7860255213196017), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6170930374198497), 'nauc_mrr_at_1_std': np.float64(-0.08394554861744855), 'nauc_mrr_at_1_diff1': np.float64(0.7848024170439133), 'nauc_mrr_at_3_max': np.float64(0.6451571239088979), 'nauc_mrr_at_3_std': np.float64(-0.04679988019819276), 'nauc_mrr_at_3_diff1': np.float64(0.7587721034534187), 'nauc_mrr_at_5_max': np.float64(0.6448380720031306), 'nauc_mrr_at_5_std': np.float64(-0.04393849341918354), 'nauc_mrr_at_5_diff1': np.float64(0.7587890049329321), 'nauc_mrr_at_10_max': np.float64(0.6428281638861976), 'nauc_mrr_at_10_std': np.float64(-0.04525870883823384), 'nauc_mrr_at_10_diff1': np.float64(0.7603466586496285), 'nauc_mrr_at_20_max': np.float64(0.6425519824938378), 'nauc_mrr_at_20_std': np.float64(-0.0462468304959706), 'nauc_mrr_at_20_diff1': np.float64(0.761203865960089), 'nauc_mrr_at_100_max': np.float64(0.6425510967771912), 'nauc_mrr_at_100_std': np.float64(-0.04670675471599345), 'nauc_mrr_at_100_diff1': np.float64(0.7619159748738072), 'nauc_mrr_at_1000_max': np.float64(0.6425205260336119), 'nauc_mrr_at_1000_std': np.float64(-0.04678575796320399), 'nauc_mrr_at_1000_diff1': np.float64(0.761906711751256), 'main_score': 0.81364}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.60444, 'ndcg_at_3': 0.68643, 'ndcg_at_5': 0.70613, 'ndcg_at_10': 0.72935, 'ndcg_at_20': 0.73847, 'ndcg_at_100': 0.75214, 'ndcg_at_1000': 0.75612, 'map_at_1': 0.60444, 'map_at_3': 0.66704, 'map_at_5': 0.67798, 'map_at_10': 0.68771, 'map_at_20': 0.69029, 'map_at_100': 0.69219, 'map_at_1000': 0.69236, 'recall_at_1': 0.60444, 'recall_at_3': 0.74222, 'recall_at_5': 0.79, 'recall_at_10': 0.86111, 'recall_at_20': 0.89667, 'recall_at_100': 0.97, 'recall_at_1000': 1.0, 'precision_at_1': 0.60444, 'precision_at_3': 0.24741, 'precision_at_5': 0.158, 'precision_at_10': 0.08611, 'precision_at_20': 0.04483, 'precision_at_100': 0.0097, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6044444444444445, 'mrr_at_3': 0.6670370370370369, 'mrr_at_5': 0.6779814814814813, 'mrr_at_10': 0.687712962962963, 'mrr_at_20': 0.6902861010821536, 'mrr_at_100': 0.6921933983514484, 'mrr_at_1000': 0.6923645791831908, 'nauc_ndcg_at_1_max': np.float64(0.6354093260115142), 'nauc_ndcg_at_1_std': np.float64(0.07498770094004718), 'nauc_ndcg_at_1_diff1': np.float64(0.7555295908734323), 'nauc_ndcg_at_3_max': np.float64(0.6550177061106123), 'nauc_ndcg_at_3_std': np.float64(0.14400897628846981), 'nauc_ndcg_at_3_diff1': np.float64(0.7013937284540342), 'nauc_ndcg_at_5_max': np.float64(0.6657407708095261), 'nauc_ndcg_at_5_std': np.float64(0.16896889457008535), 'nauc_ndcg_at_5_diff1': np.float64(0.7028517782729247), 'nauc_ndcg_at_10_max': np.float64(0.6636304934979466), 'nauc_ndcg_at_10_std': np.float64(0.16096311358585974), 'nauc_ndcg_at_10_diff1': np.float64(0.7017568070479626), 'nauc_ndcg_at_20_max': np.float64(0.6613502306460927), 'nauc_ndcg_at_20_std': np.float64(0.16170258171817603), 'nauc_ndcg_at_20_diff1': np.float64(0.7009214241904399), 'nauc_ndcg_at_100_max': np.float64(0.6584080915297769), 'nauc_ndcg_at_100_std': np.float64(0.15286649212311293), 'nauc_ndcg_at_100_diff1': np.float64(0.7065219277722831), 'nauc_ndcg_at_1000_max': np.float64(0.6569537712266803), 'nauc_ndcg_at_1000_std': np.float64(0.14494829487332683), 'nauc_ndcg_at_1000_diff1': np.float64(0.7107205688377287), 'nauc_map_at_1_max': np.float64(0.6354093260115142), 'nauc_map_at_1_std': np.float64(0.07498770094004718), 'nauc_map_at_1_diff1': np.float64(0.7555295908734323), 'nauc_map_at_3_max': np.float64(0.6488138776223844), 'nauc_map_at_3_std': np.float64(0.1232889290842282), 'nauc_map_at_3_diff1': np.float64(0.7156928905612723), 'nauc_map_at_5_max': np.float64(0.6542759542411197), 'nauc_map_at_5_std': np.float64(0.13553714641363354), 'nauc_map_at_5_diff1': np.float64(0.7167384959060558), 'nauc_map_at_10_max': np.float64(0.6532120677812777), 'nauc_map_at_10_std': np.float64(0.13125309936536475), 'nauc_map_at_10_diff1': np.float64(0.716821624833947), 'nauc_map_at_20_max': np.float64(0.6526068365059994), 'nauc_map_at_20_std': np.float64(0.13094637687910235), 'nauc_map_at_20_diff1': np.float64(0.7167322426287197), 'nauc_map_at_100_max': np.float64(0.6524229158641769), 'nauc_map_at_100_std': np.float64(0.1302386915812793), 'nauc_map_at_100_diff1': np.float64(0.7176858567903471), 'nauc_map_at_1000_max': np.float64(0.6523641697340558), 'nauc_map_at_1000_std': np.float64(0.12996121019832832), 'nauc_map_at_1000_diff1': np.float64(0.7178314560834064), 'nauc_recall_at_1_max': np.float64(0.6354093260115142), 'nauc_recall_at_1_std': np.float64(0.07498770094004718), 'nauc_recall_at_1_diff1': np.float64(0.7555295908734323), 'nauc_recall_at_3_max': np.float64(0.6769584668015719), 'nauc_recall_at_3_std': np.float64(0.2168083774194429), 'nauc_recall_at_3_diff1': np.float64(0.6520380940281857), 'nauc_recall_at_5_max': np.float64(0.7136418164864549), 'nauc_recall_at_5_std': np.float64(0.30765223106579764), 'nauc_recall_at_5_diff1': np.float64(0.6485520314841972), 'nauc_recall_at_10_max': np.float64(0.7232409381663104), 'nauc_recall_at_10_std': np.float64(0.3305408024811007), 'nauc_recall_at_10_diff1': np.float64(0.6178910641597198), 'nauc_recall_at_20_max': np.float64(0.7212778399524103), 'nauc_recall_at_20_std': np.float64(0.3918262202191913), 'nauc_recall_at_20_diff1': np.float64(0.5859976003952287), 'nauc_recall_at_100_max': np.float64(0.7307639105024742), 'nauc_recall_at_100_std': np.float64(0.5622989936715469), 'nauc_recall_at_100_diff1': np.float64(0.4892450807483507), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6354093260115142), 'nauc_precision_at_1_std': np.float64(0.07498770094004718), 'nauc_precision_at_1_diff1': np.float64(0.7555295908734323), 'nauc_precision_at_3_max': np.float64(0.6769584668015726), 'nauc_precision_at_3_std': np.float64(0.2168083774194431), 'nauc_precision_at_3_diff1': np.float64(0.6520380940281854), 'nauc_precision_at_5_max': np.float64(0.7136418164864551), 'nauc_precision_at_5_std': np.float64(0.30765223106579714), 'nauc_precision_at_5_diff1': np.float64(0.6485520314841962), 'nauc_precision_at_10_max': np.float64(0.7232409381663095), 'nauc_precision_at_10_std': np.float64(0.3305408024810991), 'nauc_precision_at_10_diff1': np.float64(0.61789106415972), 'nauc_precision_at_20_max': np.float64(0.7212778399524097), 'nauc_precision_at_20_std': np.float64(0.39182622021919034), 'nauc_precision_at_20_diff1': np.float64(0.5859976003952284), 'nauc_precision_at_100_max': np.float64(0.7307639105024795), 'nauc_precision_at_100_std': np.float64(0.5622989936715451), 'nauc_precision_at_100_diff1': np.float64(0.4892450807483536), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6354093260115142), 'nauc_mrr_at_1_std': np.float64(0.07498770094004718), 'nauc_mrr_at_1_diff1': np.float64(0.7555295908734323), 'nauc_mrr_at_3_max': np.float64(0.6488138776223844), 'nauc_mrr_at_3_std': np.float64(0.1232889290842282), 'nauc_mrr_at_3_diff1': np.float64(0.7156928905612723), 'nauc_mrr_at_5_max': np.float64(0.6542759542411197), 'nauc_mrr_at_5_std': np.float64(0.13553714641363354), 'nauc_mrr_at_5_diff1': np.float64(0.7167384959060558), 'nauc_mrr_at_10_max': np.float64(0.6532120677812777), 'nauc_mrr_at_10_std': np.float64(0.13125309936536475), 'nauc_mrr_at_10_diff1': np.float64(0.716821624833947), 'nauc_mrr_at_20_max': np.float64(0.6526068365059994), 'nauc_mrr_at_20_std': np.float64(0.13094637687910235), 'nauc_mrr_at_20_diff1': np.float64(0.7167322426287197), 'nauc_mrr_at_100_max': np.float64(0.6524229158641769), 'nauc_mrr_at_100_std': np.float64(0.1302386915812793), 'nauc_mrr_at_100_diff1': np.float64(0.7176858567903471), 'nauc_mrr_at_1000_max': np.float64(0.6523641697340558), 'nauc_mrr_at_1000_std': np.float64(0.12996121019832832), 'nauc_mrr_at_1000_diff1': np.float64(0.7178314560834064), 'main_score': 0.72935}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.84it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.01it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.52 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.80it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:00<00:00,  6.09it/s]Batches:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]Batches: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.58 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.61 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 9.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.18654, 'ndcg_at_3': 0.19216, 'ndcg_at_5': 0.20659, 'ndcg_at_10': 0.22975, 'ndcg_at_20': 0.25191, 'ndcg_at_100': 0.30138, 'ndcg_at_1000': 0.3536, 'map_at_1': 0.13048, 'map_at_3': 0.16994, 'map_at_5': 0.18096, 'map_at_10': 0.19223, 'map_at_20': 0.19862, 'map_at_100': 0.20572, 'map_at_1000': 0.20795, 'recall_at_1': 0.13048, 'recall_at_3': 0.20181, 'recall_at_5': 0.23739, 'recall_at_10': 0.30076, 'recall_at_20': 0.37984, 'recall_at_100': 0.62747, 'recall_at_1000': 1.0, 'precision_at_1': 0.18654, 'precision_at_3': 0.10398, 'precision_at_5': 0.07431, 'precision_at_10': 0.04755, 'precision_at_20': 0.02982, 'precision_at_100': 0.00965, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.18960244648318042, 'mrr_at_3': 0.2206931702344547, 'mrr_at_5': 0.2282619775739042, 'mrr_at_10': 0.23622275617688462, 'mrr_at_20': 0.2426490358891943, 'mrr_at_100': 0.2485056321988804, 'mrr_at_1000': 0.2498829356745312, 'nauc_ndcg_at_1_max': np.float64(0.1365786261494849), 'nauc_ndcg_at_1_std': np.float64(-0.2687413223634894), 'nauc_ndcg_at_1_diff1': np.float64(0.5424527203206293), 'nauc_ndcg_at_3_max': np.float64(0.10933154300468322), 'nauc_ndcg_at_3_std': np.float64(-0.225427726259147), 'nauc_ndcg_at_3_diff1': np.float64(0.44000607447234796), 'nauc_ndcg_at_5_max': np.float64(0.1080769845926262), 'nauc_ndcg_at_5_std': np.float64(-0.2097089269145889), 'nauc_ndcg_at_5_diff1': np.float64(0.4123896718646257), 'nauc_ndcg_at_10_max': np.float64(0.12200904249240174), 'nauc_ndcg_at_10_std': np.float64(-0.21939585274251094), 'nauc_ndcg_at_10_diff1': np.float64(0.3888368991911993), 'nauc_ndcg_at_20_max': np.float64(0.13339440923408818), 'nauc_ndcg_at_20_std': np.float64(-0.20000585553544675), 'nauc_ndcg_at_20_diff1': np.float64(0.38445913465920256), 'nauc_ndcg_at_100_max': np.float64(0.1531894508059785), 'nauc_ndcg_at_100_std': np.float64(-0.17294784610358258), 'nauc_ndcg_at_100_diff1': np.float64(0.37247906309491136), 'nauc_ndcg_at_1000_max': np.float64(0.13797713457682753), 'nauc_ndcg_at_1000_std': np.float64(-0.19678189158856643), 'nauc_ndcg_at_1000_diff1': np.float64(0.39931636956565386), 'nauc_map_at_1_max': np.float64(0.12131490618503277), 'nauc_map_at_1_std': np.float64(-0.21652974946136885), 'nauc_map_at_1_diff1': np.float64(0.5204177248021352), 'nauc_map_at_3_max': np.float64(0.11483263361477618), 'nauc_map_at_3_std': np.float64(-0.2152558938141256), 'nauc_map_at_3_diff1': np.float64(0.4440471144788799), 'nauc_map_at_5_max': np.float64(0.11257027958183427), 'nauc_map_at_5_std': np.float64(-0.21087738232152214), 'nauc_map_at_5_diff1': np.float64(0.4276039632328872), 'nauc_map_at_10_max': np.float64(0.11919296126375223), 'nauc_map_at_10_std': np.float64(-0.2171599517987878), 'nauc_map_at_10_diff1': np.float64(0.4158846752890592), 'nauc_map_at_20_max': np.float64(0.12248804055077422), 'nauc_map_at_20_std': np.float64(-0.21202939465312864), 'nauc_map_at_20_diff1': np.float64(0.41424628033231525), 'nauc_map_at_100_max': np.float64(0.12519116050531368), 'nauc_map_at_100_std': np.float64(-0.20828247845994521), 'nauc_map_at_100_diff1': np.float64(0.4129202923558396), 'nauc_map_at_1000_max': np.float64(0.12499895153368884), 'nauc_map_at_1000_std': np.float64(-0.2088986302528944), 'nauc_map_at_1000_diff1': np.float64(0.41398029342879905), 'nauc_recall_at_1_max': np.float64(0.12131490618503277), 'nauc_recall_at_1_std': np.float64(-0.21652974946136885), 'nauc_recall_at_1_diff1': np.float64(0.5204177248021352), 'nauc_recall_at_3_max': np.float64(0.09919635231898943), 'nauc_recall_at_3_std': np.float64(-0.19857687115002912), 'nauc_recall_at_3_diff1': np.float64(0.3799414322536562), 'nauc_recall_at_5_max': np.float64(0.09224101327388858), 'nauc_recall_at_5_std': np.float64(-0.16736524229087055), 'nauc_recall_at_5_diff1': np.float64(0.32301126332918884), 'nauc_recall_at_10_max': np.float64(0.12887212198669137), 'nauc_recall_at_10_std': np.float64(-0.18728692097222024), 'nauc_recall_at_10_diff1': np.float64(0.2689560578658039), 'nauc_recall_at_20_max': np.float64(0.1600855802099494), 'nauc_recall_at_20_std': np.float64(-0.1272161400069328), 'nauc_recall_at_20_diff1': np.float64(0.25104052162299917), 'nauc_recall_at_100_max': np.float64(0.24343104440614294), 'nauc_recall_at_100_std': np.float64(0.006095996864806184), 'nauc_recall_at_100_diff1': np.float64(0.1532456899692016), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1365786261494849), 'nauc_precision_at_1_std': np.float64(-0.2687413223634894), 'nauc_precision_at_1_diff1': np.float64(0.5424527203206293), 'nauc_precision_at_3_max': np.float64(0.10266663218577855), 'nauc_precision_at_3_std': np.float64(-0.25059548975830875), 'nauc_precision_at_3_diff1': np.float64(0.3807599070467739), 'nauc_precision_at_5_max': np.float64(0.09219147698570189), 'nauc_precision_at_5_std': np.float64(-0.22395724051653498), 'nauc_precision_at_5_diff1': np.float64(0.32266691575109374), 'nauc_precision_at_10_max': np.float64(0.09548245173484438), 'nauc_precision_at_10_std': np.float64(-0.24586645553812714), 'nauc_precision_at_10_diff1': np.float64(0.2569834532890681), 'nauc_precision_at_20_max': np.float64(0.11846780856881621), 'nauc_precision_at_20_std': np.float64(-0.19284833746638208), 'nauc_precision_at_20_diff1': np.float64(0.246524794732191), 'nauc_precision_at_100_max': np.float64(0.1823774624572872), 'nauc_precision_at_100_std': np.float64(-0.03883326768255318), 'nauc_precision_at_100_diff1': np.float64(0.1558128815074538), 'nauc_precision_at_1000_max': np.float64(0.04118830825211962), 'nauc_precision_at_1000_std': np.float64(-0.03655067079333452), 'nauc_precision_at_1000_diff1': np.float64(0.06484106073951286), 'nauc_mrr_at_1_max': np.float64(0.13813644385388055), 'nauc_mrr_at_1_std': np.float64(-0.25876751961792394), 'nauc_mrr_at_1_diff1': np.float64(0.5245224443959563), 'nauc_mrr_at_3_max': np.float64(0.11878579268407191), 'nauc_mrr_at_3_std': np.float64(-0.24489760580161646), 'nauc_mrr_at_3_diff1': np.float64(0.4787624819336987), 'nauc_mrr_at_5_max': np.float64(0.11669980450956663), 'nauc_mrr_at_5_std': np.float64(-0.23777156781214204), 'nauc_mrr_at_5_diff1': np.float64(0.4644950999357296), 'nauc_mrr_at_10_max': np.float64(0.12221245990326522), 'nauc_mrr_at_10_std': np.float64(-0.2385080377513371), 'nauc_mrr_at_10_diff1': np.float64(0.4549702282535802), 'nauc_mrr_at_20_max': np.float64(0.12646393926437344), 'nauc_mrr_at_20_std': np.float64(-0.23065097844263546), 'nauc_mrr_at_20_diff1': np.float64(0.4537457318278134), 'nauc_mrr_at_100_max': np.float64(0.12774943467175678), 'nauc_mrr_at_100_std': np.float64(-0.2286808414272922), 'nauc_mrr_at_100_diff1': np.float64(0.45248357465595396), 'nauc_mrr_at_1000_max': np.float64(0.1274558113508599), 'nauc_mrr_at_1000_std': np.float64(-0.2295105628667124), 'nauc_mrr_at_1000_diff1': np.float64(0.45331345019358943), 'main_score': 0.22975}, 'eng-kor': {'ndcg_at_1': 0.20489, 'ndcg_at_3': 0.20453, 'ndcg_at_5': 0.21908, 'ndcg_at_10': 0.25314, 'ndcg_at_20': 0.27683, 'ndcg_at_100': 0.32972, 'ndcg_at_1000': 0.37745, 'map_at_1': 0.10907, 'map_at_3': 0.16592, 'map_at_5': 0.18355, 'map_at_10': 0.20008, 'map_at_20': 0.20803, 'map_at_100': 0.21654, 'map_at_1000': 0.21892, 'recall_at_1': 0.10907, 'recall_at_3': 0.20176, 'recall_at_5': 0.25127, 'recall_at_10': 0.34044, 'recall_at_20': 0.41636, 'recall_at_100': 0.66529, 'recall_at_1000': 0.98825, 'precision_at_1': 0.20489, 'precision_at_3': 0.13558, 'precision_at_5': 0.10214, 'precision_at_10': 0.06896, 'precision_at_20': 0.04274, 'precision_at_100': 0.0132, 'precision_at_1000': 0.00193, 'mrr_at_1': 0.20489296636085627, 'mrr_at_3': 0.24413863404689096, 'mrr_at_5': 0.2553007135575943, 'mrr_at_10': 0.2683704674530362, 'mrr_at_20': 0.27413814192863817, 'mrr_at_100': 0.27983908038454547, 'mrr_at_1000': 0.2809476276007742, 'nauc_ndcg_at_1_max': np.float64(0.18222173014168144), 'nauc_ndcg_at_1_std': np.float64(-0.19426903175333218), 'nauc_ndcg_at_1_diff1': np.float64(0.4360952993868014), 'nauc_ndcg_at_3_max': np.float64(0.18098114786031724), 'nauc_ndcg_at_3_std': np.float64(-0.18192899415106736), 'nauc_ndcg_at_3_diff1': np.float64(0.400144822979588), 'nauc_ndcg_at_5_max': np.float64(0.18447801170208586), 'nauc_ndcg_at_5_std': np.float64(-0.16752783600913812), 'nauc_ndcg_at_5_diff1': np.float64(0.405058671031391), 'nauc_ndcg_at_10_max': np.float64(0.1790274032460794), 'nauc_ndcg_at_10_std': np.float64(-0.1578776113119791), 'nauc_ndcg_at_10_diff1': np.float64(0.3703927270946362), 'nauc_ndcg_at_20_max': np.float64(0.18258623084841624), 'nauc_ndcg_at_20_std': np.float64(-0.14915451411072314), 'nauc_ndcg_at_20_diff1': np.float64(0.3662327451695964), 'nauc_ndcg_at_100_max': np.float64(0.21248218039326816), 'nauc_ndcg_at_100_std': np.float64(-0.1034690973618592), 'nauc_ndcg_at_100_diff1': np.float64(0.360875865161226), 'nauc_ndcg_at_1000_max': np.float64(0.19900587131608835), 'nauc_ndcg_at_1000_std': np.float64(-0.13139026242096585), 'nauc_ndcg_at_1000_diff1': np.float64(0.36958685257583246), 'nauc_map_at_1_max': np.float64(0.16805143839694867), 'nauc_map_at_1_std': np.float64(-0.17766755641673088), 'nauc_map_at_1_diff1': np.float64(0.49254318956115406), 'nauc_map_at_3_max': np.float64(0.18636844446879836), 'nauc_map_at_3_std': np.float64(-0.17306322781898706), 'nauc_map_at_3_diff1': np.float64(0.4243095504536857), 'nauc_map_at_5_max': np.float64(0.19263538538841932), 'nauc_map_at_5_std': np.float64(-0.1706129816521939), 'nauc_map_at_5_diff1': np.float64(0.42727669566970294), 'nauc_map_at_10_max': np.float64(0.1879427797776452), 'nauc_map_at_10_std': np.float64(-0.16887691270115854), 'nauc_map_at_10_diff1': np.float64(0.4054837761856203), 'nauc_map_at_20_max': np.float64(0.18858469625997087), 'nauc_map_at_20_std': np.float64(-0.16690848048429469), 'nauc_map_at_20_diff1': np.float64(0.4031682067103435), 'nauc_map_at_100_max': np.float64(0.19251841506281442), 'nauc_map_at_100_std': np.float64(-0.15915136044483255), 'nauc_map_at_100_diff1': np.float64(0.40081352133745834), 'nauc_map_at_1000_max': np.float64(0.1925076974156427), 'nauc_map_at_1000_std': np.float64(-0.15967343000650422), 'nauc_map_at_1000_diff1': np.float64(0.40125892825241066), 'nauc_recall_at_1_max': np.float64(0.16805143839694867), 'nauc_recall_at_1_std': np.float64(-0.17766755641673088), 'nauc_recall_at_1_diff1': np.float64(0.49254318956115406), 'nauc_recall_at_3_max': np.float64(0.17054693240640964), 'nauc_recall_at_3_std': np.float64(-0.14899044774056786), 'nauc_recall_at_3_diff1': np.float64(0.3657339510461039), 'nauc_recall_at_5_max': np.float64(0.17200852368198497), 'nauc_recall_at_5_std': np.float64(-0.13291369947396878), 'nauc_recall_at_5_diff1': np.float64(0.3629567390073616), 'nauc_recall_at_10_max': np.float64(0.1556406822732104), 'nauc_recall_at_10_std': np.float64(-0.10956107040076458), 'nauc_recall_at_10_diff1': np.float64(0.2774281721836383), 'nauc_recall_at_20_max': np.float64(0.1669866122856726), 'nauc_recall_at_20_std': np.float64(-0.08082867002818131), 'nauc_recall_at_20_diff1': np.float64(0.27118855636891803), 'nauc_recall_at_100_max': np.float64(0.29234315612878653), 'nauc_recall_at_100_std': np.float64(0.12613374427453233), 'nauc_recall_at_100_diff1': np.float64(0.2374995464116671), 'nauc_recall_at_1000_max': np.float64(0.35717181759566935), 'nauc_recall_at_1000_std': np.float64(0.20865190433227918), 'nauc_recall_at_1000_diff1': np.float64(0.13250046071302277), 'nauc_precision_at_1_max': np.float64(0.18222173014168144), 'nauc_precision_at_1_std': np.float64(-0.19426903175333218), 'nauc_precision_at_1_diff1': np.float64(0.4360952993868014), 'nauc_precision_at_3_max': np.float64(0.19019117664679555), 'nauc_precision_at_3_std': np.float64(-0.17817080117581963), 'nauc_precision_at_3_diff1': np.float64(0.3161819443557705), 'nauc_precision_at_5_max': np.float64(0.18906691422276525), 'nauc_precision_at_5_std': np.float64(-0.17106447466002328), 'nauc_precision_at_5_diff1': np.float64(0.3070451212623572), 'nauc_precision_at_10_max': np.float64(0.1592005470211663), 'nauc_precision_at_10_std': np.float64(-0.14094862590265536), 'nauc_precision_at_10_diff1': np.float64(0.22908133394024585), 'nauc_precision_at_20_max': np.float64(0.14158503551823748), 'nauc_precision_at_20_std': np.float64(-0.11458398559750586), 'nauc_precision_at_20_diff1': np.float64(0.18564568526043124), 'nauc_precision_at_100_max': np.float64(0.18711406909458125), 'nauc_precision_at_100_std': np.float64(0.043438425710420954), 'nauc_precision_at_100_diff1': np.float64(0.0959242072434139), 'nauc_precision_at_1000_max': np.float64(0.07464427220092615), 'nauc_precision_at_1000_std': np.float64(-0.004144249875397938), 'nauc_precision_at_1000_diff1': np.float64(-0.009760278873842202), 'nauc_mrr_at_1_max': np.float64(0.18222173014168144), 'nauc_mrr_at_1_std': np.float64(-0.19426903175333218), 'nauc_mrr_at_1_diff1': np.float64(0.4360952993868014), 'nauc_mrr_at_3_max': np.float64(0.16691367601374762), 'nauc_mrr_at_3_std': np.float64(-0.1889784130478965), 'nauc_mrr_at_3_diff1': np.float64(0.3948773068130673), 'nauc_mrr_at_5_max': np.float64(0.16595815959557086), 'nauc_mrr_at_5_std': np.float64(-0.18167693600296836), 'nauc_mrr_at_5_diff1': np.float64(0.3914606612150105), 'nauc_mrr_at_10_max': np.float64(0.16953124037886483), 'nauc_mrr_at_10_std': np.float64(-0.1741356442559198), 'nauc_mrr_at_10_diff1': np.float64(0.38308130808487445), 'nauc_mrr_at_20_max': np.float64(0.17145329889084857), 'nauc_mrr_at_20_std': np.float64(-0.1713668797484057), 'nauc_mrr_at_20_diff1': np.float64(0.3823854391667542), 'nauc_mrr_at_100_max': np.float64(0.17559875242462214), 'nauc_mrr_at_100_std': np.float64(-0.16626696976042193), 'nauc_mrr_at_100_diff1': np.float64(0.382862977331595), 'nauc_mrr_at_1000_max': np.float64(0.17505083219623452), 'nauc_mrr_at_1000_std': np.float64(-0.1672195584018675), 'nauc_mrr_at_1000_diff1': np.float64(0.3832094222823258), 'main_score': 0.25314}, 'kor-eng': {'ndcg_at_1': 0.12866, 'ndcg_at_3': 0.15063, 'ndcg_at_5': 0.16863, 'ndcg_at_10': 0.18854, 'ndcg_at_20': 0.21035, 'ndcg_at_100': 0.25749, 'ndcg_at_1000': 0.31734, 'map_at_1': 0.08628, 'map_at_3': 0.12858, 'map_at_5': 0.14059, 'map_at_10': 0.15022, 'map_at_20': 0.15679, 'map_at_100': 0.1636, 'map_at_1000': 0.16608, 'recall_at_1': 0.08628, 'recall_at_3': 0.16522, 'recall_at_5': 0.21156, 'recall_at_10': 0.26722, 'recall_at_20': 0.34205, 'recall_at_100': 0.57244, 'recall_at_1000': 1.0, 'precision_at_1': 0.12866, 'precision_at_3': 0.0874, 'precision_at_5': 0.06612, 'precision_at_10': 0.04218, 'precision_at_20': 0.02785, 'precision_at_100': 0.00941, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.12866449511400652, 'mrr_at_3': 0.1672095548317046, 'mrr_at_5': 0.1790988056460369, 'mrr_at_10': 0.1863747996484153, 'mrr_at_20': 0.19242644503249734, 'mrr_at_100': 0.19797991387256086, 'mrr_at_1000': 0.19938274380943205, 'nauc_ndcg_at_1_max': np.float64(0.20234234109072088), 'nauc_ndcg_at_1_std': np.float64(-0.1711795561572859), 'nauc_ndcg_at_1_diff1': np.float64(0.5532161465093859), 'nauc_ndcg_at_3_max': np.float64(0.1373724039656632), 'nauc_ndcg_at_3_std': np.float64(-0.12461410579232975), 'nauc_ndcg_at_3_diff1': np.float64(0.416206049212487), 'nauc_ndcg_at_5_max': np.float64(0.11833562269454641), 'nauc_ndcg_at_5_std': np.float64(-0.15056798582708278), 'nauc_ndcg_at_5_diff1': np.float64(0.3832816653428549), 'nauc_ndcg_at_10_max': np.float64(0.11016332367408933), 'nauc_ndcg_at_10_std': np.float64(-0.15808373119311794), 'nauc_ndcg_at_10_diff1': np.float64(0.35093507861148865), 'nauc_ndcg_at_20_max': np.float64(0.12179138961557398), 'nauc_ndcg_at_20_std': np.float64(-0.1403557630327321), 'nauc_ndcg_at_20_diff1': np.float64(0.34294330342907176), 'nauc_ndcg_at_100_max': np.float64(0.1575153613547155), 'nauc_ndcg_at_100_std': np.float64(-0.11351341619223619), 'nauc_ndcg_at_100_diff1': np.float64(0.3352743487283844), 'nauc_ndcg_at_1000_max': np.float64(0.15193330970973437), 'nauc_ndcg_at_1000_std': np.float64(-0.11800552254580195), 'nauc_ndcg_at_1000_diff1': np.float64(0.3620397667807498), 'nauc_map_at_1_max': np.float64(0.1812263725055843), 'nauc_map_at_1_std': np.float64(-0.14745932194167496), 'nauc_map_at_1_diff1': np.float64(0.5772643406695391), 'nauc_map_at_3_max': np.float64(0.14365921268484447), 'nauc_map_at_3_std': np.float64(-0.1309963370048627), 'nauc_map_at_3_diff1': np.float64(0.44450088719560293), 'nauc_map_at_5_max': np.float64(0.13217354743852822), 'nauc_map_at_5_std': np.float64(-0.14749333237028583), 'nauc_map_at_5_diff1': np.float64(0.42054306877364694), 'nauc_map_at_10_max': np.float64(0.12629737694708626), 'nauc_map_at_10_std': np.float64(-0.15315800735764645), 'nauc_map_at_10_diff1': np.float64(0.40166203885913254), 'nauc_map_at_20_max': np.float64(0.1295376127897269), 'nauc_map_at_20_std': np.float64(-0.14872816492244928), 'nauc_map_at_20_diff1': np.float64(0.39744216958106177), 'nauc_map_at_100_max': np.float64(0.13569908149776974), 'nauc_map_at_100_std': np.float64(-0.1437597324384585), 'nauc_map_at_100_diff1': np.float64(0.3953718541834969), 'nauc_map_at_1000_max': np.float64(0.13633031460883702), 'nauc_map_at_1000_std': np.float64(-0.14270441349129107), 'nauc_map_at_1000_diff1': np.float64(0.3961749587192746), 'nauc_recall_at_1_max': np.float64(0.1812263725055843), 'nauc_recall_at_1_std': np.float64(-0.14745932194167496), 'nauc_recall_at_1_diff1': np.float64(0.5772643406695391), 'nauc_recall_at_3_max': np.float64(0.10584344331732437), 'nauc_recall_at_3_std': np.float64(-0.09421366212362879), 'nauc_recall_at_3_diff1': np.float64(0.34858841135869256), 'nauc_recall_at_5_max': np.float64(0.06299924702462584), 'nauc_recall_at_5_std': np.float64(-0.14673878231341503), 'nauc_recall_at_5_diff1': np.float64(0.2806949554857398), 'nauc_recall_at_10_max': np.float64(0.0581926515729071), 'nauc_recall_at_10_std': np.float64(-0.15564165226385734), 'nauc_recall_at_10_diff1': np.float64(0.21194674464393398), 'nauc_recall_at_20_max': np.float64(0.08515024629246543), 'nauc_recall_at_20_std': np.float64(-0.11225488424548549), 'nauc_recall_at_20_diff1': np.float64(0.19530799532399537), 'nauc_recall_at_100_max': np.float64(0.19308857266434395), 'nauc_recall_at_100_std': np.float64(-0.035689017928038066), 'nauc_recall_at_100_diff1': np.float64(0.1534987258193809), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.20234234109072088), 'nauc_precision_at_1_std': np.float64(-0.1711795561572859), 'nauc_precision_at_1_diff1': np.float64(0.5532161465093859), 'nauc_precision_at_3_max': np.float64(0.12901936986540974), 'nauc_precision_at_3_std': np.float64(-0.13619109700191925), 'nauc_precision_at_3_diff1': np.float64(0.33811569394251934), 'nauc_precision_at_5_max': np.float64(0.0991923610893025), 'nauc_precision_at_5_std': np.float64(-0.17585512890320865), 'nauc_precision_at_5_diff1': np.float64(0.27729264934861564), 'nauc_precision_at_10_max': np.float64(0.07621906696086887), 'nauc_precision_at_10_std': np.float64(-0.18309903410526088), 'nauc_precision_at_10_diff1': np.float64(0.21033455908631898), 'nauc_precision_at_20_max': np.float64(0.12704866502027365), 'nauc_precision_at_20_std': np.float64(-0.09655011562809865), 'nauc_precision_at_20_diff1': np.float64(0.18426777979291808), 'nauc_precision_at_100_max': np.float64(0.248637803302968), 'nauc_precision_at_100_std': np.float64(0.06687791464672636), 'nauc_precision_at_100_diff1': np.float64(0.11779657900549495), 'nauc_precision_at_1000_max': np.float64(0.1778694945466508), 'nauc_precision_at_1000_std': np.float64(0.13646227286260842), 'nauc_precision_at_1000_diff1': np.float64(0.04810858620991635), 'nauc_mrr_at_1_max': np.float64(0.20234234109072088), 'nauc_mrr_at_1_std': np.float64(-0.1711795561572859), 'nauc_mrr_at_1_diff1': np.float64(0.5532161465093859), 'nauc_mrr_at_3_max': np.float64(0.1646389203981862), 'nauc_mrr_at_3_std': np.float64(-0.14086190943672985), 'nauc_mrr_at_3_diff1': np.float64(0.4449810814898764), 'nauc_mrr_at_5_max': np.float64(0.15116622705088098), 'nauc_mrr_at_5_std': np.float64(-0.15449478413236747), 'nauc_mrr_at_5_diff1': np.float64(0.4268234976332322), 'nauc_mrr_at_10_max': np.float64(0.14784292715963446), 'nauc_mrr_at_10_std': np.float64(-0.1543621148354669), 'nauc_mrr_at_10_diff1': np.float64(0.41715433348067593), 'nauc_mrr_at_20_max': np.float64(0.15117806717621682), 'nauc_mrr_at_20_std': np.float64(-0.1482440961106289), 'nauc_mrr_at_20_diff1': np.float64(0.4161597722125335), 'nauc_mrr_at_100_max': np.float64(0.15578791899689512), 'nauc_mrr_at_100_std': np.float64(-0.14533230409922412), 'nauc_mrr_at_100_diff1': np.float64(0.4145559463869153), 'nauc_mrr_at_1000_max': np.float64(0.15512126861054923), 'nauc_mrr_at_1000_std': np.float64(-0.1459467216985746), 'nauc_mrr_at_1000_diff1': np.float64(0.4152618047751168), 'main_score': 0.18854}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 18.97it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:04,  5.39s/it]Batches:  15%|█▌        | 2/13 [00:08<00:45,  4.11s/it]Batches:  23%|██▎       | 3/13 [00:11<00:37,  3.70s/it]Batches:  31%|███       | 4/13 [00:15<00:31,  3.52s/it]Batches:  38%|███▊      | 5/13 [00:18<00:27,  3.42s/it]Batches:  46%|████▌     | 6/13 [00:21<00:23,  3.36s/it]Batches:  54%|█████▍    | 7/13 [00:24<00:19,  3.32s/it]Batches:  62%|██████▏   | 8/13 [00:28<00:16,  3.30s/it]Batches:  69%|██████▉   | 9/13 [00:31<00:13,  3.29s/it]Batches:  77%|███████▋  | 10/13 [00:34<00:09,  3.28s/it]Batches:  85%|████████▍ | 11/13 [00:37<00:06,  3.27s/it]Batches:  92%|█████████▏| 12/13 [00:41<00:03,  3.27s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.27s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.41s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 49.77 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 50.04 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.145, 'ndcg_at_3': 0.18274, 'ndcg_at_5': 0.19307, 'ndcg_at_10': 0.20781, 'ndcg_at_20': 0.21909, 'ndcg_at_100': 0.24581, 'ndcg_at_1000': 0.28322, 'map_at_1': 0.145, 'map_at_3': 0.17333, 'map_at_5': 0.17908, 'map_at_10': 0.18529, 'map_at_20': 0.18832, 'map_at_100': 0.19198, 'map_at_1000': 0.19321, 'recall_at_1': 0.145, 'recall_at_3': 0.21, 'recall_at_5': 0.235, 'recall_at_10': 0.28, 'recall_at_20': 0.325, 'recall_at_100': 0.47, 'recall_at_1000': 0.775, 'precision_at_1': 0.145, 'precision_at_3': 0.07, 'precision_at_5': 0.047, 'precision_at_10': 0.028, 'precision_at_20': 0.01625, 'precision_at_100': 0.0047, 'precision_at_1000': 0.00078, 'mrr_at_1': 0.145, 'mrr_at_3': 0.1733333333333333, 'mrr_at_5': 0.17908333333333332, 'mrr_at_10': 0.18529166666666666, 'mrr_at_20': 0.1883248716153128, 'mrr_at_100': 0.19198382037835227, 'mrr_at_1000': 0.1932147728625254, 'nauc_ndcg_at_1_max': np.float64(0.44267802321615013), 'nauc_ndcg_at_1_std': np.float64(0.0860113910050338), 'nauc_ndcg_at_1_diff1': np.float64(0.5214434119264443), 'nauc_ndcg_at_3_max': np.float64(0.4423423997602828), 'nauc_ndcg_at_3_std': np.float64(0.11316498197047978), 'nauc_ndcg_at_3_diff1': np.float64(0.4342069055493271), 'nauc_ndcg_at_5_max': np.float64(0.43015323968204994), 'nauc_ndcg_at_5_std': np.float64(0.1120491672169895), 'nauc_ndcg_at_5_diff1': np.float64(0.4324362542076813), 'nauc_ndcg_at_10_max': np.float64(0.40820548062211715), 'nauc_ndcg_at_10_std': np.float64(0.12629083259707208), 'nauc_ndcg_at_10_diff1': np.float64(0.42348908772605887), 'nauc_ndcg_at_20_max': np.float64(0.39621906546059027), 'nauc_ndcg_at_20_std': np.float64(0.14359923316885082), 'nauc_ndcg_at_20_diff1': np.float64(0.4224780508945248), 'nauc_ndcg_at_100_max': np.float64(0.41898438212455835), 'nauc_ndcg_at_100_std': np.float64(0.1523455572688703), 'nauc_ndcg_at_100_diff1': np.float64(0.43793987432945564), 'nauc_ndcg_at_1000_max': np.float64(0.41374681508253064), 'nauc_ndcg_at_1000_std': np.float64(0.16164644714574353), 'nauc_ndcg_at_1000_diff1': np.float64(0.4450678301323203), 'nauc_map_at_1_max': np.float64(0.44267802321615013), 'nauc_map_at_1_std': np.float64(0.0860113910050338), 'nauc_map_at_1_diff1': np.float64(0.5214434119264443), 'nauc_map_at_3_max': np.float64(0.4424097825559386), 'nauc_map_at_3_std': np.float64(0.10567332427316417), 'nauc_map_at_3_diff1': np.float64(0.45288459204970144), 'nauc_map_at_5_max': np.float64(0.4350220625582384), 'nauc_map_at_5_std': np.float64(0.10540883547827717), 'nauc_map_at_5_diff1': np.float64(0.4517829863292874), 'nauc_map_at_10_max': np.float64(0.4254687422985359), 'nauc_map_at_10_std': np.float64(0.11213997235804717), 'nauc_map_at_10_diff1': np.float64(0.44693851294924924), 'nauc_map_at_20_max': np.float64(0.421668974507344), 'nauc_map_at_20_std': np.float64(0.1168479238698225), 'nauc_map_at_20_diff1': np.float64(0.4464424271859814), 'nauc_map_at_100_max': np.float64(0.4265445737125238), 'nauc_map_at_100_std': np.float64(0.11868245036989694), 'nauc_map_at_100_diff1': np.float64(0.45040172028225095), 'nauc_map_at_1000_max': np.float64(0.4261664565744733), 'nauc_map_at_1000_std': np.float64(0.11932543759436441), 'nauc_map_at_1000_diff1': np.float64(0.45062550040979643), 'nauc_recall_at_1_max': np.float64(0.44267802321615013), 'nauc_recall_at_1_std': np.float64(0.0860113910050338), 'nauc_recall_at_1_diff1': np.float64(0.5214434119264443), 'nauc_recall_at_3_max': np.float64(0.4421746084532915), 'nauc_recall_at_3_std': np.float64(0.13259537270179103), 'nauc_recall_at_3_diff1': np.float64(0.38725513484409396), 'nauc_recall_at_5_max': np.float64(0.4171496799643313), 'nauc_recall_at_5_std': np.float64(0.12830898744795188), 'nauc_recall_at_5_diff1': np.float64(0.38504787310415717), 'nauc_recall_at_10_max': np.float64(0.3603832616347282), 'nauc_recall_at_10_std': np.float64(0.162299569808369), 'nauc_recall_at_10_diff1': np.float64(0.3679605005866248), 'nauc_recall_at_20_max': np.float64(0.325067565313136), 'nauc_recall_at_20_std': np.float64(0.21884488338727429), 'nauc_recall_at_20_diff1': np.float64(0.3677554969804144), 'nauc_recall_at_100_max': np.float64(0.4085233191365917), 'nauc_recall_at_100_std': np.float64(0.25014174764962627), 'nauc_recall_at_100_diff1': np.float64(0.4192433971966929), 'nauc_recall_at_1000_max': np.float64(0.36096338894266317), 'nauc_recall_at_1000_std': np.float64(0.3920856345726817), 'nauc_recall_at_1000_diff1': np.float64(0.47530604110915015), 'nauc_precision_at_1_max': np.float64(0.44267802321615013), 'nauc_precision_at_1_std': np.float64(0.0860113910050338), 'nauc_precision_at_1_diff1': np.float64(0.5214434119264443), 'nauc_precision_at_3_max': np.float64(0.44217460845329143), 'nauc_precision_at_3_std': np.float64(0.13259537270179117), 'nauc_precision_at_3_diff1': np.float64(0.3872551348440939), 'nauc_precision_at_5_max': np.float64(0.41714967996433167), 'nauc_precision_at_5_std': np.float64(0.12830898744795183), 'nauc_precision_at_5_diff1': np.float64(0.3850478731041573), 'nauc_precision_at_10_max': np.float64(0.36038326163472845), 'nauc_precision_at_10_std': np.float64(0.16229956980836938), 'nauc_precision_at_10_diff1': np.float64(0.3679605005866255), 'nauc_precision_at_20_max': np.float64(0.32506756531313613), 'nauc_precision_at_20_std': np.float64(0.21884488338727445), 'nauc_precision_at_20_diff1': np.float64(0.3677554969804145), 'nauc_precision_at_100_max': np.float64(0.40852331913659207), 'nauc_precision_at_100_std': np.float64(0.2501417476496263), 'nauc_precision_at_100_diff1': np.float64(0.419243397196693), 'nauc_precision_at_1000_max': np.float64(0.3609633889426637), 'nauc_precision_at_1000_std': np.float64(0.3920856345726816), 'nauc_precision_at_1000_diff1': np.float64(0.47530604110915015), 'nauc_mrr_at_1_max': np.float64(0.44267802321615013), 'nauc_mrr_at_1_std': np.float64(0.0860113910050338), 'nauc_mrr_at_1_diff1': np.float64(0.5214434119264443), 'nauc_mrr_at_3_max': np.float64(0.4424097825559386), 'nauc_mrr_at_3_std': np.float64(0.10567332427316417), 'nauc_mrr_at_3_diff1': np.float64(0.45288459204970144), 'nauc_mrr_at_5_max': np.float64(0.4350220625582384), 'nauc_mrr_at_5_std': np.float64(0.10540883547827717), 'nauc_mrr_at_5_diff1': np.float64(0.4517829863292874), 'nauc_mrr_at_10_max': np.float64(0.4254687422985359), 'nauc_mrr_at_10_std': np.float64(0.11213997235804717), 'nauc_mrr_at_10_diff1': np.float64(0.44693851294924924), 'nauc_mrr_at_20_max': np.float64(0.421668974507344), 'nauc_mrr_at_20_std': np.float64(0.1168479238698225), 'nauc_mrr_at_20_diff1': np.float64(0.4464424271859814), 'nauc_mrr_at_100_max': np.float64(0.4265445737125238), 'nauc_mrr_at_100_std': np.float64(0.11868245036989694), 'nauc_mrr_at_100_diff1': np.float64(0.45040172028225095), 'nauc_mrr_at_1000_max': np.float64(0.4261664565744733), 'nauc_mrr_at_1000_std': np.float64(0.11932543759436441), 'nauc_mrr_at_1000_diff1': np.float64(0.45062550040979643), 'main_score': 0.20781}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 37.03it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/13 [00:00<?, ?it/s]Batches:   8%|▊         | 1/13 [00:05<01:06,  5.52s/it]Batches:  15%|█▌        | 2/13 [00:08<00:46,  4.18s/it]Batches:  23%|██▎       | 3/13 [00:12<00:37,  3.76s/it]Batches:  31%|███       | 4/13 [00:15<00:32,  3.57s/it]Batches:  38%|███▊      | 5/13 [00:18<00:27,  3.46s/it]Batches:  46%|████▌     | 6/13 [00:21<00:23,  3.40s/it]Batches:  54%|█████▍    | 7/13 [00:25<00:20,  3.36s/it]Batches:  62%|██████▏   | 8/13 [00:28<00:16,  3.33s/it]Batches:  69%|██████▉   | 9/13 [00:31<00:13,  3.32s/it]Batches:  77%|███████▋  | 10/13 [00:34<00:09,  3.31s/it]Batches:  85%|████████▍ | 11/13 [00:38<00:06,  3.30s/it]Batches:  92%|█████████▏| 12/13 [00:41<00:03,  3.30s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.29s/it]Batches: 100%|██████████| 13/13 [00:44<00:00,  3.45s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 49.53 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 49.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.165, 'ndcg_at_3': 0.20143, 'ndcg_at_5': 0.20938, 'ndcg_at_10': 0.21894, 'ndcg_at_20': 0.23422, 'ndcg_at_100': 0.25465, 'ndcg_at_1000': 0.29282, 'map_at_1': 0.165, 'map_at_3': 0.19167, 'map_at_5': 0.19592, 'map_at_10': 0.19977, 'map_at_20': 0.20402, 'map_at_100': 0.20649, 'map_at_1000': 0.20752, 'recall_at_1': 0.165, 'recall_at_3': 0.23, 'recall_at_5': 0.25, 'recall_at_10': 0.28, 'recall_at_20': 0.34, 'recall_at_100': 0.455, 'recall_at_1000': 0.78, 'precision_at_1': 0.165, 'precision_at_3': 0.07667, 'precision_at_5': 0.05, 'precision_at_10': 0.028, 'precision_at_20': 0.017, 'precision_at_100': 0.00455, 'precision_at_1000': 0.00078, 'mrr_at_1': 0.165, 'mrr_at_3': 0.19166666666666668, 'mrr_at_5': 0.19591666666666666, 'mrr_at_10': 0.19977380952380955, 'mrr_at_20': 0.204016696023275, 'mrr_at_100': 0.20649144224821897, 'mrr_at_1000': 0.20752064280572122, 'nauc_ndcg_at_1_max': np.float64(0.5234544277794976), 'nauc_ndcg_at_1_std': np.float64(-0.05076399245856434), 'nauc_ndcg_at_1_diff1': np.float64(0.6201048672275845), 'nauc_ndcg_at_3_max': np.float64(0.4739020403761328), 'nauc_ndcg_at_3_std': np.float64(-0.03284985880964725), 'nauc_ndcg_at_3_diff1': np.float64(0.5586858556326989), 'nauc_ndcg_at_5_max': np.float64(0.45887369671291245), 'nauc_ndcg_at_5_std': np.float64(-0.016024033402916214), 'nauc_ndcg_at_5_diff1': np.float64(0.546681845331466), 'nauc_ndcg_at_10_max': np.float64(0.46570991103867687), 'nauc_ndcg_at_10_std': np.float64(0.0010590339752548571), 'nauc_ndcg_at_10_diff1': np.float64(0.5358069064937044), 'nauc_ndcg_at_20_max': np.float64(0.4595495413852217), 'nauc_ndcg_at_20_std': np.float64(0.033625862881167916), 'nauc_ndcg_at_20_diff1': np.float64(0.5236475339804766), 'nauc_ndcg_at_100_max': np.float64(0.45115665501008495), 'nauc_ndcg_at_100_std': np.float64(0.05542686041973977), 'nauc_ndcg_at_100_diff1': np.float64(0.5162533290582946), 'nauc_ndcg_at_1000_max': np.float64(0.4503616586158029), 'nauc_ndcg_at_1000_std': np.float64(0.05915381766426138), 'nauc_ndcg_at_1000_diff1': np.float64(0.5199862137406661), 'nauc_map_at_1_max': np.float64(0.5234544277794976), 'nauc_map_at_1_std': np.float64(-0.05076399245856434), 'nauc_map_at_1_diff1': np.float64(0.6201048672275845), 'nauc_map_at_3_max': np.float64(0.4828170976133281), 'nauc_map_at_3_std': np.float64(-0.04273550441370882), 'nauc_map_at_3_diff1': np.float64(0.5740749690827162), 'nauc_map_at_5_max': np.float64(0.47448480276848004), 'nauc_map_at_5_std': np.float64(-0.03333536721211727), 'nauc_map_at_5_diff1': np.float64(0.567430902491201), 'nauc_map_at_10_max': np.float64(0.47683752815044106), 'nauc_map_at_10_std': np.float64(-0.02612179973394065), 'nauc_map_at_10_diff1': np.float64(0.5625235250712822), 'nauc_map_at_20_max': np.float64(0.47446743142712483), 'nauc_map_at_20_std': np.float64(-0.016145223528028423), 'nauc_map_at_20_diff1': np.float64(0.5586730480679323), 'nauc_map_at_100_max': np.float64(0.4735961012311268), 'nauc_map_at_100_std': np.float64(-0.013836822394907607), 'nauc_map_at_100_diff1': np.float64(0.557864054635877), 'nauc_map_at_1000_max': np.float64(0.47360472296901307), 'nauc_map_at_1000_std': np.float64(-0.013522244935920483), 'nauc_map_at_1000_diff1': np.float64(0.5580741530900482), 'nauc_recall_at_1_max': np.float64(0.5234544277794976), 'nauc_recall_at_1_std': np.float64(-0.05076399245856434), 'nauc_recall_at_1_diff1': np.float64(0.6201048672275845), 'nauc_recall_at_3_max': np.float64(0.45161757752322274), 'nauc_recall_at_3_std': np.float64(-0.005140251063894778), 'nauc_recall_at_3_diff1': np.float64(0.5182654321929195), 'nauc_recall_at_5_max': np.float64(0.41803604266274336), 'nauc_recall_at_5_std': np.float64(0.03210003677822733), 'nauc_recall_at_5_diff1': np.float64(0.4919455682236117), 'nauc_recall_at_10_max': np.float64(0.4407788144589083), 'nauc_recall_at_10_std': np.float64(0.0771970501145313), 'nauc_recall_at_10_diff1': np.float64(0.4655637186434996), 'nauc_recall_at_20_max': np.float64(0.4246866636635838), 'nauc_recall_at_20_std': np.float64(0.17958875433901247), 'nauc_recall_at_20_diff1': np.float64(0.42974111661676234), 'nauc_recall_at_100_max': np.float64(0.3844372880688935), 'nauc_recall_at_100_std': np.float64(0.28660628201512456), 'nauc_recall_at_100_diff1': np.float64(0.39542983071746685), 'nauc_recall_at_1000_max': np.float64(0.32699262762553866), 'nauc_recall_at_1000_std': np.float64(0.48129086103769614), 'nauc_recall_at_1000_diff1': np.float64(0.34427597718736896), 'nauc_precision_at_1_max': np.float64(0.5234544277794976), 'nauc_precision_at_1_std': np.float64(-0.05076399245856434), 'nauc_precision_at_1_diff1': np.float64(0.6201048672275845), 'nauc_precision_at_3_max': np.float64(0.45161757752322285), 'nauc_precision_at_3_std': np.float64(-0.005140251063894511), 'nauc_precision_at_3_diff1': np.float64(0.5182654321929198), 'nauc_precision_at_5_max': np.float64(0.4180360426627437), 'nauc_precision_at_5_std': np.float64(0.03210003677822725), 'nauc_precision_at_5_diff1': np.float64(0.49194556822361185), 'nauc_precision_at_10_max': np.float64(0.44077881445890865), 'nauc_precision_at_10_std': np.float64(0.07719705011453173), 'nauc_precision_at_10_diff1': np.float64(0.46556371864350016), 'nauc_precision_at_20_max': np.float64(0.4246866636635844), 'nauc_precision_at_20_std': np.float64(0.17958875433901297), 'nauc_precision_at_20_diff1': np.float64(0.4297411166167628), 'nauc_precision_at_100_max': np.float64(0.3844372880688936), 'nauc_precision_at_100_std': np.float64(0.28660628201512456), 'nauc_precision_at_100_diff1': np.float64(0.3954298307174672), 'nauc_precision_at_1000_max': np.float64(0.3269926276255392), 'nauc_precision_at_1000_std': np.float64(0.4812908610376967), 'nauc_precision_at_1000_diff1': np.float64(0.34427597718736913), 'nauc_mrr_at_1_max': np.float64(0.5234544277794976), 'nauc_mrr_at_1_std': np.float64(-0.05076399245856434), 'nauc_mrr_at_1_diff1': np.float64(0.6201048672275845), 'nauc_mrr_at_3_max': np.float64(0.4828170976133281), 'nauc_mrr_at_3_std': np.float64(-0.04273550441370882), 'nauc_mrr_at_3_diff1': np.float64(0.5740749690827162), 'nauc_mrr_at_5_max': np.float64(0.47448480276848004), 'nauc_mrr_at_5_std': np.float64(-0.03333536721211727), 'nauc_mrr_at_5_diff1': np.float64(0.567430902491201), 'nauc_mrr_at_10_max': np.float64(0.47683752815044106), 'nauc_mrr_at_10_std': np.float64(-0.02612179973394065), 'nauc_mrr_at_10_diff1': np.float64(0.5625235250712822), 'nauc_mrr_at_20_max': np.float64(0.47446743142712483), 'nauc_mrr_at_20_std': np.float64(-0.016145223528028423), 'nauc_mrr_at_20_diff1': np.float64(0.5586730480679323), 'nauc_mrr_at_100_max': np.float64(0.4735961012311268), 'nauc_mrr_at_100_std': np.float64(-0.013836822394907607), 'nauc_mrr_at_100_diff1': np.float64(0.557864054635877), 'nauc_mrr_at_1000_max': np.float64(0.47360472296901307), 'nauc_mrr_at_1000_std': np.float64(-0.013522244935920483), 'nauc_mrr_at_1000_diff1': np.float64(0.5580741530900482), 'main_score': 0.21894}}



==================================================
Running model: BAAI/bge-multilingual-gemma2
--------------------------------------------------
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:51, 17.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:47, 23.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:09<00:23, 23.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.03s/it]
WARNING:mteb.models.overview:Failed to extract metadata from model: 'InstructWrapper' object has no attribute 'model_card_data'. Upgrading to sentence-transformers v3.0.0 or above is recommended.
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Created GritLM: torch.float16 dtype, lasttoken pool, embedding mode, cccc attn
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / BAAI/bge-multilingual-gemma2 on GPU 0 in process Process-13
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:03<00:07,  3.99s/it]Batches:  67%|██████▋   | 2/3 [00:05<00:02,  2.63s/it]Batches: 100%|██████████| 3/3 [00:07<00:00,  2.09s/it]Batches: 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'Ko-StrategyQA'
Batches:   0%|          | 0/37 [00:00<?, ?it/s]Batches:   3%|▎         | 1/37 [00:19<11:46, 19.61s/it]Batches:   5%|▌         | 2/37 [00:49<14:52, 25.49s/it]Batches:   8%|▊         | 3/37 [01:18<15:33, 27.44s/it]Batches:  11%|█         | 4/37 [01:48<15:37, 28.41s/it]Batches:  14%|█▎        | 5/37 [02:18<15:26, 28.95s/it]Batches:  16%|█▌        | 6/37 [02:48<15:07, 29.28s/it]Batches:  19%|█▉        | 7/37 [03:18<14:45, 29.51s/it]Batches:  22%|██▏       | 8/37 [03:48<14:19, 29.65s/it]Batches:  24%|██▍       | 9/37 [04:18<13:53, 29.76s/it]Batches:  27%|██▋       | 10/37 [04:48<13:25, 29.84s/it]Batches:  30%|██▉       | 11/37 [05:18<12:56, 29.88s/it]Batches:  32%|███▏      | 12/37 [05:48<12:28, 29.93s/it]Batches:  35%|███▌      | 13/37 [06:18<11:59, 29.97s/it]Batches:  38%|███▊      | 14/37 [06:48<11:29, 29.98s/it]Batches:  41%|████      | 15/37 [07:18<10:59, 30.00s/it]Batches:  43%|████▎     | 16/37 [07:48<10:30, 30.01s/it]Batches:  46%|████▌     | 17/37 [08:18<10:00, 30.01s/it]Batches:  49%|████▊     | 18/37 [08:48<09:30, 30.02s/it]Batches:  51%|█████▏    | 19/37 [09:18<09:00, 30.02s/it]Batches:  54%|█████▍    | 20/37 [09:48<08:30, 30.03s/it]Batches:  57%|█████▋    | 21/37 [10:19<08:00, 30.05s/it]Batches:  59%|█████▉    | 22/37 [10:49<07:30, 30.04s/it]Batches:  62%|██████▏   | 23/37 [11:19<07:00, 30.05s/it]Batches:  65%|██████▍   | 24/37 [11:49<06:30, 30.05s/it]Batches:  68%|██████▊   | 25/37 [12:19<06:00, 30.04s/it]Batches:  70%|███████   | 26/37 [12:49<05:30, 30.04s/it]Batches:  73%|███████▎  | 27/37 [13:19<05:00, 30.04s/it]Batches:  76%|███████▌  | 28/37 [13:49<04:30, 30.03s/it]Batches:  78%|███████▊  | 29/37 [14:19<04:00, 30.03s/it]Batches:  81%|████████  | 30/37 [14:49<03:30, 30.02s/it]Batches:  84%|████████▍ | 31/37 [15:19<03:00, 30.02s/it]Batches:  86%|████████▋ | 32/37 [15:49<02:30, 30.02s/it]Batches:  89%|████████▉ | 33/37 [16:19<02:00, 30.03s/it]Batches:  92%|█████████▏| 34/37 [16:49<01:30, 30.03s/it]Batches:  95%|█████████▍| 35/37 [17:19<01:00, 30.03s/it]Batches:  97%|█████████▋| 36/37 [17:49<00:30, 30.03s/it]Batches: 100%|██████████| 37/37 [18:02<00:00, 24.82s/it]Batches: 100%|██████████| 37/37 [18:02<00:00, 29.25s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1092.24 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 1092.86 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.72297, 'ndcg_at_3': 0.74053, 'ndcg_at_5': 0.77273, 'ndcg_at_10': 0.78957, 'ndcg_at_20': 0.79823, 'ndcg_at_100': 0.80537, 'ndcg_at_1000': 0.81172, 'map_at_1': 0.47172, 'map_at_3': 0.69611, 'map_at_5': 0.72996, 'map_at_10': 0.74202, 'map_at_20': 0.7458, 'map_at_100': 0.74733, 'map_at_1000': 0.74764, 'recall_at_1': 0.47172, 'recall_at_3': 0.75721, 'recall_at_5': 0.82302, 'recall_at_10': 0.86219, 'recall_at_20': 0.88824, 'recall_at_100': 0.91864, 'recall_at_1000': 0.95721, 'precision_at_1': 0.72297, 'precision_at_3': 0.44538, 'precision_at_5': 0.3, 'precision_at_10': 0.1603, 'precision_at_20': 0.08336, 'precision_at_100': 0.01736, 'precision_at_1000': 0.00183, 'mrr_at_1': 0.722972972972973, 'mrr_at_3': 0.7891328828828827, 'mrr_at_5': 0.7934403153153151, 'mrr_at_10': 0.7953118296868293, 'mrr_at_20': 0.7964322839322836, 'mrr_at_100': 0.7969770467393054, 'mrr_at_1000': 0.7971439117575713, 'nauc_ndcg_at_1_max': np.float64(0.5506374802454409), 'nauc_ndcg_at_1_std': np.float64(0.19751420925146365), 'nauc_ndcg_at_1_diff1': np.float64(0.6699940042089989), 'nauc_ndcg_at_3_max': np.float64(0.5466815606494104), 'nauc_ndcg_at_3_std': np.float64(0.18143740359855087), 'nauc_ndcg_at_3_diff1': np.float64(0.6240319354966923), 'nauc_ndcg_at_5_max': np.float64(0.6143879966474913), 'nauc_ndcg_at_5_std': np.float64(0.2599137946766607), 'nauc_ndcg_at_5_diff1': np.float64(0.6361824149507154), 'nauc_ndcg_at_10_max': np.float64(0.6328758158497113), 'nauc_ndcg_at_10_std': np.float64(0.28369873043823135), 'nauc_ndcg_at_10_diff1': np.float64(0.6455623398351875), 'nauc_ndcg_at_20_max': np.float64(0.6418166953124675), 'nauc_ndcg_at_20_std': np.float64(0.2985193671226087), 'nauc_ndcg_at_20_diff1': np.float64(0.653749653926623), 'nauc_ndcg_at_100_max': np.float64(0.6400723520683582), 'nauc_ndcg_at_100_std': np.float64(0.3068247860361259), 'nauc_ndcg_at_100_diff1': np.float64(0.6543903701068109), 'nauc_ndcg_at_1000_max': np.float64(0.6295517683320556), 'nauc_ndcg_at_1000_std': np.float64(0.29306518941834026), 'nauc_ndcg_at_1000_diff1': np.float64(0.6507711817602371), 'nauc_map_at_1_max': np.float64(0.23235831685274702), 'nauc_map_at_1_std': np.float64(0.02392109283757035), 'nauc_map_at_1_diff1': np.float64(0.608545101980908), 'nauc_map_at_3_max': np.float64(0.4893305019199787), 'nauc_map_at_3_std': np.float64(0.12643366312214557), 'nauc_map_at_3_diff1': np.float64(0.6165053329626807), 'nauc_map_at_5_max': np.float64(0.5567065783421888), 'nauc_map_at_5_std': np.float64(0.19174614701108872), 'nauc_map_at_5_diff1': np.float64(0.6232764017900854), 'nauc_map_at_10_max': np.float64(0.5659718044881504), 'nauc_map_at_10_std': np.float64(0.20360703500801042), 'nauc_map_at_10_diff1': np.float64(0.6281475589342009), 'nauc_map_at_20_max': np.float64(0.5693054275639216), 'nauc_map_at_20_std': np.float64(0.20914290349452302), 'nauc_map_at_20_diff1': np.float64(0.631365610024937), 'nauc_map_at_100_max': np.float64(0.5696565937421008), 'nauc_map_at_100_std': np.float64(0.21073863541233512), 'nauc_map_at_100_diff1': np.float64(0.6312638843452146), 'nauc_map_at_1000_max': np.float64(0.5691341187506447), 'nauc_map_at_1000_std': np.float64(0.21004162452899314), 'nauc_map_at_1000_diff1': np.float64(0.6310899722560835), 'nauc_recall_at_1_max': np.float64(0.23235831685274702), 'nauc_recall_at_1_std': np.float64(0.02392109283757035), 'nauc_recall_at_1_diff1': np.float64(0.608545101980908), 'nauc_recall_at_3_max': np.float64(0.5269965568005559), 'nauc_recall_at_3_std': np.float64(0.17401779344141602), 'nauc_recall_at_3_diff1': np.float64(0.5792873886525984), 'nauc_recall_at_5_max': np.float64(0.6922095361495195), 'nauc_recall_at_5_std': np.float64(0.35824591041643106), 'nauc_recall_at_5_diff1': np.float64(0.6079724542436665), 'nauc_recall_at_10_max': np.float64(0.7767262149994878), 'nauc_recall_at_10_std': np.float64(0.4605619706168273), 'nauc_recall_at_10_diff1': np.float64(0.6434279534592869), 'nauc_recall_at_20_max': np.float64(0.8625295002881975), 'nauc_recall_at_20_std': np.float64(0.5707665310578435), 'nauc_recall_at_20_diff1': np.float64(0.7009988617177662), 'nauc_recall_at_100_max': np.float64(0.9174348516938887), 'nauc_recall_at_100_std': np.float64(0.7416317430966797), 'nauc_recall_at_100_diff1': np.float64(0.7332395711404674), 'nauc_recall_at_1000_max': np.float64(0.9370955784004804), 'nauc_recall_at_1000_std': np.float64(0.8345173811553217), 'nauc_recall_at_1000_diff1': np.float64(0.730736632524254), 'nauc_precision_at_1_max': np.float64(0.5506374802454409), 'nauc_precision_at_1_std': np.float64(0.19751420925146365), 'nauc_precision_at_1_diff1': np.float64(0.6699940042089989), 'nauc_precision_at_3_max': np.float64(0.3916204984164927), 'nauc_precision_at_3_std': np.float64(0.2134971823163419), 'nauc_precision_at_3_diff1': np.float64(0.061490037900560936), 'nauc_precision_at_5_max': np.float64(0.3647877358588659), 'nauc_precision_at_5_std': np.float64(0.2659305001662368), 'nauc_precision_at_5_diff1': np.float64(-0.0339588056613758), 'nauc_precision_at_10_max': np.float64(0.30361861380196786), 'nauc_precision_at_10_std': np.float64(0.25632967780876964), 'nauc_precision_at_10_diff1': np.float64(-0.09006654671038908), 'nauc_precision_at_20_max': np.float64(0.2725040128095253), 'nauc_precision_at_20_std': np.float64(0.264462141164091), 'nauc_precision_at_20_diff1': np.float64(-0.12551074392818148), 'nauc_precision_at_100_max': np.float64(0.21765950332885092), 'nauc_precision_at_100_std': np.float64(0.2598690003052531), 'nauc_precision_at_100_diff1': np.float64(-0.17868084960710476), 'nauc_precision_at_1000_max': np.float64(0.10224815764953218), 'nauc_precision_at_1000_std': np.float64(0.1780556401327899), 'nauc_precision_at_1000_diff1': np.float64(-0.2892715081187271), 'nauc_mrr_at_1_max': np.float64(0.5506374802454409), 'nauc_mrr_at_1_std': np.float64(0.19751420925146365), 'nauc_mrr_at_1_diff1': np.float64(0.6699940042089989), 'nauc_mrr_at_3_max': np.float64(0.6404354659580417), 'nauc_mrr_at_3_std': np.float64(0.2975630892653952), 'nauc_mrr_at_3_diff1': np.float64(0.6741632909894306), 'nauc_mrr_at_5_max': np.float64(0.6420606278527045), 'nauc_mrr_at_5_std': np.float64(0.3066520079623406), 'nauc_mrr_at_5_diff1': np.float64(0.6744799763025348), 'nauc_mrr_at_10_max': np.float64(0.6431102218806993), 'nauc_mrr_at_10_std': np.float64(0.3070004276492985), 'nauc_mrr_at_10_diff1': np.float64(0.6751100230763001), 'nauc_mrr_at_20_max': np.float64(0.6424817075201075), 'nauc_mrr_at_20_std': np.float64(0.30587569743685067), 'nauc_mrr_at_20_diff1': np.float64(0.6754373766287737), 'nauc_mrr_at_100_max': np.float64(0.6418470462224783), 'nauc_mrr_at_100_std': np.float64(0.3054247034939742), 'nauc_mrr_at_100_diff1': np.float64(0.6757692957822654), 'nauc_mrr_at_1000_max': np.float64(0.6415967971471751), 'nauc_mrr_at_1000_std': np.float64(0.30505156631701036), 'nauc_mrr_at_1000_diff1': np.float64(0.6756690836560901), 'main_score': 0.78957}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'AutoRAGRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'AutoRAGRetrieval'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:20<00:40, 20.03s/it]Batches:  67%|██████▋   | 2/3 [00:50<00:25, 25.88s/it]Batches: 100%|██████████| 3/3 [01:16<00:00, 26.03s/it]Batches: 100%|██████████| 3/3 [01:16<00:00, 25.40s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 87.27 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 87.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.59649, 'ndcg_at_3': 0.72681, 'ndcg_at_5': 0.7491, 'ndcg_at_10': 0.76736, 'ndcg_at_20': 0.77568, 'ndcg_at_100': 0.78222, 'ndcg_at_1000': 0.78332, 'map_at_1': 0.59649, 'map_at_3': 0.69591, 'map_at_5': 0.70863, 'map_at_10': 0.71691, 'map_at_20': 0.71891, 'map_at_100': 0.71986, 'map_at_1000': 0.71989, 'recall_at_1': 0.59649, 'recall_at_3': 0.81579, 'recall_at_5': 0.86842, 'recall_at_10': 0.92105, 'recall_at_20': 0.95614, 'recall_at_100': 0.99123, 'recall_at_1000': 1.0, 'precision_at_1': 0.59649, 'precision_at_3': 0.27193, 'precision_at_5': 0.17368, 'precision_at_10': 0.09211, 'precision_at_20': 0.04781, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5964912280701754, 'mrr_at_3': 0.6959064327485381, 'mrr_at_5': 0.708625730994152, 'mrr_at_10': 0.7169103313840157, 'mrr_at_20': 0.718907099620396, 'mrr_at_100': 0.7198594525285231, 'mrr_at_1000': 0.7198949664144525, 'nauc_ndcg_at_1_max': np.float64(0.126771978137183), 'nauc_ndcg_at_1_std': np.float64(-0.40912623263660736), 'nauc_ndcg_at_1_diff1': np.float64(0.7322787459536919), 'nauc_ndcg_at_3_max': np.float64(0.0952637496799088), 'nauc_ndcg_at_3_std': np.float64(-0.4685277564008933), 'nauc_ndcg_at_3_diff1': np.float64(0.645931955331979), 'nauc_ndcg_at_5_max': np.float64(0.1401665418280689), 'nauc_ndcg_at_5_std': np.float64(-0.4405597411656915), 'nauc_ndcg_at_5_diff1': np.float64(0.6531846196799456), 'nauc_ndcg_at_10_max': np.float64(0.14876300362881492), 'nauc_ndcg_at_10_std': np.float64(-0.4721959825722479), 'nauc_ndcg_at_10_diff1': np.float64(0.6353336393508974), 'nauc_ndcg_at_20_max': np.float64(0.14226065677992117), 'nauc_ndcg_at_20_std': np.float64(-0.47426464961998505), 'nauc_ndcg_at_20_diff1': np.float64(0.6584091437547132), 'nauc_ndcg_at_100_max': np.float64(0.1430219820106326), 'nauc_ndcg_at_100_std': np.float64(-0.4528009710178), 'nauc_ndcg_at_100_diff1': np.float64(0.6541423622260367), 'nauc_ndcg_at_1000_max': np.float64(0.1431494419746683), 'nauc_ndcg_at_1000_std': np.float64(-0.44480735059854043), 'nauc_ndcg_at_1000_diff1': np.float64(0.6616098995657822), 'nauc_map_at_1_max': np.float64(0.126771978137183), 'nauc_map_at_1_std': np.float64(-0.40912623263660736), 'nauc_map_at_1_diff1': np.float64(0.7322787459536919), 'nauc_map_at_3_max': np.float64(0.1121464247829035), 'nauc_map_at_3_std': np.float64(-0.44307489383276855), 'nauc_map_at_3_diff1': np.float64(0.6723193919828901), 'nauc_map_at_5_max': np.float64(0.13612304432346545), 'nauc_map_at_5_std': np.float64(-0.42674920364042246), 'nauc_map_at_5_diff1': np.float64(0.6765845484302393), 'nauc_map_at_10_max': np.float64(0.13934316350785994), 'nauc_map_at_10_std': np.float64(-0.43807963497296315), 'nauc_map_at_10_diff1': np.float64(0.6700091981210569), 'nauc_map_at_20_max': np.float64(0.13799626624712824), 'nauc_map_at_20_std': np.float64(-0.43782109293881954), 'nauc_map_at_20_diff1': np.float64(0.6745491385664443), 'nauc_map_at_100_max': np.float64(0.13903682304516368), 'nauc_map_at_100_std': np.float64(-0.4339586660434974), 'nauc_map_at_100_diff1': np.float64(0.6742207864378913), 'nauc_map_at_1000_max': np.float64(0.13903940947163007), 'nauc_map_at_1000_std': np.float64(-0.43375508845684757), 'nauc_map_at_1000_diff1': np.float64(0.6744113471464466), 'nauc_recall_at_1_max': np.float64(0.126771978137183), 'nauc_recall_at_1_std': np.float64(-0.40912623263660736), 'nauc_recall_at_1_diff1': np.float64(0.7322787459536919), 'nauc_recall_at_3_max': np.float64(0.019687517112643306), 'nauc_recall_at_3_std': np.float64(-0.5803005009661268), 'nauc_recall_at_3_diff1': np.float64(0.5345681539653969), 'nauc_recall_at_5_max': np.float64(0.16492619762000793), 'nauc_recall_at_5_std': np.float64(-0.5187176375691132), 'nauc_recall_at_5_diff1': np.float64(0.5277379522111229), 'nauc_recall_at_10_max': np.float64(0.24017067800846637), 'nauc_recall_at_10_std': np.float64(-0.7962881634526358), 'nauc_recall_at_10_diff1': np.float64(0.3321483033007771), 'nauc_recall_at_20_max': np.float64(0.19626248767482157), 'nauc_recall_at_20_std': np.float64(-1.1093459207664476), 'nauc_recall_at_20_diff1': np.float64(0.5166329680345346), 'nauc_recall_at_100_max': np.float64(0.12223365206031499), 'nauc_recall_at_100_std': np.float64(-1.756535991114336), 'nauc_recall_at_100_diff1': np.float64(-0.5637901180615443), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.126771978137183), 'nauc_precision_at_1_std': np.float64(-0.40912623263660736), 'nauc_precision_at_1_diff1': np.float64(0.7322787459536919), 'nauc_precision_at_3_max': np.float64(0.019687517112642182), 'nauc_precision_at_3_std': np.float64(-0.5803005009661283), 'nauc_precision_at_3_diff1': np.float64(0.5345681539653959), 'nauc_precision_at_5_max': np.float64(0.1649261976200069), 'nauc_precision_at_5_std': np.float64(-0.5187176375691124), 'nauc_precision_at_5_diff1': np.float64(0.527737952211121), 'nauc_precision_at_10_max': np.float64(0.2401706780084637), 'nauc_precision_at_10_std': np.float64(-0.7962881634526331), 'nauc_precision_at_10_diff1': np.float64(0.3321483033007756), 'nauc_precision_at_20_max': np.float64(0.19626248767481844), 'nauc_precision_at_20_std': np.float64(-1.1093459207664509), 'nauc_precision_at_20_diff1': np.float64(0.5166329680345332), 'nauc_precision_at_100_max': np.float64(0.12223365206034731), 'nauc_precision_at_100_std': np.float64(-1.7565359911142433), 'nauc_precision_at_100_diff1': np.float64(-0.5637901180614636), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.126771978137183), 'nauc_mrr_at_1_std': np.float64(-0.40912623263660736), 'nauc_mrr_at_1_diff1': np.float64(0.7322787459536919), 'nauc_mrr_at_3_max': np.float64(0.1121464247829035), 'nauc_mrr_at_3_std': np.float64(-0.44307489383276855), 'nauc_mrr_at_3_diff1': np.float64(0.6723193919828901), 'nauc_mrr_at_5_max': np.float64(0.13612304432346545), 'nauc_mrr_at_5_std': np.float64(-0.42674920364042246), 'nauc_mrr_at_5_diff1': np.float64(0.6765845484302393), 'nauc_mrr_at_10_max': np.float64(0.13934316350785994), 'nauc_mrr_at_10_std': np.float64(-0.43807963497296315), 'nauc_mrr_at_10_diff1': np.float64(0.6700091981210569), 'nauc_mrr_at_20_max': np.float64(0.13799626624712824), 'nauc_mrr_at_20_std': np.float64(-0.43782109293881954), 'nauc_mrr_at_20_diff1': np.float64(0.6745491385664443), 'nauc_mrr_at_100_max': np.float64(0.13903682304516368), 'nauc_mrr_at_100_std': np.float64(-0.4339586660434974), 'nauc_mrr_at_100_diff1': np.float64(0.6742207864378913), 'nauc_mrr_at_1000_max': np.float64(0.13903940947163007), 'nauc_mrr_at_1000_std': np.float64(-0.43375508845684757), 'nauc_mrr_at_1000_diff1': np.float64(0.6744113471464466), 'main_score': 0.76736}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'PublicHealthQA'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'PublicHealthQA'
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.28 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 10.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.76623, 'ndcg_at_3': 0.84957, 'ndcg_at_5': 0.85516, 'ndcg_at_10': 0.87102, 'ndcg_at_20': 0.87826, 'ndcg_at_100': 0.87826, 'ndcg_at_1000': 0.87826, 'map_at_1': 0.76623, 'map_at_3': 0.829, 'map_at_5': 0.83225, 'map_at_10': 0.83824, 'map_at_20': 0.8406, 'map_at_100': 0.8406, 'map_at_1000': 0.8406, 'recall_at_1': 0.76623, 'recall_at_3': 0.90909, 'recall_at_5': 0.92208, 'recall_at_10': 0.97403, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.76623, 'precision_at_3': 0.30303, 'precision_at_5': 0.18442, 'precision_at_10': 0.0974, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7662337662337663, 'mrr_at_3': 0.8290043290043291, 'mrr_at_5': 0.8322510822510824, 'mrr_at_10': 0.8382395382395383, 'mrr_at_20': 0.8406008133280862, 'mrr_at_100': 0.8406008133280862, 'mrr_at_1000': 0.8406008133280862, 'nauc_ndcg_at_1_max': np.float64(0.4691591722758418), 'nauc_ndcg_at_1_std': np.float64(-0.04903115664558869), 'nauc_ndcg_at_1_diff1': np.float64(0.7158820619720496), 'nauc_ndcg_at_3_max': np.float64(0.5162820063696817), 'nauc_ndcg_at_3_std': np.float64(0.001959353725228958), 'nauc_ndcg_at_3_diff1': np.float64(0.7121525614996133), 'nauc_ndcg_at_5_max': np.float64(0.4963559043702825), 'nauc_ndcg_at_5_std': np.float64(-0.03915356739636289), 'nauc_ndcg_at_5_diff1': np.float64(0.7002950794638967), 'nauc_ndcg_at_10_max': np.float64(0.4753715542957344), 'nauc_ndcg_at_10_std': np.float64(-0.08166804488905967), 'nauc_ndcg_at_10_diff1': np.float64(0.6957694014977888), 'nauc_ndcg_at_20_max': np.float64(0.4918067397257687), 'nauc_ndcg_at_20_std': np.float64(-0.042788126060565944), 'nauc_ndcg_at_20_diff1': np.float64(0.7010714401525306), 'nauc_ndcg_at_100_max': np.float64(0.4918067397257687), 'nauc_ndcg_at_100_std': np.float64(-0.042788126060565944), 'nauc_ndcg_at_100_diff1': np.float64(0.7010714401525306), 'nauc_ndcg_at_1000_max': np.float64(0.4918067397257687), 'nauc_ndcg_at_1000_std': np.float64(-0.042788126060565944), 'nauc_ndcg_at_1000_diff1': np.float64(0.7010714401525306), 'nauc_map_at_1_max': np.float64(0.4691591722758418), 'nauc_map_at_1_std': np.float64(-0.04903115664558869), 'nauc_map_at_1_diff1': np.float64(0.7158820619720496), 'nauc_map_at_3_max': np.float64(0.5041937160694657), 'nauc_map_at_3_std': np.float64(-0.01740315649056545), 'nauc_map_at_3_diff1': np.float64(0.7075713776140952), 'nauc_map_at_5_max': np.float64(0.4938432184645834), 'nauc_map_at_5_std': np.float64(-0.03864255840167695), 'nauc_map_at_5_diff1': np.float64(0.7014666107853866), 'nauc_map_at_10_max': np.float64(0.48687056680246493), 'nauc_map_at_10_std': np.float64(-0.05217570853794742), 'nauc_map_at_10_diff1': np.float64(0.7003162267606045), 'nauc_map_at_20_max': np.float64(0.4911557909438372), 'nauc_map_at_20_std': np.float64(-0.04200162661471245), 'nauc_map_at_20_diff1': np.float64(0.7017120847200689), 'nauc_map_at_100_max': np.float64(0.4911557909438372), 'nauc_map_at_100_std': np.float64(-0.04200162661471245), 'nauc_map_at_100_diff1': np.float64(0.7017120847200689), 'nauc_map_at_1000_max': np.float64(0.4911557909438372), 'nauc_map_at_1000_std': np.float64(-0.04200162661471245), 'nauc_map_at_1000_diff1': np.float64(0.7017120847200689), 'nauc_recall_at_1_max': np.float64(0.4691591722758418), 'nauc_recall_at_1_std': np.float64(-0.04903115664558869), 'nauc_recall_at_1_diff1': np.float64(0.7158820619720496), 'nauc_recall_at_3_max': np.float64(0.5750317724577277), 'nauc_recall_at_3_std': np.float64(0.10172403925188503), 'nauc_recall_at_3_diff1': np.float64(0.739408495204222), 'nauc_recall_at_5_max': np.float64(0.5042037345340157), 'nauc_recall_at_5_std': np.float64(-0.04798862087280273), 'nauc_recall_at_5_diff1': np.float64(0.6959765777382573), 'nauc_recall_at_10_max': np.float64(0.21977808756952488), 'nauc_recall_at_10_std': np.float64(-0.6863130780536503), 'nauc_recall_at_10_diff1': np.float64(0.6133142052208155), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.4691591722758418), 'nauc_precision_at_1_std': np.float64(-0.04903115664558869), 'nauc_precision_at_1_diff1': np.float64(0.7158820619720496), 'nauc_precision_at_3_max': np.float64(0.5750317724577289), 'nauc_precision_at_3_std': np.float64(0.10172403925188567), 'nauc_precision_at_3_diff1': np.float64(0.7394084952042222), 'nauc_precision_at_5_max': np.float64(0.5042037345340171), 'nauc_precision_at_5_std': np.float64(-0.047988620872798975), 'nauc_precision_at_5_diff1': np.float64(0.6959765777382597), 'nauc_precision_at_10_max': np.float64(0.21977808756952869), 'nauc_precision_at_10_std': np.float64(-0.68631307805364), 'nauc_precision_at_10_diff1': np.float64(0.613314205220816), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.4691591722758418), 'nauc_mrr_at_1_std': np.float64(-0.04903115664558869), 'nauc_mrr_at_1_diff1': np.float64(0.7158820619720496), 'nauc_mrr_at_3_max': np.float64(0.5041937160694657), 'nauc_mrr_at_3_std': np.float64(-0.01740315649056545), 'nauc_mrr_at_3_diff1': np.float64(0.7075713776140952), 'nauc_mrr_at_5_max': np.float64(0.4938432184645834), 'nauc_mrr_at_5_std': np.float64(-0.03864255840167695), 'nauc_mrr_at_5_diff1': np.float64(0.7014666107853866), 'nauc_mrr_at_10_max': np.float64(0.48687056680246493), 'nauc_mrr_at_10_std': np.float64(-0.05217570853794742), 'nauc_mrr_at_10_diff1': np.float64(0.7003162267606045), 'nauc_mrr_at_20_max': np.float64(0.4911557909438372), 'nauc_mrr_at_20_std': np.float64(-0.04200162661471245), 'nauc_mrr_at_20_diff1': np.float64(0.7017120847200689), 'nauc_mrr_at_100_max': np.float64(0.4911557909438372), 'nauc_mrr_at_100_std': np.float64(-0.04200162661471245), 'nauc_mrr_at_100_diff1': np.float64(0.7017120847200689), 'nauc_mrr_at_1000_max': np.float64(0.4911557909438372), 'nauc_mrr_at_1000_std': np.float64(-0.04200162661471245), 'nauc_mrr_at_1000_diff1': np.float64(0.7017120847200689), 'main_score': 0.87102}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:02<00:06,  2.17s/it]Batches:  50%|█████     | 2/4 [00:05<00:05,  2.71s/it]Batches:  75%|███████▌  | 3/4 [00:08<00:02,  2.84s/it]Batches: 100%|██████████| 4/4 [00:10<00:00,  2.63s/it]Batches: 100%|██████████| 4/4 [00:10<00:00,  2.64s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:18<00:18, 18.38s/it]Batches: 100%|██████████| 2/2 [00:39<00:00, 19.85s/it]Batches: 100%|██████████| 2/2 [00:39<00:00, 19.63s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 56.87 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:01<00:04,  1.63s/it]Batches:  50%|█████     | 2/4 [00:04<00:04,  2.11s/it]Batches:  75%|███████▌  | 3/4 [00:06<00:02,  2.26s/it]Batches: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]Batches: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:18<00:18, 18.41s/it]Batches: 100%|██████████| 2/2 [00:39<00:00, 19.89s/it]Batches: 100%|██████████| 2/2 [00:39<00:00, 19.67s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 54.28 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:02<00:06,  2.18s/it]Batches:  50%|█████     | 2/4 [00:05<00:05,  2.72s/it]Batches:  75%|███████▌  | 3/4 [00:08<00:02,  2.85s/it]Batches: 100%|██████████| 4/4 [00:10<00:00,  2.64s/it]Batches: 100%|██████████| 4/4 [00:10<00:00,  2.65s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'BelebeleRetrieval'
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:10<00:10, 10.84s/it]Batches: 100%|██████████| 2/2 [00:23<00:00, 12.05s/it]Batches: 100%|██████████| 2/2 [00:23<00:00, 11.87s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 39.09 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 151.53 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.90889, 'ndcg_at_3': 0.94079, 'ndcg_at_5': 0.94687, 'ndcg_at_10': 0.95031, 'ndcg_at_20': 0.95149, 'ndcg_at_100': 0.95268, 'ndcg_at_1000': 0.95298, 'map_at_1': 0.90889, 'map_at_3': 0.93333, 'map_at_5': 0.93678, 'map_at_10': 0.93833, 'map_at_20': 0.93867, 'map_at_100': 0.93882, 'map_at_1000': 0.93883, 'recall_at_1': 0.90889, 'recall_at_3': 0.96222, 'recall_at_5': 0.97667, 'recall_at_10': 0.98667, 'recall_at_20': 0.99111, 'recall_at_100': 0.99778, 'recall_at_1000': 1.0, 'precision_at_1': 0.90889, 'precision_at_3': 0.32074, 'precision_at_5': 0.19533, 'precision_at_10': 0.09867, 'precision_at_20': 0.04956, 'precision_at_100': 0.00998, 'precision_at_1000': 0.001, 'mrr_at_1': 0.9088888888888889, 'mrr_at_3': 0.9333333333333333, 'mrr_at_5': 0.9367777777777778, 'mrr_at_10': 0.938325396825397, 'mrr_at_20': 0.9386724386724388, 'mrr_at_100': 0.9388189704418067, 'mrr_at_1000': 0.9388320093524833, 'nauc_ndcg_at_1_max': np.float64(0.7188403816811271), 'nauc_ndcg_at_1_std': np.float64(-0.05228188836510175), 'nauc_ndcg_at_1_diff1': np.float64(0.9116963858714215), 'nauc_ndcg_at_3_max': np.float64(0.7490498897924648), 'nauc_ndcg_at_3_std': np.float64(-0.012166422423827794), 'nauc_ndcg_at_3_diff1': np.float64(0.9105035266030604), 'nauc_ndcg_at_5_max': np.float64(0.7554889418977155), 'nauc_ndcg_at_5_std': np.float64(-0.0019225978879477586), 'nauc_ndcg_at_5_diff1': np.float64(0.9148044996618037), 'nauc_ndcg_at_10_max': np.float64(0.7465292385376752), 'nauc_ndcg_at_10_std': np.float64(-0.02055860257876861), 'nauc_ndcg_at_10_diff1': np.float64(0.9117811583720616), 'nauc_ndcg_at_20_max': np.float64(0.7486534231968061), 'nauc_ndcg_at_20_std': np.float64(-0.007896671167473451), 'nauc_ndcg_at_20_diff1': np.float64(0.9153077919896532), 'nauc_ndcg_at_100_max': np.float64(0.7459189211012296), 'nauc_ndcg_at_100_std': np.float64(-0.010346632084277016), 'nauc_ndcg_at_100_diff1': np.float64(0.9142147010881485), 'nauc_ndcg_at_1000_max': np.float64(0.7443128971492403), 'nauc_ndcg_at_1000_std': np.float64(-0.016732943485235553), 'nauc_ndcg_at_1000_diff1': np.float64(0.9136724598265082), 'nauc_map_at_1_max': np.float64(0.7188403816811271), 'nauc_map_at_1_std': np.float64(-0.05228188836510175), 'nauc_map_at_1_diff1': np.float64(0.9116963858714215), 'nauc_map_at_3_max': np.float64(0.7412244527440593), 'nauc_map_at_3_std': np.float64(-0.02079183525262172), 'nauc_map_at_3_diff1': np.float64(0.911265432098766), 'nauc_map_at_5_max': np.float64(0.7439519646952714), 'nauc_map_at_5_std': np.float64(-0.017185100949187605), 'nauc_map_at_5_diff1': np.float64(0.9134646047444563), 'nauc_map_at_10_max': np.float64(0.7404355728479339), 'nauc_map_at_10_std': np.float64(-0.024010559341766262), 'nauc_map_at_10_diff1': np.float64(0.9122743937363892), 'nauc_map_at_20_max': np.float64(0.7410651672433659), 'nauc_map_at_20_std': np.float64(-0.02110324966587853), 'nauc_map_at_20_diff1': np.float64(0.9131905036524406), 'nauc_map_at_100_max': np.float64(0.7407123827790311), 'nauc_map_at_100_std': np.float64(-0.021777597736298053), 'nauc_map_at_100_diff1': np.float64(0.9130654356261662), 'nauc_map_at_1000_max': np.float64(0.7406571115817144), 'nauc_map_at_1000_std': np.float64(-0.02199540555845129), 'nauc_map_at_1000_diff1': np.float64(0.9130469041686572), 'nauc_recall_at_1_max': np.float64(0.7188403816811271), 'nauc_recall_at_1_std': np.float64(-0.05228188836510175), 'nauc_recall_at_1_diff1': np.float64(0.9116963858714215), 'nauc_recall_at_3_max': np.float64(0.7873482726423862), 'nauc_recall_at_3_std': np.float64(0.028409402976878335), 'nauc_recall_at_3_diff1': np.float64(0.9063546987422432), 'nauc_recall_at_5_max': np.float64(0.8449602063047459), 'nauc_recall_at_5_std': np.float64(0.11802498777288983), 'nauc_recall_at_5_diff1': np.float64(0.9258592325819207), 'nauc_recall_at_10_max': np.float64(0.8148537192654788), 'nauc_recall_at_10_std': np.float64(-0.00042794895735932413), 'nauc_recall_at_10_diff1': np.float64(0.9029333955804517), 'nauc_recall_at_20_max': np.float64(0.8850373482726468), 'nauc_recall_at_20_std': np.float64(0.2735760971055196), 'nauc_recall_at_20_diff1': np.float64(0.9673202614379147), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(1.0), 'nauc_recall_at_100_diff1': np.float64(1.0), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7188403816811271), 'nauc_precision_at_1_std': np.float64(-0.05228188836510175), 'nauc_precision_at_1_diff1': np.float64(0.9116963858714215), 'nauc_precision_at_3_max': np.float64(0.7873482726424003), 'nauc_precision_at_3_std': np.float64(0.02840940297688026), 'nauc_precision_at_3_diff1': np.float64(0.9063546987422461), 'nauc_precision_at_5_max': np.float64(0.8449602063047322), 'nauc_precision_at_5_std': np.float64(0.11802498777287107), 'nauc_precision_at_5_diff1': np.float64(0.9258592325819174), 'nauc_precision_at_10_max': np.float64(0.8148537192654776), 'nauc_precision_at_10_std': np.float64(-0.00042794895737402667), 'nauc_precision_at_10_diff1': np.float64(0.9029333955804523), 'nauc_precision_at_20_max': np.float64(0.8850373482726227), 'nauc_precision_at_20_std': np.float64(0.27357609710550823), 'nauc_precision_at_20_diff1': np.float64(0.9673202614378968), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7188403816811271), 'nauc_mrr_at_1_std': np.float64(-0.05228188836510175), 'nauc_mrr_at_1_diff1': np.float64(0.9116963858714215), 'nauc_mrr_at_3_max': np.float64(0.7412244527440593), 'nauc_mrr_at_3_std': np.float64(-0.02079183525262172), 'nauc_mrr_at_3_diff1': np.float64(0.911265432098766), 'nauc_mrr_at_5_max': np.float64(0.7439519646952714), 'nauc_mrr_at_5_std': np.float64(-0.017185100949187605), 'nauc_mrr_at_5_diff1': np.float64(0.9134646047444563), 'nauc_mrr_at_10_max': np.float64(0.7404355728479339), 'nauc_mrr_at_10_std': np.float64(-0.024010559341766262), 'nauc_mrr_at_10_diff1': np.float64(0.9122743937363892), 'nauc_mrr_at_20_max': np.float64(0.7410651672433659), 'nauc_mrr_at_20_std': np.float64(-0.02110324966587853), 'nauc_mrr_at_20_diff1': np.float64(0.9131905036524406), 'nauc_mrr_at_100_max': np.float64(0.7407123827790311), 'nauc_mrr_at_100_std': np.float64(-0.021777597736298053), 'nauc_mrr_at_100_diff1': np.float64(0.9130654356261662), 'nauc_mrr_at_1000_max': np.float64(0.7406571115817144), 'nauc_mrr_at_1000_std': np.float64(-0.02199540555845129), 'nauc_mrr_at_1000_diff1': np.float64(0.9130469041686572), 'main_score': 0.95031}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.90889, 'ndcg_at_3': 0.9478, 'ndcg_at_5': 0.9501, 'ndcg_at_10': 0.95403, 'ndcg_at_20': 0.95481, 'ndcg_at_100': 0.9556, 'ndcg_at_1000': 0.95576, 'map_at_1': 0.90889, 'map_at_3': 0.93889, 'map_at_5': 0.94017, 'map_at_10': 0.94178, 'map_at_20': 0.94196, 'map_at_100': 0.94205, 'map_at_1000': 0.94206, 'recall_at_1': 0.90889, 'recall_at_3': 0.97333, 'recall_at_5': 0.97889, 'recall_at_10': 0.99111, 'recall_at_20': 0.99444, 'recall_at_100': 0.99889, 'recall_at_1000': 1.0, 'precision_at_1': 0.90889, 'precision_at_3': 0.32444, 'precision_at_5': 0.19578, 'precision_at_10': 0.09911, 'precision_at_20': 0.04972, 'precision_at_100': 0.00999, 'precision_at_1000': 0.001, 'mrr_at_1': 0.9088888888888889, 'mrr_at_3': 0.938888888888889, 'mrr_at_5': 0.9401666666666668, 'mrr_at_10': 0.9417768959435627, 'mrr_at_20': 0.9419595393713043, 'mrr_at_100': 0.9420515214632863, 'mrr_at_1000': 0.9420616224733873, 'nauc_ndcg_at_1_max': np.float64(0.6832570426544589), 'nauc_ndcg_at_1_std': np.float64(-0.10903873744619684), 'nauc_ndcg_at_1_diff1': np.float64(0.9158809865409577), 'nauc_ndcg_at_3_max': np.float64(0.7169198103823423), 'nauc_ndcg_at_3_std': np.float64(-0.100640194438491), 'nauc_ndcg_at_3_diff1': np.float64(0.9167697603147099), 'nauc_ndcg_at_5_max': np.float64(0.7225253866469404), 'nauc_ndcg_at_5_std': np.float64(-0.10146331439589137), 'nauc_ndcg_at_5_diff1': np.float64(0.9191107269135225), 'nauc_ndcg_at_10_max': np.float64(0.7095228252590379), 'nauc_ndcg_at_10_std': np.float64(-0.09864955349067836), 'nauc_ndcg_at_10_diff1': np.float64(0.9163129178755556), 'nauc_ndcg_at_20_max': np.float64(0.7114095295281287), 'nauc_ndcg_at_20_std': np.float64(-0.10072449724871624), 'nauc_ndcg_at_20_diff1': np.float64(0.9174955994414876), 'nauc_ndcg_at_100_max': np.float64(0.710209999135402), 'nauc_ndcg_at_100_std': np.float64(-0.09621003941891325), 'nauc_ndcg_at_100_diff1': np.float64(0.9171811541065946), 'nauc_ndcg_at_1000_max': np.float64(0.7091387368551462), 'nauc_ndcg_at_1000_std': np.float64(-0.10026238236712921), 'nauc_ndcg_at_1000_diff1': np.float64(0.9168749989410084), 'nauc_map_at_1_max': np.float64(0.6832570426544589), 'nauc_map_at_1_std': np.float64(-0.10903873744619684), 'nauc_map_at_1_diff1': np.float64(0.9158809865409577), 'nauc_map_at_3_max': np.float64(0.7075446340152217), 'nauc_map_at_3_std': np.float64(-0.10185892538833605), 'nauc_map_at_3_diff1': np.float64(0.9161927397221514), 'nauc_map_at_5_max': np.float64(0.7102568459551353), 'nauc_map_at_5_std': np.float64(-0.10187330890263689), 'nauc_map_at_5_diff1': np.float64(0.9172704261731529), 'nauc_map_at_10_max': np.float64(0.7058293745366361), 'nauc_map_at_10_std': np.float64(-0.10136474986309112), 'nauc_map_at_10_diff1': np.float64(0.9163435814815639), 'nauc_map_at_20_max': np.float64(0.7062227126431071), 'nauc_map_at_20_std': np.float64(-0.10160605455726894), 'nauc_map_at_20_diff1': np.float64(0.9165823959431059), 'nauc_map_at_100_max': np.float64(0.7061024157988216), 'nauc_map_at_100_std': np.float64(-0.10122817053584164), 'nauc_map_at_100_diff1': np.float64(0.9165514368738306), 'nauc_map_at_1000_max': np.float64(0.7060511775247559), 'nauc_map_at_1000_std': np.float64(-0.10142015928922532), 'nauc_map_at_1000_diff1': np.float64(0.9165368884032821), 'nauc_recall_at_1_max': np.float64(0.6832570426544589), 'nauc_recall_at_1_std': np.float64(-0.10903873744619684), 'nauc_recall_at_1_diff1': np.float64(0.9158809865409577), 'nauc_recall_at_3_max': np.float64(0.7763383131030149), 'nauc_recall_at_3_std': np.float64(-0.09428493619670865), 'nauc_recall_at_3_diff1': np.float64(0.9208294428882646), 'nauc_recall_at_5_max': np.float64(0.8204088653005103), 'nauc_recall_at_5_std': np.float64(-0.10194604157452254), 'nauc_recall_at_5_diff1': np.float64(0.9352548036758563), 'nauc_recall_at_10_max': np.float64(0.742121848739506), 'nauc_recall_at_10_std': np.float64(-0.04382586367881708), 'nauc_recall_at_10_diff1': np.float64(0.9115896358543438), 'nauc_recall_at_20_max': np.float64(0.8216619981325954), 'nauc_recall_at_20_std': np.float64(-0.09598506069095802), 'nauc_recall_at_20_diff1': np.float64(0.9477124183006633), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(1.0), 'nauc_recall_at_100_diff1': np.float64(1.0), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6832570426544589), 'nauc_precision_at_1_std': np.float64(-0.10903873744619684), 'nauc_precision_at_1_diff1': np.float64(0.9158809865409577), 'nauc_precision_at_3_max': np.float64(0.7763383131030174), 'nauc_precision_at_3_std': np.float64(-0.09428493619669641), 'nauc_precision_at_3_diff1': np.float64(0.9208294428882671), 'nauc_precision_at_5_max': np.float64(0.8204088653004997), 'nauc_precision_at_5_std': np.float64(-0.10194604157453166), 'nauc_precision_at_5_diff1': np.float64(0.9352548036758487), 'nauc_precision_at_10_max': np.float64(0.7421218487394915), 'nauc_precision_at_10_std': np.float64(-0.04382586367882378), 'nauc_precision_at_10_diff1': np.float64(0.9115896358543304), 'nauc_precision_at_20_max': np.float64(0.8216619981325554), 'nauc_precision_at_20_std': np.float64(-0.09598506069096334), 'nauc_precision_at_20_diff1': np.float64(0.9477124183006342), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6832570426544589), 'nauc_mrr_at_1_std': np.float64(-0.10903873744619684), 'nauc_mrr_at_1_diff1': np.float64(0.9158809865409577), 'nauc_mrr_at_3_max': np.float64(0.7075446340152217), 'nauc_mrr_at_3_std': np.float64(-0.10185892538833605), 'nauc_mrr_at_3_diff1': np.float64(0.9161927397221514), 'nauc_mrr_at_5_max': np.float64(0.7102568459551353), 'nauc_mrr_at_5_std': np.float64(-0.10187330890263689), 'nauc_mrr_at_5_diff1': np.float64(0.9172704261731529), 'nauc_mrr_at_10_max': np.float64(0.7058293745366361), 'nauc_mrr_at_10_std': np.float64(-0.10136474986309112), 'nauc_mrr_at_10_diff1': np.float64(0.9163435814815639), 'nauc_mrr_at_20_max': np.float64(0.7062227126431071), 'nauc_mrr_at_20_std': np.float64(-0.10160605455726894), 'nauc_mrr_at_20_diff1': np.float64(0.9165823959431059), 'nauc_mrr_at_100_max': np.float64(0.7061024157988216), 'nauc_mrr_at_100_std': np.float64(-0.10122817053584164), 'nauc_mrr_at_100_diff1': np.float64(0.9165514368738306), 'nauc_mrr_at_1000_max': np.float64(0.7060511775247559), 'nauc_mrr_at_1000_std': np.float64(-0.10142015928922532), 'nauc_mrr_at_1000_diff1': np.float64(0.9165368884032821), 'main_score': 0.95403}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.86889, 'ndcg_at_3': 0.91143, 'ndcg_at_5': 0.92023, 'ndcg_at_10': 0.92536, 'ndcg_at_20': 0.92789, 'ndcg_at_100': 0.92929, 'ndcg_at_1000': 0.93003, 'map_at_1': 0.86889, 'map_at_3': 0.90148, 'map_at_5': 0.90643, 'map_at_10': 0.9086, 'map_at_20': 0.90929, 'map_at_100': 0.90947, 'map_at_1000': 0.9095, 'recall_at_1': 0.86889, 'recall_at_3': 0.94, 'recall_at_5': 0.96111, 'recall_at_10': 0.97667, 'recall_at_20': 0.98667, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.86889, 'precision_at_3': 0.31333, 'precision_at_5': 0.19222, 'precision_at_10': 0.09767, 'precision_at_20': 0.04933, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8688888888888889, 'mrr_at_3': 0.9014814814814817, 'mrr_at_5': 0.906425925925926, 'mrr_at_10': 0.9085996472663139, 'mrr_at_20': 0.9092942746012922, 'mrr_at_100': 0.909470360116632, 'mrr_at_1000': 0.9095048720485812, 'nauc_ndcg_at_1_max': np.float64(0.6804618726420486), 'nauc_ndcg_at_1_std': np.float64(0.007827173398226054), 'nauc_ndcg_at_1_diff1': np.float64(0.8736832220026454), 'nauc_ndcg_at_3_max': np.float64(0.7258945931659551), 'nauc_ndcg_at_3_std': np.float64(0.10824551074368814), 'nauc_ndcg_at_3_diff1': np.float64(0.8574694167626213), 'nauc_ndcg_at_5_max': np.float64(0.7308859072140415), 'nauc_ndcg_at_5_std': np.float64(0.10481918411817163), 'nauc_ndcg_at_5_diff1': np.float64(0.8613417296690747), 'nauc_ndcg_at_10_max': np.float64(0.7258421215464931), 'nauc_ndcg_at_10_std': np.float64(0.10635033992074794), 'nauc_ndcg_at_10_diff1': np.float64(0.8637689373566968), 'nauc_ndcg_at_20_max': np.float64(0.7210805281595255), 'nauc_ndcg_at_20_std': np.float64(0.1007631450435083), 'nauc_ndcg_at_20_diff1': np.float64(0.8637896567144416), 'nauc_ndcg_at_100_max': np.float64(0.7189638881008403), 'nauc_ndcg_at_100_std': np.float64(0.09633730593253717), 'nauc_ndcg_at_100_diff1': np.float64(0.8629779195228341), 'nauc_ndcg_at_1000_max': np.float64(0.71590023848875), 'nauc_ndcg_at_1000_std': np.float64(0.08648623788497728), 'nauc_ndcg_at_1000_diff1': np.float64(0.8632286841031792), 'nauc_map_at_1_max': np.float64(0.6804618726420486), 'nauc_map_at_1_std': np.float64(0.007827173398226054), 'nauc_map_at_1_diff1': np.float64(0.8736832220026454), 'nauc_map_at_3_max': np.float64(0.7125151430435159), 'nauc_map_at_3_std': np.float64(0.0784992079023399), 'nauc_map_at_3_diff1': np.float64(0.8615719733625798), 'nauc_map_at_5_max': np.float64(0.7136930804737212), 'nauc_map_at_5_std': np.float64(0.07481050356779848), 'nauc_map_at_5_diff1': np.float64(0.8632428771082424), 'nauc_map_at_10_max': np.float64(0.7117231646069888), 'nauc_map_at_10_std': np.float64(0.07553818679731193), 'nauc_map_at_10_diff1': np.float64(0.8640198824353712), 'nauc_map_at_20_max': np.float64(0.7105814519919821), 'nauc_map_at_20_std': np.float64(0.07404367355252923), 'nauc_map_at_20_diff1': np.float64(0.8640360445505845), 'nauc_map_at_100_max': np.float64(0.7102647913389938), 'nauc_map_at_100_std': np.float64(0.07322744957382026), 'nauc_map_at_100_diff1': np.float64(0.8639562723583244), 'nauc_map_at_1000_max': np.float64(0.7101517557618113), 'nauc_map_at_1000_std': np.float64(0.07286588402353471), 'nauc_map_at_1000_diff1': np.float64(0.8639608449306619), 'nauc_recall_at_1_max': np.float64(0.6804618726420486), 'nauc_recall_at_1_std': np.float64(0.007827173398226054), 'nauc_recall_at_1_diff1': np.float64(0.8736832220026454), 'nauc_recall_at_3_max': np.float64(0.7872877546080163), 'nauc_recall_at_3_std': np.float64(0.24486461251167338), 'nauc_recall_at_3_diff1': np.float64(0.839125773766298), 'nauc_recall_at_5_max': np.float64(0.8495664932639706), 'nauc_recall_at_5_std': np.float64(0.3067360277444287), 'nauc_recall_at_5_diff1': np.float64(0.851874082966519), 'nauc_recall_at_10_max': np.float64(0.8768618558534561), 'nauc_recall_at_10_std': np.float64(0.4379974211906987), 'nauc_recall_at_10_diff1': np.float64(0.8708372237783996), 'nauc_recall_at_20_max': np.float64(0.8897447868036054), 'nauc_recall_at_20_std': np.float64(0.5705726735138528), 'nauc_recall_at_20_diff1': np.float64(0.8760893246187288), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(1.0), 'nauc_recall_at_100_diff1': np.float64(0.8366013071895522), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6804618726420486), 'nauc_precision_at_1_std': np.float64(0.007827173398226054), 'nauc_precision_at_1_diff1': np.float64(0.8736832220026454), 'nauc_precision_at_3_max': np.float64(0.787287754608017), 'nauc_precision_at_3_std': np.float64(0.24486461251167171), 'nauc_precision_at_3_diff1': np.float64(0.839125773766297), 'nauc_precision_at_5_max': np.float64(0.8495664932639713), 'nauc_precision_at_5_std': np.float64(0.30673602774442654), 'nauc_precision_at_5_diff1': np.float64(0.8518740829665197), 'nauc_precision_at_10_max': np.float64(0.8768618558534468), 'nauc_precision_at_10_std': np.float64(0.43799742119069335), 'nauc_precision_at_10_diff1': np.float64(0.8708372237784001), 'nauc_precision_at_20_max': np.float64(0.8897447868036057), 'nauc_precision_at_20_std': np.float64(0.5705726735138443), 'nauc_precision_at_20_diff1': np.float64(0.8760893246187312), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(0.8366013071895334), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6804618726420486), 'nauc_mrr_at_1_std': np.float64(0.007827173398226054), 'nauc_mrr_at_1_diff1': np.float64(0.8736832220026454), 'nauc_mrr_at_3_max': np.float64(0.7125151430435159), 'nauc_mrr_at_3_std': np.float64(0.0784992079023399), 'nauc_mrr_at_3_diff1': np.float64(0.8615719733625798), 'nauc_mrr_at_5_max': np.float64(0.7136930804737212), 'nauc_mrr_at_5_std': np.float64(0.07481050356779848), 'nauc_mrr_at_5_diff1': np.float64(0.8632428771082424), 'nauc_mrr_at_10_max': np.float64(0.7117231646069888), 'nauc_mrr_at_10_std': np.float64(0.07553818679731193), 'nauc_mrr_at_10_diff1': np.float64(0.8640198824353712), 'nauc_mrr_at_20_max': np.float64(0.7105814519919821), 'nauc_mrr_at_20_std': np.float64(0.07404367355252923), 'nauc_mrr_at_20_diff1': np.float64(0.8640360445505845), 'nauc_mrr_at_100_max': np.float64(0.7102647913389938), 'nauc_mrr_at_100_std': np.float64(0.07322744957382026), 'nauc_mrr_at_100_diff1': np.float64(0.8639562723583244), 'nauc_mrr_at_1000_max': np.float64(0.7101517557618113), 'nauc_mrr_at_1000_std': np.float64(0.07286588402353471), 'nauc_mrr_at_1000_diff1': np.float64(0.8639608449306619), 'main_score': 0.92536}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:03<00:06,  3.11s/it]Batches:  67%|██████▋   | 2/3 [00:08<00:04,  4.56s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.37s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.28s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/it]Batches:  50%|█████     | 2/4 [00:08<00:08,  4.40s/it]Batches:  75%|███████▌  | 3/4 [00:15<00:05,  5.48s/it]Batches: 100%|██████████| 4/4 [00:20<00:00,  5.31s/it]Batches: 100%|██████████| 4/4 [00:20<00:00,  5.03s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 35.89 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:03<00:06,  3.14s/it]Batches:  67%|██████▋   | 2/3 [00:08<00:04,  4.59s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.39s/it]Batches: 100%|██████████| 3/3 [00:12<00:00,  4.30s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/5 [00:00<?, ?it/s]Batches:  20%|██        | 1/5 [00:14<00:58, 14.56s/it]Batches:  40%|████      | 2/5 [00:27<00:41, 13.67s/it]Batches:  60%|██████    | 3/5 [00:50<00:35, 17.89s/it]Batches:  80%|████████  | 4/5 [01:08<00:17, 17.88s/it]Batches: 100%|██████████| 5/5 [01:18<00:00, 15.11s/it]Batches: 100%|██████████| 5/5 [01:18<00:00, 15.72s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 96.30 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  33%|███▎      | 1/3 [00:02<00:05,  2.56s/it]Batches:  67%|██████▋   | 2/3 [00:07<00:03,  3.84s/it]Batches: 100%|██████████| 3/3 [00:09<00:00,  3.26s/it]Batches: 100%|██████████| 3/3 [00:09<00:00,  3.29s/it]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'XPQARetrieval'
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:02<00:08,  2.72s/it]Batches:  50%|█████     | 2/4 [00:08<00:08,  4.42s/it]Batches:  75%|███████▌  | 3/4 [00:15<00:05,  5.50s/it]Batches: 100%|██████████| 4/4 [00:20<00:00,  5.33s/it]Batches: 100%|██████████| 4/4 [00:20<00:00,  5.05s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 32.22 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 166.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.29664, 'ndcg_at_3': 0.32396, 'ndcg_at_5': 0.34845, 'ndcg_at_10': 0.37592, 'ndcg_at_20': 0.40338, 'ndcg_at_100': 0.44897, 'ndcg_at_1000': 0.47593, 'map_at_1': 0.21073, 'map_at_3': 0.29525, 'map_at_5': 0.31584, 'map_at_10': 0.32965, 'map_at_20': 0.33811, 'map_at_100': 0.34505, 'map_at_1000': 0.34617, 'recall_at_1': 0.21073, 'recall_at_3': 0.34182, 'recall_at_5': 0.40268, 'recall_at_10': 0.47847, 'recall_at_20': 0.57783, 'recall_at_100': 0.80008, 'recall_at_1000': 1.0, 'precision_at_1': 0.29664, 'precision_at_3': 0.18298, 'precision_at_5': 0.13211, 'precision_at_10': 0.07798, 'precision_at_20': 0.04656, 'precision_at_100': 0.01287, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.2981651376146789, 'mrr_at_3': 0.34327217125382276, 'mrr_at_5': 0.35527522935779815, 'mrr_at_10': 0.3644556089510217, 'mrr_at_20': 0.37102385034738683, 'mrr_at_100': 0.3762740658689807, 'mrr_at_1000': 0.3769803860239061, 'nauc_ndcg_at_1_max': np.float64(0.05557780805418263), 'nauc_ndcg_at_1_std': np.float64(-0.33582415764917956), 'nauc_ndcg_at_1_diff1': np.float64(0.5140988552200851), 'nauc_ndcg_at_3_max': np.float64(0.033862171173852026), 'nauc_ndcg_at_3_std': np.float64(-0.34791166229539255), 'nauc_ndcg_at_3_diff1': np.float64(0.4634166248449727), 'nauc_ndcg_at_5_max': np.float64(0.03436568948065042), 'nauc_ndcg_at_5_std': np.float64(-0.35105343784099086), 'nauc_ndcg_at_5_diff1': np.float64(0.4490295160400167), 'nauc_ndcg_at_10_max': np.float64(0.03329203611265299), 'nauc_ndcg_at_10_std': np.float64(-0.36064098025357194), 'nauc_ndcg_at_10_diff1': np.float64(0.4422924330214788), 'nauc_ndcg_at_20_max': np.float64(0.025499595390370375), 'nauc_ndcg_at_20_std': np.float64(-0.3623075007311051), 'nauc_ndcg_at_20_diff1': np.float64(0.43440545757951177), 'nauc_ndcg_at_100_max': np.float64(0.036428932562475855), 'nauc_ndcg_at_100_std': np.float64(-0.3319199190513103), 'nauc_ndcg_at_100_diff1': np.float64(0.4241166160129607), 'nauc_ndcg_at_1000_max': np.float64(0.035618324045892276), 'nauc_ndcg_at_1000_std': np.float64(-0.34399680434226604), 'nauc_ndcg_at_1000_diff1': np.float64(0.441208014586694), 'nauc_map_at_1_max': np.float64(0.06707422095579671), 'nauc_map_at_1_std': np.float64(-0.27169880219771503), 'nauc_map_at_1_diff1': np.float64(0.5499538425315931), 'nauc_map_at_3_max': np.float64(0.051672120805383207), 'nauc_map_at_3_std': np.float64(-0.32511159938976775), 'nauc_map_at_3_diff1': np.float64(0.46709381228326974), 'nauc_map_at_5_max': np.float64(0.0471418368579935), 'nauc_map_at_5_std': np.float64(-0.33706036871879985), 'nauc_map_at_5_diff1': np.float64(0.45901942051942357), 'nauc_map_at_10_max': np.float64(0.04433789441300373), 'nauc_map_at_10_std': np.float64(-0.343407481730035), 'nauc_map_at_10_diff1': np.float64(0.4550116286649479), 'nauc_map_at_20_max': np.float64(0.040102245891802765), 'nauc_map_at_20_std': np.float64(-0.3454531703849382), 'nauc_map_at_20_diff1': np.float64(0.4519292842707661), 'nauc_map_at_100_max': np.float64(0.04097045258035305), 'nauc_map_at_100_std': np.float64(-0.34231077492837786), 'nauc_map_at_100_diff1': np.float64(0.45057804868286105), 'nauc_map_at_1000_max': np.float64(0.04105499716186191), 'nauc_map_at_1000_std': np.float64(-0.34248298590751103), 'nauc_map_at_1000_diff1': np.float64(0.45118254221391046), 'nauc_recall_at_1_max': np.float64(0.06707422095579671), 'nauc_recall_at_1_std': np.float64(-0.27169880219771503), 'nauc_recall_at_1_diff1': np.float64(0.5499538425315931), 'nauc_recall_at_3_max': np.float64(0.02346401962629475), 'nauc_recall_at_3_std': np.float64(-0.3391912635813522), 'nauc_recall_at_3_diff1': np.float64(0.42521453300707407), 'nauc_recall_at_5_max': np.float64(0.022382243197831813), 'nauc_recall_at_5_std': np.float64(-0.34951012487246325), 'nauc_recall_at_5_diff1': np.float64(0.393625707521241), 'nauc_recall_at_10_max': np.float64(0.0261687268553862), 'nauc_recall_at_10_std': np.float64(-0.3702060163171477), 'nauc_recall_at_10_diff1': np.float64(0.37401666451734666), 'nauc_recall_at_20_max': np.float64(-0.0016547210256395546), 'nauc_recall_at_20_std': np.float64(-0.3722772376118425), 'nauc_recall_at_20_diff1': np.float64(0.34034545231647373), 'nauc_recall_at_100_max': np.float64(0.05660458022876323), 'nauc_recall_at_100_std': np.float64(-0.14201566869772833), 'nauc_recall_at_100_diff1': np.float64(0.19267932767253274), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.05557780805418263), 'nauc_precision_at_1_std': np.float64(-0.33582415764917956), 'nauc_precision_at_1_diff1': np.float64(0.5140988552200851), 'nauc_precision_at_3_max': np.float64(0.009190499286246987), 'nauc_precision_at_3_std': np.float64(-0.34314588521355643), 'nauc_precision_at_3_diff1': np.float64(0.2797084528868581), 'nauc_precision_at_5_max': np.float64(-0.012960372511823054), 'nauc_precision_at_5_std': np.float64(-0.34761210134718035), 'nauc_precision_at_5_diff1': np.float64(0.23559678451612145), 'nauc_precision_at_10_max': np.float64(-0.025722833971433528), 'nauc_precision_at_10_std': np.float64(-0.3492346243116707), 'nauc_precision_at_10_diff1': np.float64(0.19745903113472338), 'nauc_precision_at_20_max': np.float64(-0.043449399258429056), 'nauc_precision_at_20_std': np.float64(-0.31693249339322505), 'nauc_precision_at_20_diff1': np.float64(0.1367997226598164), 'nauc_precision_at_100_max': np.float64(0.02358157147512951), 'nauc_precision_at_100_std': np.float64(-0.08469202659277113), 'nauc_precision_at_100_diff1': np.float64(-0.0117526765233394), 'nauc_precision_at_1000_max': np.float64(0.013899248168794804), 'nauc_precision_at_1000_std': np.float64(-0.039723913443499785), 'nauc_precision_at_1000_diff1': np.float64(-0.07245721273567073), 'nauc_mrr_at_1_max': np.float64(0.05158009918334785), 'nauc_mrr_at_1_std': np.float64(-0.33884286914246503), 'nauc_mrr_at_1_diff1': np.float64(0.508374465290196), 'nauc_mrr_at_3_max': np.float64(0.025671114670976703), 'nauc_mrr_at_3_std': np.float64(-0.3628541803266646), 'nauc_mrr_at_3_diff1': np.float64(0.4836171970008714), 'nauc_mrr_at_5_max': np.float64(0.024182208820007357), 'nauc_mrr_at_5_std': np.float64(-0.36351922472564824), 'nauc_mrr_at_5_diff1': np.float64(0.47502527781899906), 'nauc_mrr_at_10_max': np.float64(0.025720454448439792), 'nauc_mrr_at_10_std': np.float64(-0.36432229030936475), 'nauc_mrr_at_10_diff1': np.float64(0.4742888539450159), 'nauc_mrr_at_20_max': np.float64(0.026266164673668112), 'nauc_mrr_at_20_std': np.float64(-0.3634048323486007), 'nauc_mrr_at_20_diff1': np.float64(0.47361404593644774), 'nauc_mrr_at_100_max': np.float64(0.026299882318369897), 'nauc_mrr_at_100_std': np.float64(-0.3615646261690853), 'nauc_mrr_at_100_diff1': np.float64(0.4728085697801015), 'nauc_mrr_at_1000_max': np.float64(0.02642342925980236), 'nauc_mrr_at_1000_std': np.float64(-0.36179749396145205), 'nauc_mrr_at_1000_diff1': np.float64(0.473328740730085), 'main_score': 0.37592}, 'eng-kor': {'ndcg_at_1': 0.28746, 'ndcg_at_3': 0.29548, 'ndcg_at_5': 0.31737, 'ndcg_at_10': 0.34602, 'ndcg_at_20': 0.3756, 'ndcg_at_100': 0.42667, 'ndcg_at_1000': 0.46008, 'map_at_1': 0.16901, 'map_at_3': 0.24639, 'map_at_5': 0.27459, 'map_at_10': 0.29034, 'map_at_20': 0.30032, 'map_at_100': 0.30873, 'map_at_1000': 0.31058, 'recall_at_1': 0.16901, 'recall_at_3': 0.29174, 'recall_at_5': 0.36371, 'recall_at_10': 0.43346, 'recall_at_20': 0.53196, 'recall_at_100': 0.77029, 'recall_at_1000': 0.99529, 'precision_at_1': 0.28746, 'precision_at_3': 0.18858, 'precision_at_5': 0.14495, 'precision_at_10': 0.08869, 'precision_at_20': 0.05382, 'precision_at_100': 0.01537, 'precision_at_1000': 0.00194, 'mrr_at_1': 0.2874617737003058, 'mrr_at_3': 0.33919469928644264, 'mrr_at_5': 0.35165647298674835, 'mrr_at_10': 0.36143451774185714, 'mrr_at_20': 0.3686706661818145, 'mrr_at_100': 0.3738564439533803, 'mrr_at_1000': 0.3746312411314341, 'nauc_ndcg_at_1_max': np.float64(-0.07557913101326526), 'nauc_ndcg_at_1_std': np.float64(-0.3919091714869001), 'nauc_ndcg_at_1_diff1': np.float64(0.5239759944443022), 'nauc_ndcg_at_3_max': np.float64(-0.07508114804437861), 'nauc_ndcg_at_3_std': np.float64(-0.37859375677032936), 'nauc_ndcg_at_3_diff1': np.float64(0.43528770133570827), 'nauc_ndcg_at_5_max': np.float64(-0.08337118086137862), 'nauc_ndcg_at_5_std': np.float64(-0.3740086418226439), 'nauc_ndcg_at_5_diff1': np.float64(0.42054918503867317), 'nauc_ndcg_at_10_max': np.float64(-0.09006608911199636), 'nauc_ndcg_at_10_std': np.float64(-0.3913244638349171), 'nauc_ndcg_at_10_diff1': np.float64(0.4154316808411303), 'nauc_ndcg_at_20_max': np.float64(-0.08687688172654597), 'nauc_ndcg_at_20_std': np.float64(-0.3902022010304215), 'nauc_ndcg_at_20_diff1': np.float64(0.41979544830433646), 'nauc_ndcg_at_100_max': np.float64(-0.0688200111277367), 'nauc_ndcg_at_100_std': np.float64(-0.3592910749333413), 'nauc_ndcg_at_100_diff1': np.float64(0.41967610026756824), 'nauc_ndcg_at_1000_max': np.float64(-0.0698252293424869), 'nauc_ndcg_at_1000_std': np.float64(-0.36634056860821734), 'nauc_ndcg_at_1000_diff1': np.float64(0.43002528642034604), 'nauc_map_at_1_max': np.float64(-0.07903816820370207), 'nauc_map_at_1_std': np.float64(-0.306576717555627), 'nauc_map_at_1_diff1': np.float64(0.4702667027438464), 'nauc_map_at_3_max': np.float64(-0.07133037835849922), 'nauc_map_at_3_std': np.float64(-0.35673089974850686), 'nauc_map_at_3_diff1': np.float64(0.4414727726016833), 'nauc_map_at_5_max': np.float64(-0.07699440272778688), 'nauc_map_at_5_std': np.float64(-0.36523546368776894), 'nauc_map_at_5_diff1': np.float64(0.43497792263515683), 'nauc_map_at_10_max': np.float64(-0.07976755795540036), 'nauc_map_at_10_std': np.float64(-0.3748188439515774), 'nauc_map_at_10_diff1': np.float64(0.43123652064648366), 'nauc_map_at_20_max': np.float64(-0.08083624693340537), 'nauc_map_at_20_std': np.float64(-0.37641132074854966), 'nauc_map_at_20_diff1': np.float64(0.43309787564754665), 'nauc_map_at_100_max': np.float64(-0.07823585517088828), 'nauc_map_at_100_std': np.float64(-0.3727379265974714), 'nauc_map_at_100_diff1': np.float64(0.4341285240442023), 'nauc_map_at_1000_max': np.float64(-0.07738204421691947), 'nauc_map_at_1000_std': np.float64(-0.3719610658164897), 'nauc_map_at_1000_diff1': np.float64(0.43454259687207253), 'nauc_recall_at_1_max': np.float64(-0.07903816820370207), 'nauc_recall_at_1_std': np.float64(-0.306576717555627), 'nauc_recall_at_1_diff1': np.float64(0.4702667027438464), 'nauc_recall_at_3_max': np.float64(-0.07649022603466982), 'nauc_recall_at_3_std': np.float64(-0.3412366758489287), 'nauc_recall_at_3_diff1': np.float64(0.35765139112123506), 'nauc_recall_at_5_max': np.float64(-0.08206549980665223), 'nauc_recall_at_5_std': np.float64(-0.3414271595469804), 'nauc_recall_at_5_diff1': np.float64(0.3356623184418774), 'nauc_recall_at_10_max': np.float64(-0.10053323626515304), 'nauc_recall_at_10_std': np.float64(-0.38203201316820184), 'nauc_recall_at_10_diff1': np.float64(0.32140890735588934), 'nauc_recall_at_20_max': np.float64(-0.08719839778109112), 'nauc_recall_at_20_std': np.float64(-0.3704497576042195), 'nauc_recall_at_20_diff1': np.float64(0.3236304189423448), 'nauc_recall_at_100_max': np.float64(0.0079107284556092), 'nauc_recall_at_100_std': np.float64(-0.1704396471531876), 'nauc_recall_at_100_diff1': np.float64(0.2564164978345398), 'nauc_recall_at_1000_max': np.float64(0.5028113070253024), 'nauc_recall_at_1000_std': np.float64(0.44697916727698483), 'nauc_recall_at_1000_diff1': np.float64(-0.10407317508841295), 'nauc_precision_at_1_max': np.float64(-0.07557913101326526), 'nauc_precision_at_1_std': np.float64(-0.3919091714869001), 'nauc_precision_at_1_diff1': np.float64(0.5239759944443022), 'nauc_precision_at_3_max': np.float64(-0.05627704117444213), 'nauc_precision_at_3_std': np.float64(-0.37911767759125187), 'nauc_precision_at_3_diff1': np.float64(0.36814708868802454), 'nauc_precision_at_5_max': np.float64(-0.06568243696191937), 'nauc_precision_at_5_std': np.float64(-0.35348354651671987), 'nauc_precision_at_5_diff1': np.float64(0.32510528514702947), 'nauc_precision_at_10_max': np.float64(-0.06771404249834337), 'nauc_precision_at_10_std': np.float64(-0.34628680355800207), 'nauc_precision_at_10_diff1': np.float64(0.28061874328458825), 'nauc_precision_at_20_max': np.float64(-0.058201148391753686), 'nauc_precision_at_20_std': np.float64(-0.32007467920467797), 'nauc_precision_at_20_diff1': np.float64(0.2656176182709642), 'nauc_precision_at_100_max': np.float64(0.04309338084975882), 'nauc_precision_at_100_std': np.float64(-0.10329859805643939), 'nauc_precision_at_100_diff1': np.float64(0.1657115501789244), 'nauc_precision_at_1000_max': np.float64(0.06035578926403879), 'nauc_precision_at_1000_std': np.float64(-0.03420392424932585), 'nauc_precision_at_1000_diff1': np.float64(0.09909451217699854), 'nauc_mrr_at_1_max': np.float64(-0.07557913101326526), 'nauc_mrr_at_1_std': np.float64(-0.3919091714869001), 'nauc_mrr_at_1_diff1': np.float64(0.5239759944443022), 'nauc_mrr_at_3_max': np.float64(-0.09267487133847752), 'nauc_mrr_at_3_std': np.float64(-0.40223073877344434), 'nauc_mrr_at_3_diff1': np.float64(0.4680326266035005), 'nauc_mrr_at_5_max': np.float64(-0.090381255630442), 'nauc_mrr_at_5_std': np.float64(-0.39720714241906285), 'nauc_mrr_at_5_diff1': np.float64(0.46267343271336625), 'nauc_mrr_at_10_max': np.float64(-0.09216145507287433), 'nauc_mrr_at_10_std': np.float64(-0.4022177947847317), 'nauc_mrr_at_10_diff1': np.float64(0.4615072703153556), 'nauc_mrr_at_20_max': np.float64(-0.0885453344201705), 'nauc_mrr_at_20_std': np.float64(-0.3987160407003344), 'nauc_mrr_at_20_diff1': np.float64(0.4615549240074451), 'nauc_mrr_at_100_max': np.float64(-0.08815504339697978), 'nauc_mrr_at_100_std': np.float64(-0.3972941447006013), 'nauc_mrr_at_100_diff1': np.float64(0.46209109843028023), 'nauc_mrr_at_1000_max': np.float64(-0.08819017414593382), 'nauc_mrr_at_1000_std': np.float64(-0.3974611242011401), 'nauc_mrr_at_1000_diff1': np.float64(0.4623773028855601), 'main_score': 0.34602}, 'kor-eng': {'ndcg_at_1': 0.29316, 'ndcg_at_3': 0.31575, 'ndcg_at_5': 0.33503, 'ndcg_at_10': 0.36744, 'ndcg_at_20': 0.3918, 'ndcg_at_100': 0.44076, 'ndcg_at_1000': 0.46929, 'map_at_1': 0.20135, 'map_at_3': 0.28543, 'map_at_5': 0.30397, 'map_at_10': 0.32078, 'map_at_20': 0.32853, 'map_at_100': 0.33585, 'map_at_1000': 0.33705, 'recall_at_1': 0.20135, 'recall_at_3': 0.32904, 'recall_at_5': 0.37835, 'recall_at_10': 0.46615, 'recall_at_20': 0.55196, 'recall_at_100': 0.79104, 'recall_at_1000': 1.0, 'precision_at_1': 0.29316, 'precision_at_3': 0.18187, 'precision_at_5': 0.12997, 'precision_at_10': 0.08029, 'precision_at_20': 0.04731, 'precision_at_100': 0.01352, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.2947882736156352, 'mrr_at_3': 0.3371335504885994, 'mrr_at_5': 0.3469055374592833, 'mrr_at_10': 0.3582208779277182, 'mrr_at_20': 0.36400288528563496, 'mrr_at_100': 0.3693169497410437, 'mrr_at_1000': 0.3700350770479795, 'nauc_ndcg_at_1_max': np.float64(0.006884255364796974), 'nauc_ndcg_at_1_std': np.float64(-0.2993040780314914), 'nauc_ndcg_at_1_diff1': np.float64(0.45301556456254305), 'nauc_ndcg_at_3_max': np.float64(-0.003585872617241586), 'nauc_ndcg_at_3_std': np.float64(-0.3178301281434147), 'nauc_ndcg_at_3_diff1': np.float64(0.43788022641176066), 'nauc_ndcg_at_5_max': np.float64(0.005647753477491042), 'nauc_ndcg_at_5_std': np.float64(-0.3157220236307141), 'nauc_ndcg_at_5_diff1': np.float64(0.41901429844395216), 'nauc_ndcg_at_10_max': np.float64(0.005804588154272886), 'nauc_ndcg_at_10_std': np.float64(-0.3111234798673641), 'nauc_ndcg_at_10_diff1': np.float64(0.40533939627542065), 'nauc_ndcg_at_20_max': np.float64(-0.0005156171733678147), 'nauc_ndcg_at_20_std': np.float64(-0.31065564145035746), 'nauc_ndcg_at_20_diff1': np.float64(0.39981470796546487), 'nauc_ndcg_at_100_max': np.float64(0.015227395178639008), 'nauc_ndcg_at_100_std': np.float64(-0.28367162283548253), 'nauc_ndcg_at_100_diff1': np.float64(0.39429739532468744), 'nauc_ndcg_at_1000_max': np.float64(0.015174781068620309), 'nauc_ndcg_at_1000_std': np.float64(-0.29273728089941975), 'nauc_ndcg_at_1000_diff1': np.float64(0.4049096639814209), 'nauc_map_at_1_max': np.float64(0.01623799065714781), 'nauc_map_at_1_std': np.float64(-0.24359214399586804), 'nauc_map_at_1_diff1': np.float64(0.5187873479788793), 'nauc_map_at_3_max': np.float64(0.008613530421277172), 'nauc_map_at_3_std': np.float64(-0.2975744235729337), 'nauc_map_at_3_diff1': np.float64(0.4473212904850428), 'nauc_map_at_5_max': np.float64(0.008682091270174386), 'nauc_map_at_5_std': np.float64(-0.3064128722104408), 'nauc_map_at_5_diff1': np.float64(0.42975066488251734), 'nauc_map_at_10_max': np.float64(0.006742367248613375), 'nauc_map_at_10_std': np.float64(-0.30714434525559864), 'nauc_map_at_10_diff1': np.float64(0.4191982594410954), 'nauc_map_at_20_max': np.float64(0.00430451823534425), 'nauc_map_at_20_std': np.float64(-0.30771683727864585), 'nauc_map_at_20_diff1': np.float64(0.41765071057152414), 'nauc_map_at_100_max': np.float64(0.007051468460482115), 'nauc_map_at_100_std': np.float64(-0.303480799707148), 'nauc_map_at_100_diff1': np.float64(0.4159864941343379), 'nauc_map_at_1000_max': np.float64(0.00741406586749766), 'nauc_map_at_1000_std': np.float64(-0.3033632762154121), 'nauc_map_at_1000_diff1': np.float64(0.4162982463840893), 'nauc_recall_at_1_max': np.float64(0.01623799065714781), 'nauc_recall_at_1_std': np.float64(-0.24359214399586804), 'nauc_recall_at_1_diff1': np.float64(0.5187873479788793), 'nauc_recall_at_3_max': np.float64(-0.007079077951201584), 'nauc_recall_at_3_std': np.float64(-0.31061233210859285), 'nauc_recall_at_3_diff1': np.float64(0.42705378492844515), 'nauc_recall_at_5_max': np.float64(0.007916200822763977), 'nauc_recall_at_5_std': np.float64(-0.31455959241723075), 'nauc_recall_at_5_diff1': np.float64(0.3793686313792769), 'nauc_recall_at_10_max': np.float64(0.014399974508723807), 'nauc_recall_at_10_std': np.float64(-0.2954893609817157), 'nauc_recall_at_10_diff1': np.float64(0.34401852160466656), 'nauc_recall_at_20_max': np.float64(-0.008972860040900315), 'nauc_recall_at_20_std': np.float64(-0.28960218917624253), 'nauc_recall_at_20_diff1': np.float64(0.31500524031290705), 'nauc_recall_at_100_max': np.float64(0.060804807459457905), 'nauc_recall_at_100_std': np.float64(-0.11413603880776196), 'nauc_recall_at_100_diff1': np.float64(0.24605438464709314), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.006884255364796974), 'nauc_precision_at_1_std': np.float64(-0.2993040780314914), 'nauc_precision_at_1_diff1': np.float64(0.45301556456254305), 'nauc_precision_at_3_max': np.float64(-0.015588741185408176), 'nauc_precision_at_3_std': np.float64(-0.3191864508946142), 'nauc_precision_at_3_diff1': np.float64(0.2485946571214141), 'nauc_precision_at_5_max': np.float64(-0.007762195687039114), 'nauc_precision_at_5_std': np.float64(-0.31014681871215455), 'nauc_precision_at_5_diff1': np.float64(0.19017267431311005), 'nauc_precision_at_10_max': np.float64(-0.00787610644739459), 'nauc_precision_at_10_std': np.float64(-0.2751104566277905), 'nauc_precision_at_10_diff1': np.float64(0.1342760295816469), 'nauc_precision_at_20_max': np.float64(-0.013235146132391701), 'nauc_precision_at_20_std': np.float64(-0.2443750174732303), 'nauc_precision_at_20_diff1': np.float64(0.09793746278840713), 'nauc_precision_at_100_max': np.float64(0.0996726300442833), 'nauc_precision_at_100_std': np.float64(-0.019184335607684427), 'nauc_precision_at_100_diff1': np.float64(-0.030006156498062677), 'nauc_precision_at_1000_max': np.float64(0.12818459147975028), 'nauc_precision_at_1000_std': np.float64(0.047135016518121395), 'nauc_precision_at_1000_diff1': np.float64(-0.0930114159366461), 'nauc_mrr_at_1_max': np.float64(0.002111915678628758), 'nauc_mrr_at_1_std': np.float64(-0.30325613525990913), 'nauc_mrr_at_1_diff1': np.float64(0.4470480333982122), 'nauc_mrr_at_3_max': np.float64(-0.013130584031647219), 'nauc_mrr_at_3_std': np.float64(-0.32320119796463775), 'nauc_mrr_at_3_diff1': np.float64(0.441350319061339), 'nauc_mrr_at_5_max': np.float64(-0.005111855284574282), 'nauc_mrr_at_5_std': np.float64(-0.3197844030873073), 'nauc_mrr_at_5_diff1': np.float64(0.43270220295695244), 'nauc_mrr_at_10_max': np.float64(-0.0028705782539395473), 'nauc_mrr_at_10_std': np.float64(-0.31497163831324226), 'nauc_mrr_at_10_diff1': np.float64(0.4299872722965155), 'nauc_mrr_at_20_max': np.float64(-0.003918017674019746), 'nauc_mrr_at_20_std': np.float64(-0.314836487369418), 'nauc_mrr_at_20_diff1': np.float64(0.4294279487187518), 'nauc_mrr_at_100_max': np.float64(-0.003914596557641437), 'nauc_mrr_at_100_std': np.float64(-0.31364987996423144), 'nauc_mrr_at_100_diff1': np.float64(0.4287508060605321), 'nauc_mrr_at_1000_max': np.float64(-0.003731608547828169), 'nauc_mrr_at_1000_std': np.float64(-0.31370420248018255), 'nauc_mrr_at_1000_diff1': np.float64(0.42893822857378433), 'main_score': 0.36744}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/25 [00:00<?, ?it/s]Batches:   4%|▍         | 1/25 [00:20<08:10, 20.42s/it]Batches:   8%|▊         | 2/25 [00:50<09:57, 25.98s/it]Batches:  12%|█▏        | 3/25 [01:20<10:12, 27.82s/it]Batches:  16%|█▌        | 4/25 [01:50<10:01, 28.67s/it]Batches:  20%|██        | 5/25 [02:20<09:42, 29.14s/it]Batches:  24%|██▍       | 6/25 [02:50<09:19, 29.45s/it]Batches:  28%|██▊       | 7/25 [03:20<08:53, 29.65s/it]Batches:  32%|███▏      | 8/25 [03:50<08:26, 29.78s/it]Batches:  36%|███▌      | 9/25 [04:20<07:57, 29.86s/it]Batches:  40%|████      | 10/25 [04:50<07:28, 29.91s/it]Batches:  44%|████▍     | 11/25 [05:20<06:59, 29.97s/it]Batches:  48%|████▊     | 12/25 [05:50<06:30, 30.00s/it]Batches:  52%|█████▏    | 13/25 [06:20<06:00, 30.02s/it]Batches:  56%|█████▌    | 14/25 [06:50<05:30, 30.02s/it]Batches:  60%|██████    | 15/25 [07:20<05:00, 30.04s/it]Batches:  64%|██████▍   | 16/25 [07:51<04:30, 30.08s/it]Batches:  68%|██████▊   | 17/25 [08:21<04:00, 30.10s/it]Batches:  72%|███████▏  | 18/25 [08:51<03:30, 30.12s/it]Batches:  76%|███████▌  | 19/25 [09:21<03:00, 30.13s/it]Batches:  80%|████████  | 20/25 [09:51<02:30, 30.14s/it]Batches:  84%|████████▍ | 21/25 [10:21<02:00, 30.14s/it]Batches:  88%|████████▊ | 22/25 [10:51<01:30, 30.15s/it]Batches:  92%|█████████▏| 23/25 [11:22<01:00, 30.16s/it]Batches:  96%|█████████▌| 24/25 [11:52<00:30, 30.17s/it]Batches: 100%|██████████| 25/25 [12:04<00:00, 24.90s/it]Batches: 100%|██████████| 25/25 [12:04<00:00, 29.00s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 750.17 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 750.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.205, 'ndcg_at_3': 0.2622, 'ndcg_at_5': 0.29341, 'ndcg_at_10': 0.3117, 'ndcg_at_20': 0.32041, 'ndcg_at_100': 0.34258, 'ndcg_at_1000': 0.37133, 'map_at_1': 0.205, 'map_at_3': 0.2475, 'map_at_5': 0.265, 'map_at_10': 0.27285, 'map_at_20': 0.27517, 'map_at_100': 0.27822, 'map_at_1000': 0.27913, 'recall_at_1': 0.205, 'recall_at_3': 0.305, 'recall_at_5': 0.38, 'recall_at_10': 0.435, 'recall_at_20': 0.47, 'recall_at_100': 0.59, 'recall_at_1000': 0.825, 'precision_at_1': 0.205, 'precision_at_3': 0.10167, 'precision_at_5': 0.076, 'precision_at_10': 0.0435, 'precision_at_20': 0.0235, 'precision_at_100': 0.0059, 'precision_at_1000': 0.00083, 'mrr_at_1': 0.205, 'mrr_at_3': 0.24749999999999997, 'mrr_at_5': 0.26499999999999996, 'mrr_at_10': 0.27284722222222224, 'mrr_at_20': 0.2751698232323232, 'mrr_at_100': 0.27822086065383106, 'mrr_at_1000': 0.2791287198476754, 'nauc_ndcg_at_1_max': np.float64(0.21421890364306456), 'nauc_ndcg_at_1_std': np.float64(-0.057424032873120374), 'nauc_ndcg_at_1_diff1': np.float64(0.41729356367967885), 'nauc_ndcg_at_3_max': np.float64(0.26261181728748806), 'nauc_ndcg_at_3_std': np.float64(-0.06895437740272989), 'nauc_ndcg_at_3_diff1': np.float64(0.4009933785797956), 'nauc_ndcg_at_5_max': np.float64(0.29093753462176347), 'nauc_ndcg_at_5_std': np.float64(-0.04133938065271729), 'nauc_ndcg_at_5_diff1': np.float64(0.4209062164284841), 'nauc_ndcg_at_10_max': np.float64(0.31404514392985694), 'nauc_ndcg_at_10_std': np.float64(-0.0004801515870732909), 'nauc_ndcg_at_10_diff1': np.float64(0.4323516230061433), 'nauc_ndcg_at_20_max': np.float64(0.3006040509358563), 'nauc_ndcg_at_20_std': np.float64(-0.0020612902800491223), 'nauc_ndcg_at_20_diff1': np.float64(0.4252119442346557), 'nauc_ndcg_at_100_max': np.float64(0.2991289443305772), 'nauc_ndcg_at_100_std': np.float64(0.023689369425239797), 'nauc_ndcg_at_100_diff1': np.float64(0.4175713240186009), 'nauc_ndcg_at_1000_max': np.float64(0.2960437685002154), 'nauc_ndcg_at_1000_std': np.float64(0.01920447144945708), 'nauc_ndcg_at_1000_diff1': np.float64(0.4189684945556936), 'nauc_map_at_1_max': np.float64(0.21421890364306456), 'nauc_map_at_1_std': np.float64(-0.057424032873120374), 'nauc_map_at_1_diff1': np.float64(0.41729356367967885), 'nauc_map_at_3_max': np.float64(0.24957706018886983), 'nauc_map_at_3_std': np.float64(-0.06687446554104834), 'nauc_map_at_3_diff1': np.float64(0.4029533600115499), 'nauc_map_at_5_max': np.float64(0.2668179918005735), 'nauc_map_at_5_std': np.float64(-0.05126145022772119), 'nauc_map_at_5_diff1': np.float64(0.41565408394511233), 'nauc_map_at_10_max': np.float64(0.2775233496978395), 'nauc_map_at_10_std': np.float64(-0.03316403187559568), 'nauc_map_at_10_diff1': np.float64(0.42027105277122856), 'nauc_map_at_20_max': np.float64(0.2742549098383242), 'nauc_map_at_20_std': np.float64(-0.03271585960240901), 'nauc_map_at_20_diff1': np.float64(0.418499405202359), 'nauc_map_at_100_max': np.float64(0.27345638042333137), 'nauc_map_at_100_std': np.float64(-0.028910014572144413), 'nauc_map_at_100_diff1': np.float64(0.4169891344020899), 'nauc_map_at_1000_max': np.float64(0.2732479660054246), 'nauc_map_at_1000_std': np.float64(-0.02906661777426786), 'nauc_map_at_1000_diff1': np.float64(0.4169836585487395), 'nauc_recall_at_1_max': np.float64(0.21421890364306456), 'nauc_recall_at_1_std': np.float64(-0.057424032873120374), 'nauc_recall_at_1_diff1': np.float64(0.41729356367967885), 'nauc_recall_at_3_max': np.float64(0.29768780283987134), 'nauc_recall_at_3_std': np.float64(-0.07423157015102409), 'nauc_recall_at_3_diff1': np.float64(0.3964767803109436), 'nauc_recall_at_5_max': np.float64(0.35606789176825293), 'nauc_recall_at_5_std': np.float64(-0.012027915681127077), 'nauc_recall_at_5_diff1': np.float64(0.43604605827463433), 'nauc_recall_at_10_max': np.float64(0.4176811990698221), 'nauc_recall_at_10_std': np.float64(0.10048919026309432), 'nauc_recall_at_10_diff1': np.float64(0.46965522182922), 'nauc_recall_at_20_max': np.float64(0.36597924550692906), 'nauc_recall_at_20_std': np.float64(0.08976911615395783), 'nauc_recall_at_20_diff1': np.float64(0.4423449676287928), 'nauc_recall_at_100_max': np.float64(0.374550603841695), 'nauc_recall_at_100_std': np.float64(0.23667219393370165), 'nauc_recall_at_100_diff1': np.float64(0.4105683302273026), 'nauc_recall_at_1000_max': np.float64(0.4062173237247424), 'nauc_recall_at_1000_std': np.float64(0.35745372332909375), 'nauc_recall_at_1000_diff1': np.float64(0.43026706231453987), 'nauc_precision_at_1_max': np.float64(0.21421890364306456), 'nauc_precision_at_1_std': np.float64(-0.057424032873120374), 'nauc_precision_at_1_diff1': np.float64(0.41729356367967885), 'nauc_precision_at_3_max': np.float64(0.29768780283987123), 'nauc_precision_at_3_std': np.float64(-0.074231570151024), 'nauc_precision_at_3_diff1': np.float64(0.3964767803109438), 'nauc_precision_at_5_max': np.float64(0.3560678917682533), 'nauc_precision_at_5_std': np.float64(-0.012027915681126806), 'nauc_precision_at_5_diff1': np.float64(0.4360460582746341), 'nauc_precision_at_10_max': np.float64(0.4176811990698221), 'nauc_precision_at_10_std': np.float64(0.10048919026309458), 'nauc_precision_at_10_diff1': np.float64(0.4696552218292198), 'nauc_precision_at_20_max': np.float64(0.36597924550692923), 'nauc_precision_at_20_std': np.float64(0.08976911615395776), 'nauc_precision_at_20_diff1': np.float64(0.44234496762879244), 'nauc_precision_at_100_max': np.float64(0.37455060384169536), 'nauc_precision_at_100_std': np.float64(0.23667219393370215), 'nauc_precision_at_100_diff1': np.float64(0.41056833022730294), 'nauc_precision_at_1000_max': np.float64(0.4062173237247422), 'nauc_precision_at_1000_std': np.float64(0.35745372332909353), 'nauc_precision_at_1000_diff1': np.float64(0.4302670623145395), 'nauc_mrr_at_1_max': np.float64(0.21421890364306456), 'nauc_mrr_at_1_std': np.float64(-0.057424032873120374), 'nauc_mrr_at_1_diff1': np.float64(0.41729356367967885), 'nauc_mrr_at_3_max': np.float64(0.24957706018886983), 'nauc_mrr_at_3_std': np.float64(-0.06687446554104834), 'nauc_mrr_at_3_diff1': np.float64(0.4029533600115499), 'nauc_mrr_at_5_max': np.float64(0.2668179918005735), 'nauc_mrr_at_5_std': np.float64(-0.05126145022772119), 'nauc_mrr_at_5_diff1': np.float64(0.41565408394511233), 'nauc_mrr_at_10_max': np.float64(0.2775233496978395), 'nauc_mrr_at_10_std': np.float64(-0.03316403187559568), 'nauc_mrr_at_10_diff1': np.float64(0.42027105277122856), 'nauc_mrr_at_20_max': np.float64(0.2742549098383242), 'nauc_mrr_at_20_std': np.float64(-0.03271585960240901), 'nauc_mrr_at_20_diff1': np.float64(0.418499405202359), 'nauc_mrr_at_100_max': np.float64(0.27345638042333137), 'nauc_mrr_at_100_std': np.float64(-0.028910014572144413), 'nauc_mrr_at_100_diff1': np.float64(0.4169891344020899), 'nauc_mrr_at_1000_max': np.float64(0.2732479660054246), 'nauc_mrr_at_1000_std': np.float64(-0.02906661777426786), 'nauc_mrr_at_1000_diff1': np.float64(0.4169836585487395), 'main_score': 0.3117}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'MultiLongDocRetrieval'
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.instruct_wrapper:Using instruction: '<instruct>Retrieve text based on user query.
<query>' for task: 'MultiLongDocRetrieval'
Batches:   0%|          | 0/25 [00:00<?, ?it/s]Batches:   4%|▍         | 1/25 [00:20<08:16, 20.70s/it]Batches:   8%|▊         | 2/25 [00:50<10:04, 26.27s/it]Batches:  12%|█▏        | 3/25 [01:20<10:16, 28.01s/it]Batches:  16%|█▌        | 4/25 [01:51<10:05, 28.82s/it]Batches:  20%|██        | 5/25 [02:21<09:45, 29.27s/it]Batches:  24%|██▍       | 6/25 [02:51<09:21, 29.54s/it]Batches:  28%|██▊       | 7/25 [03:21<08:54, 29.71s/it]Batches:  32%|███▏      | 8/25 [03:51<08:27, 29.83s/it]Batches:  36%|███▌      | 9/25 [04:21<07:58, 29.90s/it]Batches:  40%|████      | 10/25 [04:51<07:29, 29.95s/it]Batches:  44%|████▍     | 11/25 [05:21<06:59, 29.99s/it]Batches:  48%|████▊     | 12/25 [05:51<06:30, 30.02s/it]Batches:  52%|█████▏    | 13/25 [06:21<06:00, 30.03s/it]Batches:  56%|█████▌    | 14/25 [06:51<05:30, 30.05s/it]Batches:  60%|██████    | 15/25 [07:21<05:00, 30.08s/it]Batches:  64%|██████▍   | 16/25 [07:52<04:30, 30.11s/it]Batches:  68%|██████▊   | 17/25 [08:22<04:01, 30.13s/it]Batches:  72%|███████▏  | 18/25 [08:52<03:30, 30.14s/it]Batches:  76%|███████▌  | 19/25 [09:22<03:00, 30.14s/it]Batches:  80%|████████  | 20/25 [09:52<02:30, 30.15s/it]Batches:  84%|████████▍ | 21/25 [10:22<02:00, 30.17s/it]Batches:  88%|████████▊ | 22/25 [10:53<01:30, 30.16s/it]Batches:  92%|█████████▏| 23/25 [11:23<01:00, 30.17s/it]Batches:  96%|█████████▌| 24/25 [11:53<00:30, 30.19s/it]Batches: 100%|██████████| 25/25 [12:06<00:00, 24.91s/it]Batches: 100%|██████████| 25/25 [12:06<00:00, 29.04s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 738.07 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 738.37 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.2, 'ndcg_at_3': 0.25405, 'ndcg_at_5': 0.2704, 'ndcg_at_10': 0.28193, 'ndcg_at_20': 0.29989, 'ndcg_at_100': 0.32877, 'ndcg_at_1000': 0.35501, 'map_at_1': 0.2, 'map_at_3': 0.24, 'map_at_5': 0.249, 'map_at_10': 0.25387, 'map_at_20': 0.25893, 'map_at_100': 0.263, 'map_at_1000': 0.26385, 'recall_at_1': 0.2, 'recall_at_3': 0.295, 'recall_at_5': 0.335, 'recall_at_10': 0.37, 'recall_at_20': 0.44, 'recall_at_100': 0.595, 'recall_at_1000': 0.81, 'precision_at_1': 0.2, 'precision_at_3': 0.09833, 'precision_at_5': 0.067, 'precision_at_10': 0.037, 'precision_at_20': 0.022, 'precision_at_100': 0.00595, 'precision_at_1000': 0.00081, 'mrr_at_1': 0.2, 'mrr_at_3': 0.24000000000000005, 'mrr_at_5': 0.24900000000000005, 'mrr_at_10': 0.2538710317460318, 'mrr_at_20': 0.2589304306804308, 'mrr_at_100': 0.2630043857413787, 'mrr_at_1000': 0.26385362701884074, 'nauc_ndcg_at_1_max': np.float64(0.40082337746206026), 'nauc_ndcg_at_1_std': np.float64(0.08329835324507581), 'nauc_ndcg_at_1_diff1': np.float64(0.5438973199870843), 'nauc_ndcg_at_3_max': np.float64(0.4155409015792822), 'nauc_ndcg_at_3_std': np.float64(0.13506341475837183), 'nauc_ndcg_at_3_diff1': np.float64(0.47659113961617205), 'nauc_ndcg_at_5_max': np.float64(0.44316748630757125), 'nauc_ndcg_at_5_std': np.float64(0.16542765302266157), 'nauc_ndcg_at_5_diff1': np.float64(0.4823288920345984), 'nauc_ndcg_at_10_max': np.float64(0.4257366280746924), 'nauc_ndcg_at_10_std': np.float64(0.1691458128843398), 'nauc_ndcg_at_10_diff1': np.float64(0.489517573275302), 'nauc_ndcg_at_20_max': np.float64(0.4248017742267412), 'nauc_ndcg_at_20_std': np.float64(0.17308191941969125), 'nauc_ndcg_at_20_diff1': np.float64(0.4735251447024523), 'nauc_ndcg_at_100_max': np.float64(0.4334340774864439), 'nauc_ndcg_at_100_std': np.float64(0.20201148402174735), 'nauc_ndcg_at_100_diff1': np.float64(0.4635381223019771), 'nauc_ndcg_at_1000_max': np.float64(0.4255892585533067), 'nauc_ndcg_at_1000_std': np.float64(0.19426389984523537), 'nauc_ndcg_at_1000_diff1': np.float64(0.46126444308866354), 'nauc_map_at_1_max': np.float64(0.40082337746206026), 'nauc_map_at_1_std': np.float64(0.08329835324507581), 'nauc_map_at_1_diff1': np.float64(0.5438973199870843), 'nauc_map_at_3_max': np.float64(0.41320318116462973), 'nauc_map_at_3_std': np.float64(0.12417001158239462), 'nauc_map_at_3_diff1': np.float64(0.491715093058551), 'nauc_map_at_5_max': np.float64(0.42876465887835863), 'nauc_map_at_5_std': np.float64(0.14124876804164882), 'nauc_map_at_5_diff1': np.float64(0.49521352870072366), 'nauc_map_at_10_max': np.float64(0.4211510759552601), 'nauc_map_at_10_std': np.float64(0.14286223363614145), 'nauc_map_at_10_diff1': np.float64(0.4981696783890358), 'nauc_map_at_20_max': np.float64(0.42017572049360996), 'nauc_map_at_20_std': np.float64(0.14329728241520306), 'nauc_map_at_20_diff1': np.float64(0.4929884341910656), 'nauc_map_at_100_max': np.float64(0.4216564429134758), 'nauc_map_at_100_std': np.float64(0.147443527070846), 'nauc_map_at_100_diff1': np.float64(0.4909313487486887), 'nauc_map_at_1000_max': np.float64(0.4212927882658119), 'nauc_map_at_1000_std': np.float64(0.1471331843781842), 'nauc_map_at_1000_diff1': np.float64(0.49062247481457416), 'nauc_recall_at_1_max': np.float64(0.40082337746206026), 'nauc_recall_at_1_std': np.float64(0.08329835324507581), 'nauc_recall_at_1_diff1': np.float64(0.5438973199870843), 'nauc_recall_at_3_max': np.float64(0.4213182756295424), 'nauc_recall_at_3_std': np.float64(0.1633983366595602), 'nauc_recall_at_3_diff1': np.float64(0.4368686696682172), 'nauc_recall_at_5_max': np.float64(0.48378035580288065), 'nauc_recall_at_5_std': np.float64(0.23178983856722588), 'nauc_recall_at_5_diff1': np.float64(0.4495082642158457), 'nauc_recall_at_10_max': np.float64(0.43511275937267396), 'nauc_recall_at_10_std': np.float64(0.2412084252863058), 'nauc_recall_at_10_diff1': np.float64(0.47060551848417975), 'nauc_recall_at_20_max': np.float64(0.43653103304275187), 'nauc_recall_at_20_std': np.float64(0.2596766195124496), 'nauc_recall_at_20_diff1': np.float64(0.41759539593882106), 'nauc_recall_at_100_max': np.float64(0.4817416455761584), 'nauc_recall_at_100_std': np.float64(0.4266308558442232), 'nauc_recall_at_100_diff1': np.float64(0.3656171832918903), 'nauc_recall_at_1000_max': np.float64(0.42220650636492246), 'nauc_recall_at_1000_std': np.float64(0.4906228718109902), 'nauc_recall_at_1000_diff1': np.float64(0.2835795484310334), 'nauc_precision_at_1_max': np.float64(0.40082337746206026), 'nauc_precision_at_1_std': np.float64(0.08329835324507581), 'nauc_precision_at_1_diff1': np.float64(0.5438973199870843), 'nauc_precision_at_3_max': np.float64(0.4213182756295426), 'nauc_precision_at_3_std': np.float64(0.1633983366595601), 'nauc_precision_at_3_diff1': np.float64(0.4368686696682174), 'nauc_precision_at_5_max': np.float64(0.483780355802881), 'nauc_precision_at_5_std': np.float64(0.2317898385672261), 'nauc_precision_at_5_diff1': np.float64(0.4495082642158461), 'nauc_precision_at_10_max': np.float64(0.4351127593726742), 'nauc_precision_at_10_std': np.float64(0.24120842528630604), 'nauc_precision_at_10_diff1': np.float64(0.47060551848418), 'nauc_precision_at_20_max': np.float64(0.43653103304275226), 'nauc_precision_at_20_std': np.float64(0.2596766195124501), 'nauc_precision_at_20_diff1': np.float64(0.41759539593882145), 'nauc_precision_at_100_max': np.float64(0.4817416455761585), 'nauc_precision_at_100_std': np.float64(0.42663085584422306), 'nauc_precision_at_100_diff1': np.float64(0.3656171832918905), 'nauc_precision_at_1000_max': np.float64(0.4222065063649222), 'nauc_precision_at_1000_std': np.float64(0.490622871810991), 'nauc_precision_at_1000_diff1': np.float64(0.28357954843103367), 'nauc_mrr_at_1_max': np.float64(0.40082337746206026), 'nauc_mrr_at_1_std': np.float64(0.08329835324507581), 'nauc_mrr_at_1_diff1': np.float64(0.5438973199870843), 'nauc_mrr_at_3_max': np.float64(0.41320318116462973), 'nauc_mrr_at_3_std': np.float64(0.12417001158239462), 'nauc_mrr_at_3_diff1': np.float64(0.491715093058551), 'nauc_mrr_at_5_max': np.float64(0.42876465887835863), 'nauc_mrr_at_5_std': np.float64(0.14124876804164882), 'nauc_mrr_at_5_diff1': np.float64(0.49521352870072366), 'nauc_mrr_at_10_max': np.float64(0.4211510759552601), 'nauc_mrr_at_10_std': np.float64(0.14286223363614145), 'nauc_mrr_at_10_diff1': np.float64(0.4981696783890358), 'nauc_mrr_at_20_max': np.float64(0.42017572049360996), 'nauc_mrr_at_20_std': np.float64(0.14329728241520306), 'nauc_mrr_at_20_diff1': np.float64(0.4929884341910656), 'nauc_mrr_at_100_max': np.float64(0.4216564429134758), 'nauc_mrr_at_100_std': np.float64(0.147443527070846), 'nauc_mrr_at_100_diff1': np.float64(0.4909313487486887), 'nauc_mrr_at_1000_max': np.float64(0.4212927882658119), 'nauc_mrr_at_1000_std': np.float64(0.1471331843781842), 'nauc_mrr_at_1000_diff1': np.float64(0.49062247481457416), 'main_score': 0.28193}}



==================================================
Running model: Alibaba-NLP/gte-multilingual-base
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: Alibaba-NLP/gte-multilingual-base
Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: {'classifier.weight', 'classifier.bias'}
- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / Alibaba-NLP/gte-multilingual-base on GPU 0 in process Process-14
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  10%|█         | 1/10 [00:00<00:02,  4.02it/s]Batches:  60%|██████    | 6/10 [00:00<00:00, 20.29it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 23.23it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/145 [00:00<?, ?it/s]Batches:   1%|          | 1/145 [00:00<00:27,  5.23it/s]Batches:   1%|▏         | 2/145 [00:05<07:07,  2.99s/it]Batches:   2%|▏         | 3/145 [00:06<04:52,  2.06s/it]Batches:   3%|▎         | 4/145 [00:06<03:33,  1.52s/it]Batches:   3%|▎         | 5/145 [00:07<02:43,  1.17s/it]Batches:   4%|▍         | 6/145 [00:07<02:11,  1.05it/s]Batches:   5%|▍         | 7/145 [00:08<01:51,  1.24it/s]Batches:   6%|▌         | 8/145 [00:08<01:35,  1.43it/s]Batches:   6%|▌         | 9/145 [00:09<01:25,  1.59it/s]Batches:   7%|▋         | 10/145 [00:09<01:17,  1.75it/s]Batches:   8%|▊         | 11/145 [00:10<01:11,  1.88it/s]Batches:   8%|▊         | 12/145 [00:10<01:08,  1.95it/s]Batches:   9%|▉         | 13/145 [00:11<01:02,  2.12it/s]Batches:  10%|▉         | 14/145 [00:11<00:59,  2.22it/s]Batches:  10%|█         | 15/145 [00:11<00:55,  2.33it/s]Batches:  11%|█         | 16/145 [00:12<00:52,  2.45it/s]Batches:  12%|█▏        | 17/145 [00:12<00:50,  2.54it/s]Batches:  12%|█▏        | 18/145 [00:12<00:49,  2.59it/s]Batches:  13%|█▎        | 19/145 [00:13<00:46,  2.68it/s]Batches:  14%|█▍        | 20/145 [00:13<00:45,  2.75it/s]Batches:  14%|█▍        | 21/145 [00:13<00:44,  2.80it/s]Batches:  15%|█▌        | 22/145 [00:14<00:43,  2.86it/s]Batches:  16%|█▌        | 23/145 [00:14<00:42,  2.84it/s]Batches:  17%|█▋        | 24/145 [00:14<00:41,  2.92it/s]Batches:  17%|█▋        | 25/145 [00:15<00:39,  3.02it/s]Batches:  18%|█▊        | 26/145 [00:15<00:39,  3.03it/s]Batches:  19%|█▊        | 27/145 [00:15<00:38,  3.08it/s]Batches:  19%|█▉        | 28/145 [00:16<00:37,  3.14it/s]Batches:  20%|██        | 29/145 [00:16<00:36,  3.17it/s]Batches:  21%|██        | 30/145 [00:16<00:35,  3.23it/s]Batches:  21%|██▏       | 31/145 [00:17<00:34,  3.29it/s]Batches:  22%|██▏       | 32/145 [00:17<00:34,  3.30it/s]Batches:  23%|██▎       | 33/145 [00:17<00:33,  3.36it/s]Batches:  23%|██▎       | 34/145 [00:17<00:32,  3.36it/s]Batches:  24%|██▍       | 35/145 [00:18<00:31,  3.47it/s]Batches:  25%|██▍       | 36/145 [00:18<00:30,  3.54it/s]Batches:  26%|██▌       | 37/145 [00:18<00:29,  3.61it/s]Batches:  26%|██▌       | 38/145 [00:19<00:29,  3.58it/s]Batches:  27%|██▋       | 39/145 [00:19<00:28,  3.67it/s]Batches:  28%|██▊       | 40/145 [00:19<00:28,  3.75it/s]Batches:  28%|██▊       | 41/145 [00:19<00:27,  3.78it/s]Batches:  29%|██▉       | 42/145 [00:20<00:26,  3.83it/s]Batches:  30%|██▉       | 43/145 [00:20<00:26,  3.81it/s]Batches:  30%|███       | 44/145 [00:20<00:26,  3.81it/s]Batches:  31%|███       | 45/145 [00:20<00:25,  3.89it/s]Batches:  32%|███▏      | 46/145 [00:21<00:25,  3.96it/s]Batches:  32%|███▏      | 47/145 [00:21<00:24,  3.98it/s]Batches:  33%|███▎      | 48/145 [00:21<00:24,  4.00it/s]Batches:  34%|███▍      | 49/145 [00:21<00:23,  4.01it/s]Batches:  34%|███▍      | 50/145 [00:22<00:23,  4.09it/s]Batches:  35%|███▌      | 51/145 [00:22<00:23,  4.07it/s]Batches:  36%|███▌      | 52/145 [00:22<00:22,  4.06it/s]Batches:  37%|███▋      | 53/145 [00:22<00:22,  4.11it/s]Batches:  37%|███▋      | 54/145 [00:23<00:21,  4.17it/s]Batches:  38%|███▊      | 55/145 [00:23<00:21,  4.24it/s]Batches:  39%|███▊      | 56/145 [00:23<00:21,  4.21it/s]Batches:  39%|███▉      | 57/145 [00:23<00:20,  4.27it/s]Batches:  40%|████      | 58/145 [00:23<00:20,  4.32it/s]Batches:  41%|████      | 59/145 [00:24<00:19,  4.36it/s]Batches:  41%|████▏     | 60/145 [00:24<00:19,  4.33it/s]Batches:  42%|████▏     | 61/145 [00:24<00:19,  4.41it/s]Batches:  43%|████▎     | 62/145 [00:24<00:18,  4.47it/s]Batches:  43%|████▎     | 63/145 [00:25<00:18,  4.52it/s]Batches:  44%|████▍     | 64/145 [00:25<00:17,  4.54it/s]Batches:  45%|████▍     | 65/145 [00:25<00:17,  4.54it/s]Batches:  46%|████▌     | 66/145 [00:25<00:17,  4.60it/s]Batches:  46%|████▌     | 67/145 [00:25<00:17,  4.55it/s]Batches:  47%|████▋     | 68/145 [00:26<00:16,  4.69it/s]Batches:  48%|████▊     | 69/145 [00:26<00:16,  4.71it/s]Batches:  48%|████▊     | 70/145 [00:26<00:15,  4.79it/s]Batches:  49%|████▉     | 71/145 [00:26<00:15,  4.82it/s]Batches:  50%|████▉     | 72/145 [00:26<00:14,  4.94it/s]Batches:  50%|█████     | 73/145 [00:27<00:14,  5.07it/s]Batches:  51%|█████     | 74/145 [00:27<00:13,  5.14it/s]Batches:  52%|█████▏    | 75/145 [00:27<00:13,  5.18it/s]Batches:  52%|█████▏    | 76/145 [00:27<00:13,  5.26it/s]Batches:  53%|█████▎    | 77/145 [00:27<00:12,  5.28it/s]Batches:  54%|█████▍    | 78/145 [00:28<00:12,  5.32it/s]Batches:  54%|█████▍    | 79/145 [00:28<00:12,  5.32it/s]Batches:  55%|█████▌    | 80/145 [00:28<00:12,  5.30it/s]Batches:  56%|█████▌    | 81/145 [00:28<00:11,  5.41it/s]Batches:  57%|█████▋    | 82/145 [00:28<00:11,  5.42it/s]Batches:  57%|█████▋    | 83/145 [00:28<00:11,  5.44it/s]Batches:  58%|█████▊    | 84/145 [00:29<00:11,  5.37it/s]Batches:  59%|█████▊    | 85/145 [00:29<00:11,  5.34it/s]Batches:  59%|█████▉    | 86/145 [00:29<00:10,  5.45it/s]Batches:  60%|██████    | 87/145 [00:29<00:10,  5.52it/s]Batches:  61%|██████    | 88/145 [00:29<00:10,  5.68it/s]Batches:  61%|██████▏   | 89/145 [00:30<00:09,  5.74it/s]Batches:  62%|██████▏   | 90/145 [00:30<00:09,  5.83it/s]Batches:  63%|██████▎   | 91/145 [00:30<00:09,  5.81it/s]Batches:  63%|██████▎   | 92/145 [00:30<00:08,  5.92it/s]Batches:  64%|██████▍   | 93/145 [00:30<00:08,  6.00it/s]Batches:  65%|██████▍   | 94/145 [00:30<00:08,  5.94it/s]Batches:  66%|██████▌   | 95/145 [00:31<00:08,  6.01it/s]Batches:  66%|██████▌   | 96/145 [00:31<00:08,  5.90it/s]Batches:  67%|██████▋   | 97/145 [00:31<00:08,  5.98it/s]Batches:  68%|██████▊   | 98/145 [00:31<00:07,  6.01it/s]Batches:  68%|██████▊   | 99/145 [00:31<00:07,  6.11it/s]Batches:  69%|██████▉   | 100/145 [00:31<00:07,  6.28it/s]Batches:  70%|██████▉   | 101/145 [00:32<00:06,  6.42it/s]Batches:  70%|███████   | 102/145 [00:32<00:06,  6.41it/s]Batches:  71%|███████   | 103/145 [00:32<00:06,  6.54it/s]Batches:  72%|███████▏  | 104/145 [00:32<00:06,  6.62it/s]Batches:  72%|███████▏  | 105/145 [00:32<00:05,  6.73it/s]Batches:  73%|███████▎  | 106/145 [00:32<00:05,  6.81it/s]Batches:  74%|███████▍  | 107/145 [00:32<00:05,  6.85it/s]Batches:  74%|███████▍  | 108/145 [00:33<00:05,  6.93it/s]Batches:  75%|███████▌  | 109/145 [00:33<00:05,  6.96it/s]Batches:  76%|███████▌  | 110/145 [00:33<00:04,  7.11it/s]Batches:  77%|███████▋  | 111/145 [00:33<00:04,  7.20it/s]Batches:  77%|███████▋  | 112/145 [00:33<00:04,  7.34it/s]Batches:  78%|███████▊  | 113/145 [00:33<00:04,  7.46it/s]Batches:  79%|███████▊  | 114/145 [00:33<00:04,  7.63it/s]Batches:  79%|███████▉  | 115/145 [00:33<00:03,  7.71it/s]Batches:  80%|████████  | 116/145 [00:34<00:03,  7.67it/s]Batches:  81%|████████  | 117/145 [00:34<00:03,  7.80it/s]Batches:  81%|████████▏ | 118/145 [00:34<00:03,  7.91it/s]Batches:  82%|████████▏ | 119/145 [00:34<00:03,  8.13it/s]Batches:  83%|████████▎ | 120/145 [00:34<00:03,  8.28it/s]Batches:  83%|████████▎ | 121/145 [00:34<00:02,  8.32it/s]Batches:  84%|████████▍ | 122/145 [00:34<00:02,  8.55it/s]Batches:  85%|████████▍ | 123/145 [00:34<00:02,  8.58it/s]Batches:  86%|████████▌ | 124/145 [00:35<00:02,  8.56it/s]Batches:  86%|████████▌ | 125/145 [00:35<00:02,  8.79it/s]Batches:  87%|████████▋ | 126/145 [00:35<00:02,  9.03it/s]Batches:  88%|████████▊ | 127/145 [00:35<00:01,  9.06it/s]Batches:  88%|████████▊ | 128/145 [00:35<00:01,  9.24it/s]Batches:  89%|████████▉ | 129/145 [00:35<00:01,  9.39it/s]Batches:  90%|█████████ | 131/145 [00:35<00:01,  9.76it/s]Batches:  92%|█████████▏| 133/145 [00:35<00:01, 10.00it/s]Batches:  93%|█████████▎| 135/145 [00:36<00:00, 10.40it/s]Batches:  94%|█████████▍| 137/145 [00:36<00:00, 10.98it/s]Batches:  96%|█████████▌| 139/145 [00:36<00:00, 11.47it/s]Batches:  97%|█████████▋| 141/145 [00:36<00:00, 12.06it/s]Batches:  99%|█████████▊| 143/145 [00:36<00:00, 12.93it/s]Batches: 100%|██████████| 145/145 [00:36<00:00, 14.50it/s]Batches: 100%|██████████| 145/145 [00:36<00:00,  3.94it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 38.27 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 39.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.70101, 'ndcg_at_3': 0.70056, 'ndcg_at_5': 0.73113, 'ndcg_at_10': 0.75121, 'ndcg_at_20': 0.76145, 'ndcg_at_100': 0.77256, 'ndcg_at_1000': 0.78115, 'map_at_1': 0.45135, 'map_at_3': 0.65496, 'map_at_5': 0.68422, 'map_at_10': 0.69709, 'map_at_20': 0.70167, 'map_at_100': 0.70379, 'map_at_1000': 0.7042, 'recall_at_1': 0.45135, 'recall_at_3': 0.71127, 'recall_at_5': 0.77506, 'recall_at_10': 0.82298, 'recall_at_20': 0.85468, 'recall_at_100': 0.90386, 'recall_at_1000': 0.9587, 'precision_at_1': 0.70101, 'precision_at_3': 0.41667, 'precision_at_5': 0.27939, 'precision_at_10': 0.15152, 'precision_at_20': 0.07956, 'precision_at_100': 0.01698, 'precision_at_1000': 0.00183, 'mrr_at_1': 0.7010135135135135, 'mrr_at_3': 0.764921171171171, 'mrr_at_5': 0.7705799549549547, 'mrr_at_10': 0.7737069658944656, 'mrr_at_20': 0.7747121401629913, 'mrr_at_100': 0.7755940101379746, 'mrr_at_1000': 0.775762024387044, 'nauc_ndcg_at_1_max': np.float64(0.5770263549598156), 'nauc_ndcg_at_1_std': np.float64(0.1313742842575525), 'nauc_ndcg_at_1_diff1': np.float64(0.661500115820817), 'nauc_ndcg_at_3_max': np.float64(0.6059582416432887), 'nauc_ndcg_at_3_std': np.float64(0.12743795996465662), 'nauc_ndcg_at_3_diff1': np.float64(0.5479702226955419), 'nauc_ndcg_at_5_max': np.float64(0.6411398480758634), 'nauc_ndcg_at_5_std': np.float64(0.18438351907666847), 'nauc_ndcg_at_5_diff1': np.float64(0.5628160195267607), 'nauc_ndcg_at_10_max': np.float64(0.6643418532861225), 'nauc_ndcg_at_10_std': np.float64(0.22326362761367885), 'nauc_ndcg_at_10_diff1': np.float64(0.5831817543877047), 'nauc_ndcg_at_20_max': np.float64(0.673272767215356), 'nauc_ndcg_at_20_std': np.float64(0.24635138529614536), 'nauc_ndcg_at_20_diff1': np.float64(0.5899026096075843), 'nauc_ndcg_at_100_max': np.float64(0.670641015014622), 'nauc_ndcg_at_100_std': np.float64(0.25487773336698044), 'nauc_ndcg_at_100_diff1': np.float64(0.5937442728212519), 'nauc_ndcg_at_1000_max': np.float64(0.6615877024334198), 'nauc_ndcg_at_1000_std': np.float64(0.2393015359142359), 'nauc_ndcg_at_1000_diff1': np.float64(0.5907551369979055), 'nauc_map_at_1_max': np.float64(0.299451623991129), 'nauc_map_at_1_std': np.float64(-0.022953282119810403), 'nauc_map_at_1_diff1': np.float64(0.5834434025577803), 'nauc_map_at_3_max': np.float64(0.5594477813787555), 'nauc_map_at_3_std': np.float64(0.08416007387108534), 'nauc_map_at_3_diff1': np.float64(0.5248726081949865), 'nauc_map_at_5_max': np.float64(0.5899555474257632), 'nauc_map_at_5_std': np.float64(0.12732982461525347), 'nauc_map_at_5_diff1': np.float64(0.5373092416579366), 'nauc_map_at_10_max': np.float64(0.6036640161616742), 'nauc_map_at_10_std': np.float64(0.14948304159183426), 'nauc_map_at_10_diff1': np.float64(0.5482356659883542), 'nauc_map_at_20_max': np.float64(0.6074107021103508), 'nauc_map_at_20_std': np.float64(0.15853657489864967), 'nauc_map_at_20_diff1': np.float64(0.551019680772447), 'nauc_map_at_100_max': np.float64(0.6071358257277069), 'nauc_map_at_100_std': np.float64(0.15992886906044776), 'nauc_map_at_100_diff1': np.float64(0.552117983876564), 'nauc_map_at_1000_max': np.float64(0.6067402935995151), 'nauc_map_at_1000_std': np.float64(0.1594828873545819), 'nauc_map_at_1000_diff1': np.float64(0.5519197145137611), 'nauc_recall_at_1_max': np.float64(0.299451623991129), 'nauc_recall_at_1_std': np.float64(-0.022953282119810403), 'nauc_recall_at_1_diff1': np.float64(0.5834434025577803), 'nauc_recall_at_3_max': np.float64(0.6109051461139894), 'nauc_recall_at_3_std': np.float64(0.12072253500359617), 'nauc_recall_at_3_diff1': np.float64(0.49205076291344274), 'nauc_recall_at_5_max': np.float64(0.6817156339665192), 'nauc_recall_at_5_std': np.float64(0.24410069255370517), 'nauc_recall_at_5_diff1': np.float64(0.5088705234664951), 'nauc_recall_at_10_max': np.float64(0.7654270251851792), 'nauc_recall_at_10_std': np.float64(0.3773682882526592), 'nauc_recall_at_10_diff1': np.float64(0.5650349723481966), 'nauc_recall_at_20_max': np.float64(0.829226851926464), 'nauc_recall_at_20_std': np.float64(0.5101268399413494), 'nauc_recall_at_20_diff1': np.float64(0.5996092880814857), 'nauc_recall_at_100_max': np.float64(0.8803880729883224), 'nauc_recall_at_100_std': np.float64(0.6979867070823739), 'nauc_recall_at_100_diff1': np.float64(0.6368032349603382), 'nauc_recall_at_1000_max': np.float64(0.9077919776775288), 'nauc_recall_at_1000_std': np.float64(0.7655930243673666), 'nauc_recall_at_1000_diff1': np.float64(0.6310537710228703), 'nauc_precision_at_1_max': np.float64(0.5770263549598156), 'nauc_precision_at_1_std': np.float64(0.1313742842575525), 'nauc_precision_at_1_diff1': np.float64(0.661500115820817), 'nauc_precision_at_3_max': np.float64(0.4643801024890446), 'nauc_precision_at_3_std': np.float64(0.21573365606067008), 'nauc_precision_at_3_diff1': np.float64(0.10652022166353019), 'nauc_precision_at_5_max': np.float64(0.3993637294469268), 'nauc_precision_at_5_std': np.float64(0.26849236828347134), 'nauc_precision_at_5_diff1': np.float64(0.04752964400629679), 'nauc_precision_at_10_max': np.float64(0.35106876700614753), 'nauc_precision_at_10_std': np.float64(0.30589978246233046), 'nauc_precision_at_10_diff1': np.float64(0.012468448328005923), 'nauc_precision_at_20_max': np.float64(0.31120661076351014), 'nauc_precision_at_20_std': np.float64(0.32862281412296374), 'nauc_precision_at_20_diff1': np.float64(-0.015991023617958375), 'nauc_precision_at_100_max': np.float64(0.21703569000810188), 'nauc_precision_at_100_std': np.float64(0.31518785228088636), 'nauc_precision_at_100_diff1': np.float64(-0.07861027277114246), 'nauc_precision_at_1000_max': np.float64(0.07063855451998648), 'nauc_precision_at_1000_std': np.float64(0.23065877466350113), 'nauc_precision_at_1000_diff1': np.float64(-0.2004685252782137), 'nauc_mrr_at_1_max': np.float64(0.5770263549598156), 'nauc_mrr_at_1_std': np.float64(0.1313742842575525), 'nauc_mrr_at_1_diff1': np.float64(0.661500115820817), 'nauc_mrr_at_3_max': np.float64(0.6720413722313505), 'nauc_mrr_at_3_std': np.float64(0.214088474893056), 'nauc_mrr_at_3_diff1': np.float64(0.658707138510419), 'nauc_mrr_at_5_max': np.float64(0.6736745604944314), 'nauc_mrr_at_5_std': np.float64(0.22846499218561858), 'nauc_mrr_at_5_diff1': np.float64(0.6603441608824964), 'nauc_mrr_at_10_max': np.float64(0.6762588126119293), 'nauc_mrr_at_10_std': np.float64(0.23291273028624304), 'nauc_mrr_at_10_diff1': np.float64(0.6636967780082375), 'nauc_mrr_at_20_max': np.float64(0.6747824530605779), 'nauc_mrr_at_20_std': np.float64(0.23226267353927715), 'nauc_mrr_at_20_diff1': np.float64(0.662962026964006), 'nauc_mrr_at_100_max': np.float64(0.6738925445530085), 'nauc_mrr_at_100_std': np.float64(0.2325917862628659), 'nauc_mrr_at_100_diff1': np.float64(0.663057226112171), 'nauc_mrr_at_1000_max': np.float64(0.6736685608978698), 'nauc_mrr_at_1000_std': np.float64(0.2320878485491545), 'nauc_mrr_at_1000_diff1': np.float64(0.6630500026079771), 'main_score': 0.75121}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 19.38it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 19.22it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/12 [00:00<?, ?it/s]Batches:   8%|▊         | 1/12 [00:00<00:01,  9.83it/s]Batches:  17%|█▋        | 2/12 [00:01<00:10,  1.02s/it]Batches:  25%|██▌       | 3/12 [00:02<00:08,  1.02it/s]Batches:  33%|███▎      | 4/12 [00:03<00:07,  1.10it/s]Batches:  42%|████▏     | 5/12 [00:04<00:05,  1.20it/s]Batches:  50%|█████     | 6/12 [00:04<00:04,  1.27it/s]Batches:  58%|█████▊    | 7/12 [00:05<00:03,  1.36it/s]Batches:  67%|██████▋   | 8/12 [00:06<00:02,  1.47it/s]Batches:  75%|███████▌  | 9/12 [00:06<00:01,  1.60it/s]Batches:  83%|████████▎ | 10/12 [00:07<00:01,  1.78it/s]Batches:  92%|█████████▏| 11/12 [00:07<00:00,  2.08it/s]Batches: 100%|██████████| 12/12 [00:07<00:00,  2.59it/s]Batches: 100%|██████████| 12/12 [00:07<00:00,  1.60it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 7.75 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 7.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.59649, 'ndcg_at_3': 0.72452, 'ndcg_at_5': 0.7468, 'ndcg_at_10': 0.77108, 'ndcg_at_20': 0.77556, 'ndcg_at_100': 0.78411, 'ndcg_at_1000': 0.78411, 'map_at_1': 0.59649, 'map_at_3': 0.69298, 'map_at_5': 0.7057, 'map_at_10': 0.71667, 'map_at_20': 0.71793, 'map_at_100': 0.71923, 'map_at_1000': 0.71923, 'recall_at_1': 0.59649, 'recall_at_3': 0.81579, 'recall_at_5': 0.86842, 'recall_at_10': 0.9386, 'recall_at_20': 0.95614, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.59649, 'precision_at_3': 0.27193, 'precision_at_5': 0.17368, 'precision_at_10': 0.09386, 'precision_at_20': 0.04781, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5964912280701754, 'mrr_at_3': 0.6929824561403509, 'mrr_at_5': 0.7057017543859649, 'mrr_at_10': 0.7166666666666666, 'mrr_at_20': 0.717925795349618, 'mrr_at_100': 0.7192301247857292, 'mrr_at_1000': 0.7192301247857292, 'nauc_ndcg_at_1_max': np.float64(0.1908294474342627), 'nauc_ndcg_at_1_std': np.float64(-0.35314996932177417), 'nauc_ndcg_at_1_diff1': np.float64(0.6110833815898389), 'nauc_ndcg_at_3_max': np.float64(0.2439244231908955), 'nauc_ndcg_at_3_std': np.float64(-0.4669491517657949), 'nauc_ndcg_at_3_diff1': np.float64(0.5896443334804378), 'nauc_ndcg_at_5_max': np.float64(0.2509765225930184), 'nauc_ndcg_at_5_std': np.float64(-0.5086643597687968), 'nauc_ndcg_at_5_diff1': np.float64(0.5816884009461497), 'nauc_ndcg_at_10_max': np.float64(0.24203689898525843), 'nauc_ndcg_at_10_std': np.float64(-0.5118177090163054), 'nauc_ndcg_at_10_diff1': np.float64(0.5800090322494245), 'nauc_ndcg_at_20_max': np.float64(0.25996203653945654), 'nauc_ndcg_at_20_std': np.float64(-0.5029431420978402), 'nauc_ndcg_at_20_diff1': np.float64(0.598047860353563), 'nauc_ndcg_at_100_max': np.float64(0.2381630983055214), 'nauc_ndcg_at_100_std': np.float64(-0.467474281511242), 'nauc_ndcg_at_100_diff1': np.float64(0.5925722016847822), 'nauc_ndcg_at_1000_max': np.float64(0.2381630983055214), 'nauc_ndcg_at_1000_std': np.float64(-0.467474281511242), 'nauc_ndcg_at_1000_diff1': np.float64(0.5925722016847822), 'nauc_map_at_1_max': np.float64(0.1908294474342627), 'nauc_map_at_1_std': np.float64(-0.35314996932177417), 'nauc_map_at_1_diff1': np.float64(0.6110833815898389), 'nauc_map_at_3_max': np.float64(0.23164372605869038), 'nauc_map_at_3_std': np.float64(-0.43564852034913903), 'nauc_map_at_3_diff1': np.float64(0.5938383228262359), 'nauc_map_at_5_max': np.float64(0.23294445889550133), 'nauc_map_at_5_std': np.float64(-0.45567242172858874), 'nauc_map_at_5_diff1': np.float64(0.5900023435482211), 'nauc_map_at_10_max': np.float64(0.2276498001316117), 'nauc_map_at_10_std': np.float64(-0.4551546095194692), 'nauc_map_at_10_diff1': np.float64(0.5893271930047639), 'nauc_map_at_20_max': np.float64(0.2329357588721152), 'nauc_map_at_20_std': np.float64(-0.45255932263784404), 'nauc_map_at_20_diff1': np.float64(0.59448055498058), 'nauc_map_at_100_max': np.float64(0.23025820800907956), 'nauc_map_at_100_std': np.float64(-0.44830854310298024), 'nauc_map_at_100_diff1': np.float64(0.5936517099361166), 'nauc_map_at_1000_max': np.float64(0.23025820800907956), 'nauc_map_at_1000_std': np.float64(-0.44830854310298024), 'nauc_map_at_1000_diff1': np.float64(0.5936517099361166), 'nauc_recall_at_1_max': np.float64(0.1908294474342627), 'nauc_recall_at_1_std': np.float64(-0.35314996932177417), 'nauc_recall_at_1_diff1': np.float64(0.6110833815898389), 'nauc_recall_at_3_max': np.float64(0.2938957496013749), 'nauc_recall_at_3_std': np.float64(-0.5982375555469336), 'nauc_recall_at_3_diff1': np.float64(0.5731811728893031), 'nauc_recall_at_5_max': np.float64(0.3533477450295955), 'nauc_recall_at_5_std': np.float64(-0.8077434531545817), 'nauc_recall_at_5_diff1': np.float64(0.5358095787755134), 'nauc_recall_at_10_max': np.float64(0.40503318457167875), 'nauc_recall_at_10_std': np.float64(-1.1435692978106466), 'nauc_recall_at_10_diff1': np.float64(0.4796532007537782), 'nauc_recall_at_20_max': np.float64(0.7183536566232177), 'nauc_recall_at_20_std': np.float64(-1.2588569287895657), 'nauc_recall_at_20_diff1': np.float64(0.700896545588321), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1908294474342627), 'nauc_precision_at_1_std': np.float64(-0.35314996932177417), 'nauc_precision_at_1_diff1': np.float64(0.6110833815898389), 'nauc_precision_at_3_max': np.float64(0.2938957496013745), 'nauc_precision_at_3_std': np.float64(-0.5982375555469349), 'nauc_precision_at_3_diff1': np.float64(0.5731811728893021), 'nauc_precision_at_5_max': np.float64(0.35334774502959576), 'nauc_precision_at_5_std': np.float64(-0.8077434531545805), 'nauc_precision_at_5_diff1': np.float64(0.5358095787755137), 'nauc_precision_at_10_max': np.float64(0.40503318457167936), 'nauc_precision_at_10_std': np.float64(-1.143569297810643), 'nauc_precision_at_10_diff1': np.float64(0.47965320075378115), 'nauc_precision_at_20_max': np.float64(0.7183536566232184), 'nauc_precision_at_20_std': np.float64(-1.2588569287895695), 'nauc_precision_at_20_diff1': np.float64(0.7008965455883202), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.1908294474342627), 'nauc_mrr_at_1_std': np.float64(-0.35314996932177417), 'nauc_mrr_at_1_diff1': np.float64(0.6110833815898389), 'nauc_mrr_at_3_max': np.float64(0.23164372605869038), 'nauc_mrr_at_3_std': np.float64(-0.43564852034913903), 'nauc_mrr_at_3_diff1': np.float64(0.5938383228262359), 'nauc_mrr_at_5_max': np.float64(0.23294445889550133), 'nauc_mrr_at_5_std': np.float64(-0.45567242172858874), 'nauc_mrr_at_5_diff1': np.float64(0.5900023435482211), 'nauc_mrr_at_10_max': np.float64(0.2276498001316117), 'nauc_mrr_at_10_std': np.float64(-0.4551546095194692), 'nauc_mrr_at_10_diff1': np.float64(0.5893271930047639), 'nauc_mrr_at_20_max': np.float64(0.2329357588721152), 'nauc_mrr_at_20_std': np.float64(-0.45255932263784404), 'nauc_mrr_at_20_diff1': np.float64(0.59448055498058), 'nauc_mrr_at_100_max': np.float64(0.23025820800907956), 'nauc_mrr_at_100_std': np.float64(-0.44830854310298024), 'nauc_mrr_at_100_diff1': np.float64(0.5936517099361166), 'nauc_mrr_at_1000_max': np.float64(0.23025820800907956), 'nauc_mrr_at_1000_std': np.float64(-0.44830854310298024), 'nauc_mrr_at_1000_diff1': np.float64(0.5936517099361166), 'main_score': 0.77108}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 24.63it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 0.93 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 1.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.58442, 'ndcg_at_3': 0.69063, 'ndcg_at_5': 0.72864, 'ndcg_at_10': 0.74584, 'ndcg_at_20': 0.74935, 'ndcg_at_100': 0.76531, 'ndcg_at_1000': 0.76531, 'map_at_1': 0.58442, 'map_at_3': 0.6645, 'map_at_5': 0.68593, 'map_at_10': 0.69325, 'map_at_20': 0.69433, 'map_at_100': 0.6971, 'map_at_1000': 0.6971, 'recall_at_1': 0.58442, 'recall_at_3': 0.76623, 'recall_at_5': 0.85714, 'recall_at_10': 0.90909, 'recall_at_20': 0.92208, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.58442, 'precision_at_3': 0.25541, 'precision_at_5': 0.17143, 'precision_at_10': 0.09091, 'precision_at_20': 0.0461, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5844155844155844, 'mrr_at_3': 0.6645021645021645, 'mrr_at_5': 0.685930735930736, 'mrr_at_10': 0.6932488146773862, 'mrr_at_20': 0.6943310657596372, 'mrr_at_100': 0.6970974064556953, 'mrr_at_1000': 0.6970974064556953, 'nauc_ndcg_at_1_max': np.float64(0.3888661331865086), 'nauc_ndcg_at_1_std': np.float64(0.182953924038586), 'nauc_ndcg_at_1_diff1': np.float64(0.8173815695220201), 'nauc_ndcg_at_3_max': np.float64(0.33335386066642836), 'nauc_ndcg_at_3_std': np.float64(0.09914814670853166), 'nauc_ndcg_at_3_diff1': np.float64(0.7075235631793855), 'nauc_ndcg_at_5_max': np.float64(0.3034500672099746), 'nauc_ndcg_at_5_std': np.float64(0.03592370656674037), 'nauc_ndcg_at_5_diff1': np.float64(0.7186345849221563), 'nauc_ndcg_at_10_max': np.float64(0.28679437262219604), 'nauc_ndcg_at_10_std': np.float64(0.07027087615828691), 'nauc_ndcg_at_10_diff1': np.float64(0.7245304898357027), 'nauc_ndcg_at_20_max': np.float64(0.3112863125754883), 'nauc_ndcg_at_20_std': np.float64(0.09110844214276108), 'nauc_ndcg_at_20_diff1': np.float64(0.7245630270157414), 'nauc_ndcg_at_100_max': np.float64(0.3294039014370792), 'nauc_ndcg_at_100_std': np.float64(0.10640993082293992), 'nauc_ndcg_at_100_diff1': np.float64(0.7412942244900864), 'nauc_ndcg_at_1000_max': np.float64(0.3294039014370792), 'nauc_ndcg_at_1000_std': np.float64(0.10640993082293992), 'nauc_ndcg_at_1000_diff1': np.float64(0.7412942244900864), 'nauc_map_at_1_max': np.float64(0.3888661331865086), 'nauc_map_at_1_std': np.float64(0.182953924038586), 'nauc_map_at_1_diff1': np.float64(0.8173815695220201), 'nauc_map_at_3_max': np.float64(0.3464508902718699), 'nauc_map_at_3_std': np.float64(0.12606109572212115), 'nauc_map_at_3_diff1': np.float64(0.7388199939774669), 'nauc_map_at_5_max': np.float64(0.3326396709852455), 'nauc_map_at_5_std': np.float64(0.0958479589280496), 'nauc_map_at_5_diff1': np.float64(0.745049440719342), 'nauc_map_at_10_max': np.float64(0.3278511780894081), 'nauc_map_at_10_std': np.float64(0.10838335653878874), 'nauc_map_at_10_diff1': np.float64(0.7483846046747796), 'nauc_map_at_20_max': np.float64(0.3343465578187079), 'nauc_map_at_20_std': np.float64(0.11392342799281159), 'nauc_map_at_20_diff1': np.float64(0.748496829413396), 'nauc_map_at_100_max': np.float64(0.33771961050685273), 'nauc_map_at_100_std': np.float64(0.11725264519083228), 'nauc_map_at_100_diff1': np.float64(0.7508489385385345), 'nauc_map_at_1000_max': np.float64(0.33771961050685273), 'nauc_map_at_1000_std': np.float64(0.11725264519083228), 'nauc_map_at_1000_diff1': np.float64(0.7508489385385345), 'nauc_recall_at_1_max': np.float64(0.3888661331865086), 'nauc_recall_at_1_std': np.float64(0.182953924038586), 'nauc_recall_at_1_diff1': np.float64(0.8173815695220201), 'nauc_recall_at_3_max': np.float64(0.2857584753139499), 'nauc_recall_at_3_std': np.float64(-0.0032297965710566382), 'nauc_recall_at_3_diff1': np.float64(0.5903452819024316), 'nauc_recall_at_5_max': np.float64(0.14081401961952994), 'nauc_recall_at_5_std': np.float64(-0.30320792552759585), 'nauc_recall_at_5_diff1': np.float64(0.582689705390142), 'nauc_recall_at_10_max': np.float64(-0.0663487422995702), 'nauc_recall_at_10_std': np.float64(-0.21572501610658368), 'nauc_recall_at_10_diff1': np.float64(0.5468315567317299), 'nauc_recall_at_20_max': np.float64(0.11665403289856766), 'nauc_recall_at_20_std': np.float64(-0.05761828654294978), 'nauc_recall_at_20_diff1': np.float64(0.5175363752626353), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.3888661331865086), 'nauc_precision_at_1_std': np.float64(0.182953924038586), 'nauc_precision_at_1_diff1': np.float64(0.8173815695220201), 'nauc_precision_at_3_max': np.float64(0.28575847531395104), 'nauc_precision_at_3_std': np.float64(-0.0032297965710546225), 'nauc_precision_at_3_diff1': np.float64(0.5903452819024319), 'nauc_precision_at_5_max': np.float64(0.14081401961953136), 'nauc_precision_at_5_std': np.float64(-0.3032079255275951), 'nauc_precision_at_5_diff1': np.float64(0.5826897053901425), 'nauc_precision_at_10_max': np.float64(-0.06634874229956951), 'nauc_precision_at_10_std': np.float64(-0.21572501610658196), 'nauc_precision_at_10_diff1': np.float64(0.5468315567317322), 'nauc_precision_at_20_max': np.float64(0.11665403289856896), 'nauc_precision_at_20_std': np.float64(-0.057618286542947705), 'nauc_precision_at_20_diff1': np.float64(0.5175363752626384), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.3888661331865086), 'nauc_mrr_at_1_std': np.float64(0.182953924038586), 'nauc_mrr_at_1_diff1': np.float64(0.8173815695220201), 'nauc_mrr_at_3_max': np.float64(0.3464508902718699), 'nauc_mrr_at_3_std': np.float64(0.12606109572212115), 'nauc_mrr_at_3_diff1': np.float64(0.7388199939774669), 'nauc_mrr_at_5_max': np.float64(0.3326396709852455), 'nauc_mrr_at_5_std': np.float64(0.0958479589280496), 'nauc_mrr_at_5_diff1': np.float64(0.745049440719342), 'nauc_mrr_at_10_max': np.float64(0.3278511780894081), 'nauc_mrr_at_10_std': np.float64(0.10838335653878874), 'nauc_mrr_at_10_diff1': np.float64(0.7483846046747796), 'nauc_mrr_at_20_max': np.float64(0.3343465578187079), 'nauc_mrr_at_20_std': np.float64(0.11392342799281159), 'nauc_mrr_at_20_diff1': np.float64(0.748496829413396), 'nauc_mrr_at_100_max': np.float64(0.33771961050685273), 'nauc_mrr_at_100_std': np.float64(0.11725264519083228), 'nauc_mrr_at_100_diff1': np.float64(0.7508489385385345), 'nauc_mrr_at_1000_max': np.float64(0.33771961050685273), 'nauc_mrr_at_1000_std': np.float64(0.11725264519083228), 'nauc_mrr_at_1000_diff1': np.float64(0.7508489385385345), 'main_score': 0.74584}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  20%|██        | 3/15 [00:00<00:00, 29.89it/s]Batches:  40%|████      | 6/15 [00:00<00:00, 29.78it/s]Batches:  67%|██████▋   | 10/15 [00:00<00:00, 32.22it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 35.98it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 34.16it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:01,  4.68it/s]Batches:  38%|███▊      | 3/8 [00:00<00:01,  4.68it/s]Batches:  50%|█████     | 4/8 [00:00<00:00,  4.89it/s]Batches:  62%|██████▎   | 5/8 [00:01<00:00,  5.16it/s]Batches:  75%|███████▌  | 6/8 [00:01<00:00,  5.56it/s]Batches:  88%|████████▊ | 7/8 [00:01<00:00,  6.12it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  6.66it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  5.69it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.23 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  27%|██▋       | 4/15 [00:00<00:00, 31.97it/s]Batches:  53%|█████▎    | 8/15 [00:00<00:00, 33.76it/s]Batches:  87%|████████▋ | 13/15 [00:00<00:00, 37.44it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 37.93it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:01,  4.74it/s]Batches:  38%|███▊      | 3/8 [00:00<00:01,  4.71it/s]Batches:  50%|█████     | 4/8 [00:00<00:00,  4.90it/s]Batches:  62%|██████▎   | 5/8 [00:00<00:00,  5.19it/s]Batches:  75%|███████▌  | 6/8 [00:01<00:00,  5.58it/s]Batches:  88%|████████▊ | 7/8 [00:01<00:00,  6.14it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  6.73it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  5.73it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.12 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]Batches:  27%|██▋       | 4/15 [00:00<00:00, 30.45it/s]Batches:  53%|█████▎    | 8/15 [00:00<00:00, 31.38it/s]Batches:  80%|████████  | 12/15 [00:00<00:00, 33.86it/s]Batches: 100%|██████████| 15/15 [00:00<00:00, 35.01it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/8 [00:00<?, ?it/s]Batches:  25%|██▌       | 2/8 [00:00<00:01,  5.12it/s]Batches:  38%|███▊      | 3/8 [00:00<00:00,  5.17it/s]Batches:  50%|█████     | 4/8 [00:00<00:00,  5.51it/s]Batches:  62%|██████▎   | 5/8 [00:00<00:00,  5.95it/s]Batches:  75%|███████▌  | 6/8 [00:01<00:00,  6.41it/s]Batches:  88%|████████▊ | 7/8 [00:01<00:00,  6.91it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  7.51it/s]Batches: 100%|██████████| 8/8 [00:01<00:00,  6.42it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.08 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 7.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.80333, 'ndcg_at_3': 0.86465, 'ndcg_at_5': 0.87532, 'ndcg_at_10': 0.8796, 'ndcg_at_20': 0.88409, 'ndcg_at_100': 0.88994, 'ndcg_at_1000': 0.89097, 'map_at_1': 0.80333, 'map_at_3': 0.85074, 'map_at_5': 0.85674, 'map_at_10': 0.85849, 'map_at_20': 0.85972, 'map_at_100': 0.86055, 'map_at_1000': 0.86059, 'recall_at_1': 0.80333, 'recall_at_3': 0.90444, 'recall_at_5': 0.93, 'recall_at_10': 0.94333, 'recall_at_20': 0.96111, 'recall_at_100': 0.99222, 'recall_at_1000': 1.0, 'precision_at_1': 0.80333, 'precision_at_3': 0.30148, 'precision_at_5': 0.186, 'precision_at_10': 0.09433, 'precision_at_20': 0.04806, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8033333333333333, 'mrr_at_3': 0.8507407407407409, 'mrr_at_5': 0.8567407407407408, 'mrr_at_10': 0.8584872134038802, 'mrr_at_20': 0.859719015958051, 'mrr_at_100': 0.8605501771786044, 'mrr_at_1000': 0.860594347604656, 'nauc_ndcg_at_1_max': np.float64(0.7144604734281541), 'nauc_ndcg_at_1_std': np.float64(-0.03075479037358894), 'nauc_ndcg_at_1_diff1': np.float64(0.8783845490368515), 'nauc_ndcg_at_3_max': np.float64(0.7460751997142202), 'nauc_ndcg_at_3_std': np.float64(0.01431613860324495), 'nauc_ndcg_at_3_diff1': np.float64(0.8518734277875382), 'nauc_ndcg_at_5_max': np.float64(0.7588431787096619), 'nauc_ndcg_at_5_std': np.float64(0.04660310694125582), 'nauc_ndcg_at_5_diff1': np.float64(0.8600816216068748), 'nauc_ndcg_at_10_max': np.float64(0.7537308843825129), 'nauc_ndcg_at_10_std': np.float64(0.02743877031929201), 'nauc_ndcg_at_10_diff1': np.float64(0.8601464938487059), 'nauc_ndcg_at_20_max': np.float64(0.756589310017133), 'nauc_ndcg_at_20_std': np.float64(0.03472573440205783), 'nauc_ndcg_at_20_diff1': np.float64(0.8660678949081592), 'nauc_ndcg_at_100_max': np.float64(0.7497271398718169), 'nauc_ndcg_at_100_std': np.float64(0.030462267429729645), 'nauc_ndcg_at_100_diff1': np.float64(0.8646708926516866), 'nauc_ndcg_at_1000_max': np.float64(0.7476194763678936), 'nauc_ndcg_at_1000_std': np.float64(0.023164955045697332), 'nauc_ndcg_at_1000_diff1': np.float64(0.8640736382725115), 'nauc_map_at_1_max': np.float64(0.7144604734281541), 'nauc_map_at_1_std': np.float64(-0.03075479037358894), 'nauc_map_at_1_diff1': np.float64(0.8783845490368515), 'nauc_map_at_3_max': np.float64(0.7380410878857894), 'nauc_map_at_3_std': np.float64(0.0037690970412170128), 'nauc_map_at_3_diff1': np.float64(0.8595602194780724), 'nauc_map_at_5_max': np.float64(0.7441652104318379), 'nauc_map_at_5_std': np.float64(0.019813631471681307), 'nauc_map_at_5_diff1': np.float64(0.8639913582671778), 'nauc_map_at_10_max': np.float64(0.7423022391957348), 'nauc_map_at_10_std': np.float64(0.013077755502568747), 'nauc_map_at_10_diff1': np.float64(0.8642127452490442), 'nauc_map_at_20_max': np.float64(0.7427858268462051), 'nauc_map_at_20_std': np.float64(0.015015758160884355), 'nauc_map_at_20_diff1': np.float64(0.8653809000316373), 'nauc_map_at_100_max': np.float64(0.7419304322492464), 'nauc_map_at_100_std': np.float64(0.013970732162235726), 'nauc_map_at_100_diff1': np.float64(0.8651555699121707), 'nauc_map_at_1000_max': np.float64(0.7418586175399554), 'nauc_map_at_1000_std': np.float64(0.013734735612603912), 'nauc_map_at_1000_diff1': np.float64(0.8651361278493194), 'nauc_recall_at_1_max': np.float64(0.7144604734281541), 'nauc_recall_at_1_std': np.float64(-0.03075479037358894), 'nauc_recall_at_1_diff1': np.float64(0.8783845490368515), 'nauc_recall_at_3_max': np.float64(0.7795691920178919), 'nauc_recall_at_3_std': np.float64(0.057602110611686456), 'nauc_recall_at_3_diff1': np.float64(0.8191105899724227), 'nauc_recall_at_5_max': np.float64(0.8426852222370445), 'nauc_recall_at_5_std': np.float64(0.2010433803150886), 'nauc_recall_at_5_diff1': np.float64(0.8404324692840107), 'nauc_recall_at_10_max': np.float64(0.8285091814503583), 'nauc_recall_at_10_std': np.float64(0.1116237344611009), 'nauc_recall_at_10_diff1': np.float64(0.8343768880101047), 'nauc_recall_at_20_max': np.float64(0.8967587034813924), 'nauc_recall_at_20_std': np.float64(0.22232893157262798), 'nauc_recall_at_20_diff1': np.float64(0.8951580632252891), 'nauc_recall_at_100_max': np.float64(0.962651727357617), 'nauc_recall_at_100_std': np.float64(0.7736427904495109), 'nauc_recall_at_100_diff1': np.float64(0.9253034547152172), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7144604734281541), 'nauc_precision_at_1_std': np.float64(-0.03075479037358894), 'nauc_precision_at_1_diff1': np.float64(0.8783845490368515), 'nauc_precision_at_3_max': np.float64(0.7795691920178943), 'nauc_precision_at_3_std': np.float64(0.05760211061168791), 'nauc_precision_at_3_diff1': np.float64(0.8191105899724272), 'nauc_precision_at_5_max': np.float64(0.8426852222370399), 'nauc_precision_at_5_std': np.float64(0.20104338031508923), 'nauc_precision_at_5_diff1': np.float64(0.8404324692840104), 'nauc_precision_at_10_max': np.float64(0.8285091814503543), 'nauc_precision_at_10_std': np.float64(0.1116237344611039), 'nauc_precision_at_10_diff1': np.float64(0.834376888010103), 'nauc_precision_at_20_max': np.float64(0.8967587034813862), 'nauc_precision_at_20_std': np.float64(0.22232893157262623), 'nauc_precision_at_20_diff1': np.float64(0.8951580632252828), 'nauc_precision_at_100_max': np.float64(0.962651727357627), 'nauc_precision_at_100_std': np.float64(0.7736427904495127), 'nauc_precision_at_100_diff1': np.float64(0.9253034547152017), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7144604734281541), 'nauc_mrr_at_1_std': np.float64(-0.03075479037358894), 'nauc_mrr_at_1_diff1': np.float64(0.8783845490368515), 'nauc_mrr_at_3_max': np.float64(0.7380410878857894), 'nauc_mrr_at_3_std': np.float64(0.0037690970412170128), 'nauc_mrr_at_3_diff1': np.float64(0.8595602194780724), 'nauc_mrr_at_5_max': np.float64(0.7441652104318379), 'nauc_mrr_at_5_std': np.float64(0.019813631471681307), 'nauc_mrr_at_5_diff1': np.float64(0.8639913582671778), 'nauc_mrr_at_10_max': np.float64(0.7423022391957348), 'nauc_mrr_at_10_std': np.float64(0.013077755502568747), 'nauc_mrr_at_10_diff1': np.float64(0.8642127452490442), 'nauc_mrr_at_20_max': np.float64(0.7427858268462051), 'nauc_mrr_at_20_std': np.float64(0.015015758160884355), 'nauc_mrr_at_20_diff1': np.float64(0.8653809000316373), 'nauc_mrr_at_100_max': np.float64(0.7419304322492464), 'nauc_mrr_at_100_std': np.float64(0.013970732162235726), 'nauc_mrr_at_100_diff1': np.float64(0.8651555699121707), 'nauc_mrr_at_1000_max': np.float64(0.7418586175399554), 'nauc_mrr_at_1000_std': np.float64(0.013734735612603912), 'nauc_mrr_at_1000_diff1': np.float64(0.8651361278493194), 'main_score': 0.8796}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.79778, 'ndcg_at_3': 0.86407, 'ndcg_at_5': 0.8734, 'ndcg_at_10': 0.88062, 'ndcg_at_20': 0.88536, 'ndcg_at_100': 0.88921, 'ndcg_at_1000': 0.88998, 'map_at_1': 0.79778, 'map_at_3': 0.84815, 'map_at_5': 0.85343, 'map_at_10': 0.85643, 'map_at_20': 0.85771, 'map_at_100': 0.85821, 'map_at_1000': 0.85825, 'recall_at_1': 0.79778, 'recall_at_3': 0.91, 'recall_at_5': 0.93222, 'recall_at_10': 0.95444, 'recall_at_20': 0.97333, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.79778, 'precision_at_3': 0.30333, 'precision_at_5': 0.18644, 'precision_at_10': 0.09544, 'precision_at_20': 0.04867, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7977777777777778, 'mrr_at_3': 0.8481481481481484, 'mrr_at_5': 0.8534259259259264, 'mrr_at_10': 0.856428130511464, 'mrr_at_20': 0.8577066769468734, 'mrr_at_100': 0.8582147049962549, 'mrr_at_1000': 0.8582509822841501, 'nauc_ndcg_at_1_max': np.float64(0.6136072240228472), 'nauc_ndcg_at_1_std': np.float64(-0.10831081787516371), 'nauc_ndcg_at_1_diff1': np.float64(0.8469104756035148), 'nauc_ndcg_at_3_max': np.float64(0.6396350400369007), 'nauc_ndcg_at_3_std': np.float64(-0.07909721619527248), 'nauc_ndcg_at_3_diff1': np.float64(0.8196030620594603), 'nauc_ndcg_at_5_max': np.float64(0.6395382719190128), 'nauc_ndcg_at_5_std': np.float64(-0.06251199626346327), 'nauc_ndcg_at_5_diff1': np.float64(0.8181558557674538), 'nauc_ndcg_at_10_max': np.float64(0.643210997098357), 'nauc_ndcg_at_10_std': np.float64(-0.0682725779951663), 'nauc_ndcg_at_10_diff1': np.float64(0.8236698658167095), 'nauc_ndcg_at_20_max': np.float64(0.6425555639374455), 'nauc_ndcg_at_20_std': np.float64(-0.07771461296268094), 'nauc_ndcg_at_20_diff1': np.float64(0.8243330368189321), 'nauc_ndcg_at_100_max': np.float64(0.6394490798501035), 'nauc_ndcg_at_100_std': np.float64(-0.07252899389683454), 'nauc_ndcg_at_100_diff1': np.float64(0.8275142613783739), 'nauc_ndcg_at_1000_max': np.float64(0.6368223960440613), 'nauc_ndcg_at_1000_std': np.float64(-0.0795689943247917), 'nauc_ndcg_at_1000_diff1': np.float64(0.827275101042018), 'nauc_map_at_1_max': np.float64(0.6136072240228472), 'nauc_map_at_1_std': np.float64(-0.10831081787516371), 'nauc_map_at_1_diff1': np.float64(0.8469104756035148), 'nauc_map_at_3_max': np.float64(0.6325155136406339), 'nauc_map_at_3_std': np.float64(-0.08899414161844547), 'nauc_map_at_3_diff1': np.float64(0.827284260162407), 'nauc_map_at_5_max': np.float64(0.6324112783164382), 'nauc_map_at_5_std': np.float64(-0.08103465516566621), 'nauc_map_at_5_diff1': np.float64(0.8268611228256288), 'nauc_map_at_10_max': np.float64(0.6333210130677666), 'nauc_map_at_10_std': np.float64(-0.08382181759549567), 'nauc_map_at_10_diff1': np.float64(0.8288997350230023), 'nauc_map_at_20_max': np.float64(0.6330502230134387), 'nauc_map_at_20_std': np.float64(-0.08618019653766029), 'nauc_map_at_20_diff1': np.float64(0.8291637416330593), 'nauc_map_at_100_max': np.float64(0.6326847487835539), 'nauc_map_at_100_std': np.float64(-0.0856605907756247), 'nauc_map_at_100_diff1': np.float64(0.8295521080594748), 'nauc_map_at_1000_max': np.float64(0.6325855821857873), 'nauc_map_at_1000_std': np.float64(-0.08592721118228824), 'nauc_map_at_1000_diff1': np.float64(0.829546134330904), 'nauc_recall_at_1_max': np.float64(0.6136072240228472), 'nauc_recall_at_1_std': np.float64(-0.10831081787516371), 'nauc_recall_at_1_diff1': np.float64(0.8469104756035148), 'nauc_recall_at_3_max': np.float64(0.6719057993567795), 'nauc_recall_at_3_std': np.float64(-0.03278348376387673), 'nauc_recall_at_3_diff1': np.float64(0.7846249610955486), 'nauc_recall_at_5_max': np.float64(0.6802589888414381), 'nauc_recall_at_5_std': np.float64(0.05159112825458121), 'nauc_recall_at_5_diff1': np.float64(0.7670095360548592), 'nauc_recall_at_10_max': np.float64(0.7316731570677064), 'nauc_recall_at_10_std': np.float64(0.0690601443829571), 'nauc_recall_at_10_diff1': np.float64(0.7854751656760276), 'nauc_recall_at_20_max': np.float64(0.7847027699968866), 'nauc_recall_at_20_std': np.float64(0.017098506069086708), 'nauc_recall_at_20_diff1': np.float64(0.7666705571117347), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.892156862745096), 'nauc_recall_at_100_diff1': np.float64(0.8627450980392323), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6136072240228472), 'nauc_precision_at_1_std': np.float64(-0.10831081787516371), 'nauc_precision_at_1_diff1': np.float64(0.8469104756035148), 'nauc_precision_at_3_max': np.float64(0.6719057993567797), 'nauc_precision_at_3_std': np.float64(-0.032783483763876776), 'nauc_precision_at_3_diff1': np.float64(0.7846249610955512), 'nauc_precision_at_5_max': np.float64(0.6802589888414331), 'nauc_precision_at_5_std': np.float64(0.0515911282545789), 'nauc_precision_at_5_diff1': np.float64(0.7670095360548549), 'nauc_precision_at_10_max': np.float64(0.7316731570677019), 'nauc_precision_at_10_std': np.float64(0.0690601443829509), 'nauc_precision_at_10_diff1': np.float64(0.7854751656760247), 'nauc_precision_at_20_max': np.float64(0.784702769996881), 'nauc_precision_at_20_std': np.float64(0.017098506069089116), 'nauc_precision_at_20_diff1': np.float64(0.7666705571117243), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.8921568627450869), 'nauc_precision_at_100_diff1': np.float64(0.8627450980391947), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6136072240228472), 'nauc_mrr_at_1_std': np.float64(-0.10831081787516371), 'nauc_mrr_at_1_diff1': np.float64(0.8469104756035148), 'nauc_mrr_at_3_max': np.float64(0.6325155136406339), 'nauc_mrr_at_3_std': np.float64(-0.08899414161844547), 'nauc_mrr_at_3_diff1': np.float64(0.827284260162407), 'nauc_mrr_at_5_max': np.float64(0.6324112783164382), 'nauc_mrr_at_5_std': np.float64(-0.08103465516566621), 'nauc_mrr_at_5_diff1': np.float64(0.8268611228256288), 'nauc_mrr_at_10_max': np.float64(0.6333210130677666), 'nauc_mrr_at_10_std': np.float64(-0.08382181759549567), 'nauc_mrr_at_10_diff1': np.float64(0.8288997350230023), 'nauc_mrr_at_20_max': np.float64(0.6330502230134387), 'nauc_mrr_at_20_std': np.float64(-0.08618019653766029), 'nauc_mrr_at_20_diff1': np.float64(0.8291637416330593), 'nauc_mrr_at_100_max': np.float64(0.6326847487835539), 'nauc_mrr_at_100_std': np.float64(-0.0856605907756247), 'nauc_mrr_at_100_diff1': np.float64(0.8295521080594748), 'nauc_mrr_at_1000_max': np.float64(0.6325855821857873), 'nauc_mrr_at_1000_std': np.float64(-0.08592721118228824), 'nauc_mrr_at_1000_diff1': np.float64(0.829546134330904), 'main_score': 0.88062}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.75889, 'ndcg_at_3': 0.8276, 'ndcg_at_5': 0.84601, 'ndcg_at_10': 0.85657, 'ndcg_at_20': 0.85967, 'ndcg_at_100': 0.86461, 'ndcg_at_1000': 0.86607, 'map_at_1': 0.75889, 'map_at_3': 0.81167, 'map_at_5': 0.82194, 'map_at_10': 0.82638, 'map_at_20': 0.82724, 'map_at_100': 0.82792, 'map_at_1000': 0.82798, 'recall_at_1': 0.75889, 'recall_at_3': 0.87333, 'recall_at_5': 0.91778, 'recall_at_10': 0.95, 'recall_at_20': 0.96222, 'recall_at_100': 0.98889, 'recall_at_1000': 1.0, 'precision_at_1': 0.75889, 'precision_at_3': 0.29111, 'precision_at_5': 0.18356, 'precision_at_10': 0.095, 'precision_at_20': 0.04811, 'precision_at_100': 0.00989, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7588888888888888, 'mrr_at_3': 0.8116666666666666, 'mrr_at_5': 0.8219444444444447, 'mrr_at_10': 0.8263791887125224, 'mrr_at_20': 0.8272371670392827, 'mrr_at_100': 0.8279172664600791, 'mrr_at_1000': 0.8279781231588634, 'nauc_ndcg_at_1_max': np.float64(0.6885576833277857), 'nauc_ndcg_at_1_std': np.float64(-0.005981815090553283), 'nauc_ndcg_at_1_diff1': np.float64(0.8148941927542931), 'nauc_ndcg_at_3_max': np.float64(0.7294359748625586), 'nauc_ndcg_at_3_std': np.float64(0.06181714689020046), 'nauc_ndcg_at_3_diff1': np.float64(0.8059262738497057), 'nauc_ndcg_at_5_max': np.float64(0.7164772902430775), 'nauc_ndcg_at_5_std': np.float64(0.05087262789435781), 'nauc_ndcg_at_5_diff1': np.float64(0.8028769320851481), 'nauc_ndcg_at_10_max': np.float64(0.7284930166428097), 'nauc_ndcg_at_10_std': np.float64(0.07720960494895679), 'nauc_ndcg_at_10_diff1': np.float64(0.8084808695754142), 'nauc_ndcg_at_20_max': np.float64(0.7277722658852183), 'nauc_ndcg_at_20_std': np.float64(0.07684336868935904), 'nauc_ndcg_at_20_diff1': np.float64(0.8062310856840769), 'nauc_ndcg_at_100_max': np.float64(0.7219947254747765), 'nauc_ndcg_at_100_std': np.float64(0.06398427568254675), 'nauc_ndcg_at_100_diff1': np.float64(0.8061779133250535), 'nauc_ndcg_at_1000_max': np.float64(0.7194181195131821), 'nauc_ndcg_at_1000_std': np.float64(0.05342224213986593), 'nauc_ndcg_at_1000_diff1': np.float64(0.8071936485236224), 'nauc_map_at_1_max': np.float64(0.6885576833277857), 'nauc_map_at_1_std': np.float64(-0.005981815090553283), 'nauc_map_at_1_diff1': np.float64(0.8148941927542931), 'nauc_map_at_3_max': np.float64(0.717892878661459), 'nauc_map_at_3_std': np.float64(0.03975692189966652), 'nauc_map_at_3_diff1': np.float64(0.8077983411024191), 'nauc_map_at_5_max': np.float64(0.7106092932047338), 'nauc_map_at_5_std': np.float64(0.03282925356427449), 'nauc_map_at_5_diff1': np.float64(0.8063046003130837), 'nauc_map_at_10_max': np.float64(0.7147965670336995), 'nauc_map_at_10_std': np.float64(0.041601046039760524), 'nauc_map_at_10_diff1': np.float64(0.8085438358710668), 'nauc_map_at_20_max': np.float64(0.7144601462940647), 'nauc_map_at_20_std': np.float64(0.04099096241352047), 'nauc_map_at_20_diff1': np.float64(0.8079968971636359), 'nauc_map_at_100_max': np.float64(0.713844142428308), 'nauc_map_at_100_std': np.float64(0.03925475947340508), 'nauc_map_at_100_diff1': np.float64(0.8080206640656972), 'nauc_map_at_1000_max': np.float64(0.7137610309322288), 'nauc_map_at_1000_std': np.float64(0.03889981948933412), 'nauc_map_at_1000_diff1': np.float64(0.8080662924334656), 'nauc_recall_at_1_max': np.float64(0.6885576833277857), 'nauc_recall_at_1_std': np.float64(-0.005981815090553283), 'nauc_recall_at_1_diff1': np.float64(0.8148941927542931), 'nauc_recall_at_3_max': np.float64(0.7759908703488476), 'nauc_recall_at_3_std': np.float64(0.15259740259740326), 'nauc_recall_at_3_diff1': np.float64(0.7987855205754045), 'nauc_recall_at_5_max': np.float64(0.7469086733792616), 'nauc_recall_at_5_std': np.float64(0.15426350720468285), 'nauc_recall_at_5_diff1': np.float64(0.7832790773967254), 'nauc_recall_at_10_max': np.float64(0.8620915032679746), 'nauc_recall_at_10_std': np.float64(0.4347235190372419), 'nauc_recall_at_10_diff1': np.float64(0.8131756406266185), 'nauc_recall_at_20_max': np.float64(0.8985280386664473), 'nauc_recall_at_20_std': np.float64(0.5554457076948423), 'nauc_recall_at_20_diff1': np.float64(0.7854122040973217), 'nauc_recall_at_100_max': np.float64(0.9423436041083036), 'nauc_recall_at_100_std': np.float64(0.9554154995331435), 'nauc_recall_at_100_diff1': np.float64(0.7288048552754446), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.6885576833277857), 'nauc_precision_at_1_std': np.float64(-0.005981815090553283), 'nauc_precision_at_1_diff1': np.float64(0.8148941927542931), 'nauc_precision_at_3_max': np.float64(0.7759908703488474), 'nauc_precision_at_3_std': np.float64(0.15259740259740234), 'nauc_precision_at_3_diff1': np.float64(0.7987855205754054), 'nauc_precision_at_5_max': np.float64(0.7469086733792593), 'nauc_precision_at_5_std': np.float64(0.15426350720468127), 'nauc_precision_at_5_diff1': np.float64(0.7832790773967219), 'nauc_precision_at_10_max': np.float64(0.8620915032679718), 'nauc_precision_at_10_std': np.float64(0.4347235190372405), 'nauc_precision_at_10_diff1': np.float64(0.813175640626619), 'nauc_precision_at_20_max': np.float64(0.8985280386664453), 'nauc_precision_at_20_std': np.float64(0.5554457076948398), 'nauc_precision_at_20_diff1': np.float64(0.7854122040973202), 'nauc_precision_at_100_max': np.float64(0.9423436041083034), 'nauc_precision_at_100_std': np.float64(0.9554154995331525), 'nauc_precision_at_100_diff1': np.float64(0.7288048552754708), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.6885576833277857), 'nauc_mrr_at_1_std': np.float64(-0.005981815090553283), 'nauc_mrr_at_1_diff1': np.float64(0.8148941927542931), 'nauc_mrr_at_3_max': np.float64(0.717892878661459), 'nauc_mrr_at_3_std': np.float64(0.03975692189966652), 'nauc_mrr_at_3_diff1': np.float64(0.8077983411024191), 'nauc_mrr_at_5_max': np.float64(0.7106092932047338), 'nauc_mrr_at_5_std': np.float64(0.03282925356427449), 'nauc_mrr_at_5_diff1': np.float64(0.8063046003130837), 'nauc_mrr_at_10_max': np.float64(0.7147965670336995), 'nauc_mrr_at_10_std': np.float64(0.041601046039760524), 'nauc_mrr_at_10_diff1': np.float64(0.8085438358710668), 'nauc_mrr_at_20_max': np.float64(0.7144601462940647), 'nauc_mrr_at_20_std': np.float64(0.04099096241352047), 'nauc_mrr_at_20_diff1': np.float64(0.8079968971636359), 'nauc_mrr_at_100_max': np.float64(0.713844142428308), 'nauc_mrr_at_100_std': np.float64(0.03925475947340508), 'nauc_mrr_at_100_diff1': np.float64(0.8080206640656972), 'nauc_mrr_at_1000_max': np.float64(0.7137610309322288), 'nauc_mrr_at_1000_std': np.float64(0.03889981948933412), 'nauc_mrr_at_1000_diff1': np.float64(0.8080662924334656), 'main_score': 0.85657}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:  27%|██▋       | 3/11 [00:00<00:00, 25.61it/s]Batches:  73%|███████▎  | 8/11 [00:00<00:00, 38.96it/s]Batches: 100%|██████████| 11/11 [00:00<00:00, 42.08it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:  14%|█▍        | 2/14 [00:00<00:00, 15.28it/s]Batches:  43%|████▎     | 6/14 [00:00<00:00, 25.41it/s]Batches:  79%|███████▊  | 11/14 [00:00<00:00, 32.97it/s]Batches: 100%|██████████| 14/14 [00:00<00:00, 33.82it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.11 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/11 [00:00<?, ?it/s]Batches:  27%|██▋       | 3/11 [00:00<00:00, 25.78it/s]Batches:  82%|████████▏ | 9/11 [00:00<00:00, 41.22it/s]Batches: 100%|██████████| 11/11 [00:00<00:00, 42.30it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:  11%|█         | 2/19 [00:01<00:14,  1.21it/s]Batches:  16%|█▌        | 3/19 [00:01<00:08,  1.89it/s]Batches:  21%|██        | 4/19 [00:01<00:05,  2.69it/s]Batches:  32%|███▏      | 6/19 [00:02<00:02,  4.44it/s]Batches:  42%|████▏     | 8/19 [00:02<00:01,  6.32it/s]Batches:  53%|█████▎    | 10/19 [00:02<00:01,  8.30it/s]Batches:  68%|██████▊   | 13/19 [00:02<00:00, 11.43it/s]Batches:  84%|████████▍ | 16/19 [00:02<00:00, 14.76it/s]Batches: 100%|██████████| 19/19 [00:02<00:00,  7.23it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3.35 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]Batches:  30%|███       | 3/10 [00:00<00:00, 23.76it/s]Batches:  90%|█████████ | 9/10 [00:00<00:00, 40.48it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 39.70it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/14 [00:00<?, ?it/s]Batches:  14%|█▍        | 2/14 [00:00<00:00, 15.50it/s]Batches:  43%|████▎     | 6/14 [00:00<00:00, 25.57it/s]Batches:  79%|███████▊  | 11/14 [00:00<00:00, 33.11it/s]Batches: 100%|██████████| 14/14 [00:00<00:00, 34.03it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.03 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 7.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.23853, 'ndcg_at_3': 0.25869, 'ndcg_at_5': 0.27568, 'ndcg_at_10': 0.30724, 'ndcg_at_20': 0.32478, 'ndcg_at_100': 0.37295, 'ndcg_at_1000': 0.41312, 'map_at_1': 0.16654, 'map_at_3': 0.23243, 'map_at_5': 0.24625, 'map_at_10': 0.26179, 'map_at_20': 0.26735, 'map_at_100': 0.27442, 'map_at_1000': 0.27604, 'recall_at_1': 0.16654, 'recall_at_3': 0.27859, 'recall_at_5': 0.31873, 'recall_at_10': 0.40482, 'recall_at_20': 0.46774, 'recall_at_100': 0.70308, 'recall_at_1000': 1.0, 'precision_at_1': 0.23853, 'precision_at_3': 0.14526, 'precision_at_5': 0.10336, 'precision_at_10': 0.06575, 'precision_at_20': 0.03754, 'precision_at_100': 0.01139, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.23853211009174313, 'mrr_at_3': 0.2787971457696229, 'mrr_at_5': 0.28835372069317033, 'mrr_at_10': 0.29942721227124897, 'mrr_at_20': 0.30378116537829103, 'mrr_at_100': 0.3092477532452282, 'mrr_at_1000': 0.31036788152074596, 'nauc_ndcg_at_1_max': np.float64(0.1710328904197035), 'nauc_ndcg_at_1_std': np.float64(-0.20048698319894603), 'nauc_ndcg_at_1_diff1': np.float64(0.5011382624720796), 'nauc_ndcg_at_3_max': np.float64(0.16634419046964202), 'nauc_ndcg_at_3_std': np.float64(-0.17793218801362695), 'nauc_ndcg_at_3_diff1': np.float64(0.4619158776702101), 'nauc_ndcg_at_5_max': np.float64(0.16888164823356713), 'nauc_ndcg_at_5_std': np.float64(-0.16992609978088177), 'nauc_ndcg_at_5_diff1': np.float64(0.45333962167423275), 'nauc_ndcg_at_10_max': np.float64(0.16954406130459498), 'nauc_ndcg_at_10_std': np.float64(-0.17789010934584001), 'nauc_ndcg_at_10_diff1': np.float64(0.46073080277527323), 'nauc_ndcg_at_20_max': np.float64(0.18150513667976045), 'nauc_ndcg_at_20_std': np.float64(-0.16700412381328508), 'nauc_ndcg_at_20_diff1': np.float64(0.46113699681564296), 'nauc_ndcg_at_100_max': np.float64(0.2063646865699599), 'nauc_ndcg_at_100_std': np.float64(-0.12463051900546804), 'nauc_ndcg_at_100_diff1': np.float64(0.43901906049625317), 'nauc_ndcg_at_1000_max': np.float64(0.18694366236028562), 'nauc_ndcg_at_1000_std': np.float64(-0.15413964907882177), 'nauc_ndcg_at_1000_diff1': np.float64(0.45074365877848266), 'nauc_map_at_1_max': np.float64(0.1415086449494959), 'nauc_map_at_1_std': np.float64(-0.15905266073600383), 'nauc_map_at_1_diff1': np.float64(0.5347896707142972), 'nauc_map_at_3_max': np.float64(0.16869218091148191), 'nauc_map_at_3_std': np.float64(-0.17287896666367372), 'nauc_map_at_3_diff1': np.float64(0.4636462501096955), 'nauc_map_at_5_max': np.float64(0.16880300762739983), 'nauc_map_at_5_std': np.float64(-0.17282665641306172), 'nauc_map_at_5_diff1': np.float64(0.4574507609721948), 'nauc_map_at_10_max': np.float64(0.16943752853507563), 'nauc_map_at_10_std': np.float64(-0.17910099308198982), 'nauc_map_at_10_diff1': np.float64(0.4638975070561861), 'nauc_map_at_20_max': np.float64(0.17223984521621846), 'nauc_map_at_20_std': np.float64(-0.17701332110165344), 'nauc_map_at_20_diff1': np.float64(0.4642375713413905), 'nauc_map_at_100_max': np.float64(0.17602933099469562), 'nauc_map_at_100_std': np.float64(-0.17064935233055337), 'nauc_map_at_100_diff1': np.float64(0.4602240097529401), 'nauc_map_at_1000_max': np.float64(0.17516137058481462), 'nauc_map_at_1000_std': np.float64(-0.17186097363447977), 'nauc_map_at_1000_diff1': np.float64(0.46046998178331117), 'nauc_recall_at_1_max': np.float64(0.1415086449494959), 'nauc_recall_at_1_std': np.float64(-0.15905266073600383), 'nauc_recall_at_1_diff1': np.float64(0.5347896707142972), 'nauc_recall_at_3_max': np.float64(0.16120603935905187), 'nauc_recall_at_3_std': np.float64(-0.15232329094239325), 'nauc_recall_at_3_diff1': np.float64(0.42538434941403624), 'nauc_recall_at_5_max': np.float64(0.16241875942413933), 'nauc_recall_at_5_std': np.float64(-0.1459331777008506), 'nauc_recall_at_5_diff1': np.float64(0.41206673640909786), 'nauc_recall_at_10_max': np.float64(0.16052388393415576), 'nauc_recall_at_10_std': np.float64(-0.16547893285006554), 'nauc_recall_at_10_diff1': np.float64(0.42512716966311526), 'nauc_recall_at_20_max': np.float64(0.20118521431192207), 'nauc_recall_at_20_std': np.float64(-0.12773593944421877), 'nauc_recall_at_20_diff1': np.float64(0.4267970206817293), 'nauc_recall_at_100_max': np.float64(0.34308274479573453), 'nauc_recall_at_100_std': np.float64(0.12212368148463992), 'nauc_recall_at_100_diff1': np.float64(0.3042749854292903), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.1710328904197035), 'nauc_precision_at_1_std': np.float64(-0.20048698319894603), 'nauc_precision_at_1_diff1': np.float64(0.5011382624720796), 'nauc_precision_at_3_max': np.float64(0.17714261527312772), 'nauc_precision_at_3_std': np.float64(-0.19270047922441152), 'nauc_precision_at_3_diff1': np.float64(0.3367612336349229), 'nauc_precision_at_5_max': np.float64(0.164027258650643), 'nauc_precision_at_5_std': np.float64(-0.17750788382137142), 'nauc_precision_at_5_diff1': np.float64(0.30820104113069113), 'nauc_precision_at_10_max': np.float64(0.15602145143955257), 'nauc_precision_at_10_std': np.float64(-0.1775482769290137), 'nauc_precision_at_10_diff1': np.float64(0.3090540190553256), 'nauc_precision_at_20_max': np.float64(0.17499612606897091), 'nauc_precision_at_20_std': np.float64(-0.14158176879585316), 'nauc_precision_at_20_diff1': np.float64(0.29084470955788), 'nauc_precision_at_100_max': np.float64(0.21804049604114545), 'nauc_precision_at_100_std': np.float64(0.05638855924167594), 'nauc_precision_at_100_diff1': np.float64(0.09814930477773491), 'nauc_precision_at_1000_max': np.float64(0.0970387619515828), 'nauc_precision_at_1000_std': np.float64(0.007738454229137765), 'nauc_precision_at_1000_diff1': np.float64(-0.03034936062924852), 'nauc_mrr_at_1_max': np.float64(0.1710328904197035), 'nauc_mrr_at_1_std': np.float64(-0.20048698319894603), 'nauc_mrr_at_1_diff1': np.float64(0.5011382624720796), 'nauc_mrr_at_3_max': np.float64(0.16802519862298554), 'nauc_mrr_at_3_std': np.float64(-0.188463319155195), 'nauc_mrr_at_3_diff1': np.float64(0.4807309717858008), 'nauc_mrr_at_5_max': np.float64(0.16830225143196942), 'nauc_mrr_at_5_std': np.float64(-0.18397246262737063), 'nauc_mrr_at_5_diff1': np.float64(0.4757825397621256), 'nauc_mrr_at_10_max': np.float64(0.16980398591064655), 'nauc_mrr_at_10_std': np.float64(-0.18516046465724778), 'nauc_mrr_at_10_diff1': np.float64(0.47737509105723896), 'nauc_mrr_at_20_max': np.float64(0.1739472122587537), 'nauc_mrr_at_20_std': np.float64(-0.18078729469188906), 'nauc_mrr_at_20_diff1': np.float64(0.47670417514242625), 'nauc_mrr_at_100_max': np.float64(0.176405656211285), 'nauc_mrr_at_100_std': np.float64(-0.17715746519605918), 'nauc_mrr_at_100_diff1': np.float64(0.474438900959708), 'nauc_mrr_at_1000_max': np.float64(0.1755287321535211), 'nauc_mrr_at_1000_std': np.float64(-0.17822699605477396), 'nauc_mrr_at_1000_diff1': np.float64(0.4746875998243863), 'main_score': 0.30724}, 'eng-kor': {'ndcg_at_1': 0.28287, 'ndcg_at_3': 0.27816, 'ndcg_at_5': 0.2897, 'ndcg_at_10': 0.31766, 'ndcg_at_20': 0.34667, 'ndcg_at_100': 0.40368, 'ndcg_at_1000': 0.43972, 'map_at_1': 0.15966, 'map_at_3': 0.23239, 'map_at_5': 0.25223, 'map_at_10': 0.26846, 'map_at_20': 0.27774, 'map_at_100': 0.28676, 'map_at_1000': 0.28869, 'recall_at_1': 0.15966, 'recall_at_3': 0.26937, 'recall_at_5': 0.31955, 'recall_at_10': 0.39006, 'recall_at_20': 0.48675, 'recall_at_100': 0.75754, 'recall_at_1000': 0.99791, 'precision_at_1': 0.28287, 'precision_at_3': 0.18094, 'precision_at_5': 0.1315, 'precision_at_10': 0.08073, 'precision_at_20': 0.04992, 'precision_at_100': 0.01489, 'precision_at_1000': 0.00194, 'mrr_at_1': 0.28287461773700306, 'mrr_at_3': 0.3216106014271153, 'mrr_at_5': 0.33086136595310917, 'mrr_at_10': 0.3392487015193438, 'mrr_at_20': 0.34650892144856427, 'mrr_at_100': 0.35277378154240957, 'mrr_at_1000': 0.3536028531807654, 'nauc_ndcg_at_1_max': np.float64(0.1702882626404106), 'nauc_ndcg_at_1_std': np.float64(-0.19022047922326274), 'nauc_ndcg_at_1_diff1': np.float64(0.43078365226721643), 'nauc_ndcg_at_3_max': np.float64(0.19472976699280825), 'nauc_ndcg_at_3_std': np.float64(-0.19475941988238804), 'nauc_ndcg_at_3_diff1': np.float64(0.422294467926566), 'nauc_ndcg_at_5_max': np.float64(0.19273669097369414), 'nauc_ndcg_at_5_std': np.float64(-0.19416658235162243), 'nauc_ndcg_at_5_diff1': np.float64(0.42150046271189157), 'nauc_ndcg_at_10_max': np.float64(0.18667149808409864), 'nauc_ndcg_at_10_std': np.float64(-0.19353584269122937), 'nauc_ndcg_at_10_diff1': np.float64(0.40908554730068114), 'nauc_ndcg_at_20_max': np.float64(0.18870669151138467), 'nauc_ndcg_at_20_std': np.float64(-0.18182405645328933), 'nauc_ndcg_at_20_diff1': np.float64(0.39752948895740603), 'nauc_ndcg_at_100_max': np.float64(0.20449587213426224), 'nauc_ndcg_at_100_std': np.float64(-0.15578624738992278), 'nauc_ndcg_at_100_diff1': np.float64(0.39638795164490487), 'nauc_ndcg_at_1000_max': np.float64(0.20062503222203149), 'nauc_ndcg_at_1000_std': np.float64(-0.16597810418774883), 'nauc_ndcg_at_1000_diff1': np.float64(0.3973743141054969), 'nauc_map_at_1_max': np.float64(0.2022136942837982), 'nauc_map_at_1_std': np.float64(-0.16629879431908526), 'nauc_map_at_1_diff1': np.float64(0.5094094888816958), 'nauc_map_at_3_max': np.float64(0.2114974049562774), 'nauc_map_at_3_std': np.float64(-0.18973643431599205), 'nauc_map_at_3_diff1': np.float64(0.45683769382324835), 'nauc_map_at_5_max': np.float64(0.20755508120960656), 'nauc_map_at_5_std': np.float64(-0.1907358768225807), 'nauc_map_at_5_diff1': np.float64(0.44408303291369394), 'nauc_map_at_10_max': np.float64(0.2030921230434491), 'nauc_map_at_10_std': np.float64(-0.1923008639657004), 'nauc_map_at_10_diff1': np.float64(0.43593056645539535), 'nauc_map_at_20_max': np.float64(0.20226479462888725), 'nauc_map_at_20_std': np.float64(-0.19010346297444206), 'nauc_map_at_20_diff1': np.float64(0.43243985671766244), 'nauc_map_at_100_max': np.float64(0.20367492987213248), 'nauc_map_at_100_std': np.float64(-0.18720038490313232), 'nauc_map_at_100_diff1': np.float64(0.43053846390549116), 'nauc_map_at_1000_max': np.float64(0.2047801905278878), 'nauc_map_at_1000_std': np.float64(-0.18617149418779316), 'nauc_map_at_1000_diff1': np.float64(0.43023679180575036), 'nauc_recall_at_1_max': np.float64(0.2022136942837982), 'nauc_recall_at_1_std': np.float64(-0.16629879431908526), 'nauc_recall_at_1_diff1': np.float64(0.5094094888816958), 'nauc_recall_at_3_max': np.float64(0.19605999728416043), 'nauc_recall_at_3_std': np.float64(-0.17775588225430455), 'nauc_recall_at_3_diff1': np.float64(0.4025757277241289), 'nauc_recall_at_5_max': np.float64(0.1769513092530404), 'nauc_recall_at_5_std': np.float64(-0.189916223373261), 'nauc_recall_at_5_diff1': np.float64(0.37889647475908744), 'nauc_recall_at_10_max': np.float64(0.1643013408968958), 'nauc_recall_at_10_std': np.float64(-0.1839318165372178), 'nauc_recall_at_10_diff1': np.float64(0.348625448128896), 'nauc_recall_at_20_max': np.float64(0.1706168126949685), 'nauc_recall_at_20_std': np.float64(-0.14440748314209284), 'nauc_recall_at_20_diff1': np.float64(0.30871358932428533), 'nauc_recall_at_100_max': np.float64(0.26057031713542306), 'nauc_recall_at_100_std': np.float64(0.028329931041429883), 'nauc_recall_at_100_diff1': np.float64(0.29569892516149393), 'nauc_recall_at_1000_max': np.float64(0.85774024244626), 'nauc_recall_at_1000_std': np.float64(0.8178081164635485), 'nauc_recall_at_1000_diff1': np.float64(0.3794834485562372), 'nauc_precision_at_1_max': np.float64(0.1702882626404106), 'nauc_precision_at_1_std': np.float64(-0.19022047922326274), 'nauc_precision_at_1_diff1': np.float64(0.43078365226721643), 'nauc_precision_at_3_max': np.float64(0.15377715751169105), 'nauc_precision_at_3_std': np.float64(-0.18440380852826943), 'nauc_precision_at_3_diff1': np.float64(0.28366520674490603), 'nauc_precision_at_5_max': np.float64(0.13773446176999182), 'nauc_precision_at_5_std': np.float64(-0.1731204992204692), 'nauc_precision_at_5_diff1': np.float64(0.2419626741051632), 'nauc_precision_at_10_max': np.float64(0.11219194377794384), 'nauc_precision_at_10_std': np.float64(-0.15977413044551775), 'nauc_precision_at_10_diff1': np.float64(0.20270424761964256), 'nauc_precision_at_20_max': np.float64(0.10458895602149304), 'nauc_precision_at_20_std': np.float64(-0.12484103264505014), 'nauc_precision_at_20_diff1': np.float64(0.15945868712736777), 'nauc_precision_at_100_max': np.float64(0.10853805071890375), 'nauc_precision_at_100_std': np.float64(0.016852971188687477), 'nauc_precision_at_100_diff1': np.float64(0.04597533172148491), 'nauc_precision_at_1000_max': np.float64(0.03273543588118617), 'nauc_precision_at_1000_std': np.float64(0.034027378427526046), 'nauc_precision_at_1000_diff1': np.float64(-0.08592574039060139), 'nauc_mrr_at_1_max': np.float64(0.1702882626404106), 'nauc_mrr_at_1_std': np.float64(-0.19022047922326274), 'nauc_mrr_at_1_diff1': np.float64(0.43078365226721643), 'nauc_mrr_at_3_max': np.float64(0.1702917598959025), 'nauc_mrr_at_3_std': np.float64(-0.18516509262458347), 'nauc_mrr_at_3_diff1': np.float64(0.4052476466508942), 'nauc_mrr_at_5_max': np.float64(0.16467520855433232), 'nauc_mrr_at_5_std': np.float64(-0.1915264977988557), 'nauc_mrr_at_5_diff1': np.float64(0.39963181278379417), 'nauc_mrr_at_10_max': np.float64(0.1644470783065337), 'nauc_mrr_at_10_std': np.float64(-0.18923968143016953), 'nauc_mrr_at_10_diff1': np.float64(0.3972387519821158), 'nauc_mrr_at_20_max': np.float64(0.1679152011326394), 'nauc_mrr_at_20_std': np.float64(-0.18344317235319288), 'nauc_mrr_at_20_diff1': np.float64(0.3940616573944725), 'nauc_mrr_at_100_max': np.float64(0.16898359040555758), 'nauc_mrr_at_100_std': np.float64(-0.18250706743167894), 'nauc_mrr_at_100_diff1': np.float64(0.39442191623894046), 'nauc_mrr_at_1000_max': np.float64(0.16875800040104552), 'nauc_mrr_at_1000_std': np.float64(-0.18296893777149567), 'nauc_mrr_at_1000_diff1': np.float64(0.3945721990349661), 'main_score': 0.31766}, 'kor-eng': {'ndcg_at_1': 0.2329, 'ndcg_at_3': 0.25664, 'ndcg_at_5': 0.26976, 'ndcg_at_10': 0.29367, 'ndcg_at_20': 0.32186, 'ndcg_at_100': 0.36766, 'ndcg_at_1000': 0.41067, 'map_at_1': 0.16169, 'map_at_3': 0.22819, 'map_at_5': 0.24023, 'map_at_10': 0.25273, 'map_at_20': 0.26192, 'map_at_100': 0.26951, 'map_at_1000': 0.27126, 'recall_at_1': 0.16169, 'recall_at_3': 0.2719, 'recall_at_5': 0.30482, 'recall_at_10': 0.36858, 'recall_at_20': 0.46359, 'recall_at_100': 0.68048, 'recall_at_1000': 1.0, 'precision_at_1': 0.2329, 'precision_at_3': 0.14767, 'precision_at_5': 0.10293, 'precision_at_10': 0.06336, 'precision_at_20': 0.04055, 'precision_at_100': 0.01197, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.23289902280130292, 'mrr_at_3': 0.27904451682953324, 'mrr_at_5': 0.28669923995656904, 'mrr_at_10': 0.29536476914327064, 'mrr_at_20': 0.30237662198185994, 'mrr_at_100': 0.30716380355993184, 'mrr_at_1000': 0.3082069084459137, 'nauc_ndcg_at_1_max': np.float64(0.15042533595554772), 'nauc_ndcg_at_1_std': np.float64(-0.18437012032221006), 'nauc_ndcg_at_1_diff1': np.float64(0.48468119540124965), 'nauc_ndcg_at_3_max': np.float64(0.11944364435132239), 'nauc_ndcg_at_3_std': np.float64(-0.19126849095602919), 'nauc_ndcg_at_3_diff1': np.float64(0.4051695223146839), 'nauc_ndcg_at_5_max': np.float64(0.10992273316880617), 'nauc_ndcg_at_5_std': np.float64(-0.20016531175412253), 'nauc_ndcg_at_5_diff1': np.float64(0.39947912250237116), 'nauc_ndcg_at_10_max': np.float64(0.12349649856821782), 'nauc_ndcg_at_10_std': np.float64(-0.20417246723001942), 'nauc_ndcg_at_10_diff1': np.float64(0.3979861873680755), 'nauc_ndcg_at_20_max': np.float64(0.1308420665491274), 'nauc_ndcg_at_20_std': np.float64(-0.1852330260389345), 'nauc_ndcg_at_20_diff1': np.float64(0.38202113029359375), 'nauc_ndcg_at_100_max': np.float64(0.15143587604230319), 'nauc_ndcg_at_100_std': np.float64(-0.1575336469290791), 'nauc_ndcg_at_100_diff1': np.float64(0.36635145619339143), 'nauc_ndcg_at_1000_max': np.float64(0.1408284887995377), 'nauc_ndcg_at_1000_std': np.float64(-0.1744672116115654), 'nauc_ndcg_at_1000_diff1': np.float64(0.3880999705799889), 'nauc_map_at_1_max': np.float64(0.13000935252442475), 'nauc_map_at_1_std': np.float64(-0.15265135985215136), 'nauc_map_at_1_diff1': np.float64(0.49998577979517983), 'nauc_map_at_3_max': np.float64(0.12281456025945924), 'nauc_map_at_3_std': np.float64(-0.18824030125445101), 'nauc_map_at_3_diff1': np.float64(0.41724986246003115), 'nauc_map_at_5_max': np.float64(0.11919557019524485), 'nauc_map_at_5_std': np.float64(-0.19524997617072462), 'nauc_map_at_5_diff1': np.float64(0.41152774793705993), 'nauc_map_at_10_max': np.float64(0.12556479956797875), 'nauc_map_at_10_std': np.float64(-0.19958904974330713), 'nauc_map_at_10_diff1': np.float64(0.4097225970897698), 'nauc_map_at_20_max': np.float64(0.12709499309729613), 'nauc_map_at_20_std': np.float64(-0.19416896544072584), 'nauc_map_at_20_diff1': np.float64(0.4043273387934694), 'nauc_map_at_100_max': np.float64(0.13024512108407538), 'nauc_map_at_100_std': np.float64(-0.1896762596433364), 'nauc_map_at_100_diff1': np.float64(0.401460057815147), 'nauc_map_at_1000_max': np.float64(0.12989945725252075), 'nauc_map_at_1000_std': np.float64(-0.19026658643276256), 'nauc_map_at_1000_diff1': np.float64(0.402364930855965), 'nauc_recall_at_1_max': np.float64(0.13000935252442475), 'nauc_recall_at_1_std': np.float64(-0.15265135985215136), 'nauc_recall_at_1_diff1': np.float64(0.49998577979517983), 'nauc_recall_at_3_max': np.float64(0.09429804779858321), 'nauc_recall_at_3_std': np.float64(-0.18793468626423918), 'nauc_recall_at_3_diff1': np.float64(0.3532291466642572), 'nauc_recall_at_5_max': np.float64(0.07987294522395673), 'nauc_recall_at_5_std': np.float64(-0.2053014135072843), 'nauc_recall_at_5_diff1': np.float64(0.3371090964412974), 'nauc_recall_at_10_max': np.float64(0.11110187252727514), 'nauc_recall_at_10_std': np.float64(-0.21373713455388565), 'nauc_recall_at_10_diff1': np.float64(0.33286347153551493), 'nauc_recall_at_20_max': np.float64(0.1309001978764897), 'nauc_recall_at_20_std': np.float64(-0.15195365980849182), 'nauc_recall_at_20_diff1': np.float64(0.2808225129566676), 'nauc_recall_at_100_max': np.float64(0.22326397283006172), 'nauc_recall_at_100_std': np.float64(-0.012573773594995362), 'nauc_recall_at_100_diff1': np.float64(0.17567011906387164), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.15042533595554772), 'nauc_precision_at_1_std': np.float64(-0.18437012032221006), 'nauc_precision_at_1_diff1': np.float64(0.48468119540124965), 'nauc_precision_at_3_max': np.float64(0.11466029738009711), 'nauc_precision_at_3_std': np.float64(-0.20702151399249047), 'nauc_precision_at_3_diff1': np.float64(0.291841490033633), 'nauc_precision_at_5_max': np.float64(0.09186387677675449), 'nauc_precision_at_5_std': np.float64(-0.21344184500612426), 'nauc_precision_at_5_diff1': np.float64(0.26375878245224577), 'nauc_precision_at_10_max': np.float64(0.11426078100074637), 'nauc_precision_at_10_std': np.float64(-0.20522689718638462), 'nauc_precision_at_10_diff1': np.float64(0.238221357538195), 'nauc_precision_at_20_max': np.float64(0.12064257063411347), 'nauc_precision_at_20_std': np.float64(-0.1401821039917873), 'nauc_precision_at_20_diff1': np.float64(0.1709476117260024), 'nauc_precision_at_100_max': np.float64(0.19226963732967228), 'nauc_precision_at_100_std': np.float64(0.026170385214899197), 'nauc_precision_at_100_diff1': np.float64(0.04345755772775644), 'nauc_precision_at_1000_max': np.float64(0.13899813834379615), 'nauc_precision_at_1000_std': np.float64(0.04000898712738393), 'nauc_precision_at_1000_diff1': np.float64(-0.01258523599785369), 'nauc_mrr_at_1_max': np.float64(0.15042533595554772), 'nauc_mrr_at_1_std': np.float64(-0.18437012032221006), 'nauc_mrr_at_1_diff1': np.float64(0.48468119540124965), 'nauc_mrr_at_3_max': np.float64(0.1254625553396092), 'nauc_mrr_at_3_std': np.float64(-0.19092380547574533), 'nauc_mrr_at_3_diff1': np.float64(0.43897967255324455), 'nauc_mrr_at_5_max': np.float64(0.12200585923704393), 'nauc_mrr_at_5_std': np.float64(-0.19294483424478642), 'nauc_mrr_at_5_diff1': np.float64(0.43502145833562217), 'nauc_mrr_at_10_max': np.float64(0.12881780828582814), 'nauc_mrr_at_10_std': np.float64(-0.19015371067992137), 'nauc_mrr_at_10_diff1': np.float64(0.43488458644787525), 'nauc_mrr_at_20_max': np.float64(0.1332294340042301), 'nauc_mrr_at_20_std': np.float64(-0.18458454350554737), 'nauc_mrr_at_20_diff1': np.float64(0.4314733670851503), 'nauc_mrr_at_100_max': np.float64(0.1340731274409209), 'nauc_mrr_at_100_std': np.float64(-0.18347948741993558), 'nauc_mrr_at_100_diff1': np.float64(0.430314138745653), 'nauc_mrr_at_1000_max': np.float64(0.13352774688129232), 'nauc_mrr_at_1000_std': np.float64(-0.1840406546945592), 'nauc_mrr_at_1000_diff1': np.float64(0.4307508644451908), 'main_score': 0.29367}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  50%|█████     | 2/4 [00:00<00:00,  4.69it/s]Batches: 100%|██████████| 4/4 [00:00<00:00,  8.05it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/97 [00:00<?, ?it/s]Batches:   1%|          | 1/97 [00:01<02:41,  1.69s/it]Batches:   2%|▏         | 2/97 [00:31<29:01, 18.33s/it]Batches:   3%|▎         | 3/97 [01:01<37:12, 23.75s/it]Batches:   4%|▍         | 4/97 [01:32<40:47, 26.32s/it]Batches:   5%|▌         | 5/97 [02:02<42:32, 27.75s/it]Batches:   6%|▌         | 6/97 [02:32<43:23, 28.61s/it]Batches:   7%|▋         | 7/97 [03:03<43:45, 29.17s/it]Batches:   8%|▊         | 8/97 [03:33<43:48, 29.54s/it]Batches:   9%|▉         | 9/97 [04:03<43:40, 29.78s/it]Batches:  10%|█         | 10/97 [04:33<43:25, 29.95s/it]Batches:  11%|█▏        | 11/97 [05:04<43:05, 30.07s/it]Batches:  12%|█▏        | 12/97 [05:34<42:42, 30.15s/it]Batches:  13%|█▎        | 13/97 [06:04<42:16, 30.20s/it]Batches:  14%|█▍        | 14/97 [06:35<41:49, 30.24s/it]Batches:  15%|█▌        | 15/97 [07:05<41:21, 30.27s/it]Batches:  16%|█▋        | 16/97 [07:35<40:53, 30.29s/it]Batches:  18%|█▊        | 17/97 [08:06<40:24, 30.30s/it]Batches:  19%|█▊        | 18/97 [08:36<39:54, 30.31s/it]Batches:  20%|█▉        | 19/97 [09:06<39:24, 30.32s/it]Batches:  21%|██        | 20/97 [09:37<38:54, 30.32s/it]Batches:  22%|██▏       | 21/97 [10:07<38:24, 30.32s/it]Batches:  23%|██▎       | 22/97 [10:37<37:54, 30.33s/it]Batches:  24%|██▎       | 23/97 [11:08<37:24, 30.33s/it]Batches:  25%|██▍       | 24/97 [11:38<36:53, 30.33s/it]Batches:  26%|██▌       | 25/97 [12:08<36:23, 30.33s/it]Batches:  27%|██▋       | 26/97 [12:39<35:53, 30.33s/it]Batches:  28%|██▊       | 27/97 [13:09<35:22, 30.32s/it]Batches:  29%|██▉       | 28/97 [13:39<34:52, 30.33s/it]Batches:  30%|██▉       | 29/97 [14:10<34:22, 30.33s/it]Batches:  31%|███       | 30/97 [14:40<33:51, 30.33s/it]Batches:  32%|███▏      | 31/97 [15:10<33:21, 30.33s/it]Batches:  33%|███▎      | 32/97 [15:41<32:51, 30.33s/it]Batches:  34%|███▍      | 33/97 [16:11<32:21, 30.33s/it]Batches:  35%|███▌      | 34/97 [16:41<31:50, 30.33s/it]Batches:  36%|███▌      | 35/97 [17:12<31:20, 30.33s/it]Batches:  37%|███▋      | 36/97 [17:42<30:50, 30.33s/it]Batches:  38%|███▊      | 37/97 [18:12<30:19, 30.33s/it]Batches:  39%|███▉      | 38/97 [18:43<29:49, 30.33s/it]Batches:  40%|████      | 39/97 [19:13<29:19, 30.33s/it]Batches:  41%|████      | 40/97 [19:43<28:48, 30.33s/it]Batches:  42%|████▏     | 41/97 [20:14<28:18, 30.33s/it]Batches:  43%|████▎     | 42/97 [20:44<27:47, 30.32s/it]Batches:  44%|████▍     | 43/97 [21:14<27:17, 30.32s/it]Batches:  45%|████▌     | 44/97 [21:45<26:46, 30.32s/it]Batches:  46%|████▋     | 45/97 [22:15<26:16, 30.32s/it]Batches:  47%|████▋     | 46/97 [22:45<25:46, 30.32s/it]Batches:  48%|████▊     | 47/97 [23:16<25:15, 30.31s/it]Batches:  49%|████▉     | 48/97 [23:46<24:45, 30.31s/it]Batches:  51%|█████     | 49/97 [24:16<24:15, 30.31s/it]Batches:  52%|█████▏    | 50/97 [24:47<23:44, 30.31s/it]Batches:  53%|█████▎    | 51/97 [25:17<23:14, 30.31s/it]Batches:  54%|█████▎    | 52/97 [25:47<22:43, 30.31s/it]Batches:  55%|█████▍    | 53/97 [26:17<22:13, 30.31s/it]Batches:  56%|█████▌    | 54/97 [26:48<21:43, 30.31s/it]Batches:  57%|█████▋    | 55/97 [27:18<21:12, 30.31s/it]Batches:  58%|█████▊    | 56/97 [27:46<20:09, 29.51s/it]Batches:  59%|█████▉    | 57/97 [28:16<19:50, 29.75s/it]Batches:  60%|█████▉    | 58/97 [28:44<18:55, 29.13s/it]Batches:  61%|██████    | 59/97 [29:14<18:40, 29.48s/it]Batches:  62%|██████▏   | 60/97 [29:44<18:13, 29.55s/it]Batches:  63%|██████▎   | 61/97 [30:03<15:54, 26.51s/it]Batches:  64%|██████▍   | 62/97 [30:18<13:26, 23.05s/it]Batches:  65%|██████▍   | 63/97 [30:30<11:08, 19.67s/it]Batches:  66%|██████▌   | 64/97 [30:41<09:26, 17.15s/it]Batches:  67%|██████▋   | 65/97 [30:50<07:53, 14.79s/it]Batches:  68%|██████▊   | 66/97 [31:00<06:49, 13.20s/it]Batches:  69%|██████▉   | 67/97 [31:08<05:48, 11.63s/it]Batches:  70%|███████   | 68/97 [31:15<05:01, 10.38s/it]Batches:  71%|███████   | 69/97 [31:23<04:23,  9.41s/it]Batches:  72%|███████▏  | 70/97 [31:28<03:42,  8.24s/it]Batches:  73%|███████▎  | 71/97 [31:34<03:14,  7.49s/it]Batches:  74%|███████▍  | 72/97 [31:38<02:45,  6.64s/it]Batches:  75%|███████▌  | 73/97 [31:43<02:26,  6.11s/it]Batches:  76%|███████▋  | 74/97 [31:47<02:07,  5.54s/it]Batches:  77%|███████▋  | 75/97 [31:51<01:51,  5.07s/it]Batches:  78%|███████▊  | 76/97 [31:55<01:37,  4.66s/it]Batches:  79%|███████▉  | 77/97 [31:59<01:25,  4.30s/it]Batches:  80%|████████  | 78/97 [32:02<01:18,  4.13s/it]Batches:  81%|████████▏ | 79/97 [32:06<01:13,  4.07s/it]Batches:  82%|████████▏ | 80/97 [32:10<01:05,  3.83s/it]Batches:  84%|████████▎ | 81/97 [32:13<00:58,  3.67s/it]Batches:  85%|████████▍ | 82/97 [32:16<00:51,  3.44s/it]Batches:  86%|████████▌ | 83/97 [32:18<00:45,  3.22s/it]Batches:  87%|████████▋ | 84/97 [32:21<00:39,  3.01s/it]Batches:  88%|████████▊ | 85/97 [32:24<00:34,  2.89s/it]Batches:  89%|████████▊ | 86/97 [32:26<00:30,  2.80s/it]Batches:  90%|████████▉ | 87/97 [32:29<00:27,  2.71s/it]Batches:  91%|█████████ | 88/97 [32:31<00:22,  2.54s/it]Batches:  92%|█████████▏| 89/97 [32:33<00:20,  2.53s/it]Batches:  93%|█████████▎| 90/97 [32:35<00:16,  2.38s/it]Batches:  94%|█████████▍| 91/97 [32:37<00:13,  2.24s/it]Batches:  95%|█████████▍| 92/97 [32:39<00:11,  2.23s/it]Batches:  96%|█████████▌| 93/97 [32:41<00:08,  2.16s/it]Batches:  97%|█████████▋| 94/97 [32:43<00:06,  2.07s/it]Batches:  98%|█████████▊| 95/97 [32:45<00:03,  1.93s/it]Batches:  99%|█████████▉| 96/97 [32:47<00:01,  1.95s/it]Batches: 100%|██████████| 97/97 [32:49<00:00,  1.83s/it]Batches: 100%|██████████| 97/97 [32:49<00:00, 20.30s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1974.79 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 1975.06 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.36, 'ndcg_at_3': 0.44178, 'ndcg_at_5': 0.4562, 'ndcg_at_10': 0.48402, 'ndcg_at_20': 0.50135, 'ndcg_at_100': 0.53127, 'ndcg_at_1000': 0.54818, 'map_at_1': 0.36, 'map_at_3': 0.42167, 'map_at_5': 0.42967, 'map_at_10': 0.44135, 'map_at_20': 0.44591, 'map_at_100': 0.45013, 'map_at_1000': 0.45073, 'recall_at_1': 0.36, 'recall_at_3': 0.5, 'recall_at_5': 0.535, 'recall_at_10': 0.62, 'recall_at_20': 0.69, 'recall_at_100': 0.85, 'recall_at_1000': 0.985, 'precision_at_1': 0.36, 'precision_at_3': 0.16667, 'precision_at_5': 0.107, 'precision_at_10': 0.062, 'precision_at_20': 0.0345, 'precision_at_100': 0.0085, 'precision_at_1000': 0.00099, 'mrr_at_1': 0.36, 'mrr_at_3': 0.4216666666666667, 'mrr_at_5': 0.4296666666666667, 'mrr_at_10': 0.4413511904761906, 'mrr_at_20': 0.44590807700211743, 'mrr_at_100': 0.450129543381387, 'mrr_at_1000': 0.45073324355439376, 'nauc_ndcg_at_1_max': np.float64(0.5840418831680049), 'nauc_ndcg_at_1_std': np.float64(-0.021833831942476276), 'nauc_ndcg_at_1_diff1': np.float64(0.7126436781609194), 'nauc_ndcg_at_3_max': np.float64(0.6004543836287595), 'nauc_ndcg_at_3_std': np.float64(0.047787735554177944), 'nauc_ndcg_at_3_diff1': np.float64(0.6506603473332017), 'nauc_ndcg_at_5_max': np.float64(0.6005997287841836), 'nauc_ndcg_at_5_std': np.float64(0.07005047365688216), 'nauc_ndcg_at_5_diff1': np.float64(0.6287749223122684), 'nauc_ndcg_at_10_max': np.float64(0.5982485402739869), 'nauc_ndcg_at_10_std': np.float64(0.06006582165943897), 'nauc_ndcg_at_10_diff1': np.float64(0.6293196340250062), 'nauc_ndcg_at_20_max': np.float64(0.5970582271477827), 'nauc_ndcg_at_20_std': np.float64(0.07622456371047974), 'nauc_ndcg_at_20_diff1': np.float64(0.6261813451342695), 'nauc_ndcg_at_100_max': np.float64(0.6037341341497577), 'nauc_ndcg_at_100_std': np.float64(0.09785768793288292), 'nauc_ndcg_at_100_diff1': np.float64(0.6360589988421134), 'nauc_ndcg_at_1000_max': np.float64(0.5998470404188347), 'nauc_ndcg_at_1000_std': np.float64(0.07410684021566737), 'nauc_ndcg_at_1000_diff1': np.float64(0.6432566916474228), 'nauc_map_at_1_max': np.float64(0.5840418831680049), 'nauc_map_at_1_std': np.float64(-0.021833831942476276), 'nauc_map_at_1_diff1': np.float64(0.7126436781609194), 'nauc_map_at_3_max': np.float64(0.5918378557726748), 'nauc_map_at_3_std': np.float64(0.027992687337536), 'nauc_map_at_3_diff1': np.float64(0.6640690747768079), 'nauc_map_at_5_max': np.float64(0.591985080836136), 'nauc_map_at_5_std': np.float64(0.040401896772712935), 'nauc_map_at_5_diff1': np.float64(0.6522396910722045), 'nauc_map_at_10_max': np.float64(0.5909253802982799), 'nauc_map_at_10_std': np.float64(0.036022144467421524), 'nauc_map_at_10_diff1': np.float64(0.652369406457342), 'nauc_map_at_20_max': np.float64(0.5908525887352375), 'nauc_map_at_20_std': np.float64(0.04020584504644928), 'nauc_map_at_20_diff1': np.float64(0.6520302323881799), 'nauc_map_at_100_max': np.float64(0.591719062921236), 'nauc_map_at_100_std': np.float64(0.042690974962164625), 'nauc_map_at_100_diff1': np.float64(0.6537378762654921), 'nauc_map_at_1000_max': np.float64(0.5915981156693542), 'nauc_map_at_1000_std': np.float64(0.04204665806066081), 'nauc_map_at_1000_diff1': np.float64(0.653999576097392), 'nauc_recall_at_1_max': np.float64(0.5840418831680049), 'nauc_recall_at_1_std': np.float64(-0.021833831942476276), 'nauc_recall_at_1_diff1': np.float64(0.7126436781609194), 'nauc_recall_at_3_max': np.float64(0.6275216522318453), 'nauc_recall_at_3_std': np.float64(0.10674217188540977), 'nauc_recall_at_3_diff1': np.float64(0.6122251832111921), 'nauc_recall_at_5_max': np.float64(0.6282966330640981), 'nauc_recall_at_5_std': np.float64(0.16318549585092318), 'nauc_recall_at_5_diff1': np.float64(0.5556584283947461), 'nauc_recall_at_10_max': np.float64(0.6234424514660182), 'nauc_recall_at_10_std': np.float64(0.13918715195520406), 'nauc_recall_at_10_diff1': np.float64(0.5518721348798571), 'nauc_recall_at_20_max': np.float64(0.6184366015838583), 'nauc_recall_at_20_std': np.float64(0.22843360318888178), 'nauc_recall_at_20_diff1': np.float64(0.5220822971233048), 'nauc_recall_at_100_max': np.float64(0.7116986657988936), 'nauc_recall_at_100_std': np.float64(0.5987146111291889), 'nauc_recall_at_100_diff1': np.float64(0.5412788805727307), 'nauc_recall_at_1000_max': np.float64(1.0), 'nauc_recall_at_1000_std': np.float64(1.0), 'nauc_recall_at_1000_diff1': np.float64(0.8078120136943671), 'nauc_precision_at_1_max': np.float64(0.5840418831680049), 'nauc_precision_at_1_std': np.float64(-0.021833831942476276), 'nauc_precision_at_1_diff1': np.float64(0.7126436781609194), 'nauc_precision_at_3_max': np.float64(0.6275216522318455), 'nauc_precision_at_3_std': np.float64(0.10674217188541009), 'nauc_precision_at_3_diff1': np.float64(0.6122251832111925), 'nauc_precision_at_5_max': np.float64(0.6282966330640979), 'nauc_precision_at_5_std': np.float64(0.16318549585092312), 'nauc_precision_at_5_diff1': np.float64(0.5556584283947462), 'nauc_precision_at_10_max': np.float64(0.6234424514660185), 'nauc_precision_at_10_std': np.float64(0.13918715195520429), 'nauc_precision_at_10_diff1': np.float64(0.5518721348798572), 'nauc_precision_at_20_max': np.float64(0.6184366015838579), 'nauc_precision_at_20_std': np.float64(0.22843360318888078), 'nauc_precision_at_20_diff1': np.float64(0.5220822971233046), 'nauc_precision_at_100_max': np.float64(0.7116986657988953), 'nauc_precision_at_100_std': np.float64(0.598714611129191), 'nauc_precision_at_100_diff1': np.float64(0.5412788805727321), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(0.8078120136943695), 'nauc_mrr_at_1_max': np.float64(0.5840418831680049), 'nauc_mrr_at_1_std': np.float64(-0.021833831942476276), 'nauc_mrr_at_1_diff1': np.float64(0.7126436781609194), 'nauc_mrr_at_3_max': np.float64(0.5918378557726748), 'nauc_mrr_at_3_std': np.float64(0.027992687337536), 'nauc_mrr_at_3_diff1': np.float64(0.6640690747768079), 'nauc_mrr_at_5_max': np.float64(0.591985080836136), 'nauc_mrr_at_5_std': np.float64(0.040401896772712935), 'nauc_mrr_at_5_diff1': np.float64(0.6522396910722045), 'nauc_mrr_at_10_max': np.float64(0.5909253802982799), 'nauc_mrr_at_10_std': np.float64(0.036022144467421524), 'nauc_mrr_at_10_diff1': np.float64(0.652369406457342), 'nauc_mrr_at_20_max': np.float64(0.5908525887352375), 'nauc_mrr_at_20_std': np.float64(0.04020584504644928), 'nauc_mrr_at_20_diff1': np.float64(0.6520302323881799), 'nauc_mrr_at_100_max': np.float64(0.591719062921236), 'nauc_mrr_at_100_std': np.float64(0.042690974962164625), 'nauc_mrr_at_100_diff1': np.float64(0.6537378762654921), 'nauc_mrr_at_1000_max': np.float64(0.5915981156693542), 'nauc_mrr_at_1000_std': np.float64(0.04204665806066081), 'nauc_mrr_at_1000_diff1': np.float64(0.653999576097392), 'main_score': 0.48402}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  50%|█████     | 2/4 [00:00<00:00,  9.80it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 14.53it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/97 [00:00<?, ?it/s]Batches:   1%|          | 1/97 [00:01<02:39,  1.66s/it]Batches:   2%|▏         | 2/97 [00:31<29:17, 18.49s/it]Batches:   3%|▎         | 3/97 [01:02<37:25, 23.89s/it]Batches:   4%|▍         | 4/97 [01:32<40:57, 26.43s/it]Batches:   5%|▌         | 5/97 [02:02<42:40, 27.83s/it]Batches:   6%|▌         | 6/97 [02:33<43:29, 28.68s/it]Batches:   7%|▋         | 7/97 [03:03<43:49, 29.22s/it]Batches:   8%|▊         | 8/97 [03:33<43:51, 29.57s/it]Batches:   9%|▉         | 9/97 [04:04<43:42, 29.81s/it]Batches:  10%|█         | 10/97 [04:34<43:26, 29.96s/it]Batches:  11%|█▏        | 11/97 [05:04<43:06, 30.07s/it]Batches:  12%|█▏        | 12/97 [05:35<42:42, 30.15s/it]Batches:  13%|█▎        | 13/97 [06:05<42:16, 30.20s/it]Batches:  14%|█▍        | 14/97 [06:35<41:49, 30.24s/it]Batches:  15%|█▌        | 15/97 [07:06<41:21, 30.26s/it]Batches:  16%|█▋        | 16/97 [07:36<40:52, 30.28s/it]Batches:  18%|█▊        | 17/97 [08:06<40:23, 30.29s/it]Batches:  19%|█▊        | 18/97 [08:37<39:54, 30.30s/it]Batches:  20%|█▉        | 19/97 [09:07<39:24, 30.31s/it]Batches:  21%|██        | 20/97 [09:37<38:54, 30.32s/it]Batches:  22%|██▏       | 21/97 [10:08<38:24, 30.32s/it]Batches:  23%|██▎       | 22/97 [10:38<37:54, 30.32s/it]Batches:  24%|██▎       | 23/97 [11:08<37:23, 30.32s/it]Batches:  25%|██▍       | 24/97 [11:39<36:53, 30.32s/it]Batches:  26%|██▌       | 25/97 [12:09<36:23, 30.32s/it]Batches:  27%|██▋       | 26/97 [12:39<35:53, 30.32s/it]Batches:  28%|██▊       | 27/97 [13:10<35:22, 30.33s/it]Batches:  29%|██▉       | 28/97 [13:40<34:52, 30.32s/it]Batches:  30%|██▉       | 29/97 [14:10<34:22, 30.32s/it]Batches:  31%|███       | 30/97 [14:41<33:51, 30.32s/it]Batches:  32%|███▏      | 31/97 [15:11<33:21, 30.33s/it]Batches:  33%|███▎      | 32/97 [15:41<32:51, 30.33s/it]Batches:  34%|███▍      | 33/97 [16:12<32:21, 30.33s/it]Batches:  35%|███▌      | 34/97 [16:42<31:50, 30.33s/it]Batches:  36%|███▌      | 35/97 [17:12<31:20, 30.33s/it]Batches:  37%|███▋      | 36/97 [17:42<30:50, 30.33s/it]Batches:  38%|███▊      | 37/97 [18:13<30:19, 30.33s/it]Batches:  39%|███▉      | 38/97 [18:43<29:49, 30.33s/it]Batches:  40%|████      | 39/97 [19:13<29:19, 30.33s/it]Batches:  41%|████      | 40/97 [19:44<28:48, 30.33s/it]Batches:  42%|████▏     | 41/97 [20:14<28:18, 30.33s/it]Batches:  43%|████▎     | 42/97 [20:44<27:47, 30.33s/it]Batches:  44%|████▍     | 43/97 [21:15<27:17, 30.32s/it]Batches:  45%|████▌     | 44/97 [21:45<26:47, 30.32s/it]Batches:  46%|████▋     | 45/97 [22:15<26:16, 30.32s/it]Batches:  47%|████▋     | 46/97 [22:46<25:46, 30.32s/it]Batches:  48%|████▊     | 47/97 [23:16<25:16, 30.32s/it]Batches:  49%|████▉     | 48/97 [23:46<24:45, 30.32s/it]Batches:  51%|█████     | 49/97 [24:17<24:15, 30.32s/it]Batches:  52%|█████▏    | 50/97 [24:47<23:45, 30.32s/it]Batches:  53%|█████▎    | 51/97 [25:17<23:14, 30.32s/it]Batches:  54%|█████▎    | 52/97 [25:48<22:44, 30.32s/it]Batches:  55%|█████▍    | 53/97 [26:18<22:14, 30.32s/it]Batches:  56%|█████▌    | 54/97 [26:48<21:43, 30.32s/it]Batches:  57%|█████▋    | 55/97 [27:19<21:13, 30.32s/it]Batches:  58%|█████▊    | 56/97 [27:46<20:10, 29.53s/it]Batches:  59%|█████▉    | 57/97 [28:17<19:50, 29.76s/it]Batches:  60%|█████▉    | 58/97 [28:44<18:56, 29.14s/it]Batches:  61%|██████    | 59/97 [29:15<18:40, 29.49s/it]Batches:  62%|██████▏   | 60/97 [29:44<18:13, 29.56s/it]Batches:  63%|██████▎   | 61/97 [30:04<15:54, 26.52s/it]Batches:  64%|██████▍   | 62/97 [30:19<13:27, 23.07s/it]Batches:  65%|██████▍   | 63/97 [30:31<11:09, 19.69s/it]Batches:  66%|██████▌   | 64/97 [30:42<09:26, 17.17s/it]Batches:  67%|██████▋   | 65/97 [30:51<07:53, 14.81s/it]Batches:  68%|██████▊   | 66/97 [31:01<06:49, 13.21s/it]Batches:  69%|██████▉   | 67/97 [31:09<05:49, 11.64s/it]Batches:  70%|███████   | 68/97 [31:16<05:01, 10.39s/it]Batches:  71%|███████   | 69/97 [31:23<04:23,  9.42s/it]Batches:  72%|███████▏  | 70/97 [31:29<03:42,  8.25s/it]Batches:  73%|███████▎  | 71/97 [31:35<03:14,  7.50s/it]Batches:  74%|███████▍  | 72/97 [31:39<02:46,  6.65s/it]Batches:  75%|███████▌  | 73/97 [31:44<02:26,  6.11s/it]Batches:  76%|███████▋  | 74/97 [31:48<02:07,  5.54s/it]Batches:  77%|███████▋  | 75/97 [31:52<01:51,  5.08s/it]Batches:  78%|███████▊  | 76/97 [31:56<01:37,  4.66s/it]Batches:  79%|███████▉  | 77/97 [31:59<01:26,  4.30s/it]Batches:  80%|████████  | 78/97 [32:03<01:18,  4.14s/it]Batches:  81%|████████▏ | 79/97 [32:07<01:13,  4.07s/it]Batches:  82%|████████▏ | 80/97 [32:10<01:05,  3.83s/it]Batches:  84%|████████▎ | 81/97 [32:14<00:58,  3.68s/it]Batches:  85%|████████▍ | 82/97 [32:17<00:51,  3.44s/it]Batches:  86%|████████▌ | 83/97 [32:19<00:45,  3.22s/it]Batches:  87%|████████▋ | 84/97 [32:22<00:39,  3.01s/it]Batches:  88%|████████▊ | 85/97 [32:24<00:34,  2.89s/it]Batches:  89%|████████▊ | 86/97 [32:27<00:30,  2.80s/it]Batches:  90%|████████▉ | 87/97 [32:29<00:27,  2.71s/it]Batches:  91%|█████████ | 88/97 [32:32<00:22,  2.54s/it]Batches:  92%|█████████▏| 89/97 [32:34<00:20,  2.53s/it]Batches:  93%|█████████▎| 90/97 [32:36<00:16,  2.38s/it]Batches:  94%|█████████▍| 91/97 [32:38<00:13,  2.24s/it]Batches:  95%|█████████▍| 92/97 [32:40<00:11,  2.23s/it]Batches:  96%|█████████▌| 93/97 [32:42<00:08,  2.16s/it]Batches:  97%|█████████▋| 94/97 [32:44<00:06,  2.08s/it]Batches:  98%|█████████▊| 95/97 [32:46<00:03,  1.94s/it]Batches:  99%|█████████▉| 96/97 [32:48<00:01,  1.95s/it]Batches: 100%|██████████| 97/97 [32:49<00:00,  1.84s/it]Batches: 100%|██████████| 97/97 [32:49<00:00, 20.31s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1974.95 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 1975.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.33, 'ndcg_at_3': 0.4269, 'ndcg_at_5': 0.44971, 'ndcg_at_10': 0.46733, 'ndcg_at_20': 0.48667, 'ndcg_at_100': 0.51055, 'ndcg_at_1000': 0.53145, 'map_at_1': 0.33, 'map_at_3': 0.40333, 'map_at_5': 0.41608, 'map_at_10': 0.42326, 'map_at_20': 0.42878, 'map_at_100': 0.43228, 'map_at_1000': 0.43308, 'recall_at_1': 0.33, 'recall_at_3': 0.495, 'recall_at_5': 0.55, 'recall_at_10': 0.605, 'recall_at_20': 0.68, 'recall_at_100': 0.805, 'recall_at_1000': 0.97, 'precision_at_1': 0.33, 'precision_at_3': 0.165, 'precision_at_5': 0.11, 'precision_at_10': 0.0605, 'precision_at_20': 0.034, 'precision_at_100': 0.00805, 'precision_at_1000': 0.00097, 'mrr_at_1': 0.33, 'mrr_at_3': 0.40333333333333327, 'mrr_at_5': 0.4160833333333334, 'mrr_at_10': 0.4232619047619048, 'mrr_at_20': 0.4287762510107712, 'mrr_at_100': 0.432279471134081, 'mrr_at_1000': 0.4330762455314873, 'nauc_ndcg_at_1_max': np.float64(0.6154957329818537), 'nauc_ndcg_at_1_std': np.float64(0.014005937878606113), 'nauc_ndcg_at_1_diff1': np.float64(0.7091105164356752), 'nauc_ndcg_at_3_max': np.float64(0.5722148672843138), 'nauc_ndcg_at_3_std': np.float64(0.007984550405491661), 'nauc_ndcg_at_3_diff1': np.float64(0.6164968584122404), 'nauc_ndcg_at_5_max': np.float64(0.5815707344595532), 'nauc_ndcg_at_5_std': np.float64(0.032085748538331245), 'nauc_ndcg_at_5_diff1': np.float64(0.6147514584683341), 'nauc_ndcg_at_10_max': np.float64(0.594255714519112), 'nauc_ndcg_at_10_std': np.float64(0.05460105589744826), 'nauc_ndcg_at_10_diff1': np.float64(0.6233539007043118), 'nauc_ndcg_at_20_max': np.float64(0.5967141800825231), 'nauc_ndcg_at_20_std': np.float64(0.05829972851360095), 'nauc_ndcg_at_20_diff1': np.float64(0.6135707800197637), 'nauc_ndcg_at_100_max': np.float64(0.6039284709620057), 'nauc_ndcg_at_100_std': np.float64(0.08347014870182251), 'nauc_ndcg_at_100_diff1': np.float64(0.6080334683443672), 'nauc_ndcg_at_1000_max': np.float64(0.599281715322545), 'nauc_ndcg_at_1000_std': np.float64(0.06719272824721652), 'nauc_ndcg_at_1000_diff1': np.float64(0.6225573328293726), 'nauc_map_at_1_max': np.float64(0.6154957329818537), 'nauc_map_at_1_std': np.float64(0.014005937878606113), 'nauc_map_at_1_diff1': np.float64(0.7091105164356752), 'nauc_map_at_3_max': np.float64(0.5827813691071001), 'nauc_map_at_3_std': np.float64(0.008878591452145033), 'nauc_map_at_3_diff1': np.float64(0.6404104137741969), 'nauc_map_at_5_max': np.float64(0.5881739870325576), 'nauc_map_at_5_std': np.float64(0.021291218705272164), 'nauc_map_at_5_diff1': np.float64(0.6400465541544528), 'nauc_map_at_10_max': np.float64(0.5938053519033123), 'nauc_map_at_10_std': np.float64(0.031333520693003776), 'nauc_map_at_10_diff1': np.float64(0.6437977226295699), 'nauc_map_at_20_max': np.float64(0.5939793225373083), 'nauc_map_at_20_std': np.float64(0.03190726201177065), 'nauc_map_at_20_diff1': np.float64(0.6414751638548382), 'nauc_map_at_100_max': np.float64(0.5947016987665), 'nauc_map_at_100_std': np.float64(0.03519683850581178), 'nauc_map_at_100_diff1': np.float64(0.6405785551672617), 'nauc_map_at_1000_max': np.float64(0.5946002721149415), 'nauc_map_at_1000_std': np.float64(0.03492754217391834), 'nauc_map_at_1000_diff1': np.float64(0.6409752471277966), 'nauc_recall_at_1_max': np.float64(0.6154957329818537), 'nauc_recall_at_1_std': np.float64(0.014005937878606113), 'nauc_recall_at_1_diff1': np.float64(0.7091105164356752), 'nauc_recall_at_3_max': np.float64(0.5415694020470461), 'nauc_recall_at_3_std': np.float64(0.005626384150356102), 'nauc_recall_at_3_diff1': np.float64(0.5466105358366087), 'nauc_recall_at_5_max': np.float64(0.5628308642842097), 'nauc_recall_at_5_std': np.float64(0.06966931124060896), 'nauc_recall_at_5_diff1': np.float64(0.5370287158604221), 'nauc_recall_at_10_max': np.float64(0.6014014808381932), 'nauc_recall_at_10_std': np.float64(0.141413309576037), 'nauc_recall_at_10_diff1': np.float64(0.5601805754156904), 'nauc_recall_at_20_max': np.float64(0.6184524220855504), 'nauc_recall_at_20_std': np.float64(0.17396862690898954), 'nauc_recall_at_20_diff1': np.float64(0.5030837537143243), 'nauc_recall_at_100_max': np.float64(0.6985987880027614), 'nauc_recall_at_100_std': np.float64(0.45224884297731915), 'nauc_recall_at_100_diff1': np.float64(0.40935590273338546), 'nauc_recall_at_1000_max': np.float64(0.7833022097727981), 'nauc_recall_at_1000_std': np.float64(0.8712262682850952), 'nauc_recall_at_1000_diff1': np.float64(0.5799097416744453), 'nauc_precision_at_1_max': np.float64(0.6154957329818537), 'nauc_precision_at_1_std': np.float64(0.014005937878606113), 'nauc_precision_at_1_diff1': np.float64(0.7091105164356752), 'nauc_precision_at_3_max': np.float64(0.541569402047046), 'nauc_precision_at_3_std': np.float64(0.005626384150355919), 'nauc_precision_at_3_diff1': np.float64(0.5466105358366083), 'nauc_precision_at_5_max': np.float64(0.5628308642842097), 'nauc_precision_at_5_std': np.float64(0.06966931124060934), 'nauc_precision_at_5_diff1': np.float64(0.5370287158604224), 'nauc_precision_at_10_max': np.float64(0.6014014808381931), 'nauc_precision_at_10_std': np.float64(0.14141330957603684), 'nauc_precision_at_10_diff1': np.float64(0.5601805754156903), 'nauc_precision_at_20_max': np.float64(0.6184524220855502), 'nauc_precision_at_20_std': np.float64(0.1739686269089894), 'nauc_precision_at_20_diff1': np.float64(0.5030837537143249), 'nauc_precision_at_100_max': np.float64(0.6985987880027615), 'nauc_precision_at_100_std': np.float64(0.4522488429773202), 'nauc_precision_at_100_diff1': np.float64(0.40935590273338596), 'nauc_precision_at_1000_max': np.float64(0.7833022097727956), 'nauc_precision_at_1000_std': np.float64(0.8712262682850928), 'nauc_precision_at_1000_diff1': np.float64(0.5799097416744464), 'nauc_mrr_at_1_max': np.float64(0.6154957329818537), 'nauc_mrr_at_1_std': np.float64(0.014005937878606113), 'nauc_mrr_at_1_diff1': np.float64(0.7091105164356752), 'nauc_mrr_at_3_max': np.float64(0.5827813691071001), 'nauc_mrr_at_3_std': np.float64(0.008878591452145033), 'nauc_mrr_at_3_diff1': np.float64(0.6404104137741969), 'nauc_mrr_at_5_max': np.float64(0.5881739870325576), 'nauc_mrr_at_5_std': np.float64(0.021291218705272164), 'nauc_mrr_at_5_diff1': np.float64(0.6400465541544528), 'nauc_mrr_at_10_max': np.float64(0.5938053519033123), 'nauc_mrr_at_10_std': np.float64(0.031333520693003776), 'nauc_mrr_at_10_diff1': np.float64(0.6437977226295699), 'nauc_mrr_at_20_max': np.float64(0.5939793225373083), 'nauc_mrr_at_20_std': np.float64(0.03190726201177065), 'nauc_mrr_at_20_diff1': np.float64(0.6414751638548382), 'nauc_mrr_at_100_max': np.float64(0.5947016987665), 'nauc_mrr_at_100_std': np.float64(0.03519683850581178), 'nauc_mrr_at_100_diff1': np.float64(0.6405785551672617), 'nauc_mrr_at_1000_max': np.float64(0.5946002721149415), 'nauc_mrr_at_1000_std': np.float64(0.03492754217391834), 'nauc_mrr_at_1000_diff1': np.float64(0.6409752471277966), 'main_score': 0.46733}}



==================================================
Running model: jinaai/jina-embeddings-v3
--------------------------------------------------
WARNING:mteb.models.jina_models:Using flash_attn for jina-embeddings-v3 models is recommended. Please install it with `pip install mteb[flash_attention]`.Fallback to native implementation.
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: jinaai/jina-embeddings-v3
WARNING:mteb.models.jina_models:Using flash_attn for jina-embeddings-v3 models is recommended. Please install it with `pip install mteb[flash_attention]`.Fallback to native implementation.
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: jinaai/jina-embeddings-v3
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.
INFO:sentence_transformers.SentenceTransformer:5 prompts are loaded, with the keys: ['retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching']
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'Retrieval-query': 'retrieval.query', 'Retrieval-passage': 'retrieval.passage', 'Clustering': 'separation', 'Classification': 'classification', 'STS': 'text-matching', 'PairClassification': 'classification', 'BitextMining': 'text-matching', 'MultilabelClassification': 'classification', 'Reranking': 'separation', 'Summarization': 'text-matching'}
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
##### attention 적용 모델 로딩 실패 --> attention 적용 없이 재시도
XLMRobertaLoRA does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet. Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation="eager"` meanwhile. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="eager")`
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / jinaai/jina-embeddings-v3 on GPU 0 in process Process-15
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.jina_models:Encoding 592 sentences.
Batches:   0%|          | 0/74 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 1/74 [00:00<01:01,  1.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 3/74 [00:01<00:19,  3.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 5/74 [00:01<00:11,  5.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 7/74 [00:01<00:08,  7.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 9/74 [00:01<00:06,  9.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 11/74 [00:01<00:05, 11.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 13/74 [00:01<00:05, 12.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 15/74 [00:01<00:04, 12.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 17/74 [00:01<00:04, 13.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 19/74 [00:02<00:03, 14.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 21/74 [00:02<00:03, 14.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 23/74 [00:02<00:03, 14.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 25/74 [00:02<00:03, 14.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 27/74 [00:02<00:03, 14.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 29/74 [00:02<00:03, 14.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 31/74 [00:02<00:02, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 33/74 [00:02<00:02, 14.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 35/74 [00:03<00:02, 14.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 37/74 [00:03<00:02, 15.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 39/74 [00:03<00:02, 14.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 41/74 [00:03<00:02, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 43/74 [00:03<00:02, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 45/74 [00:03<00:01, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 47/74 [00:03<00:01, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 49/74 [00:04<00:01, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 51/74 [00:04<00:01, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 53/74 [00:04<00:01, 14.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 55/74 [00:04<00:01, 15.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 57/74 [00:04<00:01, 14.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 59/74 [00:04<00:01, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 61/74 [00:04<00:00, 15.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 63/74 [00:04<00:00, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 65/74 [00:05<00:00, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 67/74 [00:05<00:00, 15.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 69/74 [00:05<00:00, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 71/74 [00:05<00:00, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 73/74 [00:05<00:00, 15.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 74/74 [00:05<00:00, 12.98it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.jina_models:Encoding 9251 sentences.
Batches:   0%|          | 0/1157 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 1/1157 [00:01<26:30,  1.38s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 2/1157 [00:02<18:18,  1.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 3/1157 [00:02<14:00,  1.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 4/1157 [00:02<11:44,  1.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 5/1157 [00:03<10:16,  1.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 6/1157 [00:03<08:23,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 7/1157 [00:03<07:05,  2.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 8/1157 [00:04<06:08,  3.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 9/1157 [00:04<05:22,  3.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 10/1157 [00:04<04:49,  3.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 11/1157 [00:04<04:28,  4.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 12/1157 [00:04<04:06,  4.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 13/1157 [00:04<03:42,  5.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 14/1157 [00:05<03:27,  5.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 15/1157 [00:05<03:15,  5.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 16/1157 [00:05<03:05,  6.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 17/1157 [00:05<02:56,  6.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 18/1157 [00:05<02:51,  6.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 19/1157 [00:05<02:46,  6.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 20/1157 [00:05<02:40,  7.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 21/1157 [00:06<02:34,  7.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 22/1157 [00:06<02:33,  7.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 23/1157 [00:06<02:31,  7.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 24/1157 [00:06<02:30,  7.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 25/1157 [00:06<02:29,  7.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 26/1157 [00:06<02:23,  7.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 27/1157 [00:06<02:23,  7.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 28/1157 [00:06<02:21,  7.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 29/1157 [00:07<02:19,  8.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 30/1157 [00:07<02:16,  8.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 31/1157 [00:07<02:13,  8.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 32/1157 [00:07<02:14,  8.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 33/1157 [00:07<02:12,  8.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 34/1157 [00:07<02:10,  8.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 35/1157 [00:07<02:09,  8.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 36/1157 [00:07<02:08,  8.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 37/1157 [00:07<02:06,  8.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 38/1157 [00:08<02:04,  8.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 39/1157 [00:08<02:03,  9.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 40/1157 [00:08<02:05,  8.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 41/1157 [00:08<02:05,  8.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 42/1157 [00:08<02:04,  8.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 43/1157 [00:08<02:04,  8.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 44/1157 [00:08<02:02,  9.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 45/1157 [00:08<02:00,  9.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 46/1157 [00:08<02:03,  9.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 47/1157 [00:09<02:00,  9.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 48/1157 [00:09<01:59,  9.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 49/1157 [00:09<01:59,  9.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 50/1157 [00:09<02:03,  8.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 51/1157 [00:09<02:01,  9.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 52/1157 [00:09<02:00,  9.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 53/1157 [00:09<01:58,  9.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 54/1157 [00:09<01:56,  9.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 55/1157 [00:09<01:57,  9.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 56/1157 [00:10<01:56,  9.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 57/1157 [00:10<01:54,  9.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 58/1157 [00:10<01:56,  9.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 60/1157 [00:10<01:53,  9.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 62/1157 [00:10<01:51,  9.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 63/1157 [00:10<01:51,  9.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 64/1157 [00:10<01:52,  9.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 66/1157 [00:11<01:51,  9.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 67/1157 [00:11<01:51,  9.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 69/1157 [00:11<01:48, 10.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 70/1157 [00:11<01:48, 10.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 71/1157 [00:11<01:48,  9.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 73/1157 [00:11<01:48, 10.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 74/1157 [00:11<01:48,  9.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 76/1157 [00:12<01:46, 10.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 78/1157 [00:12<01:45, 10.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 80/1157 [00:12<01:44, 10.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 82/1157 [00:12<01:43, 10.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 84/1157 [00:12<01:43, 10.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 86/1157 [00:12<01:44, 10.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 88/1157 [00:13<01:43, 10.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 90/1157 [00:13<01:43, 10.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 92/1157 [00:13<01:42, 10.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 94/1157 [00:13<01:42, 10.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 96/1157 [00:13<01:44, 10.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 98/1157 [00:14<01:43, 10.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▊         | 100/1157 [00:14<01:45, 10.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 102/1157 [00:14<01:43, 10.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 104/1157 [00:14<01:39, 10.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 106/1157 [00:14<01:38, 10.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 108/1157 [00:15<01:38, 10.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 110/1157 [00:15<01:35, 11.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 112/1157 [00:15<01:37, 10.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 114/1157 [00:15<01:37, 10.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 116/1157 [00:15<01:35, 10.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 118/1157 [00:15<01:32, 11.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 120/1157 [00:16<01:31, 11.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 122/1157 [00:16<01:31, 11.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 124/1157 [00:16<01:30, 11.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 126/1157 [00:16<01:28, 11.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 128/1157 [00:16<01:29, 11.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 130/1157 [00:17<01:32, 11.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█▏        | 132/1157 [00:17<01:30, 11.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 134/1157 [00:17<01:31, 11.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 136/1157 [00:17<01:30, 11.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 138/1157 [00:17<01:30, 11.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 140/1157 [00:17<01:30, 11.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 142/1157 [00:18<01:28, 11.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 144/1157 [00:18<01:27, 11.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 146/1157 [00:18<01:28, 11.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 148/1157 [00:18<01:27, 11.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 150/1157 [00:18<01:26, 11.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 152/1157 [00:18<01:26, 11.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 154/1157 [00:19<01:25, 11.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 156/1157 [00:19<01:25, 11.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▎        | 158/1157 [00:19<01:24, 11.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 160/1157 [00:19<01:25, 11.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 162/1157 [00:19<01:24, 11.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 164/1157 [00:19<01:23, 11.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 166/1157 [00:20<01:25, 11.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 168/1157 [00:20<01:24, 11.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 170/1157 [00:20<01:23, 11.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 172/1157 [00:20<01:22, 11.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 174/1157 [00:20<01:22, 11.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 176/1157 [00:20<01:21, 12.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 178/1157 [00:21<01:21, 11.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 180/1157 [00:21<01:19, 12.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 182/1157 [00:21<01:19, 12.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 184/1157 [00:21<01:19, 12.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 186/1157 [00:21<01:18, 12.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 188/1157 [00:21<01:18, 12.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 190/1157 [00:22<01:17, 12.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 192/1157 [00:22<01:17, 12.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 194/1157 [00:22<01:16, 12.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 196/1157 [00:22<01:17, 12.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 198/1157 [00:22<01:16, 12.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 200/1157 [00:22<01:16, 12.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 202/1157 [00:23<01:15, 12.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 204/1157 [00:23<01:17, 12.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 206/1157 [00:23<01:16, 12.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 208/1157 [00:23<01:16, 12.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 210/1157 [00:23<01:17, 12.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 212/1157 [00:23<01:16, 12.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 214/1157 [00:24<01:16, 12.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▊        | 216/1157 [00:24<01:15, 12.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 218/1157 [00:24<01:14, 12.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 220/1157 [00:24<01:15, 12.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 222/1157 [00:24<01:14, 12.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 224/1157 [00:24<01:13, 12.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 226/1157 [00:24<01:13, 12.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 228/1157 [00:25<01:13, 12.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 230/1157 [00:25<01:12, 12.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 232/1157 [00:25<01:11, 12.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 234/1157 [00:25<01:11, 12.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 236/1157 [00:25<01:11, 12.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 238/1157 [00:25<01:11, 12.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 240/1157 [00:26<01:11, 12.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 242/1157 [00:26<01:10, 12.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 244/1157 [00:26<01:10, 12.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 246/1157 [00:26<01:11, 12.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 248/1157 [00:26<01:10, 12.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 250/1157 [00:26<01:10, 12.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 252/1157 [00:26<01:09, 13.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 254/1157 [00:27<01:09, 13.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 256/1157 [00:27<01:08, 13.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 258/1157 [00:27<01:08, 13.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 260/1157 [00:27<01:10, 12.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 262/1157 [00:27<01:09, 12.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 264/1157 [00:27<01:08, 12.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 266/1157 [00:28<01:08, 13.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 268/1157 [00:28<01:07, 13.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 270/1157 [00:28<01:07, 13.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 272/1157 [00:28<01:07, 13.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 274/1157 [00:28<01:06, 13.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 276/1157 [00:28<01:07, 13.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 278/1157 [00:28<01:07, 13.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 280/1157 [00:29<01:06, 13.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 282/1157 [00:29<01:06, 13.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 284/1157 [00:29<01:05, 13.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 286/1157 [00:29<01:04, 13.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 288/1157 [00:29<01:05, 13.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 290/1157 [00:29<01:04, 13.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 292/1157 [00:30<01:05, 13.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 294/1157 [00:30<01:04, 13.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 296/1157 [00:30<01:05, 13.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 298/1157 [00:30<01:04, 13.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 300/1157 [00:30<01:04, 13.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 302/1157 [00:30<01:03, 13.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 304/1157 [00:30<01:04, 13.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 306/1157 [00:31<01:04, 13.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 308/1157 [00:31<01:03, 13.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 310/1157 [00:31<01:03, 13.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 312/1157 [00:31<01:03, 13.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 314/1157 [00:31<01:01, 13.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 316/1157 [00:31<01:01, 13.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 318/1157 [00:31<01:01, 13.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 320/1157 [00:32<01:01, 13.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 322/1157 [00:32<01:00, 13.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 324/1157 [00:32<01:01, 13.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 326/1157 [00:32<01:01, 13.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 328/1157 [00:32<01:01, 13.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 330/1157 [00:32<01:01, 13.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 332/1157 [00:33<01:02, 13.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 334/1157 [00:33<01:01, 13.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 336/1157 [00:33<01:01, 13.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 338/1157 [00:33<01:00, 13.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 340/1157 [00:33<01:01, 13.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 342/1157 [00:33<01:00, 13.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 344/1157 [00:33<01:01, 13.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 346/1157 [00:34<01:00, 13.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 348/1157 [00:34<01:00, 13.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 350/1157 [00:34<00:59, 13.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 352/1157 [00:34<00:58, 13.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 354/1157 [00:34<00:58, 13.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 356/1157 [00:34<00:57, 13.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 358/1157 [00:34<00:56, 14.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 360/1157 [00:35<00:56, 14.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 362/1157 [00:35<00:57, 13.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 364/1157 [00:35<00:56, 13.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 366/1157 [00:35<00:56, 14.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 368/1157 [00:35<00:57, 13.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 370/1157 [00:35<00:57, 13.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 372/1157 [00:35<00:57, 13.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 374/1157 [00:36<00:56, 13.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 376/1157 [00:36<00:55, 14.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 378/1157 [00:36<00:55, 14.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 380/1157 [00:36<00:54, 14.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 382/1157 [00:36<00:54, 14.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 384/1157 [00:36<00:54, 14.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 386/1157 [00:36<00:54, 14.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 388/1157 [00:37<00:53, 14.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 390/1157 [00:37<00:52, 14.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 392/1157 [00:37<00:52, 14.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 394/1157 [00:37<00:52, 14.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 396/1157 [00:37<00:53, 14.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 398/1157 [00:37<00:52, 14.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 400/1157 [00:37<00:52, 14.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 402/1157 [00:38<00:52, 14.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 404/1157 [00:38<00:52, 14.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 406/1157 [00:38<00:53, 14.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 408/1157 [00:38<00:52, 14.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 410/1157 [00:38<00:52, 14.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 412/1157 [00:38<00:51, 14.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 414/1157 [00:38<00:51, 14.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 416/1157 [00:38<00:51, 14.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 418/1157 [00:39<00:51, 14.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 420/1157 [00:39<00:51, 14.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 422/1157 [00:39<00:50, 14.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 424/1157 [00:39<00:50, 14.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 426/1157 [00:39<00:50, 14.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 428/1157 [00:39<00:50, 14.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 430/1157 [00:39<00:49, 14.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 432/1157 [00:40<00:49, 14.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 434/1157 [00:40<00:48, 14.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 436/1157 [00:40<00:48, 14.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 438/1157 [00:40<00:50, 14.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 440/1157 [00:40<00:49, 14.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 442/1157 [00:40<00:49, 14.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 444/1157 [00:40<00:48, 14.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 446/1157 [00:41<00:48, 14.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 448/1157 [00:41<00:48, 14.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 450/1157 [00:41<00:48, 14.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 452/1157 [00:41<00:47, 14.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 454/1157 [00:41<00:48, 14.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 456/1157 [00:41<00:48, 14.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 458/1157 [00:41<00:47, 14.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 460/1157 [00:42<00:47, 14.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 462/1157 [00:42<00:47, 14.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 464/1157 [00:42<00:46, 14.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 466/1157 [00:42<00:46, 14.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 468/1157 [00:42<00:46, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 470/1157 [00:42<00:46, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 472/1157 [00:42<00:46, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 474/1157 [00:42<00:46, 14.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 476/1157 [00:43<00:46, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 478/1157 [00:43<00:45, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 480/1157 [00:43<00:45, 14.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 482/1157 [00:43<00:46, 14.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 484/1157 [00:43<00:45, 14.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 486/1157 [00:43<00:45, 14.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 488/1157 [00:43<00:45, 14.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 490/1157 [00:44<00:45, 14.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 492/1157 [00:44<00:45, 14.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 494/1157 [00:44<00:45, 14.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 496/1157 [00:44<00:44, 14.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 498/1157 [00:44<00:44, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 500/1157 [00:44<00:44, 14.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 502/1157 [00:44<00:44, 14.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 504/1157 [00:44<00:43, 14.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 506/1157 [00:45<00:43, 14.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 508/1157 [00:45<00:43, 14.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 510/1157 [00:45<00:43, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 512/1157 [00:45<00:43, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 514/1157 [00:45<00:42, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 516/1157 [00:45<00:43, 14.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 518/1157 [00:45<00:43, 14.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 520/1157 [00:46<00:43, 14.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 522/1157 [00:46<00:43, 14.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 524/1157 [00:46<00:43, 14.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 526/1157 [00:46<00:42, 14.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 528/1157 [00:46<00:42, 14.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 530/1157 [00:46<00:41, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 532/1157 [00:46<00:41, 15.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 534/1157 [00:47<00:41, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 536/1157 [00:47<00:41, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 538/1157 [00:47<00:41, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 540/1157 [00:47<00:41, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 542/1157 [00:47<00:41, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 544/1157 [00:47<00:41, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 546/1157 [00:47<00:40, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 548/1157 [00:47<00:40, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 550/1157 [00:48<00:40, 14.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 552/1157 [00:48<00:40, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 554/1157 [00:48<00:40, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 556/1157 [00:48<00:40, 14.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 558/1157 [00:48<00:40, 14.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 560/1157 [00:48<00:39, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 562/1157 [00:48<00:39, 15.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 564/1157 [00:49<00:39, 15.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 566/1157 [00:49<00:39, 15.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 568/1157 [00:49<00:38, 15.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 570/1157 [00:49<00:38, 15.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 572/1157 [00:49<00:38, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 574/1157 [00:49<00:38, 15.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 576/1157 [00:49<00:38, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 578/1157 [00:49<00:38, 15.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 580/1157 [00:50<00:38, 15.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 582/1157 [00:50<00:38, 15.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 584/1157 [00:50<00:38, 15.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 586/1157 [00:50<00:37, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 588/1157 [00:50<00:38, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 590/1157 [00:50<00:37, 15.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 592/1157 [00:50<00:37, 14.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 594/1157 [00:51<00:37, 14.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 596/1157 [00:51<00:37, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 598/1157 [00:51<00:37, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 600/1157 [00:51<00:37, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 602/1157 [00:51<00:37, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 604/1157 [00:51<00:36, 14.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 606/1157 [00:51<00:36, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 608/1157 [00:51<00:36, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 610/1157 [00:52<00:36, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 612/1157 [00:52<00:36, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 614/1157 [00:52<00:36, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 616/1157 [00:52<00:35, 15.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 618/1157 [00:52<00:36, 14.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 620/1157 [00:52<00:36, 14.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 622/1157 [00:52<00:35, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 624/1157 [00:52<00:35, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 626/1157 [00:53<00:35, 15.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 628/1157 [00:53<00:34, 15.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 630/1157 [00:53<00:35, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 632/1157 [00:53<00:35, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 634/1157 [00:53<00:34, 15.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 636/1157 [00:53<00:34, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 638/1157 [00:53<00:34, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 640/1157 [00:54<00:34, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 642/1157 [00:54<00:34, 14.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 644/1157 [00:54<00:34, 15.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 646/1157 [00:54<00:33, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 648/1157 [00:54<00:33, 15.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 650/1157 [00:54<00:33, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 652/1157 [00:54<00:33, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 654/1157 [00:54<00:33, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 656/1157 [00:55<00:33, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 658/1157 [00:55<00:32, 15.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 660/1157 [00:55<00:33, 14.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 662/1157 [00:55<00:32, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 664/1157 [00:55<00:32, 15.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 666/1157 [00:55<00:32, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 668/1157 [00:55<00:32, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 670/1157 [00:56<00:32, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 672/1157 [00:56<00:32, 14.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 674/1157 [00:56<00:32, 14.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 676/1157 [00:56<00:31, 15.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 678/1157 [00:56<00:32, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 680/1157 [00:56<00:31, 14.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 682/1157 [00:56<00:31, 15.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 684/1157 [00:56<00:31, 14.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 686/1157 [00:57<00:31, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 688/1157 [00:57<00:30, 15.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 690/1157 [00:57<00:31, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 692/1157 [00:57<00:30, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 694/1157 [00:57<00:30, 15.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 696/1157 [00:57<00:30, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 698/1157 [00:57<00:30, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 700/1157 [00:58<00:30, 15.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 702/1157 [00:58<00:30, 15.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 704/1157 [00:58<00:29, 15.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 706/1157 [00:58<00:29, 15.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 708/1157 [00:58<00:29, 15.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████▏   | 710/1157 [00:58<00:28, 15.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 712/1157 [00:58<00:28, 15.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 714/1157 [00:58<00:28, 15.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 716/1157 [00:59<00:28, 15.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 718/1157 [00:59<00:28, 15.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 720/1157 [00:59<00:28, 15.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 722/1157 [00:59<00:27, 15.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 724/1157 [00:59<00:27, 15.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 726/1157 [00:59<00:27, 15.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 728/1157 [00:59<00:27, 15.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 730/1157 [00:59<00:27, 15.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 732/1157 [01:00<00:26, 15.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 734/1157 [01:00<00:26, 15.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 736/1157 [01:00<00:26, 15.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 738/1157 [01:00<00:27, 15.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 740/1157 [01:00<00:27, 15.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 742/1157 [01:00<00:26, 15.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 744/1157 [01:00<00:27, 15.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 746/1157 [01:01<00:27, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 748/1157 [01:01<00:26, 15.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 750/1157 [01:01<00:26, 15.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 752/1157 [01:01<00:25, 15.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 754/1157 [01:01<00:25, 15.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 756/1157 [01:01<00:25, 15.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 758/1157 [01:01<00:25, 15.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 760/1157 [01:01<00:25, 15.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 762/1157 [01:02<00:25, 15.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 764/1157 [01:02<00:25, 15.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 766/1157 [01:02<00:25, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▋   | 768/1157 [01:02<00:25, 15.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 770/1157 [01:02<00:25, 15.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 772/1157 [01:02<00:24, 15.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 774/1157 [01:02<00:24, 15.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 776/1157 [01:02<00:24, 15.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 778/1157 [01:03<00:24, 15.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 780/1157 [01:03<00:25, 14.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 782/1157 [01:03<00:25, 14.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 784/1157 [01:03<00:26, 14.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 786/1157 [01:03<00:26, 14.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 788/1157 [01:03<00:25, 14.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 790/1157 [01:03<00:25, 14.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 792/1157 [01:04<00:24, 14.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 794/1157 [01:04<00:23, 15.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 796/1157 [01:04<00:23, 15.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 798/1157 [01:04<00:23, 15.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 800/1157 [01:04<00:22, 15.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 802/1157 [01:04<00:22, 15.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 804/1157 [01:04<00:22, 15.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 806/1157 [01:04<00:22, 15.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 808/1157 [01:05<00:22, 15.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 810/1157 [01:05<00:22, 15.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 812/1157 [01:05<00:22, 15.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 814/1157 [01:05<00:21, 15.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 816/1157 [01:05<00:21, 15.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 818/1157 [01:05<00:21, 15.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 820/1157 [01:05<00:21, 15.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 822/1157 [01:05<00:20, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 824/1157 [01:06<00:20, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 826/1157 [01:06<00:20, 15.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 828/1157 [01:06<00:20, 15.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 830/1157 [01:06<00:20, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 832/1157 [01:06<00:20, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 834/1157 [01:06<00:20, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 836/1157 [01:06<00:20, 16.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 838/1157 [01:06<00:19, 16.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 840/1157 [01:07<00:19, 16.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 842/1157 [01:07<00:19, 15.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 844/1157 [01:07<00:19, 15.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 846/1157 [01:07<00:19, 15.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 848/1157 [01:07<00:19, 15.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 850/1157 [01:07<00:19, 15.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▎  | 852/1157 [01:07<00:19, 16.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 854/1157 [01:07<00:18, 16.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 856/1157 [01:08<00:18, 16.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 858/1157 [01:08<00:18, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 860/1157 [01:08<00:18, 16.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 862/1157 [01:08<00:18, 16.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 864/1157 [01:08<00:18, 16.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 866/1157 [01:08<00:18, 15.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 868/1157 [01:08<00:18, 16.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 870/1157 [01:08<00:17, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 872/1157 [01:09<00:17, 16.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 874/1157 [01:09<00:17, 15.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 876/1157 [01:09<00:17, 15.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 878/1157 [01:09<00:17, 16.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 880/1157 [01:09<00:17, 16.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 882/1157 [01:09<00:17, 15.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▋  | 884/1157 [01:09<00:17, 16.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 886/1157 [01:09<00:16, 16.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 888/1157 [01:10<00:16, 16.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 890/1157 [01:10<00:16, 15.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 892/1157 [01:10<00:16, 15.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 894/1157 [01:10<00:16, 15.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 896/1157 [01:10<00:16, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 898/1157 [01:10<00:16, 15.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 900/1157 [01:10<00:16, 15.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 902/1157 [01:10<00:15, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 904/1157 [01:11<00:15, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 906/1157 [01:11<00:15, 15.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 908/1157 [01:11<00:15, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 910/1157 [01:11<00:15, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 912/1157 [01:11<00:15, 16.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 914/1157 [01:11<00:15, 15.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 916/1157 [01:11<00:15, 16.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 918/1157 [01:11<00:14, 16.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 920/1157 [01:12<00:14, 16.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 922/1157 [01:12<00:14, 15.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 924/1157 [01:12<00:14, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 926/1157 [01:12<00:14, 16.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 928/1157 [01:12<00:14, 16.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 930/1157 [01:12<00:14, 15.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 932/1157 [01:12<00:14, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 934/1157 [01:12<00:13, 16.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 936/1157 [01:13<00:13, 16.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 938/1157 [01:13<00:13, 15.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 940/1157 [01:13<00:13, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 942/1157 [01:13<00:13, 16.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 944/1157 [01:13<00:13, 16.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 946/1157 [01:13<00:12, 16.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 948/1157 [01:13<00:12, 16.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 950/1157 [01:13<00:12, 16.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 952/1157 [01:14<00:12, 16.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 954/1157 [01:14<00:12, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 956/1157 [01:14<00:12, 16.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 958/1157 [01:14<00:12, 16.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 960/1157 [01:14<00:12, 15.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 962/1157 [01:14<00:12, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 964/1157 [01:14<00:11, 16.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 966/1157 [01:14<00:11, 16.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 968/1157 [01:15<00:11, 15.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 970/1157 [01:15<00:11, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 972/1157 [01:15<00:11, 16.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 974/1157 [01:15<00:11, 16.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 976/1157 [01:15<00:11, 16.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 978/1157 [01:15<00:10, 16.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 980/1157 [01:15<00:11, 16.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 982/1157 [01:15<00:10, 16.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 984/1157 [01:16<00:10, 16.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 986/1157 [01:16<00:10, 16.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 988/1157 [01:16<00:10, 16.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 990/1157 [01:16<00:10, 16.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 992/1157 [01:16<00:10, 16.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 994/1157 [01:16<00:09, 16.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 996/1157 [01:16<00:09, 16.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 998/1157 [01:16<00:09, 16.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 1000/1157 [01:17<00:09, 16.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1002/1157 [01:17<00:09, 16.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1004/1157 [01:17<00:09, 16.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1006/1157 [01:17<00:09, 16.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1008/1157 [01:17<00:09, 16.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1010/1157 [01:17<00:08, 16.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 1012/1157 [01:17<00:08, 16.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 1014/1157 [01:17<00:08, 16.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 1016/1157 [01:18<00:08, 16.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 1018/1157 [01:18<00:08, 16.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 1020/1157 [01:18<00:08, 16.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 1022/1157 [01:18<00:08, 16.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 1024/1157 [01:18<00:08, 16.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 1026/1157 [01:18<00:07, 16.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 1028/1157 [01:18<00:07, 16.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 1030/1157 [01:18<00:07, 16.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 1032/1157 [01:18<00:07, 16.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 1034/1157 [01:19<00:07, 16.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 1036/1157 [01:19<00:07, 16.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 1038/1157 [01:19<00:07, 16.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 1040/1157 [01:19<00:07, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 1042/1157 [01:19<00:07, 16.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 1044/1157 [01:19<00:06, 16.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 1046/1157 [01:19<00:06, 16.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 1048/1157 [01:19<00:06, 16.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 1050/1157 [01:20<00:06, 16.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 1052/1157 [01:20<00:06, 16.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 1054/1157 [01:20<00:06, 16.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 1056/1157 [01:20<00:06, 16.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 1058/1157 [01:20<00:05, 16.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1060/1157 [01:20<00:05, 16.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1062/1157 [01:20<00:05, 16.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1064/1157 [01:20<00:05, 15.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1066/1157 [01:21<00:05, 15.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1068/1157 [01:21<00:05, 15.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 1070/1157 [01:21<00:05, 14.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 1072/1157 [01:21<00:05, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 1074/1157 [01:21<00:05, 14.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 1076/1157 [01:21<00:05, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 1078/1157 [01:21<00:05, 14.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 1080/1157 [01:22<00:05, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 1082/1157 [01:22<00:05, 14.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 1084/1157 [01:22<00:04, 14.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 1086/1157 [01:22<00:04, 14.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 1088/1157 [01:22<00:04, 15.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 1090/1157 [01:22<00:04, 15.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 1092/1157 [01:22<00:04, 15.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 1094/1157 [01:22<00:04, 15.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 1096/1157 [01:23<00:03, 15.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 1098/1157 [01:23<00:03, 16.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 1100/1157 [01:23<00:03, 16.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 1102/1157 [01:23<00:03, 16.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 1104/1157 [01:23<00:03, 16.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 1106/1157 [01:23<00:03, 16.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 1108/1157 [01:23<00:02, 16.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 1110/1157 [01:23<00:02, 16.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 1112/1157 [01:24<00:02, 16.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 1114/1157 [01:24<00:02, 16.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 1116/1157 [01:24<00:02, 17.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1118/1157 [01:24<00:02, 17.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1120/1157 [01:24<00:02, 17.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1122/1157 [01:24<00:02, 17.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1124/1157 [01:24<00:01, 17.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1126/1157 [01:24<00:01, 17.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 1128/1157 [01:24<00:01, 17.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 1130/1157 [01:25<00:01, 17.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 1132/1157 [01:25<00:01, 17.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 1134/1157 [01:25<00:01, 16.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 1136/1157 [01:25<00:01, 17.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 1138/1157 [01:25<00:01, 17.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 1140/1157 [01:25<00:00, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 1142/1157 [01:25<00:00, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 1144/1157 [01:25<00:00, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 1146/1157 [01:26<00:00, 17.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 1148/1157 [01:26<00:00, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 1150/1157 [01:26<00:00, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 1152/1157 [01:26<00:00, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 1154/1157 [01:26<00:00, 17.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 1156/1157 [01:26<00:00, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 1157/1157 [01:26<00:00, 13.35it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 93.44 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 94.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.75507, 'ndcg_at_3': 0.7521, 'ndcg_at_5': 0.77917, 'ndcg_at_10': 0.79775, 'ndcg_at_20': 0.80363, 'ndcg_at_100': 0.81471, 'ndcg_at_1000': 0.82224, 'map_at_1': 0.49402, 'map_at_3': 0.71227, 'map_at_5': 0.74, 'map_at_10': 0.75256, 'map_at_20': 0.75536, 'map_at_100': 0.7578, 'map_at_1000': 0.75814, 'recall_at_1': 0.49402, 'recall_at_3': 0.7611, 'recall_at_5': 0.81566, 'recall_at_10': 0.85983, 'recall_at_20': 0.87769, 'recall_at_100': 0.92379, 'recall_at_1000': 0.97179, 'precision_at_1': 0.75507, 'precision_at_3': 0.44764, 'precision_at_5': 0.29696, 'precision_at_10': 0.15912, 'precision_at_20': 0.08176, 'precision_at_100': 0.01738, 'precision_at_1000': 0.00185, 'mrr_at_1': 0.7550675675675675, 'mrr_at_3': 0.8040540540540537, 'mrr_at_5': 0.8085304054054049, 'mrr_at_10': 0.8117747211497207, 'mrr_at_20': 0.812207222281235, 'mrr_at_100': 0.8131131301930679, 'mrr_at_1000': 0.8132853503278046, 'nauc_ndcg_at_1_max': np.float64(0.6228814126445884), 'nauc_ndcg_at_1_std': np.float64(0.19902424446397876), 'nauc_ndcg_at_1_diff1': np.float64(0.6249245550866968), 'nauc_ndcg_at_3_max': np.float64(0.6054611777632152), 'nauc_ndcg_at_3_std': np.float64(0.15293546609900183), 'nauc_ndcg_at_3_diff1': np.float64(0.5282658053225904), 'nauc_ndcg_at_5_max': np.float64(0.6388908579563922), 'nauc_ndcg_at_5_std': np.float64(0.17615935485362674), 'nauc_ndcg_at_5_diff1': np.float64(0.5305271281846586), 'nauc_ndcg_at_10_max': np.float64(0.6715625443853238), 'nauc_ndcg_at_10_std': np.float64(0.23320411994961204), 'nauc_ndcg_at_10_diff1': np.float64(0.5336606126584837), 'nauc_ndcg_at_20_max': np.float64(0.6744490383314033), 'nauc_ndcg_at_20_std': np.float64(0.2525682404193242), 'nauc_ndcg_at_20_diff1': np.float64(0.529180348195799), 'nauc_ndcg_at_100_max': np.float64(0.678362622977074), 'nauc_ndcg_at_100_std': np.float64(0.2670217343756272), 'nauc_ndcg_at_100_diff1': np.float64(0.5347830607362013), 'nauc_ndcg_at_1000_max': np.float64(0.6653653542505863), 'nauc_ndcg_at_1000_std': np.float64(0.24972126219193166), 'nauc_ndcg_at_1000_diff1': np.float64(0.5307499470976454), 'nauc_map_at_1_max': np.float64(0.29346353907723527), 'nauc_map_at_1_std': np.float64(0.01340390563498681), 'nauc_map_at_1_diff1': np.float64(0.5645894488955333), 'nauc_map_at_3_max': np.float64(0.5556909915304309), 'nauc_map_at_3_std': np.float64(0.1167298594690696), 'nauc_map_at_3_diff1': np.float64(0.5191068619714311), 'nauc_map_at_5_max': np.float64(0.590835420519843), 'nauc_map_at_5_std': np.float64(0.13423593997407263), 'nauc_map_at_5_diff1': np.float64(0.5188865541380221), 'nauc_map_at_10_max': np.float64(0.6099770965686151), 'nauc_map_at_10_std': np.float64(0.16502879746104301), 'nauc_map_at_10_diff1': np.float64(0.5212107214367746), 'nauc_map_at_20_max': np.float64(0.6106674244261177), 'nauc_map_at_20_std': np.float64(0.17273958419599916), 'nauc_map_at_20_diff1': np.float64(0.5194697548669358), 'nauc_map_at_100_max': np.float64(0.6122197999770514), 'nauc_map_at_100_std': np.float64(0.17529065378585199), 'nauc_map_at_100_diff1': np.float64(0.5212283327153191), 'nauc_map_at_1000_max': np.float64(0.6117136290909787), 'nauc_map_at_1000_std': np.float64(0.1748105874673521), 'nauc_map_at_1000_diff1': np.float64(0.5210390883015985), 'nauc_recall_at_1_max': np.float64(0.29346353907723527), 'nauc_recall_at_1_std': np.float64(0.01340390563498681), 'nauc_recall_at_1_diff1': np.float64(0.5645894488955333), 'nauc_recall_at_3_max': np.float64(0.6029173308206758), 'nauc_recall_at_3_std': np.float64(0.1486225142236378), 'nauc_recall_at_3_diff1': np.float64(0.49108280806581567), 'nauc_recall_at_5_max': np.float64(0.682017508711842), 'nauc_recall_at_5_std': np.float64(0.2006100121925206), 'nauc_recall_at_5_diff1': np.float64(0.4865987247553435), 'nauc_recall_at_10_max': np.float64(0.7909698236779281), 'nauc_recall_at_10_std': np.float64(0.38427859808128223), 'nauc_recall_at_10_diff1': np.float64(0.4882358335782635), 'nauc_recall_at_20_max': np.float64(0.8253335468134124), 'nauc_recall_at_20_std': np.float64(0.4896854704071442), 'nauc_recall_at_20_diff1': np.float64(0.4666719101590229), 'nauc_recall_at_100_max': np.float64(0.9314620341130307), 'nauc_recall_at_100_std': np.float64(0.7416508414978267), 'nauc_recall_at_100_diff1': np.float64(0.48051591832428797), 'nauc_recall_at_1000_max': np.float64(0.9169502263402253), 'nauc_recall_at_1000_std': np.float64(0.9105457073478973), 'nauc_recall_at_1000_diff1': np.float64(0.2737317244978267), 'nauc_precision_at_1_max': np.float64(0.6228814126445884), 'nauc_precision_at_1_std': np.float64(0.19902424446397876), 'nauc_precision_at_1_diff1': np.float64(0.6249245550866968), 'nauc_precision_at_3_max': np.float64(0.36917791301589997), 'nauc_precision_at_3_std': np.float64(0.1940772695977921), 'nauc_precision_at_3_diff1': np.float64(-0.019414517346722757), 'nauc_precision_at_5_max': np.float64(0.30037192426339443), 'nauc_precision_at_5_std': np.float64(0.18283025980861523), 'nauc_precision_at_5_diff1': np.float64(-0.0957620960867288), 'nauc_precision_at_10_max': np.float64(0.2679556585319208), 'nauc_precision_at_10_std': np.float64(0.24098973038242658), 'nauc_precision_at_10_diff1': np.float64(-0.15136892215280937), 'nauc_precision_at_20_max': np.float64(0.23511652118949838), 'nauc_precision_at_20_std': np.float64(0.25930937113235986), 'nauc_precision_at_20_diff1': np.float64(-0.18032451579348643), 'nauc_precision_at_100_max': np.float64(0.1560947705697276), 'nauc_precision_at_100_std': np.float64(0.256136854751995), 'nauc_precision_at_100_diff1': np.float64(-0.24083111402415783), 'nauc_precision_at_1000_max': np.float64(0.003930594976641252), 'nauc_precision_at_1000_std': np.float64(0.1585187638368766), 'nauc_precision_at_1000_diff1': np.float64(-0.35672153482071667), 'nauc_mrr_at_1_max': np.float64(0.6228814126445884), 'nauc_mrr_at_1_std': np.float64(0.19902424446397876), 'nauc_mrr_at_1_diff1': np.float64(0.6249245550866968), 'nauc_mrr_at_3_max': np.float64(0.6878896207805045), 'nauc_mrr_at_3_std': np.float64(0.23793166632211815), 'nauc_mrr_at_3_diff1': np.float64(0.6041008278626523), 'nauc_mrr_at_5_max': np.float64(0.6901145644336037), 'nauc_mrr_at_5_std': np.float64(0.24455958358151736), 'nauc_mrr_at_5_diff1': np.float64(0.6046504896158091), 'nauc_mrr_at_10_max': np.float64(0.6922276066916574), 'nauc_mrr_at_10_std': np.float64(0.2539176231734778), 'nauc_mrr_at_10_diff1': np.float64(0.603062643261101), 'nauc_mrr_at_20_max': np.float64(0.6919106240785431), 'nauc_mrr_at_20_std': np.float64(0.2542352473746987), 'nauc_mrr_at_20_diff1': np.float64(0.6026399470507978), 'nauc_mrr_at_100_max': np.float64(0.6907701987005109), 'nauc_mrr_at_100_std': np.float64(0.25441043161642274), 'nauc_mrr_at_100_diff1': np.float64(0.6023686482144357), 'nauc_mrr_at_1000_max': np.float64(0.6904791523952206), 'nauc_mrr_at_1000_std': np.float64(0.2539056254312373), 'nauc_mrr_at_1000_diff1': np.float64(0.6023992511115708), 'main_score': 0.79775}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 114 sentences.
Batches:   0%|          | 0/15 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 2/15 [00:00<00:00, 13.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 4/15 [00:00<00:00, 13.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 6/15 [00:00<00:00, 14.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 8/15 [00:00<00:00, 14.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 10/15 [00:00<00:00, 14.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 12/15 [00:00<00:00, 14.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 14/15 [00:00<00:00, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 15/15 [00:01<00:00, 14.70it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 720 sentences.
Batches:   0%|          | 0/90 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 1/90 [00:00<00:40,  2.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/90 [00:00<00:29,  3.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 3/90 [00:00<00:24,  3.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 4/90 [00:01<00:22,  3.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 5/90 [00:01<00:21,  4.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 6/90 [00:01<00:19,  4.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 7/90 [00:01<00:18,  4.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 8/90 [00:01<00:17,  4.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 9/90 [00:02<00:16,  4.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 10/90 [00:02<00:15,  5.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 11/90 [00:02<00:15,  5.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 12/90 [00:02<00:14,  5.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 13/90 [00:02<00:14,  5.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 14/90 [00:03<00:13,  5.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 15/90 [00:03<00:13,  5.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 16/90 [00:03<00:12,  5.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 17/90 [00:03<00:12,  5.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 18/90 [00:03<00:12,  5.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 19/90 [00:03<00:11,  6.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 20/90 [00:04<00:11,  6.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 21/90 [00:04<00:10,  6.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 22/90 [00:04<00:10,  6.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 23/90 [00:04<00:10,  6.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 24/90 [00:04<00:10,  6.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 25/90 [00:04<00:09,  6.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 26/90 [00:04<00:09,  6.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 27/90 [00:05<00:09,  6.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 28/90 [00:05<00:09,  6.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 29/90 [00:05<00:08,  6.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 30/90 [00:05<00:09,  6.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 31/90 [00:05<00:08,  6.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 32/90 [00:05<00:08,  6.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 33/90 [00:05<00:08,  6.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 34/90 [00:06<00:08,  6.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 35/90 [00:06<00:08,  6.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 36/90 [00:06<00:08,  6.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 37/90 [00:06<00:07,  6.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 38/90 [00:06<00:07,  6.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 39/90 [00:06<00:07,  6.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 40/90 [00:06<00:07,  7.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 41/90 [00:07<00:06,  7.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 42/90 [00:07<00:06,  7.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 43/90 [00:07<00:06,  7.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 44/90 [00:07<00:06,  7.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 45/90 [00:07<00:06,  7.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 46/90 [00:07<00:05,  7.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 47/90 [00:07<00:05,  7.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 48/90 [00:08<00:05,  7.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 49/90 [00:08<00:05,  7.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 50/90 [00:08<00:04,  8.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 51/90 [00:08<00:04,  7.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 52/90 [00:08<00:04,  7.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 53/90 [00:08<00:04,  8.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 54/90 [00:08<00:04,  8.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 55/90 [00:08<00:04,  8.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 56/90 [00:08<00:04,  8.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 57/90 [00:09<00:03,  8.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 58/90 [00:09<00:03,  8.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 59/90 [00:09<00:03,  8.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 60/90 [00:09<00:03,  8.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 61/90 [00:09<00:03,  8.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 62/90 [00:09<00:03,  9.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 63/90 [00:09<00:02,  9.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 64/90 [00:09<00:02,  9.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 65/90 [00:09<00:02,  9.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 67/90 [00:10<00:02,  9.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 68/90 [00:10<00:02,  9.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 70/90 [00:10<00:01, 10.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 72/90 [00:10<00:01, 10.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 74/90 [00:10<00:01, 11.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 76/90 [00:10<00:01, 11.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 78/90 [00:11<00:00, 12.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 80/90 [00:11<00:00, 12.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 82/90 [00:11<00:00, 13.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 84/90 [00:11<00:00, 14.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 86/90 [00:11<00:00, 14.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 88/90 [00:11<00:00, 15.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 90/90 [00:11<00:00, 15.92it/s]Batches: 100%|██████████| 90/90 [00:11<00:00,  7.61it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 13.02 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 13.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.59649, 'ndcg_at_3': 0.72775, 'ndcg_at_5': 0.74248, 'ndcg_at_10': 0.7629, 'ndcg_at_20': 0.77919, 'ndcg_at_100': 0.78189, 'ndcg_at_1000': 0.78189, 'map_at_1': 0.59649, 'map_at_3': 0.69444, 'map_at_5': 0.70278, 'map_at_10': 0.71155, 'map_at_20': 0.71644, 'map_at_100': 0.71663, 'map_at_1000': 0.71663, 'recall_at_1': 0.59649, 'recall_at_3': 0.82456, 'recall_at_5': 0.85965, 'recall_at_10': 0.92105, 'recall_at_20': 0.98246, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.59649, 'precision_at_3': 0.27485, 'precision_at_5': 0.17193, 'precision_at_10': 0.09211, 'precision_at_20': 0.04912, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.5964912280701754, 'mrr_at_3': 0.6944444444444445, 'mrr_at_5': 0.7027777777777777, 'mrr_at_10': 0.7115497076023392, 'mrr_at_20': 0.7164360570177746, 'mrr_at_100': 0.7166322308606776, 'mrr_at_1000': 0.7166322308606776, 'nauc_ndcg_at_1_max': np.float64(0.29164856070839634), 'nauc_ndcg_at_1_std': np.float64(-0.07807672388888307), 'nauc_ndcg_at_1_diff1': np.float64(0.522414074938299), 'nauc_ndcg_at_3_max': np.float64(0.3215023263494403), 'nauc_ndcg_at_3_std': np.float64(-0.11819258256216061), 'nauc_ndcg_at_3_diff1': np.float64(0.5382464609380391), 'nauc_ndcg_at_5_max': np.float64(0.3162660124150181), 'nauc_ndcg_at_5_std': np.float64(-0.09125082537082478), 'nauc_ndcg_at_5_diff1': np.float64(0.5319174760815454), 'nauc_ndcg_at_10_max': np.float64(0.2766640317929683), 'nauc_ndcg_at_10_std': np.float64(-0.11456529370815116), 'nauc_ndcg_at_10_diff1': np.float64(0.5326303455411154), 'nauc_ndcg_at_20_max': np.float64(0.3173035679314968), 'nauc_ndcg_at_20_std': np.float64(-0.08276944392844622), 'nauc_ndcg_at_20_diff1': np.float64(0.5268988477838845), 'nauc_ndcg_at_100_max': np.float64(0.3070806292291853), 'nauc_ndcg_at_100_std': np.float64(-0.09211127998025512), 'nauc_ndcg_at_100_diff1': np.float64(0.5231685037528079), 'nauc_ndcg_at_1000_max': np.float64(0.3070806292291853), 'nauc_ndcg_at_1000_std': np.float64(-0.09211127998025512), 'nauc_ndcg_at_1000_diff1': np.float64(0.5231685037528079), 'nauc_map_at_1_max': np.float64(0.29164856070839634), 'nauc_map_at_1_std': np.float64(-0.07807672388888307), 'nauc_map_at_1_diff1': np.float64(0.522414074938299), 'nauc_map_at_3_max': np.float64(0.31110079022418563), 'nauc_map_at_3_std': np.float64(-0.10677785242349946), 'nauc_map_at_3_diff1': np.float64(0.5275291446369994), 'nauc_map_at_5_max': np.float64(0.3084885564202473), 'nauc_map_at_5_std': np.float64(-0.09217808505606641), 'nauc_map_at_5_diff1': np.float64(0.5236538348036748), 'nauc_map_at_10_max': np.float64(0.294551405268151), 'nauc_map_at_10_std': np.float64(-0.10082573107745375), 'nauc_map_at_10_diff1': np.float64(0.5232746281219514), 'nauc_map_at_20_max': np.float64(0.3041595682403994), 'nauc_map_at_20_std': np.float64(-0.09310817793467766), 'nauc_map_at_20_diff1': np.float64(0.5211228423917331), 'nauc_map_at_100_max': np.float64(0.30357296149433516), 'nauc_map_at_100_std': np.float64(-0.09364616864511416), 'nauc_map_at_100_diff1': np.float64(0.5209120551554439), 'nauc_map_at_1000_max': np.float64(0.30357296149433516), 'nauc_map_at_1000_std': np.float64(-0.09364616864511416), 'nauc_map_at_1000_diff1': np.float64(0.5209120551554439), 'nauc_recall_at_1_max': np.float64(0.29164856070839634), 'nauc_recall_at_1_std': np.float64(-0.07807672388888307), 'nauc_recall_at_1_diff1': np.float64(0.522414074938299), 'nauc_recall_at_3_max': np.float64(0.36835559345331664), 'nauc_recall_at_3_std': np.float64(-0.1682076232103473), 'nauc_recall_at_3_diff1': np.float64(0.5893682292992042), 'nauc_recall_at_5_max': np.float64(0.35638073235288215), 'nauc_recall_at_5_std': np.float64(-0.08144318642350515), 'nauc_recall_at_5_diff1': np.float64(0.5794871062690465), 'nauc_recall_at_10_max': np.float64(0.07507825251175473), 'nauc_recall_at_10_std': np.float64(-0.24795006860914381), 'nauc_recall_at_10_diff1': np.float64(0.6241317791856692), 'nauc_recall_at_20_max': np.float64(1.0), 'nauc_recall_at_20_std': np.float64(0.5399672160741448), 'nauc_recall_at_20_diff1': np.float64(0.7773798018086994), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.29164856070839634), 'nauc_precision_at_1_std': np.float64(-0.07807672388888307), 'nauc_precision_at_1_diff1': np.float64(0.522414074938299), 'nauc_precision_at_3_max': np.float64(0.3683555934533168), 'nauc_precision_at_3_std': np.float64(-0.16820762321034677), 'nauc_precision_at_3_diff1': np.float64(0.5893682292992029), 'nauc_precision_at_5_max': np.float64(0.3563807323528828), 'nauc_precision_at_5_std': np.float64(-0.0814431864235027), 'nauc_precision_at_5_diff1': np.float64(0.5794871062690461), 'nauc_precision_at_10_max': np.float64(0.07507825251175508), 'nauc_precision_at_10_std': np.float64(-0.2479500686091432), 'nauc_precision_at_10_diff1': np.float64(0.6241317791856679), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(0.539967216074137), 'nauc_precision_at_20_diff1': np.float64(0.7773798018086919), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.29164856070839634), 'nauc_mrr_at_1_std': np.float64(-0.07807672388888307), 'nauc_mrr_at_1_diff1': np.float64(0.522414074938299), 'nauc_mrr_at_3_max': np.float64(0.31110079022418563), 'nauc_mrr_at_3_std': np.float64(-0.10677785242349946), 'nauc_mrr_at_3_diff1': np.float64(0.5275291446369994), 'nauc_mrr_at_5_max': np.float64(0.3084885564202473), 'nauc_mrr_at_5_std': np.float64(-0.09217808505606641), 'nauc_mrr_at_5_diff1': np.float64(0.5236538348036748), 'nauc_mrr_at_10_max': np.float64(0.294551405268151), 'nauc_mrr_at_10_std': np.float64(-0.10082573107745375), 'nauc_mrr_at_10_diff1': np.float64(0.5232746281219514), 'nauc_mrr_at_20_max': np.float64(0.3041595682403994), 'nauc_mrr_at_20_std': np.float64(-0.09310817793467766), 'nauc_mrr_at_20_diff1': np.float64(0.5211228423917331), 'nauc_mrr_at_100_max': np.float64(0.30357296149433516), 'nauc_mrr_at_100_std': np.float64(-0.09364616864511416), 'nauc_mrr_at_100_diff1': np.float64(0.5209120551554439), 'nauc_mrr_at_1000_max': np.float64(0.30357296149433516), 'nauc_mrr_at_1000_std': np.float64(-0.09364616864511416), 'nauc_mrr_at_1000_diff1': np.float64(0.5209120551554439), 'main_score': 0.7629}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.jina_models:Encoding 77 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 2/10 [00:00<00:00, 12.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 4/10 [00:00<00:00, 11.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 6/10 [00:00<00:00, 13.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 8/10 [00:00<00:00, 14.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 10/10 [00:00<00:00, 15.72it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 14.48it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.jina_models:Encoding 77 sentences.
Batches:   0%|          | 0/10 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 1/10 [00:00<00:01,  6.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 2/10 [00:00<00:01,  7.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 4/10 [00:00<00:00, 10.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 6/10 [00:00<00:00, 12.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 8/10 [00:00<00:00, 13.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 10/10 [00:00<00:00, 14.54it/s]Batches: 100%|██████████| 10/10 [00:00<00:00, 12.68it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.55 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 1.67 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.72727, 'ndcg_at_3': 0.78772, 'ndcg_at_5': 0.8101, 'ndcg_at_10': 0.83051, 'ndcg_at_20': 0.84025, 'ndcg_at_100': 0.8429, 'ndcg_at_1000': 0.8429, 'map_at_1': 0.72727, 'map_at_3': 0.77273, 'map_at_5': 0.78571, 'map_at_10': 0.79379, 'map_at_20': 0.7964, 'map_at_100': 0.79685, 'map_at_1000': 0.79685, 'recall_at_1': 0.72727, 'recall_at_3': 0.83117, 'recall_at_5': 0.88312, 'recall_at_10': 0.94805, 'recall_at_20': 0.98701, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.72727, 'precision_at_3': 0.27706, 'precision_at_5': 0.17662, 'precision_at_10': 0.09481, 'precision_at_20': 0.04935, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7272727272727273, 'mrr_at_3': 0.7727272727272728, 'mrr_at_5': 0.7857142857142858, 'mrr_at_10': 0.7937899402185117, 'mrr_at_20': 0.7964000751815878, 'mrr_at_100': 0.7968479032156228, 'mrr_at_1000': 0.7968479032156228, 'nauc_ndcg_at_1_max': np.float64(0.41777799933942383), 'nauc_ndcg_at_1_std': np.float64(-0.11502937969975355), 'nauc_ndcg_at_1_diff1': np.float64(0.7577470503935713), 'nauc_ndcg_at_3_max': np.float64(0.40461393835085435), 'nauc_ndcg_at_3_std': np.float64(-0.17216329739386393), 'nauc_ndcg_at_3_diff1': np.float64(0.7750108490264357), 'nauc_ndcg_at_5_max': np.float64(0.4182363168980118), 'nauc_ndcg_at_5_std': np.float64(-0.16648908400791346), 'nauc_ndcg_at_5_diff1': np.float64(0.7906472830345547), 'nauc_ndcg_at_10_max': np.float64(0.40251867259526186), 'nauc_ndcg_at_10_std': np.float64(-0.0838306842987361), 'nauc_ndcg_at_10_diff1': np.float64(0.7749844946033875), 'nauc_ndcg_at_20_max': np.float64(0.4301232232767733), 'nauc_ndcg_at_20_std': np.float64(-0.10765294823443487), 'nauc_ndcg_at_20_diff1': np.float64(0.7630145020797847), 'nauc_ndcg_at_100_max': np.float64(0.4194960192058322), 'nauc_ndcg_at_100_std': np.float64(-0.12000740582984307), 'nauc_ndcg_at_100_diff1': np.float64(0.7668964679540566), 'nauc_ndcg_at_1000_max': np.float64(0.4194960192058322), 'nauc_ndcg_at_1000_std': np.float64(-0.12000740582984307), 'nauc_ndcg_at_1000_diff1': np.float64(0.7668964679540566), 'nauc_map_at_1_max': np.float64(0.41777799933942383), 'nauc_map_at_1_std': np.float64(-0.11502937969975355), 'nauc_map_at_1_diff1': np.float64(0.7577470503935713), 'nauc_map_at_3_max': np.float64(0.4117800788620658), 'nauc_map_at_3_std': np.float64(-0.14835870908303095), 'nauc_map_at_3_diff1': np.float64(0.7643555861209013), 'nauc_map_at_5_max': np.float64(0.4193041458114639), 'nauc_map_at_5_std': np.float64(-0.14401255779763072), 'nauc_map_at_5_diff1': np.float64(0.771892844893899), 'nauc_map_at_10_max': np.float64(0.4151079516234675), 'nauc_map_at_10_std': np.float64(-0.11515538975256824), 'nauc_map_at_10_diff1': np.float64(0.7661990504129449), 'nauc_map_at_20_max': np.float64(0.42096084933008154), 'nauc_map_at_20_std': np.float64(-0.12046203462667862), 'nauc_map_at_20_diff1': np.float64(0.7636455357270158), 'nauc_map_at_100_max': np.float64(0.41954303423410966), 'nauc_map_at_100_std': np.float64(-0.12211557196079181), 'nauc_map_at_100_diff1': np.float64(0.7641567933955553), 'nauc_map_at_1000_max': np.float64(0.41954303423410966), 'nauc_map_at_1000_std': np.float64(-0.12211557196079181), 'nauc_map_at_1000_diff1': np.float64(0.7641567933955553), 'nauc_recall_at_1_max': np.float64(0.41777799933942383), 'nauc_recall_at_1_std': np.float64(-0.11502937969975355), 'nauc_recall_at_1_diff1': np.float64(0.7577470503935713), 'nauc_recall_at_3_max': np.float64(0.3763299073053579), 'nauc_recall_at_3_std': np.float64(-0.264125499784987), 'nauc_recall_at_3_diff1': np.float64(0.8174093269102954), 'nauc_recall_at_5_max': np.float64(0.4130763535290157), 'nauc_recall_at_5_std': np.float64(-0.28023495096865575), 'nauc_recall_at_5_diff1': np.float64(0.8889212754660999), 'nauc_recall_at_10_max': np.float64(0.24031819702144214), 'nauc_recall_at_10_std': np.float64(0.3456539015073782), 'nauc_recall_at_10_diff1': np.float64(0.855889839183298), 'nauc_recall_at_20_max': np.float64(1.0), 'nauc_recall_at_20_std': np.float64(0.5548466542608921), 'nauc_recall_at_20_diff1': np.float64(0.5548466542608921), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.41777799933942383), 'nauc_precision_at_1_std': np.float64(-0.11502937969975355), 'nauc_precision_at_1_diff1': np.float64(0.7577470503935713), 'nauc_precision_at_3_max': np.float64(0.3763299073053593), 'nauc_precision_at_3_std': np.float64(-0.2641254997849845), 'nauc_precision_at_3_diff1': np.float64(0.8174093269102958), 'nauc_precision_at_5_max': np.float64(0.4130763535290174), 'nauc_precision_at_5_std': np.float64(-0.2802349509686518), 'nauc_precision_at_5_diff1': np.float64(0.8889212754660993), 'nauc_precision_at_10_max': np.float64(0.24031819702144644), 'nauc_precision_at_10_std': np.float64(0.3456539015073844), 'nauc_precision_at_10_diff1': np.float64(0.8558898391832962), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(0.5548466542608996), 'nauc_precision_at_20_diff1': np.float64(0.5548466542608996), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.41777799933942383), 'nauc_mrr_at_1_std': np.float64(-0.11502937969975355), 'nauc_mrr_at_1_diff1': np.float64(0.7577470503935713), 'nauc_mrr_at_3_max': np.float64(0.4117800788620658), 'nauc_mrr_at_3_std': np.float64(-0.14835870908303095), 'nauc_mrr_at_3_diff1': np.float64(0.7643555861209013), 'nauc_mrr_at_5_max': np.float64(0.4193041458114639), 'nauc_mrr_at_5_std': np.float64(-0.14401255779763072), 'nauc_mrr_at_5_diff1': np.float64(0.771892844893899), 'nauc_mrr_at_10_max': np.float64(0.4151079516234675), 'nauc_mrr_at_10_std': np.float64(-0.11515538975256824), 'nauc_mrr_at_10_diff1': np.float64(0.7661990504129449), 'nauc_mrr_at_20_max': np.float64(0.42096084933008154), 'nauc_mrr_at_20_std': np.float64(-0.12046203462667862), 'nauc_mrr_at_20_diff1': np.float64(0.7636455357270158), 'nauc_mrr_at_100_max': np.float64(0.41954303423410966), 'nauc_mrr_at_100_std': np.float64(-0.12211557196079181), 'nauc_mrr_at_100_diff1': np.float64(0.7641567933955553), 'nauc_mrr_at_1000_max': np.float64(0.41954303423410966), 'nauc_mrr_at_1000_std': np.float64(-0.12211557196079181), 'nauc_mrr_at_1000_diff1': np.float64(0.7641567933955553), 'main_score': 0.83051}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 900 sentences.
Batches:   0%|          | 0/113 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/113 [00:00<00:07, 14.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 4/113 [00:00<00:07, 14.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 6/113 [00:00<00:07, 14.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 8/113 [00:00<00:07, 14.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 10/113 [00:00<00:06, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 12/113 [00:00<00:06, 14.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 14/113 [00:00<00:06, 14.95it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 16/113 [00:01<00:06, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 18/113 [00:01<00:06, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 20/113 [00:01<00:06, 14.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 22/113 [00:01<00:06, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 24/113 [00:01<00:05, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 26/113 [00:01<00:05, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 28/113 [00:01<00:05, 15.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 30/113 [00:02<00:05, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 32/113 [00:02<00:05, 15.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 34/113 [00:02<00:05, 15.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 36/113 [00:02<00:05, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 38/113 [00:02<00:05, 14.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 40/113 [00:02<00:04, 15.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 42/113 [00:02<00:04, 14.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 44/113 [00:02<00:04, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 46/113 [00:03<00:04, 14.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 48/113 [00:03<00:04, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 50/113 [00:03<00:04, 14.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 52/113 [00:03<00:04, 15.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 54/113 [00:03<00:03, 14.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 56/113 [00:03<00:03, 14.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 58/113 [00:03<00:03, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 60/113 [00:04<00:03, 15.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 62/113 [00:04<00:03, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 64/113 [00:04<00:03, 15.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 66/113 [00:04<00:03, 14.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 68/113 [00:04<00:03, 14.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 70/113 [00:04<00:02, 15.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 72/113 [00:04<00:02, 14.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 74/113 [00:04<00:02, 14.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 76/113 [00:05<00:02, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 78/113 [00:05<00:02, 15.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 80/113 [00:05<00:02, 15.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 82/113 [00:05<00:01, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 84/113 [00:05<00:01, 16.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 86/113 [00:05<00:01, 16.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 88/113 [00:05<00:01, 16.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 90/113 [00:05<00:01, 17.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 92/113 [00:06<00:01, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 94/113 [00:06<00:01, 17.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 96/113 [00:06<00:00, 17.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 98/113 [00:06<00:00, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 100/113 [00:06<00:00, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 102/113 [00:06<00:00, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 104/113 [00:06<00:00, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 106/113 [00:06<00:00, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 108/113 [00:06<00:00, 17.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 110/113 [00:07<00:00, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 112/113 [00:07<00:00, 17.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 113/113 [00:07<00:00, 15.68it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 488 sentences.
Batches:   0%|          | 0/61 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 2/61 [00:00<00:05, 11.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 4/61 [00:00<00:04, 12.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 6/61 [00:00<00:04, 13.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 8/61 [00:00<00:04, 13.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 10/61 [00:00<00:03, 13.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 12/61 [00:00<00:03, 14.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 14/61 [00:01<00:03, 14.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 16/61 [00:01<00:03, 13.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 18/61 [00:01<00:03, 14.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 20/61 [00:01<00:02, 14.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 22/61 [00:01<00:02, 14.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 24/61 [00:01<00:02, 14.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 26/61 [00:01<00:02, 14.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 28/61 [00:01<00:02, 15.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 30/61 [00:02<00:02, 15.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 32/61 [00:02<00:01, 15.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 34/61 [00:02<00:01, 15.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 36/61 [00:02<00:01, 15.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 38/61 [00:02<00:01, 15.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 40/61 [00:02<00:01, 15.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 42/61 [00:02<00:01, 15.88it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 44/61 [00:02<00:01, 15.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 46/61 [00:03<00:00, 15.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 48/61 [00:03<00:00, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 50/61 [00:03<00:00, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 52/61 [00:03<00:00, 16.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 54/61 [00:03<00:00, 16.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 56/61 [00:03<00:00, 16.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 58/61 [00:03<00:00, 16.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 60/61 [00:03<00:00, 16.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 61/61 [00:04<00:00, 15.11it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.65 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 900 sentences.
Batches:   0%|          | 0/113 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/113 [00:00<00:06, 17.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 4/113 [00:00<00:06, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 6/113 [00:00<00:06, 16.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 8/113 [00:00<00:06, 17.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 10/113 [00:00<00:05, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 12/113 [00:00<00:05, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 14/113 [00:00<00:05, 17.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 16/113 [00:00<00:05, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 18/113 [00:01<00:05, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 20/113 [00:01<00:05, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 22/113 [00:01<00:05, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 24/113 [00:01<00:05, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 26/113 [00:01<00:04, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 28/113 [00:01<00:04, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 30/113 [00:01<00:04, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 32/113 [00:01<00:04, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 34/113 [00:01<00:04, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 36/113 [00:02<00:04, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 38/113 [00:02<00:04, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 40/113 [00:02<00:04, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 42/113 [00:02<00:04, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 44/113 [00:02<00:03, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 46/113 [00:02<00:03, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 48/113 [00:02<00:03, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 50/113 [00:02<00:03, 17.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 52/113 [00:02<00:03, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 54/113 [00:03<00:03, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 56/113 [00:03<00:03, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 58/113 [00:03<00:03, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 60/113 [00:03<00:03, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 62/113 [00:03<00:02, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 64/113 [00:03<00:02, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 66/113 [00:03<00:02, 17.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 68/113 [00:03<00:02, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 70/113 [00:04<00:02, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 72/113 [00:04<00:02, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 74/113 [00:04<00:02, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 76/113 [00:04<00:02, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 78/113 [00:04<00:01, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 80/113 [00:04<00:01, 17.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 82/113 [00:04<00:01, 17.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 84/113 [00:04<00:01, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 86/113 [00:04<00:01, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 88/113 [00:05<00:01, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 90/113 [00:05<00:01, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 92/113 [00:05<00:01, 17.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 94/113 [00:05<00:01, 17.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 96/113 [00:05<00:00, 17.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 98/113 [00:05<00:00, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 100/113 [00:05<00:00, 16.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 102/113 [00:05<00:00, 16.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 104/113 [00:05<00:00, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 106/113 [00:06<00:00, 15.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 108/113 [00:06<00:00, 15.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 110/113 [00:06<00:00, 16.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 112/113 [00:06<00:00, 16.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 113/113 [00:06<00:00, 17.29it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 488 sentences.
Batches:   0%|          | 0/61 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 2/61 [00:00<00:05, 11.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 4/61 [00:00<00:04, 12.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 6/61 [00:00<00:04, 13.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 8/61 [00:00<00:03, 13.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 10/61 [00:00<00:03, 13.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 12/61 [00:00<00:03, 14.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 14/61 [00:01<00:03, 14.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 16/61 [00:01<00:03, 14.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 18/61 [00:01<00:02, 14.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 20/61 [00:01<00:02, 14.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 22/61 [00:01<00:02, 14.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 24/61 [00:01<00:02, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 26/61 [00:01<00:02, 14.90it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 28/61 [00:01<00:02, 15.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 30/61 [00:02<00:02, 15.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 32/61 [00:02<00:01, 15.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 34/61 [00:02<00:01, 15.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 36/61 [00:02<00:01, 15.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 38/61 [00:02<00:01, 15.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 40/61 [00:02<00:01, 15.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 42/61 [00:02<00:01, 15.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 44/61 [00:02<00:01, 15.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 46/61 [00:03<00:00, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 48/61 [00:03<00:00, 15.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 50/61 [00:03<00:00, 15.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 52/61 [00:03<00:00, 16.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 54/61 [00:03<00:00, 16.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 56/61 [00:03<00:00, 16.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 58/61 [00:03<00:00, 16.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 60/61 [00:03<00:00, 16.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 61/61 [00:03<00:00, 15.26it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.95 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 900 sentences.
Batches:   0%|          | 0/113 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/113 [00:00<00:06, 17.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 4/113 [00:00<00:06, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 6/113 [00:00<00:06, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 8/113 [00:00<00:06, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 10/113 [00:00<00:06, 16.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 12/113 [00:00<00:05, 17.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 14/113 [00:00<00:05, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 16/113 [00:00<00:05, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 18/113 [00:01<00:05, 17.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 20/113 [00:01<00:05, 17.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 22/113 [00:01<00:05, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 24/113 [00:01<00:05, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 26/113 [00:01<00:05, 17.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 28/113 [00:01<00:04, 17.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 30/113 [00:01<00:04, 17.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 32/113 [00:01<00:04, 17.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 34/113 [00:01<00:04, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 36/113 [00:02<00:04, 17.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 38/113 [00:02<00:04, 17.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 40/113 [00:02<00:04, 17.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 42/113 [00:02<00:04, 17.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 44/113 [00:02<00:04, 17.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 46/113 [00:02<00:03, 17.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 48/113 [00:02<00:03, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 50/113 [00:02<00:03, 17.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 52/113 [00:03<00:03, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 54/113 [00:03<00:03, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 56/113 [00:03<00:03, 17.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 58/113 [00:03<00:03, 17.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 60/113 [00:03<00:03, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 62/113 [00:03<00:02, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 64/113 [00:03<00:02, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 66/113 [00:03<00:02, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 68/113 [00:03<00:02, 17.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 70/113 [00:04<00:02, 17.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 72/113 [00:04<00:02, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 74/113 [00:04<00:02, 17.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 76/113 [00:04<00:02, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 78/113 [00:04<00:01, 17.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 80/113 [00:04<00:01, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 82/113 [00:04<00:01, 17.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 84/113 [00:04<00:01, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 86/113 [00:04<00:01, 17.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 88/113 [00:05<00:01, 17.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 90/113 [00:05<00:01, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 92/113 [00:05<00:01, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 94/113 [00:05<00:01, 17.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 96/113 [00:05<00:00, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 98/113 [00:05<00:00, 17.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 100/113 [00:05<00:00, 17.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 102/113 [00:05<00:00, 17.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 104/113 [00:05<00:00, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 106/113 [00:06<00:00, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 108/113 [00:06<00:00, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 110/113 [00:06<00:00, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 112/113 [00:06<00:00, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 113/113 [00:06<00:00, 17.48it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 488 sentences.
Batches:   0%|          | 0/61 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 2/61 [00:00<00:04, 12.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 4/61 [00:00<00:04, 12.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 6/61 [00:00<00:04, 13.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 8/61 [00:00<00:03, 13.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 10/61 [00:00<00:03, 13.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 12/61 [00:00<00:03, 14.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 14/61 [00:01<00:03, 14.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 16/61 [00:01<00:03, 14.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 18/61 [00:01<00:02, 14.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 20/61 [00:01<00:02, 14.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 22/61 [00:01<00:02, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 24/61 [00:01<00:02, 15.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 26/61 [00:01<00:02, 14.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 28/61 [00:01<00:02, 15.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 30/61 [00:02<00:02, 15.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 32/61 [00:02<00:01, 15.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 34/61 [00:02<00:01, 14.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 36/61 [00:02<00:01, 15.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 38/61 [00:02<00:01, 15.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 40/61 [00:02<00:01, 15.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 42/61 [00:02<00:01, 15.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 44/61 [00:02<00:01, 15.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 46/61 [00:03<00:00, 15.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 48/61 [00:03<00:00, 15.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 50/61 [00:03<00:00, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 52/61 [00:03<00:00, 16.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 54/61 [00:03<00:00, 15.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 56/61 [00:03<00:00, 16.02it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 58/61 [00:03<00:00, 16.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 60/61 [00:03<00:00, 16.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 61/61 [00:04<00:00, 15.20it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.88 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 34.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.85333, 'ndcg_at_3': 0.89713, 'ndcg_at_5': 0.90679, 'ndcg_at_10': 0.91217, 'ndcg_at_20': 0.91492, 'ndcg_at_100': 0.91784, 'ndcg_at_1000': 0.91875, 'map_at_1': 0.85333, 'map_at_3': 0.88685, 'map_at_5': 0.89224, 'map_at_10': 0.89445, 'map_at_20': 0.89518, 'map_at_100': 0.89559, 'map_at_1000': 0.89563, 'recall_at_1': 0.85333, 'recall_at_3': 0.92667, 'recall_at_5': 0.95, 'recall_at_10': 0.96667, 'recall_at_20': 0.97778, 'recall_at_100': 0.99333, 'recall_at_1000': 1.0, 'precision_at_1': 0.85333, 'precision_at_3': 0.30889, 'precision_at_5': 0.19, 'precision_at_10': 0.09667, 'precision_at_20': 0.04889, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8533333333333334, 'mrr_at_3': 0.8868518518518521, 'mrr_at_5': 0.8922407407407411, 'mrr_at_10': 0.8944537037037043, 'mrr_at_20': 0.8951773914844093, 'mrr_at_100': 0.8955911172873383, 'mrr_at_1000': 0.8956343463137879, 'nauc_ndcg_at_1_max': np.float64(0.8330344226965433), 'nauc_ndcg_at_1_std': np.float64(-0.18125424379299104), 'nauc_ndcg_at_1_diff1': np.float64(0.9130428364774301), 'nauc_ndcg_at_3_max': np.float64(0.8385674564132664), 'nauc_ndcg_at_3_std': np.float64(-0.11716108735009896), 'nauc_ndcg_at_3_diff1': np.float64(0.8862764351634461), 'nauc_ndcg_at_5_max': np.float64(0.847381351503503), 'nauc_ndcg_at_5_std': np.float64(-0.11416251178544662), 'nauc_ndcg_at_5_diff1': np.float64(0.8974962201615823), 'nauc_ndcg_at_10_max': np.float64(0.8498071495791834), 'nauc_ndcg_at_10_std': np.float64(-0.11073632062123995), 'nauc_ndcg_at_10_diff1': np.float64(0.9008214326037927), 'nauc_ndcg_at_20_max': np.float64(0.8470171053850507), 'nauc_ndcg_at_20_std': np.float64(-0.11788042165114725), 'nauc_ndcg_at_20_diff1': np.float64(0.9005880906698405), 'nauc_ndcg_at_100_max': np.float64(0.8448657699772545), 'nauc_ndcg_at_100_std': np.float64(-0.12111597739708935), 'nauc_ndcg_at_100_diff1': np.float64(0.9008698573607562), 'nauc_ndcg_at_1000_max': np.float64(0.8430871947417808), 'nauc_ndcg_at_1000_std': np.float64(-0.1274718283644222), 'nauc_ndcg_at_1000_diff1': np.float64(0.9002401655521519), 'nauc_map_at_1_max': np.float64(0.8330344226965433), 'nauc_map_at_1_std': np.float64(-0.18125424379299104), 'nauc_map_at_1_diff1': np.float64(0.9130428364774301), 'nauc_map_at_3_max': np.float64(0.8364845360986649), 'nauc_map_at_3_std': np.float64(-0.13454450082529473), 'nauc_map_at_3_diff1': np.float64(0.8937448664370599), 'nauc_map_at_5_max': np.float64(0.8407168956309117), 'nauc_map_at_5_std': np.float64(-0.13422716166076284), 'nauc_map_at_5_diff1': np.float64(0.8997089377383367), 'nauc_map_at_10_max': np.float64(0.8412334728659785), 'nauc_map_at_10_std': np.float64(-0.1346755011542555), 'nauc_map_at_10_diff1': np.float64(0.9008790188386636), 'nauc_map_at_20_max': np.float64(0.8405643840352945), 'nauc_map_at_20_std': np.float64(-0.13656767239287315), 'nauc_map_at_20_diff1': np.float64(0.9008152835609989), 'nauc_map_at_100_max': np.float64(0.8402976592083661), 'nauc_map_at_100_std': np.float64(-0.1367929466454302), 'nauc_map_at_100_diff1': np.float64(0.9008270814130613), 'nauc_map_at_1000_max': np.float64(0.8402295178710142), 'nauc_map_at_1000_std': np.float64(-0.13703520783659656), 'nauc_map_at_1000_diff1': np.float64(0.9008036947314791), 'nauc_recall_at_1_max': np.float64(0.8330344226965433), 'nauc_recall_at_1_std': np.float64(-0.18125424379299104), 'nauc_recall_at_1_diff1': np.float64(0.9130428364774301), 'nauc_recall_at_3_max': np.float64(0.8478270095917155), 'nauc_recall_at_3_std': np.float64(-0.043304190363011835), 'nauc_recall_at_3_diff1': np.float64(0.8543983249865601), 'nauc_recall_at_5_max': np.float64(0.8902894491129766), 'nauc_recall_at_5_std': np.float64(0.006432202510633092), 'nauc_recall_at_5_diff1': np.float64(0.8875920738665819), 'nauc_recall_at_10_max': np.float64(0.9339402427637726), 'nauc_recall_at_10_std': np.float64(0.11370992841580677), 'nauc_recall_at_10_diff1': np.float64(0.9094304388422041), 'nauc_recall_at_20_max': np.float64(0.9344070961717991), 'nauc_recall_at_20_std': np.float64(0.12539682539682612), 'nauc_recall_at_20_diff1': np.float64(0.9107142857142805), 'nauc_recall_at_100_max': np.float64(1.0), 'nauc_recall_at_100_std': np.float64(0.4391534391534384), 'nauc_recall_at_100_diff1': np.float64(0.9564270152505339), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8330344226965433), 'nauc_precision_at_1_std': np.float64(-0.18125424379299104), 'nauc_precision_at_1_diff1': np.float64(0.9130428364774301), 'nauc_precision_at_3_max': np.float64(0.8478270095917201), 'nauc_precision_at_3_std': np.float64(-0.04330419036301652), 'nauc_precision_at_3_diff1': np.float64(0.8543983249865629), 'nauc_precision_at_5_max': np.float64(0.8902894491129764), 'nauc_precision_at_5_std': np.float64(0.0064322025106331), 'nauc_precision_at_5_diff1': np.float64(0.8875920738665845), 'nauc_precision_at_10_max': np.float64(0.9339402427637699), 'nauc_precision_at_10_std': np.float64(0.11370992841580742), 'nauc_precision_at_10_diff1': np.float64(0.9094304388422024), 'nauc_precision_at_20_max': np.float64(0.9344070961718046), 'nauc_precision_at_20_std': np.float64(0.12539682539681804), 'nauc_precision_at_20_diff1': np.float64(0.9107142857142799), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(0.4391534391533951), 'nauc_precision_at_100_diff1': np.float64(0.9564270152505334), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8330344226965433), 'nauc_mrr_at_1_std': np.float64(-0.18125424379299104), 'nauc_mrr_at_1_diff1': np.float64(0.9130428364774301), 'nauc_mrr_at_3_max': np.float64(0.8364845360986649), 'nauc_mrr_at_3_std': np.float64(-0.13454450082529473), 'nauc_mrr_at_3_diff1': np.float64(0.8937448664370599), 'nauc_mrr_at_5_max': np.float64(0.8407168956309117), 'nauc_mrr_at_5_std': np.float64(-0.13422716166076284), 'nauc_mrr_at_5_diff1': np.float64(0.8997089377383367), 'nauc_mrr_at_10_max': np.float64(0.8412334728659785), 'nauc_mrr_at_10_std': np.float64(-0.1346755011542555), 'nauc_mrr_at_10_diff1': np.float64(0.9008790188386636), 'nauc_mrr_at_20_max': np.float64(0.8405643840352945), 'nauc_mrr_at_20_std': np.float64(-0.13656767239287315), 'nauc_mrr_at_20_diff1': np.float64(0.9008152835609989), 'nauc_mrr_at_100_max': np.float64(0.8402976592083661), 'nauc_mrr_at_100_std': np.float64(-0.1367929466454302), 'nauc_mrr_at_100_diff1': np.float64(0.9008270814130613), 'nauc_mrr_at_1000_max': np.float64(0.8402295178710142), 'nauc_mrr_at_1000_std': np.float64(-0.13703520783659656), 'nauc_mrr_at_1000_diff1': np.float64(0.9008036947314791), 'main_score': 0.91217}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.84111, 'ndcg_at_3': 0.89218, 'ndcg_at_5': 0.90313, 'ndcg_at_10': 0.91039, 'ndcg_at_20': 0.91234, 'ndcg_at_100': 0.91447, 'ndcg_at_1000': 0.9152, 'map_at_1': 0.84111, 'map_at_3': 0.88019, 'map_at_5': 0.88624, 'map_at_10': 0.88928, 'map_at_20': 0.8898, 'map_at_100': 0.89012, 'map_at_1000': 0.89015, 'recall_at_1': 0.84111, 'recall_at_3': 0.92667, 'recall_at_5': 0.95333, 'recall_at_10': 0.97556, 'recall_at_20': 0.98333, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.84111, 'precision_at_3': 0.30889, 'precision_at_5': 0.19067, 'precision_at_10': 0.09756, 'precision_at_20': 0.04917, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8411111111111111, 'mrr_at_3': 0.8801851851851854, 'mrr_at_5': 0.8862407407407411, 'mrr_at_10': 0.8892817460317465, 'mrr_at_20': 0.8898021492611278, 'mrr_at_100': 0.8901213013516016, 'mrr_at_1000': 0.890150687945803, 'nauc_ndcg_at_1_max': np.float64(0.7421654669841423), 'nauc_ndcg_at_1_std': np.float64(-0.2530072118188745), 'nauc_ndcg_at_1_diff1': np.float64(0.8884706964105585), 'nauc_ndcg_at_3_max': np.float64(0.7770751996595193), 'nauc_ndcg_at_3_std': np.float64(-0.16965673873431655), 'nauc_ndcg_at_3_diff1': np.float64(0.8682147594839562), 'nauc_ndcg_at_5_max': np.float64(0.7769449117559789), 'nauc_ndcg_at_5_std': np.float64(-0.17127481570812284), 'nauc_ndcg_at_5_diff1': np.float64(0.8721702700739971), 'nauc_ndcg_at_10_max': np.float64(0.7707783499297846), 'nauc_ndcg_at_10_std': np.float64(-0.16422302385684298), 'nauc_ndcg_at_10_diff1': np.float64(0.8696360876812675), 'nauc_ndcg_at_20_max': np.float64(0.770246922258703), 'nauc_ndcg_at_20_std': np.float64(-0.1688932078673148), 'nauc_ndcg_at_20_diff1': np.float64(0.8720270308381243), 'nauc_ndcg_at_100_max': np.float64(0.7700810883960739), 'nauc_ndcg_at_100_std': np.float64(-0.17905639749928015), 'nauc_ndcg_at_100_diff1': np.float64(0.8736652665599405), 'nauc_ndcg_at_1000_max': np.float64(0.768513986573433), 'nauc_ndcg_at_1000_std': np.float64(-0.1823958048340563), 'nauc_ndcg_at_1000_diff1': np.float64(0.8739940101015922), 'nauc_map_at_1_max': np.float64(0.7421654669841423), 'nauc_map_at_1_std': np.float64(-0.2530072118188745), 'nauc_map_at_1_diff1': np.float64(0.8884706964105585), 'nauc_map_at_3_max': np.float64(0.7670033413998094), 'nauc_map_at_3_std': np.float64(-0.19353056687496373), 'nauc_map_at_3_diff1': np.float64(0.8733339595662295), 'nauc_map_at_5_max': np.float64(0.7667155453592526), 'nauc_map_at_5_std': np.float64(-0.1953832525269614), 'nauc_map_at_5_diff1': np.float64(0.8755241244743811), 'nauc_map_at_10_max': np.float64(0.7646890335169995), 'nauc_map_at_10_std': np.float64(-0.19285185968861207), 'nauc_map_at_10_diff1': np.float64(0.8748326674006209), 'nauc_map_at_20_max': np.float64(0.764747657725016), 'nauc_map_at_20_std': np.float64(-0.19353843634281304), 'nauc_map_at_20_diff1': np.float64(0.8755070190888856), 'nauc_map_at_100_max': np.float64(0.7647558936527933), 'nauc_map_at_100_std': np.float64(-0.19463243744146033), 'nauc_map_at_100_diff1': np.float64(0.8757047825539869), 'nauc_map_at_1000_max': np.float64(0.7647070724125986), 'nauc_map_at_1000_std': np.float64(-0.19471328759931306), 'nauc_map_at_1000_diff1': np.float64(0.8757086841742273), 'nauc_recall_at_1_max': np.float64(0.7421654669841423), 'nauc_recall_at_1_std': np.float64(-0.2530072118188745), 'nauc_recall_at_1_diff1': np.float64(0.8884706964105585), 'nauc_recall_at_3_max': np.float64(0.8224471606824549), 'nauc_recall_at_3_std': np.float64(-0.062232973997679436), 'nauc_recall_at_3_diff1': np.float64(0.8456695809636995), 'nauc_recall_at_5_max': np.float64(0.8445266995687161), 'nauc_recall_at_5_std': np.float64(-0.01101551731804213), 'nauc_recall_at_5_diff1': np.float64(0.8518407362945178), 'nauc_recall_at_10_max': np.float64(0.8309141838553625), 'nauc_recall_at_10_std': np.float64(0.19272557507852006), 'nauc_recall_at_10_diff1': np.float64(0.804261098378747), 'nauc_recall_at_20_max': np.float64(0.8388110799875537), 'nauc_recall_at_20_std': np.float64(0.24307500778088956), 'nauc_recall_at_20_diff1': np.float64(0.8160597572362351), 'nauc_recall_at_100_max': np.float64(0.9477124183006633), 'nauc_recall_at_100_std': np.float64(0.22371615312791085), 'nauc_recall_at_100_diff1': np.float64(0.8291316526610856), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7421654669841423), 'nauc_precision_at_1_std': np.float64(-0.2530072118188745), 'nauc_precision_at_1_diff1': np.float64(0.8884706964105585), 'nauc_precision_at_3_max': np.float64(0.8224471606824567), 'nauc_precision_at_3_std': np.float64(-0.06223297399768066), 'nauc_precision_at_3_diff1': np.float64(0.8456695809637005), 'nauc_precision_at_5_max': np.float64(0.8445266995687137), 'nauc_precision_at_5_std': np.float64(-0.01101551731804), 'nauc_precision_at_5_diff1': np.float64(0.8518407362945176), 'nauc_precision_at_10_max': np.float64(0.8309141838553583), 'nauc_precision_at_10_std': np.float64(0.19272557507851765), 'nauc_precision_at_10_diff1': np.float64(0.8042610983787415), 'nauc_precision_at_20_max': np.float64(0.838811079987551), 'nauc_precision_at_20_std': np.float64(0.24307500778087981), 'nauc_precision_at_20_diff1': np.float64(0.8160597572362249), 'nauc_precision_at_100_max': np.float64(0.9477124183006403), 'nauc_precision_at_100_std': np.float64(0.22371615312792476), 'nauc_precision_at_100_diff1': np.float64(0.8291316526610534), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7421654669841423), 'nauc_mrr_at_1_std': np.float64(-0.2530072118188745), 'nauc_mrr_at_1_diff1': np.float64(0.8884706964105585), 'nauc_mrr_at_3_max': np.float64(0.7670033413998094), 'nauc_mrr_at_3_std': np.float64(-0.19353056687496373), 'nauc_mrr_at_3_diff1': np.float64(0.8733339595662295), 'nauc_mrr_at_5_max': np.float64(0.7667155453592526), 'nauc_mrr_at_5_std': np.float64(-0.1953832525269614), 'nauc_mrr_at_5_diff1': np.float64(0.8755241244743811), 'nauc_mrr_at_10_max': np.float64(0.7646890335169995), 'nauc_mrr_at_10_std': np.float64(-0.19285185968861207), 'nauc_mrr_at_10_diff1': np.float64(0.8748326674006209), 'nauc_mrr_at_20_max': np.float64(0.764747657725016), 'nauc_mrr_at_20_std': np.float64(-0.19353843634281304), 'nauc_mrr_at_20_diff1': np.float64(0.8755070190888856), 'nauc_mrr_at_100_max': np.float64(0.7647558936527933), 'nauc_mrr_at_100_std': np.float64(-0.19463243744146033), 'nauc_mrr_at_100_diff1': np.float64(0.8757047825539869), 'nauc_mrr_at_1000_max': np.float64(0.7647070724125986), 'nauc_mrr_at_1000_std': np.float64(-0.19471328759931306), 'nauc_mrr_at_1000_diff1': np.float64(0.8757086841742273), 'main_score': 0.91039}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.80111, 'ndcg_at_3': 0.85595, 'ndcg_at_5': 0.86805, 'ndcg_at_10': 0.87514, 'ndcg_at_20': 0.88054, 'ndcg_at_100': 0.88552, 'ndcg_at_1000': 0.88672, 'map_at_1': 0.80111, 'map_at_3': 0.84296, 'map_at_5': 0.8498, 'map_at_10': 0.85287, 'map_at_20': 0.85439, 'map_at_100': 0.85508, 'map_at_1000': 0.85514, 'recall_at_1': 0.80111, 'recall_at_3': 0.89333, 'recall_at_5': 0.92222, 'recall_at_10': 0.94333, 'recall_at_20': 0.96444, 'recall_at_100': 0.99111, 'recall_at_1000': 1.0, 'precision_at_1': 0.80111, 'precision_at_3': 0.29778, 'precision_at_5': 0.18444, 'precision_at_10': 0.09433, 'precision_at_20': 0.04822, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8011111111111111, 'mrr_at_3': 0.842962962962963, 'mrr_at_5': 0.8497962962962966, 'mrr_at_10': 0.8528725749559085, 'mrr_at_20': 0.8543900738637583, 'mrr_at_100': 0.8550814309602767, 'mrr_at_1000': 0.8551363632925285, 'nauc_ndcg_at_1_max': np.float64(0.7206344247387712), 'nauc_ndcg_at_1_std': np.float64(-0.08568248637370313), 'nauc_ndcg_at_1_diff1': np.float64(0.8722531227510335), 'nauc_ndcg_at_3_max': np.float64(0.7524976521907926), 'nauc_ndcg_at_3_std': np.float64(-0.010509507010999593), 'nauc_ndcg_at_3_diff1': np.float64(0.8431553327762792), 'nauc_ndcg_at_5_max': np.float64(0.7567938482778592), 'nauc_ndcg_at_5_std': np.float64(-0.009923423908972412), 'nauc_ndcg_at_5_diff1': np.float64(0.8448826986817647), 'nauc_ndcg_at_10_max': np.float64(0.7686029952768144), 'nauc_ndcg_at_10_std': np.float64(0.0006562572338820566), 'nauc_ndcg_at_10_diff1': np.float64(0.8531061740689927), 'nauc_ndcg_at_20_max': np.float64(0.7667600437126383), 'nauc_ndcg_at_20_std': np.float64(0.004322111060892615), 'nauc_ndcg_at_20_diff1': np.float64(0.8577999009770315), 'nauc_ndcg_at_100_max': np.float64(0.7578517670451405), 'nauc_ndcg_at_100_std': np.float64(-0.010855317496157603), 'nauc_ndcg_at_100_diff1': np.float64(0.8553940130637324), 'nauc_ndcg_at_1000_max': np.float64(0.7553135088770108), 'nauc_ndcg_at_1000_std': np.float64(-0.01819404524922683), 'nauc_ndcg_at_1000_diff1': np.float64(0.8554659725857656), 'nauc_map_at_1_max': np.float64(0.7206344247387712), 'nauc_map_at_1_std': np.float64(-0.08568248637370313), 'nauc_map_at_1_diff1': np.float64(0.8722531227510335), 'nauc_map_at_3_max': np.float64(0.7444531654583116), 'nauc_map_at_3_std': np.float64(-0.03330643818894689), 'nauc_map_at_3_diff1': np.float64(0.851642260671747), 'nauc_map_at_5_max': np.float64(0.7463868245406764), 'nauc_map_at_5_std': np.float64(-0.03387650951872525), 'nauc_map_at_5_diff1': np.float64(0.8529192464552185), 'nauc_map_at_10_max': np.float64(0.7502153538348747), 'nauc_map_at_10_std': np.float64(-0.030954140099027323), 'nauc_map_at_10_diff1': np.float64(0.8557989382641356), 'nauc_map_at_20_max': np.float64(0.7497760923060187), 'nauc_map_at_20_std': np.float64(-0.030004078084545034), 'nauc_map_at_20_diff1': np.float64(0.8570639691432571), 'nauc_map_at_100_max': np.float64(0.7486853594735522), 'nauc_map_at_100_std': np.float64(-0.03197479431238941), 'nauc_map_at_100_diff1': np.float64(0.8567832588748107), 'nauc_map_at_1000_max': np.float64(0.7485878116806106), 'nauc_map_at_1000_std': np.float64(-0.03223613270240884), 'nauc_map_at_1000_diff1': np.float64(0.8567733801676292), 'nauc_recall_at_1_max': np.float64(0.7206344247387712), 'nauc_recall_at_1_std': np.float64(-0.08568248637370313), 'nauc_recall_at_1_diff1': np.float64(0.8722531227510335), 'nauc_recall_at_3_max': np.float64(0.7844394759551272), 'nauc_recall_at_3_std': np.float64(0.08265670353808732), 'nauc_recall_at_3_diff1': np.float64(0.8086657644936062), 'nauc_recall_at_5_max': np.float64(0.8114312391623303), 'nauc_recall_at_5_std': np.float64(0.11703348005868915), 'nauc_recall_at_5_diff1': np.float64(0.8027944511137781), 'nauc_recall_at_10_max': np.float64(0.9101169879716586), 'nauc_recall_at_10_std': np.float64(0.23673129382471816), 'nauc_recall_at_10_diff1': np.float64(0.8432379487742807), 'nauc_recall_at_20_max': np.float64(0.9656425070028023), 'nauc_recall_at_20_std': np.float64(0.40978057889822306), 'nauc_recall_at_20_diff1': np.float64(0.8919672035480841), 'nauc_recall_at_100_max': np.float64(0.9836601307189647), 'nauc_recall_at_100_std': np.float64(0.656337535014012), 'nauc_recall_at_100_diff1': np.float64(0.8395191409897229), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.7206344247387712), 'nauc_precision_at_1_std': np.float64(-0.08568248637370313), 'nauc_precision_at_1_diff1': np.float64(0.8722531227510335), 'nauc_precision_at_3_max': np.float64(0.7844394759551279), 'nauc_precision_at_3_std': np.float64(0.08265670353808795), 'nauc_precision_at_3_diff1': np.float64(0.808665764493608), 'nauc_precision_at_5_max': np.float64(0.811431239162329), 'nauc_precision_at_5_std': np.float64(0.11703348005868919), 'nauc_precision_at_5_diff1': np.float64(0.8027944511137785), 'nauc_precision_at_10_max': np.float64(0.9101169879716567), 'nauc_precision_at_10_std': np.float64(0.23673129382471722), 'nauc_precision_at_10_diff1': np.float64(0.8432379487742767), 'nauc_precision_at_20_max': np.float64(0.9656425070028003), 'nauc_precision_at_20_std': np.float64(0.4097805788982196), 'nauc_precision_at_20_diff1': np.float64(0.8919672035480838), 'nauc_precision_at_100_max': np.float64(0.9836601307189621), 'nauc_precision_at_100_std': np.float64(0.6563375350140266), 'nauc_precision_at_100_diff1': np.float64(0.8395191409897483), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.7206344247387712), 'nauc_mrr_at_1_std': np.float64(-0.08568248637370313), 'nauc_mrr_at_1_diff1': np.float64(0.8722531227510335), 'nauc_mrr_at_3_max': np.float64(0.7444531654583116), 'nauc_mrr_at_3_std': np.float64(-0.03330643818894689), 'nauc_mrr_at_3_diff1': np.float64(0.851642260671747), 'nauc_mrr_at_5_max': np.float64(0.7463868245406764), 'nauc_mrr_at_5_std': np.float64(-0.03387650951872525), 'nauc_mrr_at_5_diff1': np.float64(0.8529192464552185), 'nauc_mrr_at_10_max': np.float64(0.7502153538348747), 'nauc_mrr_at_10_std': np.float64(-0.030954140099027323), 'nauc_mrr_at_10_diff1': np.float64(0.8557989382641356), 'nauc_mrr_at_20_max': np.float64(0.7497760923060187), 'nauc_mrr_at_20_std': np.float64(-0.030004078084545034), 'nauc_mrr_at_20_diff1': np.float64(0.8570639691432571), 'nauc_mrr_at_100_max': np.float64(0.7486853594735522), 'nauc_mrr_at_100_std': np.float64(-0.03197479431238941), 'nauc_mrr_at_100_diff1': np.float64(0.8567832588748107), 'nauc_mrr_at_1000_max': np.float64(0.7485878116806106), 'nauc_mrr_at_1000_std': np.float64(-0.03223613270240884), 'nauc_mrr_at_1000_diff1': np.float64(0.8567733801676292), 'main_score': 0.87514}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 654 sentences.
Batches:   0%|          | 0/82 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/82 [00:00<00:04, 16.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 4/82 [00:00<00:04, 17.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 6/82 [00:00<00:04, 17.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 8/82 [00:00<00:04, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 10/82 [00:00<00:04, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 12/82 [00:00<00:04, 16.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 14/82 [00:00<00:03, 17.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 16/82 [00:00<00:03, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 18/82 [00:01<00:03, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 20/82 [00:01<00:03, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 22/82 [00:01<00:03, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 24/82 [00:01<00:03, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 26/82 [00:01<00:03, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 28/82 [00:01<00:03, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 30/82 [00:01<00:02, 17.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 32/82 [00:01<00:02, 17.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 34/82 [00:01<00:02, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 36/82 [00:02<00:02, 17.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 38/82 [00:02<00:02, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 40/82 [00:02<00:02, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 42/82 [00:02<00:02, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 44/82 [00:02<00:02, 17.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 46/82 [00:02<00:02, 17.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 48/82 [00:02<00:01, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 50/82 [00:02<00:01, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 52/82 [00:02<00:01, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 54/82 [00:03<00:01, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 56/82 [00:03<00:01, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 58/82 [00:03<00:01, 17.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 60/82 [00:03<00:01, 17.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 62/82 [00:03<00:01, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 64/82 [00:03<00:01, 17.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 66/82 [00:03<00:00, 17.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 68/82 [00:03<00:00, 17.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 70/82 [00:04<00:00, 17.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 72/82 [00:04<00:00, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 74/82 [00:04<00:00, 17.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 76/82 [00:04<00:00, 17.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 78/82 [00:04<00:00, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 80/82 [00:04<00:00, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 82/82 [00:04<00:00, 17.73it/s]Batches: 100%|██████████| 82/82 [00:04<00:00, 17.51it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 889 sentences.
Batches:   0%|          | 0/112 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/112 [00:00<00:06, 16.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 4/112 [00:00<00:06, 16.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 6/112 [00:00<00:06, 17.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 8/112 [00:00<00:06, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 10/112 [00:00<00:05, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 12/112 [00:00<00:05, 17.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▎        | 14/112 [00:00<00:05, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 16/112 [00:00<00:05, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 18/112 [00:01<00:05, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 20/112 [00:01<00:05, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 22/112 [00:01<00:05, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 24/112 [00:01<00:04, 17.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 26/112 [00:01<00:04, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 28/112 [00:01<00:04, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 30/112 [00:01<00:04, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 32/112 [00:01<00:04, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 34/112 [00:01<00:04, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 36/112 [00:02<00:04, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 38/112 [00:02<00:04, 17.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 40/112 [00:02<00:04, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 42/112 [00:02<00:03, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 44/112 [00:02<00:03, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 46/112 [00:02<00:03, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 48/112 [00:02<00:03, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 50/112 [00:02<00:03, 17.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 52/112 [00:02<00:03, 17.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 54/112 [00:03<00:03, 17.82it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 56/112 [00:03<00:03, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 58/112 [00:03<00:03, 17.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 60/112 [00:03<00:03, 17.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 62/112 [00:03<00:02, 17.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 64/112 [00:03<00:02, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 66/112 [00:03<00:02, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 68/112 [00:03<00:02, 17.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▎   | 70/112 [00:04<00:02, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 72/112 [00:04<00:02, 17.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 74/112 [00:04<00:02, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 76/112 [00:04<00:02, 17.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 78/112 [00:04<00:01, 17.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 80/112 [00:04<00:01, 17.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 82/112 [00:04<00:01, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 84/112 [00:04<00:01, 17.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 86/112 [00:04<00:01, 17.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 88/112 [00:05<00:01, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 90/112 [00:05<00:01, 17.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 92/112 [00:05<00:01, 17.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 94/112 [00:05<00:01, 17.91it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 96/112 [00:05<00:00, 17.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 98/112 [00:05<00:00, 17.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 100/112 [00:05<00:00, 17.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 102/112 [00:05<00:00, 17.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 104/112 [00:05<00:00, 17.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 106/112 [00:06<00:00, 17.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 108/112 [00:06<00:00, 17.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 110/112 [00:06<00:00, 17.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 112/112 [00:06<00:00, 12.92it/s]Batches: 100%|██████████| 112/112 [00:06<00:00, 17.19it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.74 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 654 sentences.
Batches:   0%|          | 0/82 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/82 [00:00<00:04, 17.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 4/82 [00:00<00:04, 17.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 6/82 [00:00<00:04, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 8/82 [00:00<00:04, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 10/82 [00:00<00:04, 17.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 12/82 [00:00<00:04, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 14/82 [00:00<00:03, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 16/82 [00:00<00:03, 17.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 18/82 [00:01<00:03, 17.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 20/82 [00:01<00:03, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 22/82 [00:01<00:03, 17.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 24/82 [00:01<00:03, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 26/82 [00:01<00:03, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 28/82 [00:01<00:03, 17.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 30/82 [00:01<00:03, 17.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 32/82 [00:01<00:02, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 34/82 [00:01<00:02, 17.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 36/82 [00:02<00:02, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 38/82 [00:02<00:02, 17.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 40/82 [00:02<00:02, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 42/82 [00:02<00:02, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 44/82 [00:02<00:02, 17.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 46/82 [00:02<00:02, 17.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 48/82 [00:02<00:01, 17.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 50/82 [00:02<00:01, 17.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 52/82 [00:02<00:01, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 54/82 [00:03<00:01, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 56/82 [00:03<00:01, 17.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 58/82 [00:03<00:01, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 60/82 [00:03<00:01, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 62/82 [00:03<00:01, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 64/82 [00:03<00:01, 16.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 66/82 [00:03<00:00, 16.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 68/82 [00:03<00:00, 15.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 70/82 [00:04<00:00, 15.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 72/82 [00:04<00:00, 15.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 74/82 [00:04<00:00, 15.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 76/82 [00:04<00:00, 15.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 78/82 [00:04<00:00, 15.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 80/82 [00:04<00:00, 15.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 82/82 [00:04<00:00, 15.07it/s]Batches: 100%|██████████| 82/82 [00:04<00:00, 16.80it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 1169 sentences.
Batches:   0%|          | 0/147 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 1/147 [00:00<01:03,  2.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 3/147 [00:00<00:23,  6.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 5/147 [00:00<00:15,  8.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 7/147 [00:00<00:12, 11.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 9/147 [00:00<00:10, 12.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 11/147 [00:01<00:09, 13.81it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 13/147 [00:01<00:09, 14.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 15/147 [00:01<00:08, 15.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 17/147 [00:01<00:08, 15.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 19/147 [00:01<00:08, 15.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 21/147 [00:01<00:07, 16.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 23/147 [00:01<00:07, 16.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 25/147 [00:01<00:07, 16.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 27/147 [00:02<00:07, 16.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 29/147 [00:02<00:07, 16.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 31/147 [00:02<00:06, 16.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 33/147 [00:02<00:06, 16.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 35/147 [00:02<00:06, 16.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 37/147 [00:02<00:06, 16.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 39/147 [00:02<00:06, 16.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 41/147 [00:02<00:06, 16.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 43/147 [00:02<00:06, 17.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 45/147 [00:03<00:05, 17.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 47/147 [00:03<00:05, 17.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 49/147 [00:03<00:05, 17.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 51/147 [00:03<00:05, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 53/147 [00:03<00:05, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 55/147 [00:03<00:05, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 57/147 [00:03<00:05, 16.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 59/147 [00:03<00:05, 17.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 61/147 [00:04<00:04, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 63/147 [00:04<00:04, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 65/147 [00:04<00:04, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 67/147 [00:04<00:04, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 69/147 [00:04<00:04, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 71/147 [00:04<00:04, 17.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 73/147 [00:04<00:04, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 75/147 [00:04<00:04, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 77/147 [00:04<00:04, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 79/147 [00:05<00:03, 17.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 81/147 [00:05<00:03, 17.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 83/147 [00:05<00:03, 17.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 85/147 [00:05<00:03, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 87/147 [00:05<00:03, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 89/147 [00:05<00:03, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 91/147 [00:05<00:03, 17.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 93/147 [00:05<00:03, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 95/147 [00:05<00:02, 17.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 97/147 [00:06<00:02, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 99/147 [00:06<00:02, 17.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 101/147 [00:06<00:02, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 103/147 [00:06<00:02, 17.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 105/147 [00:06<00:02, 17.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 107/147 [00:06<00:02, 17.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 109/147 [00:06<00:02, 17.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 111/147 [00:06<00:02, 17.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 113/147 [00:07<00:01, 17.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 115/147 [00:07<00:01, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 117/147 [00:07<00:01, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 119/147 [00:07<00:01, 17.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 121/147 [00:07<00:01, 17.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 123/147 [00:07<00:01, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 125/147 [00:07<00:01, 17.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 127/147 [00:07<00:01, 17.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 129/147 [00:07<00:01, 17.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 131/147 [00:08<00:00, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 133/147 [00:08<00:00, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 135/147 [00:08<00:00, 17.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 137/147 [00:08<00:00, 17.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 139/147 [00:08<00:00, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 141/147 [00:08<00:00, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 143/147 [00:08<00:00, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 145/147 [00:08<00:00, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 147/147 [00:08<00:00, 17.75it/s]Batches: 100%|██████████| 147/147 [00:08<00:00, 16.44it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 14.38 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 614 sentences.
Batches:   0%|          | 0/77 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 2/77 [00:00<00:04, 15.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 4/77 [00:00<00:04, 16.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 6/77 [00:00<00:04, 16.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 8/77 [00:00<00:04, 16.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 10/77 [00:00<00:03, 17.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 12/77 [00:00<00:03, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 14/77 [00:00<00:03, 17.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 16/77 [00:00<00:03, 17.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 18/77 [00:01<00:03, 17.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 20/77 [00:01<00:03, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 22/77 [00:01<00:03, 17.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 24/77 [00:01<00:02, 17.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 26/77 [00:01<00:02, 17.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 28/77 [00:01<00:02, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 30/77 [00:01<00:02, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 32/77 [00:01<00:02, 17.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 34/77 [00:01<00:02, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 36/77 [00:02<00:02, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 38/77 [00:02<00:02, 17.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 40/77 [00:02<00:02, 17.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 42/77 [00:02<00:02, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 44/77 [00:02<00:01, 17.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 46/77 [00:02<00:01, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 48/77 [00:02<00:01, 17.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 50/77 [00:02<00:01, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 52/77 [00:02<00:01, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 54/77 [00:03<00:01, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 56/77 [00:03<00:01, 17.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 58/77 [00:03<00:01, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 60/77 [00:03<00:00, 17.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 62/77 [00:03<00:00, 17.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 64/77 [00:03<00:00, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 66/77 [00:03<00:00, 17.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 68/77 [00:03<00:00, 17.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 70/77 [00:04<00:00, 17.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 72/77 [00:04<00:00, 17.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 74/77 [00:04<00:00, 17.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 76/77 [00:04<00:00, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 77/77 [00:04<00:00, 17.45it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 889 sentences.
Batches:   0%|          | 0/112 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 2/112 [00:00<00:06, 16.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 4/112 [00:00<00:06, 17.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 6/112 [00:00<00:06, 17.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 8/112 [00:00<00:05, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 10/112 [00:00<00:05, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 12/112 [00:00<00:05, 17.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▎        | 14/112 [00:00<00:05, 17.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 16/112 [00:00<00:05, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 18/112 [00:01<00:05, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 20/112 [00:01<00:05, 17.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 22/112 [00:01<00:05, 17.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 24/112 [00:01<00:04, 17.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 26/112 [00:01<00:04, 17.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 28/112 [00:01<00:04, 17.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 30/112 [00:01<00:04, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 32/112 [00:01<00:04, 17.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 34/112 [00:01<00:04, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 36/112 [00:02<00:04, 17.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 38/112 [00:02<00:04, 17.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 40/112 [00:02<00:04, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 42/112 [00:02<00:04, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 44/112 [00:02<00:03, 17.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 46/112 [00:02<00:03, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 48/112 [00:02<00:03, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 50/112 [00:02<00:03, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 52/112 [00:02<00:03, 17.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 54/112 [00:03<00:03, 17.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 56/112 [00:03<00:03, 17.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 58/112 [00:03<00:03, 17.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 60/112 [00:03<00:02, 17.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 62/112 [00:03<00:02, 17.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 64/112 [00:03<00:02, 17.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 66/112 [00:03<00:02, 17.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 68/112 [00:03<00:02, 17.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▎   | 70/112 [00:04<00:02, 17.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 72/112 [00:04<00:02, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 74/112 [00:04<00:02, 17.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 76/112 [00:04<00:02, 17.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 78/112 [00:04<00:01, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 80/112 [00:04<00:01, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 82/112 [00:04<00:01, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 84/112 [00:04<00:01, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 86/112 [00:04<00:01, 17.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 88/112 [00:05<00:01, 17.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 90/112 [00:05<00:01, 17.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 92/112 [00:05<00:01, 17.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 94/112 [00:05<00:01, 17.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 96/112 [00:05<00:00, 17.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 98/112 [00:05<00:00, 17.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 100/112 [00:05<00:00, 17.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 102/112 [00:05<00:00, 17.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 104/112 [00:05<00:00, 17.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 106/112 [00:06<00:00, 17.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 108/112 [00:06<00:00, 17.94it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 110/112 [00:06<00:00, 17.93it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 112/112 [00:06<00:00, 18.07it/s]Batches: 100%|██████████| 112/112 [00:06<00:00, 17.55it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.22 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 39.18 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.32569, 'ndcg_at_3': 0.34891, 'ndcg_at_5': 0.37795, 'ndcg_at_10': 0.41174, 'ndcg_at_20': 0.44258, 'ndcg_at_100': 0.48508, 'ndcg_at_1000': 0.50643, 'map_at_1': 0.22678, 'map_at_3': 0.3187, 'map_at_5': 0.3432, 'map_at_10': 0.35987, 'map_at_20': 0.36982, 'map_at_100': 0.37645, 'map_at_1000': 0.37751, 'recall_at_1': 0.22678, 'recall_at_3': 0.36646, 'recall_at_5': 0.43774, 'recall_at_10': 0.53035, 'recall_at_20': 0.63922, 'recall_at_100': 0.84697, 'recall_at_1000': 1.0, 'precision_at_1': 0.32569, 'precision_at_3': 0.19725, 'precision_at_5': 0.14404, 'precision_at_10': 0.0867, 'precision_at_20': 0.05176, 'precision_at_100': 0.0137, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.3256880733944954, 'mrr_at_3': 0.37028542303771683, 'mrr_at_5': 0.3843527013251785, 'mrr_at_10': 0.3963569729624775, 'mrr_at_20': 0.40348720602469856, 'mrr_at_100': 0.40811852404850313, 'mrr_at_1000': 0.4088276613275812, 'nauc_ndcg_at_1_max': np.float64(0.2930769414449494), 'nauc_ndcg_at_1_std': np.float64(-0.3121692789770937), 'nauc_ndcg_at_1_diff1': np.float64(0.4689253719224627), 'nauc_ndcg_at_3_max': np.float64(0.2757524103557473), 'nauc_ndcg_at_3_std': np.float64(-0.3076821353252962), 'nauc_ndcg_at_3_diff1': np.float64(0.41764935191692004), 'nauc_ndcg_at_5_max': np.float64(0.26959967982791644), 'nauc_ndcg_at_5_std': np.float64(-0.31015392866604313), 'nauc_ndcg_at_5_diff1': np.float64(0.3918822250474893), 'nauc_ndcg_at_10_max': np.float64(0.26999067147191685), 'nauc_ndcg_at_10_std': np.float64(-0.3019601223893862), 'nauc_ndcg_at_10_diff1': np.float64(0.38342091816944174), 'nauc_ndcg_at_20_max': np.float64(0.2610043168186679), 'nauc_ndcg_at_20_std': np.float64(-0.28645542375449734), 'nauc_ndcg_at_20_diff1': np.float64(0.3710376752019975), 'nauc_ndcg_at_100_max': np.float64(0.27882807731687337), 'nauc_ndcg_at_100_std': np.float64(-0.2699494829457612), 'nauc_ndcg_at_100_diff1': np.float64(0.38253251935164095), 'nauc_ndcg_at_1000_max': np.float64(0.27897328291623297), 'nauc_ndcg_at_1000_std': np.float64(-0.2821388089843967), 'nauc_ndcg_at_1000_diff1': np.float64(0.3905925068043019), 'nauc_map_at_1_max': np.float64(0.23899192002152056), 'nauc_map_at_1_std': np.float64(-0.28232496513597627), 'nauc_map_at_1_diff1': np.float64(0.5575867116544009), 'nauc_map_at_3_max': np.float64(0.28126004415810274), 'nauc_map_at_3_std': np.float64(-0.2988098218235944), 'nauc_map_at_3_diff1': np.float64(0.43857967346563964), 'nauc_map_at_5_max': np.float64(0.27302798920873866), 'nauc_map_at_5_std': np.float64(-0.3076673659196325), 'nauc_map_at_5_diff1': np.float64(0.4086693008592276), 'nauc_map_at_10_max': np.float64(0.271379230525849), 'nauc_map_at_10_std': np.float64(-0.3067432638642865), 'nauc_map_at_10_diff1': np.float64(0.40522651745387317), 'nauc_map_at_20_max': np.float64(0.26788110756681915), 'nauc_map_at_20_std': np.float64(-0.30228582432246215), 'nauc_map_at_20_diff1': np.float64(0.401428268778562), 'nauc_map_at_100_max': np.float64(0.2709090386264549), 'nauc_map_at_100_std': np.float64(-0.2986319009484707), 'nauc_map_at_100_diff1': np.float64(0.40207846349821774), 'nauc_map_at_1000_max': np.float64(0.2711617867830441), 'nauc_map_at_1000_std': np.float64(-0.2989949537609668), 'nauc_map_at_1000_diff1': np.float64(0.40259665341970247), 'nauc_recall_at_1_max': np.float64(0.23899192002152056), 'nauc_recall_at_1_std': np.float64(-0.28232496513597627), 'nauc_recall_at_1_diff1': np.float64(0.5575867116544009), 'nauc_recall_at_3_max': np.float64(0.26387871299523563), 'nauc_recall_at_3_std': np.float64(-0.29104094117296864), 'nauc_recall_at_3_diff1': np.float64(0.38823478043487936), 'nauc_recall_at_5_max': np.float64(0.24732198265310681), 'nauc_recall_at_5_std': np.float64(-0.30400450563649534), 'nauc_recall_at_5_diff1': np.float64(0.32354472407625595), 'nauc_recall_at_10_max': np.float64(0.24387155283348805), 'nauc_recall_at_10_std': np.float64(-0.27629295836483525), 'nauc_recall_at_10_diff1': np.float64(0.2927464931149413), 'nauc_recall_at_20_max': np.float64(0.20629162262685832), 'nauc_recall_at_20_std': np.float64(-0.21325516920878337), 'nauc_recall_at_20_diff1': np.float64(0.23579381637640373), 'nauc_recall_at_100_max': np.float64(0.29503798045785734), 'nauc_recall_at_100_std': np.float64(-0.061157551636226395), 'nauc_recall_at_100_diff1': np.float64(0.2630920256101173), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2930769414449494), 'nauc_precision_at_1_std': np.float64(-0.3121692789770937), 'nauc_precision_at_1_diff1': np.float64(0.4689253719224627), 'nauc_precision_at_3_max': np.float64(0.26760387991356194), 'nauc_precision_at_3_std': np.float64(-0.2555215515928763), 'nauc_precision_at_3_diff1': np.float64(0.18408871642921718), 'nauc_precision_at_5_max': np.float64(0.22551407144600782), 'nauc_precision_at_5_std': np.float64(-0.24304439104872583), 'nauc_precision_at_5_diff1': np.float64(0.10237618944092225), 'nauc_precision_at_10_max': np.float64(0.20141791040069734), 'nauc_precision_at_10_std': np.float64(-0.20957523646259552), 'nauc_precision_at_10_diff1': np.float64(0.06839133205903583), 'nauc_precision_at_20_max': np.float64(0.15644427995088253), 'nauc_precision_at_20_std': np.float64(-0.146519689294035), 'nauc_precision_at_20_diff1': np.float64(-0.003437718617377239), 'nauc_precision_at_100_max': np.float64(0.18472404258884914), 'nauc_precision_at_100_std': np.float64(0.028956600028576605), 'nauc_precision_at_100_diff1': np.float64(-0.0797748290334129), 'nauc_precision_at_1000_max': np.float64(0.1639463336254321), 'nauc_precision_at_1000_std': np.float64(0.06348287474469734), 'nauc_precision_at_1000_diff1': np.float64(-0.1431412763246157), 'nauc_mrr_at_1_max': np.float64(0.29531230227647953), 'nauc_mrr_at_1_std': np.float64(-0.3121692789770937), 'nauc_mrr_at_1_diff1': np.float64(0.4689253719224627), 'nauc_mrr_at_3_max': np.float64(0.2818239033204019), 'nauc_mrr_at_3_std': np.float64(-0.3138682346750162), 'nauc_mrr_at_3_diff1': np.float64(0.43241826244624526), 'nauc_mrr_at_5_max': np.float64(0.280878613355505), 'nauc_mrr_at_5_std': np.float64(-0.3111748230068178), 'nauc_mrr_at_5_diff1': np.float64(0.42257700948072685), 'nauc_mrr_at_10_max': np.float64(0.2846505986086395), 'nauc_mrr_at_10_std': np.float64(-0.3051346385315586), 'nauc_mrr_at_10_diff1': np.float64(0.4191135955161184), 'nauc_mrr_at_20_max': np.float64(0.28327148664549134), 'nauc_mrr_at_20_std': np.float64(-0.30123320109985746), 'nauc_mrr_at_20_diff1': np.float64(0.4175939590595862), 'nauc_mrr_at_100_max': np.float64(0.2846800551476455), 'nauc_mrr_at_100_std': np.float64(-0.300864658196539), 'nauc_mrr_at_100_diff1': np.float64(0.41960379500895506), 'nauc_mrr_at_1000_max': np.float64(0.2845281014345752), 'nauc_mrr_at_1000_std': np.float64(-0.3013316850860964), 'nauc_mrr_at_1000_diff1': np.float64(0.41980596395362285), 'main_score': 0.41174}, 'eng-kor': {'ndcg_at_1': 0.31193, 'ndcg_at_3': 0.32149, 'ndcg_at_5': 0.34225, 'ndcg_at_10': 0.37776, 'ndcg_at_20': 0.40167, 'ndcg_at_100': 0.45608, 'ndcg_at_1000': 0.48297, 'map_at_1': 0.18096, 'map_at_3': 0.2701, 'map_at_5': 0.30154, 'map_at_10': 0.32089, 'map_at_20': 0.32991, 'map_at_100': 0.33871, 'map_at_1000': 0.34022, 'recall_at_1': 0.18096, 'recall_at_3': 0.31223, 'recall_at_5': 0.38405, 'recall_at_10': 0.47396, 'recall_at_20': 0.5498, 'recall_at_100': 0.8105, 'recall_at_1000': 0.99541, 'precision_at_1': 0.31193, 'precision_at_3': 0.21203, 'precision_at_5': 0.16147, 'precision_at_10': 0.10046, 'precision_at_20': 0.05894, 'precision_at_100': 0.01653, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.3119266055045872, 'mrr_at_3': 0.3600917431192662, 'mrr_at_5': 0.3723241590214068, 'mrr_at_10': 0.3842143585262852, 'mrr_at_20': 0.3886319978629391, 'mrr_at_100': 0.3938526530643705, 'mrr_at_1000': 0.39456454762274484, 'nauc_ndcg_at_1_max': np.float64(0.18705489814391954), 'nauc_ndcg_at_1_std': np.float64(-0.3650591392219447), 'nauc_ndcg_at_1_diff1': np.float64(0.3911501207226409), 'nauc_ndcg_at_3_max': np.float64(0.16955769276272087), 'nauc_ndcg_at_3_std': np.float64(-0.36720928145476145), 'nauc_ndcg_at_3_diff1': np.float64(0.3441194737234161), 'nauc_ndcg_at_5_max': np.float64(0.17774478643125013), 'nauc_ndcg_at_5_std': np.float64(-0.3695485924075251), 'nauc_ndcg_at_5_diff1': np.float64(0.3401086314438197), 'nauc_ndcg_at_10_max': np.float64(0.17137173324837948), 'nauc_ndcg_at_10_std': np.float64(-0.3731634536112165), 'nauc_ndcg_at_10_diff1': np.float64(0.3245752813227831), 'nauc_ndcg_at_20_max': np.float64(0.17698699803774107), 'nauc_ndcg_at_20_std': np.float64(-0.36763150289581226), 'nauc_ndcg_at_20_diff1': np.float64(0.3279139782531202), 'nauc_ndcg_at_100_max': np.float64(0.18580943247518303), 'nauc_ndcg_at_100_std': np.float64(-0.33733296954975306), 'nauc_ndcg_at_100_diff1': np.float64(0.32597587370468867), 'nauc_ndcg_at_1000_max': np.float64(0.19149751264643064), 'nauc_ndcg_at_1000_std': np.float64(-0.34014781333967475), 'nauc_ndcg_at_1000_diff1': np.float64(0.3243957283194593), 'nauc_map_at_1_max': np.float64(0.13474766540713495), 'nauc_map_at_1_std': np.float64(-0.32633642504487037), 'nauc_map_at_1_diff1': np.float64(0.442415220924903), 'nauc_map_at_3_max': np.float64(0.16180614057083967), 'nauc_map_at_3_std': np.float64(-0.3637150567842232), 'nauc_map_at_3_diff1': np.float64(0.37750492012143605), 'nauc_map_at_5_max': np.float64(0.17992826257547728), 'nauc_map_at_5_std': np.float64(-0.3651256135401176), 'nauc_map_at_5_diff1': np.float64(0.36151186897427806), 'nauc_map_at_10_max': np.float64(0.17777157885992), 'nauc_map_at_10_std': np.float64(-0.3703182098141804), 'nauc_map_at_10_diff1': np.float64(0.3528947244032551), 'nauc_map_at_20_max': np.float64(0.1804833824060003), 'nauc_map_at_20_std': np.float64(-0.3685311688517635), 'nauc_map_at_20_diff1': np.float64(0.3527834785026265), 'nauc_map_at_100_max': np.float64(0.18057978584126871), 'nauc_map_at_100_std': np.float64(-0.3645228558953835), 'nauc_map_at_100_diff1': np.float64(0.35122882418392637), 'nauc_map_at_1000_max': np.float64(0.1815899753914136), 'nauc_map_at_1000_std': np.float64(-0.3637941154487188), 'nauc_map_at_1000_diff1': np.float64(0.3509754267607545), 'nauc_recall_at_1_max': np.float64(0.13474766540713495), 'nauc_recall_at_1_std': np.float64(-0.32633642504487037), 'nauc_recall_at_1_diff1': np.float64(0.442415220924903), 'nauc_recall_at_3_max': np.float64(0.13349784126665684), 'nauc_recall_at_3_std': np.float64(-0.36851707826931834), 'nauc_recall_at_3_diff1': np.float64(0.3294468226212998), 'nauc_recall_at_5_max': np.float64(0.1574229862898126), 'nauc_recall_at_5_std': np.float64(-0.37021336845016345), 'nauc_recall_at_5_diff1': np.float64(0.30019601472522733), 'nauc_recall_at_10_max': np.float64(0.13738525638458832), 'nauc_recall_at_10_std': np.float64(-0.3767080597427846), 'nauc_recall_at_10_diff1': np.float64(0.2655240459602597), 'nauc_recall_at_20_max': np.float64(0.14563641956858747), 'nauc_recall_at_20_std': np.float64(-0.3718455987040602), 'nauc_recall_at_20_diff1': np.float64(0.28287378473455166), 'nauc_recall_at_100_max': np.float64(0.18123726755872654), 'nauc_recall_at_100_std': np.float64(-0.16172391870580904), 'nauc_recall_at_100_diff1': np.float64(0.27857447314224426), 'nauc_recall_at_1000_max': np.float64(0.8078769144027147), 'nauc_recall_at_1000_std': np.float64(0.5661298338911104), 'nauc_recall_at_1000_diff1': np.float64(0.31723599245329515), 'nauc_precision_at_1_max': np.float64(0.18705489814391954), 'nauc_precision_at_1_std': np.float64(-0.3650591392219447), 'nauc_precision_at_1_diff1': np.float64(0.3911501207226409), 'nauc_precision_at_3_max': np.float64(0.19607002402080267), 'nauc_precision_at_3_std': np.float64(-0.2990473940371217), 'nauc_precision_at_3_diff1': np.float64(0.2074407208120812), 'nauc_precision_at_5_max': np.float64(0.20468110369594059), 'nauc_precision_at_5_std': np.float64(-0.2676930748690739), 'nauc_precision_at_5_diff1': np.float64(0.1551240310063768), 'nauc_precision_at_10_max': np.float64(0.17673210907074197), 'nauc_precision_at_10_std': np.float64(-0.24663683816770868), 'nauc_precision_at_10_diff1': np.float64(0.10416472921288486), 'nauc_precision_at_20_max': np.float64(0.18178207933923418), 'nauc_precision_at_20_std': np.float64(-0.1925409740273971), 'nauc_precision_at_20_diff1': np.float64(0.08225470769603128), 'nauc_precision_at_100_max': np.float64(0.18527888405506773), 'nauc_precision_at_100_std': np.float64(-0.0029822845219024366), 'nauc_precision_at_100_diff1': np.float64(-0.024290174031050264), 'nauc_precision_at_1000_max': np.float64(0.18872529152412684), 'nauc_precision_at_1000_std': np.float64(0.09022595821422812), 'nauc_precision_at_1000_diff1': np.float64(-0.11480603576734166), 'nauc_mrr_at_1_max': np.float64(0.18705489814391954), 'nauc_mrr_at_1_std': np.float64(-0.3650591392219447), 'nauc_mrr_at_1_diff1': np.float64(0.3911501207226409), 'nauc_mrr_at_3_max': np.float64(0.17090757484813163), 'nauc_mrr_at_3_std': np.float64(-0.36403894161816436), 'nauc_mrr_at_3_diff1': np.float64(0.3393043593152651), 'nauc_mrr_at_5_max': np.float64(0.17549053939406056), 'nauc_mrr_at_5_std': np.float64(-0.3616530627902656), 'nauc_mrr_at_5_diff1': np.float64(0.33015829425050686), 'nauc_mrr_at_10_max': np.float64(0.17315014384118496), 'nauc_mrr_at_10_std': np.float64(-0.3604343830457974), 'nauc_mrr_at_10_diff1': np.float64(0.3246797918593084), 'nauc_mrr_at_20_max': np.float64(0.17479356311640967), 'nauc_mrr_at_20_std': np.float64(-0.357988502970068), 'nauc_mrr_at_20_diff1': np.float64(0.3279939285552588), 'nauc_mrr_at_100_max': np.float64(0.1753900314295691), 'nauc_mrr_at_100_std': np.float64(-0.3564385673172796), 'nauc_mrr_at_100_diff1': np.float64(0.3287021893656851), 'nauc_mrr_at_1000_max': np.float64(0.1754101058150354), 'nauc_mrr_at_1000_std': np.float64(-0.35681233083161235), 'nauc_mrr_at_1000_diff1': np.float64(0.3288229531851765), 'main_score': 0.37776}, 'kor-eng': {'ndcg_at_1': 0.30945, 'ndcg_at_3': 0.3425, 'ndcg_at_5': 0.37149, 'ndcg_at_10': 0.40312, 'ndcg_at_20': 0.43129, 'ndcg_at_100': 0.47418, 'ndcg_at_1000': 0.49968, 'map_at_1': 0.2134, 'map_at_3': 0.30776, 'map_at_5': 0.33346, 'map_at_10': 0.34968, 'map_at_20': 0.35906, 'map_at_100': 0.36607, 'map_at_1000': 0.36734, 'recall_at_1': 0.2134, 'recall_at_3': 0.36025, 'recall_at_5': 0.432, 'recall_at_10': 0.51723, 'recall_at_20': 0.61463, 'recall_at_100': 0.8185, 'recall_at_1000': 1.0, 'precision_at_1': 0.30945, 'precision_at_3': 0.19924, 'precision_at_5': 0.14756, 'precision_at_10': 0.08925, 'precision_at_20': 0.05285, 'precision_at_100': 0.0142, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.31107491856677527, 'mrr_at_3': 0.36617806731813246, 'mrr_at_5': 0.3801031487513571, 'mrr_at_10': 0.39179592575358024, 'mrr_at_20': 0.39800399682479065, 'mrr_at_100': 0.402378581032912, 'mrr_at_1000': 0.4031933142071961, 'nauc_ndcg_at_1_max': np.float64(0.21225202404243584), 'nauc_ndcg_at_1_std': np.float64(-0.28680740927948256), 'nauc_ndcg_at_1_diff1': np.float64(0.45991546026333785), 'nauc_ndcg_at_3_max': np.float64(0.20964039713757757), 'nauc_ndcg_at_3_std': np.float64(-0.28507848323303137), 'nauc_ndcg_at_3_diff1': np.float64(0.41062219736675665), 'nauc_ndcg_at_5_max': np.float64(0.1967050255986963), 'nauc_ndcg_at_5_std': np.float64(-0.29089324724287535), 'nauc_ndcg_at_5_diff1': np.float64(0.3926683612185784), 'nauc_ndcg_at_10_max': np.float64(0.19562286989292257), 'nauc_ndcg_at_10_std': np.float64(-0.28030442572619485), 'nauc_ndcg_at_10_diff1': np.float64(0.3773525036414481), 'nauc_ndcg_at_20_max': np.float64(0.1896632646982497), 'nauc_ndcg_at_20_std': np.float64(-0.27119489734983887), 'nauc_ndcg_at_20_diff1': np.float64(0.3611049074446177), 'nauc_ndcg_at_100_max': np.float64(0.22356820248668943), 'nauc_ndcg_at_100_std': np.float64(-0.23728394775508554), 'nauc_ndcg_at_100_diff1': np.float64(0.36421474461919845), 'nauc_ndcg_at_1000_max': np.float64(0.2155930411690076), 'nauc_ndcg_at_1000_std': np.float64(-0.2572508170245179), 'nauc_ndcg_at_1000_diff1': np.float64(0.38069673591139397), 'nauc_map_at_1_max': np.float64(0.12697260386393086), 'nauc_map_at_1_std': np.float64(-0.30219969539726926), 'nauc_map_at_1_diff1': np.float64(0.5284502193651611), 'nauc_map_at_3_max': np.float64(0.19681451360825733), 'nauc_map_at_3_std': np.float64(-0.29802867454210014), 'nauc_map_at_3_diff1': np.float64(0.42806827749183546), 'nauc_map_at_5_max': np.float64(0.1895865107905663), 'nauc_map_at_5_std': np.float64(-0.3039744708922813), 'nauc_map_at_5_diff1': np.float64(0.408174938892977), 'nauc_map_at_10_max': np.float64(0.18878933714104), 'nauc_map_at_10_std': np.float64(-0.3007532894779785), 'nauc_map_at_10_diff1': np.float64(0.39897273672291506), 'nauc_map_at_20_max': np.float64(0.1875236356660587), 'nauc_map_at_20_std': np.float64(-0.29685248096905464), 'nauc_map_at_20_diff1': np.float64(0.3923685076997706), 'nauc_map_at_100_max': np.float64(0.19361610651369365), 'nauc_map_at_100_std': np.float64(-0.29026831051700386), 'nauc_map_at_100_diff1': np.float64(0.392491039063146), 'nauc_map_at_1000_max': np.float64(0.19353388268593502), 'nauc_map_at_1000_std': np.float64(-0.29098200625760073), 'nauc_map_at_1000_diff1': np.float64(0.39338465954863727), 'nauc_recall_at_1_max': np.float64(0.12697260386393086), 'nauc_recall_at_1_std': np.float64(-0.30219969539726926), 'nauc_recall_at_1_diff1': np.float64(0.5284502193651611), 'nauc_recall_at_3_max': np.float64(0.20288412969168287), 'nauc_recall_at_3_std': np.float64(-0.27405421783153033), 'nauc_recall_at_3_diff1': np.float64(0.38772726309125904), 'nauc_recall_at_5_max': np.float64(0.1813632370408345), 'nauc_recall_at_5_std': np.float64(-0.279319030824461), 'nauc_recall_at_5_diff1': np.float64(0.3336376469388931), 'nauc_recall_at_10_max': np.float64(0.1735258033904839), 'nauc_recall_at_10_std': np.float64(-0.24476931864234067), 'nauc_recall_at_10_diff1': np.float64(0.28704652181915036), 'nauc_recall_at_20_max': np.float64(0.13958360665033923), 'nauc_recall_at_20_std': np.float64(-0.21465260893919058), 'nauc_recall_at_20_diff1': np.float64(0.2246909417812956), 'nauc_recall_at_100_max': np.float64(0.330742650630492), 'nauc_recall_at_100_std': np.float64(0.03469047539334661), 'nauc_recall_at_100_diff1': np.float64(0.16486396678746001), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.21225202404243584), 'nauc_precision_at_1_std': np.float64(-0.28680740927948256), 'nauc_precision_at_1_diff1': np.float64(0.45991546026333785), 'nauc_precision_at_3_max': np.float64(0.260151834219551), 'nauc_precision_at_3_std': np.float64(-0.20514439928674294), 'nauc_precision_at_3_diff1': np.float64(0.20416689616674574), 'nauc_precision_at_5_max': np.float64(0.21533292380754193), 'nauc_precision_at_5_std': np.float64(-0.1858043164025223), 'nauc_precision_at_5_diff1': np.float64(0.13786545197514496), 'nauc_precision_at_10_max': np.float64(0.20633134645802148), 'nauc_precision_at_10_std': np.float64(-0.12765557097230817), 'nauc_precision_at_10_diff1': np.float64(0.07737620661518876), 'nauc_precision_at_20_max': np.float64(0.182528630285668), 'nauc_precision_at_20_std': np.float64(-0.07930742824036689), 'nauc_precision_at_20_diff1': np.float64(0.006155500261165618), 'nauc_precision_at_100_max': np.float64(0.28783432418439797), 'nauc_precision_at_100_std': np.float64(0.14700748892799315), 'nauc_precision_at_100_diff1': np.float64(-0.06692312447555882), 'nauc_precision_at_1000_max': np.float64(0.259525377345601), 'nauc_precision_at_1000_std': np.float64(0.1729873052917071), 'nauc_precision_at_1000_diff1': np.float64(-0.09580973411505896), 'nauc_mrr_at_1_max': np.float64(0.21040311999870512), 'nauc_mrr_at_1_std': np.float64(-0.2899645171064577), 'nauc_mrr_at_1_diff1': np.float64(0.4548572138706469), 'nauc_mrr_at_3_max': np.float64(0.21939636358719825), 'nauc_mrr_at_3_std': np.float64(-0.27129935024762425), 'nauc_mrr_at_3_diff1': np.float64(0.4251143417613329), 'nauc_mrr_at_5_max': np.float64(0.21750772166061988), 'nauc_mrr_at_5_std': np.float64(-0.26675507617880095), 'nauc_mrr_at_5_diff1': np.float64(0.41509944366843116), 'nauc_mrr_at_10_max': np.float64(0.21776179845267774), 'nauc_mrr_at_10_std': np.float64(-0.2624163387558126), 'nauc_mrr_at_10_diff1': np.float64(0.4118464337880327), 'nauc_mrr_at_20_max': np.float64(0.2174188467943706), 'nauc_mrr_at_20_std': np.float64(-0.26048438848788497), 'nauc_mrr_at_20_diff1': np.float64(0.40951020100242447), 'nauc_mrr_at_100_max': np.float64(0.21945831247886302), 'nauc_mrr_at_100_std': np.float64(-0.25888675073234096), 'nauc_mrr_at_100_diff1': np.float64(0.40995268172355437), 'nauc_mrr_at_1000_max': np.float64(0.2190005643229683), 'nauc_mrr_at_1000_std': np.float64(-0.2597178303001415), 'nauc_mrr_at_1000_diff1': np.float64(0.41040826302435685), 'main_score': 0.40312}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 200 sentences.
Batches:   0%|          | 0/25 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 1/25 [00:00<00:03,  7.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 3/25 [00:00<00:02, 10.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 5/25 [00:00<00:01, 12.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 7/25 [00:00<00:01, 13.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 9/25 [00:00<00:01, 13.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 11/25 [00:00<00:00, 14.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 13/25 [00:00<00:00, 14.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 15/25 [00:01<00:00, 13.92it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 17/25 [00:01<00:00, 14.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 19/25 [00:01<00:00, 14.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 21/25 [00:01<00:00, 14.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 23/25 [00:01<00:00, 14.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 25/25 [00:01<00:00, 14.44it/s]Batches: 100%|██████████| 25/25 [00:01<00:00, 13.82it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 6176 sentences.
Batches:   0%|          | 0/772 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 1/772 [00:07<1:36:19,  7.50s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 2/772 [00:14<1:34:32,  7.37s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 3/772 [00:22<1:33:54,  7.33s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 4/772 [00:29<1:33:29,  7.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 5/772 [00:36<1:33:05,  7.28s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 6/772 [00:43<1:32:49,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 7/772 [00:51<1:32:28,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 8/772 [00:58<1:32:06,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 9/772 [01:05<1:31:51,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 10/772 [01:12<1:31:38,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 11/772 [01:19<1:31:31,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 12/772 [01:27<1:31:20,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 13/772 [01:34<1:31:10,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 14/772 [01:41<1:31:02,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 15/772 [01:48<1:30:50,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 16/772 [01:55<1:30:43,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 17/772 [02:03<1:30:37,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 18/772 [02:10<1:30:26,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 19/772 [02:17<1:30:18,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 20/772 [02:24<1:30:09,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 21/772 [02:31<1:29:59,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 22/772 [02:38<1:29:51,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 23/772 [02:46<1:29:43,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 24/772 [02:53<1:29:33,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 25/772 [03:00<1:29:27,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 26/772 [03:07<1:29:20,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 27/772 [03:14<1:29:13,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 28/772 [03:22<1:29:05,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 29/772 [03:29<1:28:57,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 30/772 [03:36<1:28:51,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 31/772 [03:43<1:28:44,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 32/772 [03:50<1:28:36,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 33/772 [03:57<1:28:28,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 34/772 [04:05<1:28:17,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 35/772 [04:12<1:28:11,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 36/772 [04:19<1:28:03,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 37/772 [04:26<1:27:56,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 38/772 [04:33<1:27:49,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 39/772 [04:41<1:27:41,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 40/772 [04:48<1:27:29,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 41/772 [04:55<1:27:24,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 42/772 [05:02<1:27:15,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 43/772 [05:09<1:27:08,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 44/772 [05:16<1:27:00,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 45/772 [05:24<1:26:53,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 46/772 [05:31<1:26:43,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 47/772 [05:38<1:26:37,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 48/772 [05:45<1:26:30,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 49/772 [05:52<1:26:22,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 50/772 [05:59<1:26:15,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 51/772 [06:07<1:26:07,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 52/772 [06:14<1:25:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 53/772 [06:21<1:25:51,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 54/772 [06:28<1:25:45,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 55/772 [06:35<1:25:38,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 56/772 [06:42<1:25:29,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 57/772 [06:50<1:25:22,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 58/772 [06:57<1:25:13,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 59/772 [07:04<1:25:04,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 60/772 [07:11<1:24:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 61/772 [07:18<1:24:51,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 62/772 [07:25<1:24:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 63/772 [07:33<1:24:40,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 64/772 [07:40<1:24:32,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 65/772 [07:47<1:24:24,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▊         | 66/772 [07:54<1:24:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▊         | 67/772 [08:01<1:24:08,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 68/772 [08:08<1:24:01,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 69/772 [08:15<1:23:54,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 70/772 [08:23<1:23:47,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 71/772 [08:30<1:23:39,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 72/772 [08:37<1:23:31,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 73/772 [08:44<1:23:25,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 74/772 [08:51<1:23:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 75/772 [08:58<1:23:08,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 76/772 [09:06<1:23:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 77/772 [09:13<1:22:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 78/772 [09:20<1:22:46,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 79/772 [09:27<1:22:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 80/772 [09:34<1:22:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 81/772 [09:41<1:22:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 82/772 [09:49<1:22:19,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 83/772 [09:56<1:22:11,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 84/772 [10:03<1:22:02,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 85/772 [10:10<1:21:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 86/772 [10:17<1:21:47,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█▏        | 87/772 [10:24<1:21:40,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█▏        | 88/772 [10:31<1:21:32,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 89/772 [10:39<1:21:25,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 90/772 [10:46<1:21:17,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 91/772 [10:53<1:21:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 92/772 [11:00<1:21:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 93/772 [11:07<1:20:59,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 94/772 [11:14<1:20:51,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 95/772 [11:22<1:20:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 96/772 [11:29<1:20:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 97/772 [11:36<1:20:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 98/772 [11:43<1:20:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 99/772 [11:50<1:20:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 100/772 [11:57<1:20:07,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 101/772 [12:04<1:20:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 102/772 [12:12<1:19:51,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 103/772 [12:19<1:19:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 104/772 [12:26<1:19:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▎        | 105/772 [12:33<1:19:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▎        | 106/772 [12:40<1:19:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 107/772 [12:47<1:19:15,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 108/772 [12:54<1:19:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 109/772 [13:02<1:19:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 110/772 [13:09<1:18:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 111/772 [13:16<1:18:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 112/772 [13:23<1:18:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 113/772 [13:30<1:18:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 114/772 [13:37<1:18:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 115/772 [13:45<1:18:17,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 116/772 [13:52<1:18:11,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 117/772 [13:59<1:18:04,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 118/772 [14:06<1:17:56,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 119/772 [14:13<1:17:49,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 120/772 [14:20<1:17:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 121/772 [14:27<1:17:32,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 122/772 [14:35<1:17:25,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 123/772 [14:42<1:17:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 124/772 [14:49<1:17:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 125/772 [14:56<1:17:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 126/772 [15:03<1:16:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 127/772 [15:10<1:16:51,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 128/772 [15:17<1:16:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 129/772 [15:25<1:16:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 130/772 [15:32<1:16:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 131/772 [15:39<1:16:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 132/772 [15:46<1:16:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 133/772 [15:53<1:16:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 134/772 [16:00<1:16:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 135/772 [16:08<1:15:54,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 136/772 [16:15<1:15:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 137/772 [16:22<1:15:41,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 138/772 [16:29<1:15:33,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 139/772 [16:36<1:15:26,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 140/772 [16:43<1:15:19,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 141/772 [16:50<1:15:11,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 142/772 [16:58<1:15:03,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▊        | 143/772 [17:05<1:14:57,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▊        | 144/772 [17:12<1:14:50,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 145/772 [17:19<1:14:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 146/772 [17:26<1:14:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 147/772 [17:33<1:14:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 148/772 [17:40<1:14:22,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 149/772 [17:48<1:14:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 150/772 [17:55<1:14:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 151/772 [18:02<1:14:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 152/772 [18:09<1:13:54,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 153/772 [18:16<1:13:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 154/772 [18:23<1:13:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 155/772 [18:31<1:13:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 156/772 [18:38<1:13:25,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 157/772 [18:45<1:13:18,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 158/772 [18:52<1:13:11,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 159/772 [18:59<1:13:03,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 160/772 [19:06<1:12:57,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 161/772 [19:13<1:12:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 162/772 [19:21<1:12:52,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 163/772 [19:28<1:12:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 164/772 [19:35<1:12:33,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 165/772 [19:42<1:12:23,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 166/772 [19:49<1:12:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 167/772 [19:56<1:12:07,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 168/772 [20:04<1:11:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 169/772 [20:11<1:11:52,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 170/772 [20:18<1:11:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 171/772 [20:25<1:11:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 172/772 [20:32<1:11:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 173/772 [20:39<1:11:22,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 174/772 [20:46<1:11:14,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 175/772 [20:54<1:11:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 176/772 [21:01<1:11:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 177/772 [21:08<1:10:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 178/772 [21:15<1:10:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 179/772 [21:22<1:10:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 180/772 [21:29<1:10:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 181/772 [21:36<1:10:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 182/772 [21:44<1:10:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 183/772 [21:51<1:10:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 184/772 [21:58<1:10:04,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 185/772 [22:05<1:09:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 186/772 [22:12<1:09:48,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 187/772 [22:19<1:09:41,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 188/772 [22:27<1:09:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 189/772 [22:34<1:09:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 190/772 [22:41<1:09:24,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 191/772 [22:48<1:09:19,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 192/772 [22:55<1:09:12,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 193/772 [23:02<1:09:06,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 194/772 [23:10<1:08:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 195/772 [23:17<1:08:52,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 196/772 [23:24<1:08:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 197/772 [23:31<1:08:38,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 198/772 [23:38<1:08:31,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 199/772 [23:45<1:08:24,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 200/772 [23:52<1:08:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 201/772 [24:00<1:08:09,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 202/772 [24:07<1:08:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 203/772 [24:14<1:07:51,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 204/772 [24:21<1:07:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 205/772 [24:28<1:07:36,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 206/772 [24:35<1:07:29,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 207/772 [24:43<1:07:25,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 208/772 [24:50<1:07:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 209/772 [24:57<1:07:08,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 210/772 [25:04<1:07:01,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 211/772 [25:11<1:06:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 212/772 [25:18<1:06:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 213/772 [25:25<1:06:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 214/772 [25:33<1:06:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 215/772 [25:40<1:06:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 216/772 [25:47<1:06:17,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 217/772 [25:54<1:06:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 218/772 [26:01<1:05:59,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 219/772 [26:08<1:05:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 220/772 [26:16<1:05:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 221/772 [26:23<1:05:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 222/772 [26:30<1:05:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 223/772 [26:37<1:05:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 224/772 [26:44<1:05:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 225/772 [26:51<1:05:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 226/772 [26:58<1:05:02,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 227/772 [27:06<1:04:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 228/772 [27:13<1:04:47,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 229/772 [27:20<1:04:40,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 230/772 [27:27<1:04:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 231/772 [27:34<1:04:32,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 232/772 [27:41<1:04:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 233/772 [27:48<1:04:15,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 234/772 [27:56<1:04:07,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 235/772 [28:03<1:03:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 236/772 [28:10<1:03:51,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 237/772 [28:17<1:03:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 238/772 [28:24<1:03:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 239/772 [28:31<1:03:32,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 240/772 [28:39<1:03:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 241/772 [28:46<1:03:17,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 242/772 [28:53<1:03:10,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 243/772 [29:00<1:03:02,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 244/772 [29:07<1:02:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 245/772 [29:14<1:02:48,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 246/772 [29:21<1:02:41,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 247/772 [29:29<1:02:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 248/772 [29:36<1:02:27,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 249/772 [29:43<1:02:23,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 250/772 [29:50<1:02:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 251/772 [29:57<1:02:07,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 252/772 [30:04<1:02:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 253/772 [30:12<1:01:51,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 254/772 [30:19<1:01:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 255/772 [30:26<1:01:39,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 256/772 [30:33<1:01:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 257/772 [30:40<1:01:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 258/772 [30:47<1:01:15,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 259/772 [30:54<1:01:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 260/772 [31:02<1:01:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 261/772 [31:09<1:01:29,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 262/772 [31:16<1:01:11,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 263/772 [31:23<1:00:56,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 264/772 [31:30<1:00:44,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 265/772 [31:38<1:00:32,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 266/772 [31:45<1:00:23,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 267/772 [31:52<1:00:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 268/772 [31:59<1:00:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 269/772 [32:06<1:00:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 270/772 [32:13<59:52,  7.16s/it]  WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 271/772 [32:20<59:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 272/772 [32:28<59:38,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 273/772 [32:35<59:31,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 274/772 [32:42<59:25,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 275/772 [32:49<59:17,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 276/772 [32:56<59:10,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 277/772 [33:03<58:59,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 278/772 [33:11<58:51,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 279/772 [33:18<58:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 280/772 [33:25<58:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 281/772 [33:32<58:33,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 282/772 [33:39<58:27,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 283/772 [33:46<58:21,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 284/772 [33:54<58:15,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 285/772 [34:01<58:08,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 286/772 [34:08<58:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 287/772 [34:15<57:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 288/772 [34:22<57:43,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 289/772 [34:29<57:34,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 290/772 [34:36<57:26,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 291/772 [34:44<57:22,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 292/772 [34:51<57:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 293/772 [34:58<57:08,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 294/772 [35:05<57:01,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 295/772 [35:12<56:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 296/772 [35:19<56:49,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 297/772 [35:27<56:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 298/772 [35:34<56:35,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 299/772 [35:41<56:29,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 300/772 [35:48<56:22,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 301/772 [35:55<56:16,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 302/772 [36:02<56:14,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 303/772 [36:10<56:06,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 304/772 [36:17<55:56,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 305/772 [36:24<55:50,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 306/772 [36:31<55:38,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 307/772 [36:38<55:31,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 308/772 [36:45<55:24,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 309/772 [36:53<55:17,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 310/772 [37:00<55:10,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 311/772 [37:07<55:02,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 312/772 [37:14<54:59,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 313/772 [37:21<54:52,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 314/772 [37:28<54:45,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 315/772 [37:36<54:37,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 316/772 [37:43<54:27,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 317/772 [37:50<54:19,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 318/772 [37:57<54:15,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 319/772 [38:04<54:08,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 320/772 [38:11<54:02,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 321/772 [38:19<53:53,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 322/772 [38:26<53:46,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 323/772 [38:33<53:39,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 324/772 [38:40<53:34,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 325/772 [38:47<53:29,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 326/772 [38:55<53:21,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 327/772 [39:02<53:14,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 328/772 [39:09<53:07,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 329/772 [39:16<53:01,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 330/772 [39:23<52:52,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 331/772 [39:30<52:46,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 332/772 [39:38<52:39,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 333/772 [39:45<52:32,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 334/772 [39:52<52:24,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 335/772 [39:59<52:18,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 336/772 [40:06<52:10,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 337/772 [40:14<52:04,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 338/772 [40:21<51:56,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 339/772 [40:28<51:49,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 340/772 [40:35<51:42,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 341/772 [40:42<51:34,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 342/772 [40:49<51:30,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 343/772 [40:57<51:23,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 344/772 [41:04<51:16,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 345/772 [41:11<51:09,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 346/772 [41:18<51:02,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 347/772 [41:25<50:56,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 348/772 [41:33<50:49,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 349/772 [41:40<50:40,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 350/772 [41:47<50:46,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 351/772 [41:54<50:35,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 352/772 [42:01<50:22,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 353/772 [42:09<50:13,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 354/772 [42:16<50:06,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 355/772 [42:23<49:59,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 356/772 [42:30<49:52,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 357/772 [42:37<49:46,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 358/772 [42:45<49:35,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 359/772 [42:52<49:10,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 360/772 [42:59<49:10,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 361/772 [43:06<48:29,  7.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 362/772 [43:13<48:37,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 363/772 [43:20<48:39,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 364/772 [43:27<48:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 365/772 [43:34<48:20,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 366/772 [43:42<48:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 367/772 [43:49<48:21,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 368/772 [43:56<48:18,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 369/772 [44:03<48:39,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 370/772 [44:11<48:24,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 371/772 [44:18<48:12,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 372/772 [44:25<48:02,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 373/772 [44:32<47:42,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 374/772 [44:40<48:26,  7.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 375/772 [44:47<48:04,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 376/772 [44:54<48:36,  7.36s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 377/772 [45:01<47:51,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 378/772 [45:09<47:33,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 379/772 [45:16<47:19,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 380/772 [45:23<47:08,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 381/772 [45:30<46:59,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 382/772 [45:37<45:20,  6.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 383/772 [45:44<45:42,  7.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 384/772 [45:51<45:51,  7.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 385/772 [45:59<46:40,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 386/772 [46:06<46:27,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 387/772 [46:13<46:17,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 388/772 [46:20<46:20,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 389/772 [46:28<46:11,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 390/772 [46:35<46:00,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 391/772 [46:42<45:48,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 392/772 [46:49<45:39,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 393/772 [46:56<45:31,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 394/772 [47:03<45:06,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 395/772 [47:11<45:05,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 396/772 [47:18<45:11,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 397/772 [47:25<45:24,  7.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 398/772 [47:32<45:06,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 399/772 [47:39<44:36,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 400/772 [47:46<43:58,  7.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 401/772 [47:54<44:03,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 402/772 [48:01<43:52,  7.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 403/772 [48:08<43:55,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 404/772 [48:15<44:13,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 405/772 [48:22<44:02,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 406/772 [48:29<43:26,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 407/772 [48:37<43:27,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 408/772 [48:42<39:59,  6.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 409/772 [48:49<40:39,  6.72s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 410/772 [48:56<42:05,  6.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 411/772 [49:03<41:01,  6.82s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 412/772 [49:10<41:36,  6.93s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 413/772 [49:17<41:30,  6.94s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 414/772 [49:24<42:07,  7.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 415/772 [49:32<42:28,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 416/772 [49:39<43:08,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 417/772 [49:46<42:25,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 418/772 [49:53<42:05,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 419/772 [50:00<41:54,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 420/772 [50:08<41:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 421/772 [50:15<42:08,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 422/772 [50:20<38:21,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 423/772 [50:26<37:47,  6.50s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 424/772 [50:33<38:09,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 425/772 [50:40<39:06,  6.76s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 426/772 [50:48<39:47,  6.90s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 427/772 [50:53<37:17,  6.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 428/772 [51:00<38:27,  6.71s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 429/772 [51:07<38:25,  6.72s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 430/772 [51:14<39:08,  6.87s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 431/772 [51:20<36:28,  6.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 432/772 [51:27<37:43,  6.66s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 433/772 [51:32<35:31,  6.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 434/772 [51:38<35:20,  6.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 435/772 [51:45<35:12,  6.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 436/772 [51:51<35:29,  6.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 437/772 [51:58<36:08,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 438/772 [52:04<35:59,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 439/772 [52:11<35:59,  6.48s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 440/772 [52:16<33:21,  6.03s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 441/772 [52:23<34:34,  6.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 442/772 [52:29<34:12,  6.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 443/772 [52:36<35:43,  6.52s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 444/772 [52:43<36:35,  6.69s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 445/772 [52:50<35:54,  6.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 446/772 [52:56<35:12,  6.48s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 447/772 [53:03<36:20,  6.71s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 448/772 [53:09<35:43,  6.62s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 449/772 [53:16<35:57,  6.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 450/772 [53:22<35:01,  6.53s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 451/772 [53:29<35:27,  6.63s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 452/772 [53:36<36:09,  6.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 453/772 [53:43<35:57,  6.76s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 454/772 [53:49<34:25,  6.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 455/772 [53:55<34:09,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 456/772 [54:01<33:13,  6.31s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 457/772 [54:08<33:01,  6.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 458/772 [54:15<34:24,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 459/772 [54:21<33:58,  6.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 460/772 [54:27<32:52,  6.32s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 461/772 [54:33<32:02,  6.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 462/772 [54:40<33:23,  6.46s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 463/772 [54:46<32:58,  6.40s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 464/772 [54:51<30:22,  5.92s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 465/772 [54:57<30:33,  5.97s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 466/772 [55:05<32:33,  6.38s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 467/772 [55:09<29:55,  5.89s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 468/772 [55:16<31:06,  6.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 469/772 [55:20<27:37,  5.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 470/772 [55:25<26:41,  5.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 471/772 [55:30<25:44,  5.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 472/772 [55:34<24:32,  4.91s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████▏   | 473/772 [55:39<24:13,  4.86s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████▏   | 474/772 [55:44<24:07,  4.86s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 475/772 [55:48<22:54,  4.63s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 476/772 [55:52<22:47,  4.62s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 477/772 [55:56<21:20,  4.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 478/772 [55:59<19:13,  3.92s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 479/772 [56:03<19:30,  3.99s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 480/772 [56:06<18:22,  3.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 481/772 [56:09<17:23,  3.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 482/772 [56:13<16:56,  3.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 483/772 [56:17<17:14,  3.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 484/772 [56:20<16:52,  3.52s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 485/772 [56:23<16:17,  3.41s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 486/772 [56:26<15:28,  3.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 487/772 [56:29<14:56,  3.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 488/772 [56:32<14:17,  3.02s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 489/772 [56:34<13:53,  2.94s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 490/772 [56:37<13:59,  2.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 491/772 [56:40<14:02,  3.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 492/772 [56:43<14:05,  3.02s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 493/772 [56:46<13:50,  2.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 494/772 [56:49<12:54,  2.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 495/772 [56:51<12:48,  2.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 496/772 [56:54<12:25,  2.70s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 497/772 [56:57<12:20,  2.69s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 498/772 [56:59<11:33,  2.53s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 499/772 [57:01<10:43,  2.36s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 500/772 [57:04<11:14,  2.48s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 501/772 [57:06<11:15,  2.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 502/772 [57:08<10:55,  2.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 503/772 [57:10<10:14,  2.28s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 504/772 [57:12<10:01,  2.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 505/772 [57:14<09:39,  2.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 506/772 [57:16<09:22,  2.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 507/772 [57:19<09:24,  2.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 508/772 [57:21<09:16,  2.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 509/772 [57:23<09:25,  2.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 510/772 [57:25<08:44,  2.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 511/772 [57:27<08:56,  2.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▋   | 512/772 [57:29<09:10,  2.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▋   | 513/772 [57:31<09:01,  2.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 514/772 [57:33<08:56,  2.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 515/772 [57:35<09:10,  2.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 516/772 [57:37<08:33,  2.01s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 517/772 [57:39<08:42,  2.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 518/772 [57:41<08:58,  2.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 519/772 [57:43<08:34,  2.03s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 520/772 [57:45<08:26,  2.01s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 521/772 [57:47<07:49,  1.87s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 522/772 [57:48<07:26,  1.79s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 523/772 [57:50<07:02,  1.70s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 524/772 [57:52<07:17,  1.76s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 525/772 [57:54<07:12,  1.75s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 526/772 [57:55<07:21,  1.80s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 527/772 [57:57<07:31,  1.84s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 528/772 [57:59<07:05,  1.74s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 529/772 [58:00<06:47,  1.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 530/772 [58:02<06:34,  1.63s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 531/772 [58:04<07:01,  1.75s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 532/772 [58:05<06:43,  1.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 533/772 [58:07<06:33,  1.65s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 534/772 [58:08<06:18,  1.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 535/772 [58:10<06:31,  1.65s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 536/772 [58:12<06:16,  1.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 537/772 [58:13<05:51,  1.50s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 538/772 [58:14<05:48,  1.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 539/772 [58:16<05:31,  1.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 540/772 [58:17<05:33,  1.44s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 541/772 [58:19<05:35,  1.45s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 542/772 [58:20<05:09,  1.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 543/772 [58:21<05:06,  1.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 544/772 [58:23<05:45,  1.52s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 545/772 [58:24<05:22,  1.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 546/772 [58:26<05:22,  1.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 547/772 [58:27<05:21,  1.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 548/772 [58:29<05:16,  1.41s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 549/772 [58:30<05:04,  1.37s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 550/772 [58:31<05:00,  1.35s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 551/772 [58:32<04:47,  1.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 552/772 [58:33<04:36,  1.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 553/772 [58:35<04:38,  1.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 554/772 [58:36<04:29,  1.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 555/772 [58:37<04:46,  1.32s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 556/772 [58:38<04:28,  1.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 557/772 [58:40<04:17,  1.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 558/772 [58:41<04:18,  1.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 559/772 [58:42<04:10,  1.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 560/772 [58:43<04:03,  1.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 561/772 [58:44<04:00,  1.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 562/772 [58:45<03:41,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 563/772 [58:46<03:40,  1.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 564/772 [58:47<03:38,  1.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 565/772 [58:48<03:41,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 566/772 [58:49<03:45,  1.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 567/772 [58:50<03:42,  1.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▎  | 568/772 [58:51<03:35,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▎  | 569/772 [58:53<03:51,  1.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 570/772 [58:54<03:47,  1.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 571/772 [58:55<03:35,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 572/772 [58:56<03:42,  1.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 573/772 [58:57<03:34,  1.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 574/772 [58:58<03:31,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 575/772 [58:59<03:40,  1.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 576/772 [59:00<03:36,  1.10s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 577/772 [59:01<03:22,  1.04s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 578/772 [59:02<03:26,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 579/772 [59:03<03:24,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 580/772 [59:04<03:23,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 581/772 [59:05<03:22,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 582/772 [59:06<03:17,  1.04s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 583/772 [59:07<03:03,  1.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 584/772 [59:08<03:01,  1.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 585/772 [59:09<02:46,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 586/772 [59:10<02:43,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 587/772 [59:11<02:45,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 588/772 [59:12<02:42,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▋  | 589/772 [59:12<02:43,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▋  | 590/772 [59:13<02:47,  1.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 591/772 [59:14<02:49,  1.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 592/772 [59:15<02:39,  1.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 593/772 [59:16<02:33,  1.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 594/772 [59:17<02:33,  1.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 595/772 [59:18<02:33,  1.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 596/772 [59:19<02:35,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 597/772 [59:19<02:26,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 598/772 [59:20<02:32,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 599/772 [59:21<02:32,  1.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 600/772 [59:22<02:34,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 601/772 [59:23<02:35,  1.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 602/772 [59:24<02:27,  1.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 603/772 [59:25<02:20,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 604/772 [59:26<02:21,  1.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 605/772 [59:26<02:12,  1.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 606/772 [59:27<02:15,  1.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 607/772 [59:28<02:13,  1.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 608/772 [59:29<02:07,  1.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 609/772 [59:29<02:04,  1.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 610/772 [59:30<02:15,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 611/772 [59:31<02:11,  1.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 612/772 [59:32<02:13,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 613/772 [59:33<02:07,  1.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 614/772 [59:33<02:03,  1.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 615/772 [59:34<02:00,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 616/772 [59:35<01:56,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 617/772 [59:36<01:56,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 618/772 [59:36<01:52,  1.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 619/772 [59:37<02:01,  1.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 620/772 [59:38<02:02,  1.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 621/772 [59:39<01:59,  1.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 622/772 [59:40<01:55,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 623/772 [59:40<01:51,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 624/772 [59:41<01:49,  1.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 625/772 [59:42<01:45,  1.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 626/772 [59:42<01:46,  1.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 627/772 [59:43<01:45,  1.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 628/772 [59:44<01:40,  1.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 629/772 [59:45<01:47,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 630/772 [59:45<01:46,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 631/772 [59:46<01:49,  1.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 632/772 [59:47<01:45,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 633/772 [59:48<01:45,  1.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 634/772 [59:48<01:39,  1.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 635/772 [59:49<01:33,  1.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 636/772 [59:50<01:34,  1.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 637/772 [59:50<01:39,  1.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 638/772 [59:51<01:34,  1.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 639/772 [59:52<01:35,  1.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 640/772 [59:53<01:33,  1.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 641/772 [59:53<01:30,  1.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 642/772 [59:54<01:26,  1.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 643/772 [59:54<01:23,  1.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 644/772 [59:55<01:20,  1.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 645/772 [59:56<01:21,  1.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 646/772 [59:56<01:20,  1.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 647/772 [59:57<01:19,  1.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 648/772 [59:58<01:20,  1.54it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 649/772 [59:58<01:22,  1.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 650/772 [59:59<01:20,  1.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 651/772 [1:00:00<01:17,  1.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 652/772 [1:00:00<01:16,  1.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 653/772 [1:00:01<01:14,  1.59it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 654/772 [1:00:01<01:11,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 655/772 [1:00:02<01:11,  1.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 656/772 [1:00:03<01:09,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 657/772 [1:00:03<01:11,  1.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 658/772 [1:00:04<01:09,  1.64it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 659/772 [1:00:04<01:08,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 660/772 [1:00:05<01:07,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 661/772 [1:00:06<01:06,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 662/772 [1:00:06<01:05,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 663/772 [1:00:07<01:04,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 664/772 [1:00:07<01:04,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 665/772 [1:00:08<01:05,  1.63it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 666/772 [1:00:09<01:03,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 667/772 [1:00:09<01:02,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 668/772 [1:00:10<01:01,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 669/772 [1:00:10<01:02,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 670/772 [1:00:11<01:00,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 671/772 [1:00:11<00:58,  1.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 672/772 [1:00:12<00:56,  1.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 673/772 [1:00:13<00:58,  1.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 674/772 [1:00:13<00:56,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 675/772 [1:00:14<00:56,  1.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 676/772 [1:00:14<00:56,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 677/772 [1:00:15<00:57,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 678/772 [1:00:16<00:55,  1.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 679/772 [1:00:16<00:53,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 680/772 [1:00:17<00:51,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 681/772 [1:00:17<00:51,  1.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 682/772 [1:00:18<00:50,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 683/772 [1:00:18<00:49,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 684/772 [1:00:19<00:49,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 685/772 [1:00:19<00:49,  1.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 686/772 [1:00:20<00:48,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 687/772 [1:00:21<00:49,  1.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 688/772 [1:00:21<00:50,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 689/772 [1:00:22<00:49,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 690/772 [1:00:22<00:47,  1.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 691/772 [1:00:23<00:46,  1.74it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 692/772 [1:00:24<00:44,  1.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 693/772 [1:00:24<00:43,  1.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 694/772 [1:00:25<00:42,  1.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 695/772 [1:00:25<00:42,  1.83it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 696/772 [1:00:26<00:40,  1.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 697/772 [1:00:26<00:40,  1.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 698/772 [1:00:27<00:40,  1.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 699/772 [1:00:27<00:42,  1.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 700/772 [1:00:28<00:42,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 701/772 [1:00:29<00:40,  1.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 702/772 [1:00:29<00:37,  1.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 703/772 [1:00:30<00:36,  1.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 704/772 [1:00:30<00:34,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 705/772 [1:00:30<00:34,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 706/772 [1:00:31<00:33,  1.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 707/772 [1:00:32<00:33,  1.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 708/772 [1:00:32<00:32,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 709/772 [1:00:32<00:30,  2.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 710/772 [1:00:33<00:29,  2.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 711/772 [1:00:33<00:29,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 712/772 [1:00:34<00:29,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 713/772 [1:00:34<00:28,  2.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 714/772 [1:00:35<00:28,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 715/772 [1:00:35<00:28,  2.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 716/772 [1:00:36<00:27,  2.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 717/772 [1:00:36<00:25,  2.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 718/772 [1:00:37<00:25,  2.15it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 719/772 [1:00:37<00:25,  2.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 720/772 [1:00:38<00:24,  2.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 721/772 [1:00:38<00:25,  1.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 722/772 [1:00:39<00:24,  2.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 723/772 [1:00:39<00:24,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 724/772 [1:00:40<00:23,  2.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 725/772 [1:00:40<00:22,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 726/772 [1:00:41<00:21,  2.13it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 727/772 [1:00:41<00:21,  2.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 728/772 [1:00:42<00:20,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 729/772 [1:00:42<00:21,  2.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 730/772 [1:00:43<00:20,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 731/772 [1:00:43<00:19,  2.11it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 732/772 [1:00:43<00:18,  2.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 733/772 [1:00:44<00:17,  2.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 734/772 [1:00:44<00:17,  2.18it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 735/772 [1:00:45<00:16,  2.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 736/772 [1:00:45<00:15,  2.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 737/772 [1:00:46<00:15,  2.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 738/772 [1:00:46<00:15,  2.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 739/772 [1:00:47<00:14,  2.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 740/772 [1:00:47<00:14,  2.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 741/772 [1:00:47<00:14,  2.21it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 742/772 [1:00:48<00:13,  2.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 743/772 [1:00:48<00:13,  2.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 744/772 [1:00:49<00:12,  2.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 745/772 [1:00:49<00:11,  2.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 746/772 [1:00:50<00:11,  2.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 747/772 [1:00:50<00:10,  2.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 748/772 [1:00:50<00:10,  2.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 749/772 [1:00:51<00:09,  2.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 750/772 [1:00:51<00:09,  2.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 751/772 [1:00:52<00:08,  2.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 752/772 [1:00:52<00:08,  2.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 753/772 [1:00:52<00:07,  2.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 754/772 [1:00:53<00:07,  2.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 755/772 [1:00:53<00:07,  2.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 756/772 [1:00:54<00:07,  2.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 757/772 [1:00:54<00:06,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 758/772 [1:00:55<00:06,  2.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 759/772 [1:00:55<00:05,  2.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 760/772 [1:00:56<00:05,  2.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 761/772 [1:00:56<00:04,  2.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 762/772 [1:00:56<00:04,  2.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 763/772 [1:00:57<00:03,  2.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 764/772 [1:00:57<00:03,  2.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 765/772 [1:00:58<00:02,  2.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 766/772 [1:00:58<00:02,  2.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 767/772 [1:00:58<00:02,  2.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 768/772 [1:00:59<00:01,  2.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 769/772 [1:00:59<00:01,  2.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 770/772 [1:01:00<00:00,  2.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 771/772 [1:01:00<00:00,  2.53it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 772/772 [1:01:00<00:00,  2.54it/s]Batches: 100%|██████████| 772/772 [1:01:00<00:00,  4.74s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3668.30 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 3668.62 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.19, 'ndcg_at_3': 0.27625, 'ndcg_at_5': 0.29044, 'ndcg_at_10': 0.30183, 'ndcg_at_20': 0.32443, 'ndcg_at_100': 0.35985, 'ndcg_at_1000': 0.38364, 'map_at_1': 0.19, 'map_at_3': 0.25583, 'map_at_5': 0.26358, 'map_at_10': 0.26831, 'map_at_20': 0.27445, 'map_at_100': 0.27945, 'map_at_1000': 0.28021, 'recall_at_1': 0.19, 'recall_at_3': 0.335, 'recall_at_5': 0.37, 'recall_at_10': 0.405, 'recall_at_20': 0.495, 'recall_at_100': 0.685, 'recall_at_1000': 0.88, 'precision_at_1': 0.19, 'precision_at_3': 0.11167, 'precision_at_5': 0.074, 'precision_at_10': 0.0405, 'precision_at_20': 0.02475, 'precision_at_100': 0.00685, 'precision_at_1000': 0.00088, 'mrr_at_1': 0.19, 'mrr_at_3': 0.2558333333333333, 'mrr_at_5': 0.2635833333333333, 'mrr_at_10': 0.2683095238095238, 'mrr_at_20': 0.27444691134029364, 'mrr_at_100': 0.27945142637245124, 'mrr_at_1000': 0.2802141069060249, 'nauc_ndcg_at_1_max': np.float64(0.35655675684764515), 'nauc_ndcg_at_1_std': np.float64(-0.1400551510769592), 'nauc_ndcg_at_1_diff1': np.float64(0.5211944916180451), 'nauc_ndcg_at_3_max': np.float64(0.3484601080747563), 'nauc_ndcg_at_3_std': np.float64(-0.11125178120309083), 'nauc_ndcg_at_3_diff1': np.float64(0.39091228288620145), 'nauc_ndcg_at_5_max': np.float64(0.37094692254027894), 'nauc_ndcg_at_5_std': np.float64(-0.08979216816388912), 'nauc_ndcg_at_5_diff1': np.float64(0.4063442961060187), 'nauc_ndcg_at_10_max': np.float64(0.3694191486115541), 'nauc_ndcg_at_10_std': np.float64(-0.07135404747597227), 'nauc_ndcg_at_10_diff1': np.float64(0.3885450566571815), 'nauc_ndcg_at_20_max': np.float64(0.3603871875450114), 'nauc_ndcg_at_20_std': np.float64(-0.04851489855677469), 'nauc_ndcg_at_20_diff1': np.float64(0.37464341452428185), 'nauc_ndcg_at_100_max': np.float64(0.3540165468027114), 'nauc_ndcg_at_100_std': np.float64(-0.034715662232047625), 'nauc_ndcg_at_100_diff1': np.float64(0.3660852517851678), 'nauc_ndcg_at_1000_max': np.float64(0.35987950198965346), 'nauc_ndcg_at_1000_std': np.float64(-0.03497125809059364), 'nauc_ndcg_at_1000_diff1': np.float64(0.37457473529468), 'nauc_map_at_1_max': np.float64(0.35655675684764515), 'nauc_map_at_1_std': np.float64(-0.1400551510769592), 'nauc_map_at_1_diff1': np.float64(0.5211944916180451), 'nauc_map_at_3_max': np.float64(0.349260526149033), 'nauc_map_at_3_std': np.float64(-0.1181344111606315), 'nauc_map_at_3_diff1': np.float64(0.414834704017872), 'nauc_map_at_5_max': np.float64(0.3620373153044118), 'nauc_map_at_5_std': np.float64(-0.1063718408135385), 'nauc_map_at_5_diff1': np.float64(0.42410498042603806), 'nauc_map_at_10_max': np.float64(0.3612814802039768), 'nauc_map_at_10_std': np.float64(-0.09796237440028156), 'nauc_map_at_10_diff1': np.float64(0.41632061458243397), 'nauc_map_at_20_max': np.float64(0.35896349994164234), 'nauc_map_at_20_std': np.float64(-0.09144807122351122), 'nauc_map_at_20_diff1': np.float64(0.4132713267533961), 'nauc_map_at_100_max': np.float64(0.35861184138421914), 'nauc_map_at_100_std': np.float64(-0.08948585848296406), 'nauc_map_at_100_diff1': np.float64(0.41312819959261254), 'nauc_map_at_1000_max': np.float64(0.35861517894300016), 'nauc_map_at_1000_std': np.float64(-0.08961687006438877), 'nauc_map_at_1000_diff1': np.float64(0.41357541926524327), 'nauc_recall_at_1_max': np.float64(0.35655675684764515), 'nauc_recall_at_1_std': np.float64(-0.1400551510769592), 'nauc_recall_at_1_diff1': np.float64(0.5211944916180451), 'nauc_recall_at_3_max': np.float64(0.34674511418496695), 'nauc_recall_at_3_std': np.float64(-0.09329366686809806), 'nauc_recall_at_3_diff1': np.float64(0.3308674604386774), 'nauc_recall_at_5_max': np.float64(0.39698873059193784), 'nauc_recall_at_5_std': np.float64(-0.04398725499157721), 'nauc_recall_at_5_diff1': np.float64(0.36414682876506604), 'nauc_recall_at_10_max': np.float64(0.3928831634396537), 'nauc_recall_at_10_std': np.float64(0.004539094889004945), 'nauc_recall_at_10_diff1': np.float64(0.3154864375197454), 'nauc_recall_at_20_max': np.float64(0.35894468719033273), 'nauc_recall_at_20_std': np.float64(0.08968961779161094), 'nauc_recall_at_20_diff1': np.float64(0.256665536069379), 'nauc_recall_at_100_max': np.float64(0.3119714437821278), 'nauc_recall_at_100_std': np.float64(0.21593457903142727), 'nauc_recall_at_100_diff1': np.float64(0.15504315724247417), 'nauc_recall_at_1000_max': np.float64(0.3981466751511301), 'nauc_recall_at_1000_std': np.float64(0.5251352211263131), 'nauc_recall_at_1000_diff1': np.float64(0.04022828507795085), 'nauc_precision_at_1_max': np.float64(0.35655675684764515), 'nauc_precision_at_1_std': np.float64(-0.1400551510769592), 'nauc_precision_at_1_diff1': np.float64(0.5211944916180451), 'nauc_precision_at_3_max': np.float64(0.34674511418496706), 'nauc_precision_at_3_std': np.float64(-0.093293666868098), 'nauc_precision_at_3_diff1': np.float64(0.3308674604386773), 'nauc_precision_at_5_max': np.float64(0.3969887305919381), 'nauc_precision_at_5_std': np.float64(-0.04398725499157719), 'nauc_precision_at_5_diff1': np.float64(0.36414682876506654), 'nauc_precision_at_10_max': np.float64(0.392883163439654), 'nauc_precision_at_10_std': np.float64(0.0045390948890048554), 'nauc_precision_at_10_diff1': np.float64(0.31548643751974575), 'nauc_precision_at_20_max': np.float64(0.35894468719033296), 'nauc_precision_at_20_std': np.float64(0.089689617791611), 'nauc_precision_at_20_diff1': np.float64(0.256665536069379), 'nauc_precision_at_100_max': np.float64(0.31197144378212815), 'nauc_precision_at_100_std': np.float64(0.21593457903142824), 'nauc_precision_at_100_diff1': np.float64(0.15504315724247578), 'nauc_precision_at_1000_max': np.float64(0.3981466751511293), 'nauc_precision_at_1000_std': np.float64(0.5251352211263127), 'nauc_precision_at_1000_diff1': np.float64(0.04022828507795013), 'nauc_mrr_at_1_max': np.float64(0.35655675684764515), 'nauc_mrr_at_1_std': np.float64(-0.1400551510769592), 'nauc_mrr_at_1_diff1': np.float64(0.5211944916180451), 'nauc_mrr_at_3_max': np.float64(0.349260526149033), 'nauc_mrr_at_3_std': np.float64(-0.1181344111606315), 'nauc_mrr_at_3_diff1': np.float64(0.414834704017872), 'nauc_mrr_at_5_max': np.float64(0.3620373153044118), 'nauc_mrr_at_5_std': np.float64(-0.1063718408135385), 'nauc_mrr_at_5_diff1': np.float64(0.42410498042603806), 'nauc_mrr_at_10_max': np.float64(0.3612814802039768), 'nauc_mrr_at_10_std': np.float64(-0.09796237440028156), 'nauc_mrr_at_10_diff1': np.float64(0.41632061458243397), 'nauc_mrr_at_20_max': np.float64(0.35896349994164234), 'nauc_mrr_at_20_std': np.float64(-0.09144807122351122), 'nauc_mrr_at_20_diff1': np.float64(0.4132713267533961), 'nauc_mrr_at_100_max': np.float64(0.35861184138421914), 'nauc_mrr_at_100_std': np.float64(-0.08948585848296406), 'nauc_mrr_at_100_diff1': np.float64(0.41312819959261254), 'nauc_mrr_at_1000_max': np.float64(0.35861517894300016), 'nauc_mrr_at_1000_std': np.float64(-0.08961687006438877), 'nauc_mrr_at_1000_diff1': np.float64(0.41357541926524327), 'main_score': 0.30183}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.jina_models:Encoding 200 sentences.
Batches:   0%|          | 0/25 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 2/25 [00:00<00:01, 15.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 4/25 [00:00<00:01, 16.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 6/25 [00:00<00:01, 16.31it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 8/25 [00:00<00:01, 16.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 10/25 [00:00<00:00, 17.00it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 12/25 [00:00<00:00, 17.08it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 14/25 [00:00<00:00, 17.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 16/25 [00:00<00:00, 17.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 18/25 [00:01<00:00, 17.46it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 20/25 [00:01<00:00, 17.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 22/25 [00:01<00:00, 17.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 24/25 [00:01<00:00, 17.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 25/25 [00:01<00:00, 17.26it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.jina_models:Using prompt_name=Retrieval-passage for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.jina_models:Encoding 6176 sentences.
Batches:   0%|          | 0/772 [00:00<?, ?it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 1/772 [00:07<1:35:33,  7.44s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 2/772 [00:14<1:34:41,  7.38s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   0%|          | 3/772 [00:22<1:34:07,  7.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 4/772 [00:29<1:33:47,  7.33s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 5/772 [00:36<1:33:30,  7.32s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 6/772 [00:43<1:33:12,  7.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 7/772 [00:51<1:32:58,  7.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 8/772 [00:58<1:32:45,  7.28s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|          | 9/772 [01:05<1:32:29,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 10/772 [01:12<1:32:08,  7.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   1%|▏         | 11/772 [01:20<1:31:59,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 12/772 [01:27<1:31:49,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 13/772 [01:34<1:31:41,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 14/772 [01:41<1:31:34,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 15/772 [01:49<1:31:35,  7.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 16/772 [01:56<1:31:21,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 17/772 [02:03<1:31:12,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 18/772 [02:10<1:30:58,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   2%|▏         | 19/772 [02:18<1:30:46,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 20/772 [02:25<1:30:33,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 21/772 [02:32<1:30:23,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 22/772 [02:39<1:30:13,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 23/772 [02:46<1:30:06,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 24/772 [02:54<1:29:59,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 25/772 [03:01<1:29:48,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 26/772 [03:08<1:29:39,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   3%|▎         | 27/772 [03:15<1:29:30,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▎         | 28/772 [03:23<1:29:21,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 29/772 [03:30<1:29:11,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 30/772 [03:37<1:29:01,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 31/772 [03:44<1:28:53,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 32/772 [03:51<1:28:41,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 33/772 [03:58<1:28:30,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   4%|▍         | 34/772 [04:06<1:28:22,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 35/772 [04:13<1:28:13,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 36/772 [04:20<1:28:03,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 37/772 [04:27<1:27:58,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▍         | 38/772 [04:34<1:27:51,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 39/772 [04:42<1:27:44,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 40/772 [04:49<1:27:41,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 41/772 [04:56<1:27:33,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   5%|▌         | 42/772 [05:03<1:27:21,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 43/772 [05:10<1:27:12,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 44/772 [05:17<1:27:06,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 45/772 [05:25<1:27:03,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 46/772 [05:32<1:26:56,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 47/772 [05:39<1:26:46,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▌         | 48/772 [05:46<1:26:36,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 49/772 [05:53<1:26:27,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   6%|▋         | 50/772 [06:00<1:26:17,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 51/772 [06:08<1:26:07,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 52/772 [06:15<1:25:59,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 53/772 [06:22<1:25:51,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 54/772 [06:29<1:25:45,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 55/772 [06:36<1:25:38,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 56/772 [06:43<1:25:29,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   7%|▋         | 57/772 [06:51<1:25:21,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 58/772 [06:58<1:25:13,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 59/772 [07:05<1:25:06,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 60/772 [07:12<1:24:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 61/772 [07:19<1:24:51,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 62/772 [07:26<1:24:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 63/772 [07:34<1:24:38,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 64/772 [07:41<1:24:29,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   8%|▊         | 65/772 [07:48<1:24:21,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▊         | 66/772 [07:55<1:24:13,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▊         | 67/772 [08:02<1:24:05,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 68/772 [08:09<1:23:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 69/772 [08:17<1:23:52,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 70/772 [08:24<1:23:44,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 71/772 [08:31<1:23:37,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 72/772 [08:38<1:23:31,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:   9%|▉         | 73/772 [08:45<1:23:22,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 74/772 [08:52<1:23:15,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 75/772 [08:59<1:23:06,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 76/772 [09:07<1:23:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|▉         | 77/772 [09:14<1:22:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 78/772 [09:21<1:22:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 79/772 [09:28<1:22:42,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 80/772 [09:35<1:22:34,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  10%|█         | 81/772 [09:42<1:22:26,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 82/772 [09:50<1:22:18,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 83/772 [09:57<1:22:11,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 84/772 [10:04<1:22:02,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 85/772 [10:11<1:21:58,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█         | 86/772 [10:18<1:21:50,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█▏        | 87/772 [10:25<1:21:42,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  11%|█▏        | 88/772 [10:33<1:21:36,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 89/772 [10:40<1:21:27,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 90/772 [10:47<1:21:20,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 91/772 [10:54<1:21:12,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 92/772 [11:01<1:21:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 93/772 [11:08<1:21:01,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 94/772 [11:15<1:20:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 95/772 [11:23<1:20:45,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  12%|█▏        | 96/772 [11:30<1:20:37,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 97/772 [11:37<1:20:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 98/772 [11:44<1:20:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 99/772 [11:51<1:20:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 100/772 [11:58<1:20:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 101/772 [12:06<1:19:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 102/772 [12:13<1:19:50,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 103/772 [12:20<1:19:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  13%|█▎        | 104/772 [12:27<1:19:36,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▎        | 105/772 [12:34<1:19:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▎        | 106/772 [12:41<1:19:21,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 107/772 [12:48<1:19:15,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 108/772 [12:56<1:19:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 109/772 [13:03<1:19:02,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 110/772 [13:10<1:18:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  14%|█▍        | 111/772 [13:17<1:18:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 112/772 [13:24<1:18:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 113/772 [13:31<1:18:32,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 114/772 [13:38<1:18:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▍        | 115/772 [13:46<1:18:17,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 116/772 [13:53<1:18:10,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 117/772 [14:00<1:18:03,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 118/772 [14:07<1:17:56,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  15%|█▌        | 119/772 [14:14<1:17:48,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 120/772 [14:21<1:17:41,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 121/772 [14:29<1:17:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 122/772 [14:36<1:17:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 123/772 [14:43<1:17:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 124/772 [14:50<1:17:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▌        | 125/772 [14:57<1:17:07,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 126/772 [15:04<1:17:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  16%|█▋        | 127/772 [15:11<1:16:52,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 128/772 [15:19<1:16:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 129/772 [15:26<1:16:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 130/772 [15:33<1:16:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 131/772 [15:40<1:16:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 132/772 [15:47<1:16:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 133/772 [15:54<1:16:09,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 134/772 [16:01<1:16:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  17%|█▋        | 135/772 [16:09<1:15:52,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 136/772 [16:16<1:15:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 137/772 [16:23<1:15:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 138/772 [16:30<1:15:33,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 139/772 [16:37<1:15:25,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 140/772 [16:44<1:15:18,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 141/772 [16:52<1:15:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  18%|█▊        | 142/772 [16:59<1:15:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▊        | 143/772 [17:06<1:14:59,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▊        | 144/772 [17:13<1:14:53,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 145/772 [17:20<1:14:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 146/772 [17:27<1:14:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 147/772 [17:34<1:14:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 148/772 [17:42<1:14:22,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 149/772 [17:49<1:14:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  19%|█▉        | 150/772 [17:56<1:14:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 151/772 [18:03<1:13:59,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 152/772 [18:10<1:13:54,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 153/772 [18:17<1:13:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|█▉        | 154/772 [18:25<1:13:39,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 155/772 [18:32<1:13:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 156/772 [18:39<1:13:25,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 157/772 [18:46<1:13:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  20%|██        | 158/772 [18:53<1:13:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 159/772 [19:00<1:13:02,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 160/772 [19:07<1:12:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 161/772 [19:15<1:12:48,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 162/772 [19:22<1:12:39,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 163/772 [19:29<1:12:32,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██        | 164/772 [19:36<1:12:27,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  21%|██▏       | 165/772 [19:43<1:12:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 166/772 [19:50<1:12:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 167/772 [19:57<1:12:03,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 168/772 [20:05<1:11:56,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 169/772 [20:12<1:11:48,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 170/772 [20:19<1:11:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 171/772 [20:26<1:11:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 172/772 [20:33<1:11:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  22%|██▏       | 173/772 [20:40<1:11:22,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 174/772 [20:47<1:11:13,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 175/772 [20:55<1:11:06,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 176/772 [21:02<1:10:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 177/772 [21:09<1:10:52,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 178/772 [21:16<1:10:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 179/772 [21:23<1:10:37,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 180/772 [21:30<1:10:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  23%|██▎       | 181/772 [21:37<1:10:23,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 182/772 [21:45<1:10:16,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▎       | 183/772 [21:52<1:10:10,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 184/772 [21:59<1:10:04,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 185/772 [22:06<1:09:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 186/772 [22:13<1:09:48,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 187/772 [22:20<1:09:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 188/772 [22:28<1:09:36,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  24%|██▍       | 189/772 [22:35<1:09:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 190/772 [22:42<1:09:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 191/772 [22:49<1:09:14,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▍       | 192/772 [22:56<1:09:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 193/772 [23:03<1:08:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 194/772 [23:10<1:08:50,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 195/772 [23:18<1:08:43,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  25%|██▌       | 196/772 [23:25<1:08:36,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 197/772 [23:32<1:08:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 198/772 [23:39<1:08:22,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 199/772 [23:46<1:08:14,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 200/772 [23:53<1:08:06,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 201/772 [24:00<1:08:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▌       | 202/772 [24:08<1:07:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 203/772 [24:15<1:07:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  26%|██▋       | 204/772 [24:22<1:07:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 205/772 [24:29<1:07:35,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 206/772 [24:36<1:07:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 207/772 [24:43<1:07:24,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 208/772 [24:51<1:07:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 209/772 [24:58<1:07:09,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 210/772 [25:05<1:07:00,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 211/772 [25:12<1:06:54,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  27%|██▋       | 212/772 [25:19<1:06:48,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 213/772 [25:26<1:06:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 214/772 [25:33<1:06:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 215/772 [25:41<1:06:25,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 216/772 [25:48<1:06:19,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 217/772 [25:55<1:06:12,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 218/772 [26:02<1:06:04,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 219/772 [26:09<1:05:57,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  28%|██▊       | 220/772 [26:16<1:05:50,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▊       | 221/772 [26:24<1:05:43,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 222/772 [26:31<1:05:35,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 223/772 [26:38<1:05:27,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 224/772 [26:45<1:05:20,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 225/772 [26:52<1:05:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 226/772 [26:59<1:05:06,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  29%|██▉       | 227/772 [27:07<1:05:08,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 228/772 [27:14<1:04:59,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 229/772 [27:21<1:04:50,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 230/772 [27:28<1:04:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|██▉       | 231/772 [27:35<1:04:34,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 232/772 [27:42<1:04:24,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 233/772 [27:49<1:04:15,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 234/772 [27:57<1:04:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  30%|███       | 235/772 [28:04<1:04:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 236/772 [28:11<1:03:52,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 237/772 [28:18<1:03:45,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 238/772 [28:25<1:03:44,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 239/772 [28:32<1:03:36,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 240/772 [28:40<1:03:27,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███       | 241/772 [28:47<1:03:21,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 242/772 [28:54<1:03:14,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  31%|███▏      | 243/772 [29:01<1:03:06,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 244/772 [29:08<1:03:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 245/772 [29:15<1:02:52,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 246/772 [29:23<1:02:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 247/772 [29:30<1:02:36,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 248/772 [29:37<1:02:28,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 249/772 [29:44<1:02:21,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  32%|███▏      | 250/772 [29:51<1:02:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 251/772 [29:58<1:02:05,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 252/772 [30:05<1:01:58,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 253/772 [30:13<1:01:50,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 254/772 [30:20<1:01:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 255/772 [30:27<1:01:36,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 256/772 [30:34<1:01:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 257/772 [30:41<1:01:21,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  33%|███▎      | 258/772 [30:48<1:01:14,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 259/772 [30:55<1:01:08,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▎      | 260/772 [31:03<1:01:01,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 261/772 [31:10<1:00:55,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 262/772 [31:17<1:00:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 263/772 [31:24<1:00:38,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 264/772 [31:31<1:00:30,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 265/772 [31:38<1:00:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  34%|███▍      | 266/772 [31:46<1:00:18,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 267/772 [31:53<1:00:12,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 268/772 [32:00<1:00:06,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 269/772 [32:07<1:00:00,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▍      | 270/772 [32:14<59:53,  7.16s/it]  WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 271/772 [32:21<59:44,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 272/772 [32:28<59:39,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 273/772 [32:36<59:33,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  35%|███▌      | 274/772 [32:43<59:27,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 275/772 [32:50<59:18,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 276/772 [32:57<59:11,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 277/772 [33:04<59:02,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 278/772 [33:11<58:53,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▌      | 279/772 [33:19<58:46,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 280/772 [33:26<58:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  36%|███▋      | 281/772 [33:33<58:38,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 282/772 [33:40<58:30,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 283/772 [33:47<58:23,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 284/772 [33:54<58:16,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 285/772 [34:02<58:10,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 286/772 [34:09<58:01,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 287/772 [34:16<58:02,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 288/772 [34:23<57:51,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  37%|███▋      | 289/772 [34:30<57:43,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 290/772 [34:37<57:33,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 291/772 [34:45<57:26,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 292/772 [34:52<57:17,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 293/772 [34:59<57:10,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 294/772 [35:06<57:02,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 295/772 [35:13<56:55,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 296/772 [35:20<56:49,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  38%|███▊      | 297/772 [35:28<56:40,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 298/772 [35:35<56:38,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▊      | 299/772 [35:42<56:31,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 300/772 [35:49<56:24,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 301/772 [35:56<56:20,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 302/772 [36:03<56:11,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 303/772 [36:11<56:05,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  39%|███▉      | 304/772 [36:18<55:56,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 305/772 [36:25<55:51,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 306/772 [36:32<55:40,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 307/772 [36:39<55:33,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|███▉      | 308/772 [36:46<55:27,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 309/772 [36:54<55:20,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 310/772 [37:01<55:13,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 311/772 [37:08<55:05,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  40%|████      | 312/772 [37:15<54:59,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 313/772 [37:22<54:53,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 314/772 [37:30<54:46,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 315/772 [37:37<54:38,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 316/772 [37:44<54:29,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 317/772 [37:51<54:22,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████      | 318/772 [37:58<54:17,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 319/772 [38:05<54:10,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  41%|████▏     | 320/772 [38:13<54:03,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 321/772 [38:20<53:55,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 322/772 [38:27<53:48,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 323/772 [38:34<53:48,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 324/772 [38:41<53:41,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 325/772 [38:49<53:34,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 326/772 [38:56<53:25,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 327/772 [39:03<53:17,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  42%|████▏     | 328/772 [39:10<53:11,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 329/772 [39:17<53:04,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 330/772 [39:24<52:56,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 331/772 [39:32<52:51,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 332/772 [39:39<52:45,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 333/772 [39:46<52:36,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 334/772 [39:53<52:28,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  43%|████▎     | 335/772 [40:00<52:22,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 336/772 [40:08<52:13,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▎     | 337/772 [40:15<52:07,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 338/772 [40:22<51:59,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 339/772 [40:29<51:52,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 340/772 [40:36<51:47,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 341/772 [40:44<51:38,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 342/772 [40:51<51:33,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  44%|████▍     | 343/772 [40:58<51:23,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 344/772 [41:05<51:17,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 345/772 [41:12<51:09,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 346/772 [41:19<51:02,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▍     | 347/772 [41:27<50:57,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 348/772 [41:34<50:49,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 349/772 [41:41<50:40,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 350/772 [41:48<50:48,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  45%|████▌     | 351/772 [41:56<50:36,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 352/772 [42:03<50:23,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 353/772 [42:10<50:14,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 354/772 [42:17<50:08,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 355/772 [42:24<50:00,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 356/772 [42:31<49:53,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▌     | 357/772 [42:39<49:46,  7.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  46%|████▋     | 358/772 [42:46<49:36,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 359/772 [42:53<49:16,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 360/772 [43:00<49:13,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 361/772 [43:07<48:32,  7.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 362/772 [43:14<48:40,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 363/772 [43:21<48:42,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 364/772 [43:29<48:43,  7.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 365/772 [43:36<48:21,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  47%|████▋     | 366/772 [43:43<48:24,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 367/772 [43:50<48:23,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 368/772 [43:57<48:21,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 369/772 [44:05<48:43,  7.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 370/772 [44:12<48:29,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 371/772 [44:19<48:16,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 372/772 [44:26<48:06,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 373/772 [44:33<47:46,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  48%|████▊     | 374/772 [44:41<48:30,  7.31s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 375/772 [44:48<48:08,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▊     | 376/772 [44:56<48:40,  7.38s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 377/772 [45:03<47:56,  7.28s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 378/772 [45:10<47:38,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 379/772 [45:17<47:24,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 380/772 [45:25<47:13,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 381/772 [45:32<47:03,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  49%|████▉     | 382/772 [45:38<45:26,  6.99s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 383/772 [45:45<45:47,  7.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 384/772 [45:53<45:55,  7.10s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|████▉     | 385/772 [46:00<46:47,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 386/772 [46:07<46:34,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 387/772 [46:15<46:22,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 388/772 [46:22<46:24,  7.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  50%|█████     | 389/772 [46:29<46:12,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 390/772 [46:36<46:01,  7.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 391/772 [46:44<45:51,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 392/772 [46:51<45:43,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 393/772 [46:58<45:35,  7.22s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 394/772 [47:05<45:11,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████     | 395/772 [47:12<45:10,  7.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 396/772 [47:20<45:10,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  51%|█████▏    | 397/772 [47:27<45:24,  7.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 398/772 [47:34<45:08,  7.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 399/772 [47:41<44:37,  7.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 400/772 [47:48<44:00,  7.10s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 401/772 [47:55<44:03,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 402/772 [48:02<43:53,  7.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 403/772 [48:10<43:56,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 404/772 [48:17<44:13,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  52%|█████▏    | 405/772 [48:24<44:04,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 406/772 [48:31<43:28,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 407/772 [48:38<43:29,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 408/772 [48:44<40:00,  6.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 409/772 [48:51<40:39,  6.72s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 410/772 [48:58<42:05,  6.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 411/772 [49:05<41:00,  6.82s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 412/772 [49:12<41:36,  6.93s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  53%|█████▎    | 413/772 [49:19<41:30,  6.94s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▎    | 414/772 [49:26<42:09,  7.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 415/772 [49:33<42:31,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 416/772 [49:41<43:09,  7.28s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 417/772 [49:48<42:26,  7.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 418/772 [49:55<42:06,  7.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 419/772 [50:02<41:56,  7.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  54%|█████▍    | 420/772 [50:09<41:56,  7.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 421/772 [50:17<42:10,  7.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 422/772 [50:22<38:23,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 423/772 [50:28<37:50,  6.50s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▍    | 424/772 [50:35<38:10,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 425/772 [50:42<39:08,  6.77s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 426/772 [50:49<39:49,  6.91s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 427/772 [50:55<37:19,  6.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  55%|█████▌    | 428/772 [51:02<38:28,  6.71s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 429/772 [51:09<38:26,  6.72s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 430/772 [51:16<39:08,  6.87s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 431/772 [51:21<36:29,  6.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 432/772 [51:29<37:44,  6.66s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 433/772 [51:34<35:31,  6.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▌    | 434/772 [51:40<35:19,  6.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 435/772 [51:47<35:11,  6.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  56%|█████▋    | 436/772 [51:53<35:28,  6.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 437/772 [52:00<36:07,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 438/772 [52:06<35:59,  6.46s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 439/772 [52:13<35:58,  6.48s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 440/772 [52:18<33:20,  6.02s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 441/772 [52:25<34:32,  6.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 442/772 [52:31<34:10,  6.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  57%|█████▋    | 443/772 [52:38<35:40,  6.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 444/772 [52:45<36:31,  6.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 445/772 [52:51<35:51,  6.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 446/772 [52:57<35:10,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 447/772 [53:05<36:18,  6.70s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 448/772 [53:11<35:41,  6.61s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 449/772 [53:18<35:54,  6.67s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 450/772 [53:24<34:59,  6.52s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  58%|█████▊    | 451/772 [53:31<35:26,  6.62s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 452/772 [53:38<36:07,  6.77s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▊    | 453/772 [53:45<35:55,  6.76s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 454/772 [53:51<34:24,  6.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 455/772 [53:57<34:10,  6.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 456/772 [54:03<33:13,  6.31s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 457/772 [54:09<33:00,  6.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 458/772 [54:16<34:24,  6.57s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  59%|█████▉    | 459/772 [54:23<33:59,  6.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 460/772 [54:29<32:53,  6.32s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 461/772 [54:35<32:04,  6.19s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 462/772 [54:42<33:24,  6.46s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|█████▉    | 463/772 [54:48<32:58,  6.40s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 464/772 [54:53<30:22,  5.92s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 465/772 [54:59<30:33,  5.97s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 466/772 [55:06<32:33,  6.39s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  60%|██████    | 467/772 [55:11<29:56,  5.89s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 468/772 [55:18<31:06,  6.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 469/772 [55:22<27:37,  5.47s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 470/772 [55:27<26:41,  5.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 471/772 [55:31<25:44,  5.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████    | 472/772 [55:36<24:33,  4.91s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████▏   | 473/772 [55:40<24:15,  4.87s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  61%|██████▏   | 474/772 [55:45<24:08,  4.86s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 475/772 [55:49<22:55,  4.63s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 476/772 [55:54<22:48,  4.62s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 477/772 [55:58<21:20,  4.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 478/772 [56:01<19:13,  3.92s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 479/772 [56:05<19:31,  4.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 480/772 [56:08<18:23,  3.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 481/772 [56:11<17:23,  3.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  62%|██████▏   | 482/772 [56:14<16:58,  3.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 483/772 [56:18<17:16,  3.59s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 484/772 [56:22<16:54,  3.52s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 485/772 [56:25<16:18,  3.41s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 486/772 [56:28<15:30,  3.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 487/772 [56:31<15:00,  3.16s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 488/772 [56:33<14:20,  3.03s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 489/772 [56:36<13:55,  2.95s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  63%|██████▎   | 490/772 [56:39<14:01,  2.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 491/772 [56:42<14:03,  3.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▎   | 492/772 [56:45<14:05,  3.02s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 493/772 [56:48<13:50,  2.98s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 494/772 [56:50<12:53,  2.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 495/772 [56:53<12:49,  2.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 496/772 [56:56<12:27,  2.71s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  64%|██████▍   | 497/772 [56:58<12:23,  2.70s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 498/772 [57:01<11:36,  2.54s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 499/772 [57:03<10:46,  2.37s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 500/772 [57:05<11:16,  2.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▍   | 501/772 [57:08<11:16,  2.50s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 502/772 [57:10<10:56,  2.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 503/772 [57:12<10:14,  2.29s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 504/772 [57:14<10:01,  2.24s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  65%|██████▌   | 505/772 [57:16<09:38,  2.17s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 506/772 [57:18<09:22,  2.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 507/772 [57:20<09:24,  2.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 508/772 [57:22<09:15,  2.10s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 509/772 [57:25<09:24,  2.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 510/772 [57:26<08:43,  2.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▌   | 511/772 [57:29<08:55,  2.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▋   | 512/772 [57:31<09:09,  2.11s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  66%|██████▋   | 513/772 [57:33<08:59,  2.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 514/772 [57:35<08:55,  2.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 515/772 [57:37<09:09,  2.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 516/772 [57:39<08:32,  2.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 517/772 [57:41<08:41,  2.04s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 518/772 [57:43<08:57,  2.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 519/772 [57:45<08:32,  2.03s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 520/772 [57:47<08:24,  2.00s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  67%|██████▋   | 521/772 [57:49<07:46,  1.86s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 522/772 [57:50<07:24,  1.78s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 523/772 [57:52<07:00,  1.69s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 524/772 [57:54<07:14,  1.75s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 525/772 [57:55<07:10,  1.74s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 526/772 [57:57<07:21,  1.79s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 527/772 [57:59<07:32,  1.85s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  68%|██████▊   | 528/772 [58:01<07:06,  1.75s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 529/772 [58:02<06:47,  1.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▊   | 530/772 [58:04<06:33,  1.63s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 531/772 [58:06<06:59,  1.74s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 532/772 [58:07<06:42,  1.68s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 533/772 [58:09<06:30,  1.64s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 534/772 [58:10<06:15,  1.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 535/772 [58:12<06:27,  1.64s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  69%|██████▉   | 536/772 [58:13<06:13,  1.58s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 537/772 [58:15<05:49,  1.49s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 538/772 [58:16<05:45,  1.48s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 539/772 [58:17<05:28,  1.41s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|██████▉   | 540/772 [58:19<05:30,  1.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 541/772 [58:20<05:34,  1.45s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 542/772 [58:21<05:07,  1.34s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 543/772 [58:23<05:05,  1.33s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  70%|███████   | 544/772 [58:25<05:44,  1.51s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 545/772 [58:26<05:21,  1.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 546/772 [58:27<05:22,  1.43s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 547/772 [58:29<05:20,  1.42s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 548/772 [58:30<05:15,  1.41s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 549/772 [58:31<05:04,  1.36s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████   | 550/772 [58:33<04:59,  1.35s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  71%|███████▏  | 551/772 [58:34<04:47,  1.30s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 552/772 [58:35<04:36,  1.26s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 553/772 [58:36<04:38,  1.27s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 554/772 [58:37<04:28,  1.23s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 555/772 [58:39<04:46,  1.32s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 556/772 [58:40<04:29,  1.25s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 557/772 [58:41<04:17,  1.20s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 558/772 [58:42<04:18,  1.21s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  72%|███████▏  | 559/772 [58:43<04:10,  1.18s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 560/772 [58:45<04:02,  1.15s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 561/772 [58:46<03:59,  1.14s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 562/772 [58:47<03:41,  1.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 563/772 [58:48<03:40,  1.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 564/772 [58:49<03:37,  1.05s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 565/772 [58:50<03:41,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 566/772 [58:51<03:44,  1.09s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  73%|███████▎  | 567/772 [58:52<03:41,  1.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▎  | 568/772 [58:53<03:35,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▎  | 569/772 [58:54<03:50,  1.13s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 570/772 [58:55<03:46,  1.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 571/772 [58:56<03:34,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 572/772 [58:58<03:43,  1.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 573/772 [58:59<03:35,  1.08s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 574/772 [59:00<03:31,  1.07s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  74%|███████▍  | 575/772 [59:01<03:40,  1.12s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 576/772 [59:02<03:35,  1.10s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 577/772 [59:03<03:22,  1.04s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▍  | 578/772 [59:04<03:26,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 579/772 [59:05<03:24,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 580/772 [59:06<03:23,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 581/772 [59:07<03:22,  1.06s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  75%|███████▌  | 582/772 [59:08<03:17,  1.04s/it]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 583/772 [59:09<03:04,  1.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 584/772 [59:10<03:01,  1.03it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 585/772 [59:11<02:47,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 586/772 [59:11<02:43,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 587/772 [59:12<02:45,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▌  | 588/772 [59:13<02:41,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▋  | 589/772 [59:14<02:43,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  76%|███████▋  | 590/772 [59:15<02:47,  1.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 591/772 [59:16<02:49,  1.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 592/772 [59:17<02:38,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 593/772 [59:18<02:32,  1.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 594/772 [59:18<02:32,  1.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 595/772 [59:19<02:32,  1.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 596/772 [59:20<02:34,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 597/772 [59:21<02:25,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  77%|███████▋  | 598/772 [59:22<02:32,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 599/772 [59:23<02:32,  1.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 600/772 [59:24<02:33,  1.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 601/772 [59:25<02:35,  1.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 602/772 [59:25<02:27,  1.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 603/772 [59:26<02:20,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 604/772 [59:27<02:21,  1.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 605/772 [59:28<02:12,  1.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  78%|███████▊  | 606/772 [59:29<02:15,  1.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▊  | 607/772 [59:29<02:13,  1.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 608/772 [59:30<02:08,  1.28it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 609/772 [59:31<02:04,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 610/772 [59:32<02:15,  1.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 611/772 [59:33<02:12,  1.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 612/772 [59:34<02:13,  1.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  79%|███████▉  | 613/772 [59:34<02:07,  1.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 614/772 [59:35<02:03,  1.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 615/772 [59:36<02:00,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 616/772 [59:36<01:56,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|███████▉  | 617/772 [59:37<01:56,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 618/772 [59:38<01:52,  1.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 619/772 [59:39<02:02,  1.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 620/772 [59:40<02:02,  1.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  80%|████████  | 621/772 [59:40<01:59,  1.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 622/772 [59:41<01:55,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 623/772 [59:42<01:51,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 624/772 [59:43<01:48,  1.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 625/772 [59:43<01:45,  1.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 626/772 [59:44<01:46,  1.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████  | 627/772 [59:45<01:45,  1.38it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 628/772 [59:45<01:40,  1.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  81%|████████▏ | 629/772 [59:46<01:47,  1.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 630/772 [59:47<01:46,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 631/772 [59:48<01:48,  1.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 632/772 [59:48<01:44,  1.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 633/772 [59:49<01:45,  1.32it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 634/772 [59:50<01:39,  1.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 635/772 [59:50<01:33,  1.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  82%|████████▏ | 636/772 [59:51<01:33,  1.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 637/772 [59:52<01:39,  1.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 638/772 [59:53<01:33,  1.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 639/772 [59:53<01:34,  1.40it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 640/772 [59:54<01:33,  1.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 641/772 [59:55<01:31,  1.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 642/772 [59:55<01:25,  1.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 643/772 [59:56<01:22,  1.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  83%|████████▎ | 644/772 [59:56<01:19,  1.61it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 645/772 [59:57<01:21,  1.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▎ | 646/772 [59:58<01:20,  1.57it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 647/772 [59:58<01:19,  1.58it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 648/772 [59:59<01:20,  1.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 649/772 [1:00:00<01:22,  1.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 650/772 [1:00:00<01:20,  1.52it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 651/772 [1:00:01<01:17,  1.55it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  84%|████████▍ | 652/772 [1:00:02<01:16,  1.56it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 653/772 [1:00:02<01:14,  1.60it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 654/772 [1:00:03<01:11,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 655/772 [1:00:03<01:10,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▍ | 656/772 [1:00:04<01:09,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 657/772 [1:00:05<01:11,  1.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 658/772 [1:00:05<01:09,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 659/772 [1:00:06<01:08,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  85%|████████▌ | 660/772 [1:00:06<01:07,  1.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 661/772 [1:00:07<01:05,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 662/772 [1:00:08<01:05,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 663/772 [1:00:08<01:05,  1.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 664/772 [1:00:09<01:05,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▌ | 665/772 [1:00:09<01:06,  1.62it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 666/772 [1:00:10<01:04,  1.65it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  86%|████████▋ | 667/772 [1:00:11<01:02,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 668/772 [1:00:11<01:01,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 669/772 [1:00:12<01:02,  1.66it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 670/772 [1:00:12<01:00,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 671/772 [1:00:13<00:58,  1.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 672/772 [1:00:13<00:56,  1.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 673/772 [1:00:14<00:57,  1.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 674/772 [1:00:15<00:55,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  87%|████████▋ | 675/772 [1:00:15<00:56,  1.73it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 676/772 [1:00:16<00:56,  1.69it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 677/772 [1:00:17<00:57,  1.67it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 678/772 [1:00:17<00:55,  1.70it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 679/772 [1:00:18<00:53,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 680/772 [1:00:18<00:51,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 681/772 [1:00:19<00:51,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 682/772 [1:00:19<00:50,  1.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  88%|████████▊ | 683/772 [1:00:20<00:49,  1.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 684/772 [1:00:20<00:49,  1.79it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▊ | 685/772 [1:00:21<00:48,  1.78it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 686/772 [1:00:21<00:47,  1.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 687/772 [1:00:22<00:48,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 688/772 [1:00:23<00:49,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 689/772 [1:00:23<00:48,  1.71it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  89%|████████▉ | 690/772 [1:00:24<00:46,  1.75it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 691/772 [1:00:24<00:46,  1.76it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 692/772 [1:00:25<00:44,  1.80it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 693/772 [1:00:25<00:42,  1.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|████████▉ | 694/772 [1:00:26<00:41,  1.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 695/772 [1:00:27<00:41,  1.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 696/772 [1:00:27<00:40,  1.87it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 697/772 [1:00:28<00:40,  1.86it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  90%|█████████ | 698/772 [1:00:28<00:39,  1.85it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 699/772 [1:00:29<00:42,  1.72it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 700/772 [1:00:29<00:42,  1.68it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 701/772 [1:00:30<00:40,  1.77it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 702/772 [1:00:30<00:38,  1.84it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 703/772 [1:00:31<00:36,  1.89it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████ | 704/772 [1:00:31<00:34,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 705/772 [1:00:32<00:33,  1.97it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  91%|█████████▏| 706/772 [1:00:32<00:33,  1.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 707/772 [1:00:33<00:33,  1.96it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 708/772 [1:00:33<00:32,  1.98it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 709/772 [1:00:34<00:30,  2.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 710/772 [1:00:34<00:29,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 711/772 [1:00:35<00:29,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 712/772 [1:00:35<00:29,  2.06it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 713/772 [1:00:36<00:28,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  92%|█████████▏| 714/772 [1:00:36<00:28,  2.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 715/772 [1:00:37<00:27,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 716/772 [1:00:37<00:27,  2.07it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 717/772 [1:00:38<00:25,  2.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 718/772 [1:00:38<00:24,  2.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 719/772 [1:00:39<00:25,  2.10it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 720/772 [1:00:39<00:24,  2.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  93%|█████████▎| 721/772 [1:00:40<00:25,  2.01it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 722/772 [1:00:40<00:24,  2.05it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▎| 723/772 [1:00:41<00:24,  1.99it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 724/772 [1:00:41<00:22,  2.09it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 725/772 [1:00:41<00:22,  2.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 726/772 [1:00:42<00:21,  2.16it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 727/772 [1:00:42<00:20,  2.17it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 728/772 [1:00:43<00:20,  2.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  94%|█████████▍| 729/772 [1:00:43<00:21,  2.04it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 730/772 [1:00:44<00:19,  2.12it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 731/772 [1:00:44<00:19,  2.14it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 732/772 [1:00:45<00:18,  2.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▍| 733/772 [1:00:45<00:17,  2.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 734/772 [1:00:46<00:17,  2.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 735/772 [1:00:46<00:16,  2.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 736/772 [1:00:46<00:15,  2.26it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  95%|█████████▌| 737/772 [1:00:47<00:15,  2.30it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 738/772 [1:00:47<00:14,  2.27it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 739/772 [1:00:48<00:14,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 740/772 [1:00:48<00:13,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 741/772 [1:00:49<00:13,  2.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 742/772 [1:00:49<00:13,  2.20it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▌| 743/772 [1:00:50<00:12,  2.24it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  96%|█████████▋| 744/772 [1:00:50<00:12,  2.19it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 745/772 [1:00:50<00:11,  2.33it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 746/772 [1:00:51<00:11,  2.34it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 747/772 [1:00:51<00:10,  2.35it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 748/772 [1:00:52<00:10,  2.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 749/772 [1:00:52<00:09,  2.44it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 750/772 [1:00:52<00:09,  2.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 751/772 [1:00:53<00:08,  2.48it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  97%|█████████▋| 752/772 [1:00:53<00:08,  2.47it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 753/772 [1:00:54<00:07,  2.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 754/772 [1:00:54<00:07,  2.39it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 755/772 [1:00:55<00:07,  2.22it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 756/772 [1:00:55<00:07,  2.23it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 757/772 [1:00:56<00:06,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 758/772 [1:00:56<00:06,  2.25it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 759/772 [1:00:56<00:05,  2.29it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  98%|█████████▊| 760/772 [1:00:57<00:05,  2.36it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 761/772 [1:00:57<00:04,  2.37it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▊| 762/772 [1:00:58<00:04,  2.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 763/772 [1:00:58<00:03,  2.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 764/772 [1:00:58<00:03,  2.42it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 765/772 [1:00:59<00:02,  2.41it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 766/772 [1:00:59<00:02,  2.43it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 767/772 [1:01:00<00:02,  2.45it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches:  99%|█████████▉| 768/772 [1:01:00<00:01,  2.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 769/772 [1:01:00<00:01,  2.50it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 770/772 [1:01:01<00:00,  2.49it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|█████████▉| 771/772 [1:01:01<00:00,  2.51it/s]WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:Flash attention implementation does not support kwargs: prompt_length
Batches: 100%|██████████| 772/772 [1:01:02<00:00,  2.53it/s]Batches: 100%|██████████| 772/772 [1:01:02<00:00,  4.74s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3667.94 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 3668.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.235, 'ndcg_at_3': 0.28339, 'ndcg_at_5': 0.30576, 'ndcg_at_10': 0.32148, 'ndcg_at_20': 0.3317, 'ndcg_at_100': 0.36217, 'ndcg_at_1000': 0.38921, 'map_at_1': 0.235, 'map_at_3': 0.27083, 'map_at_5': 0.28308, 'map_at_10': 0.28932, 'map_at_20': 0.29218, 'map_at_100': 0.29632, 'map_at_1000': 0.29713, 'recall_at_1': 0.235, 'recall_at_3': 0.32, 'recall_at_5': 0.375, 'recall_at_10': 0.425, 'recall_at_20': 0.465, 'recall_at_100': 0.63, 'recall_at_1000': 0.855, 'precision_at_1': 0.235, 'precision_at_3': 0.10667, 'precision_at_5': 0.075, 'precision_at_10': 0.0425, 'precision_at_20': 0.02325, 'precision_at_100': 0.0063, 'precision_at_1000': 0.00086, 'mrr_at_1': 0.235, 'mrr_at_3': 0.27083333333333337, 'mrr_at_5': 0.28308333333333335, 'mrr_at_10': 0.2893194444444445, 'mrr_at_20': 0.29217721575809824, 'mrr_at_100': 0.29632070672031807, 'mrr_at_1000': 0.2971289239202354, 'nauc_ndcg_at_1_max': np.float64(0.3995722781854317), 'nauc_ndcg_at_1_std': np.float64(-0.047510371876157136), 'nauc_ndcg_at_1_diff1': np.float64(0.571295785504311), 'nauc_ndcg_at_3_max': np.float64(0.34868871093902987), 'nauc_ndcg_at_3_std': np.float64(-0.04927824192630008), 'nauc_ndcg_at_3_diff1': np.float64(0.49592365986965814), 'nauc_ndcg_at_5_max': np.float64(0.3610657286334925), 'nauc_ndcg_at_5_std': np.float64(-0.012999918696533668), 'nauc_ndcg_at_5_diff1': np.float64(0.4885052025696699), 'nauc_ndcg_at_10_max': np.float64(0.35169130492260464), 'nauc_ndcg_at_10_std': np.float64(-0.012676981189312559), 'nauc_ndcg_at_10_diff1': np.float64(0.46793951580920795), 'nauc_ndcg_at_20_max': np.float64(0.3668973826811718), 'nauc_ndcg_at_20_std': np.float64(0.004532600029109674), 'nauc_ndcg_at_20_diff1': np.float64(0.48061876690083943), 'nauc_ndcg_at_100_max': np.float64(0.36835360911212706), 'nauc_ndcg_at_100_std': np.float64(0.030455121126793053), 'nauc_ndcg_at_100_diff1': np.float64(0.46937571063734224), 'nauc_ndcg_at_1000_max': np.float64(0.37732283442968995), 'nauc_ndcg_at_1000_std': np.float64(0.03440590052557848), 'nauc_ndcg_at_1000_diff1': np.float64(0.4798022385873239), 'nauc_map_at_1_max': np.float64(0.3995722781854317), 'nauc_map_at_1_std': np.float64(-0.047510371876157136), 'nauc_map_at_1_diff1': np.float64(0.571295785504311), 'nauc_map_at_3_max': np.float64(0.35968086944605004), 'nauc_map_at_3_std': np.float64(-0.0498704053482372), 'nauc_map_at_3_diff1': np.float64(0.5111653985258982), 'nauc_map_at_5_max': np.float64(0.3667951414120113), 'nauc_map_at_5_std': np.float64(-0.02957220171359919), 'nauc_map_at_5_diff1': np.float64(0.5074575226401661), 'nauc_map_at_10_max': np.float64(0.3626499124430716), 'nauc_map_at_10_std': np.float64(-0.02977736008364212), 'nauc_map_at_10_diff1': np.float64(0.49870614950079595), 'nauc_map_at_20_max': np.float64(0.36698074453088086), 'nauc_map_at_20_std': np.float64(-0.025181890209297744), 'nauc_map_at_20_diff1': np.float64(0.5021721838341945), 'nauc_map_at_100_max': np.float64(0.3674499369044366), 'nauc_map_at_100_std': np.float64(-0.021918713600922717), 'nauc_map_at_100_diff1': np.float64(0.5012333619787828), 'nauc_map_at_1000_max': np.float64(0.3676029509312789), 'nauc_map_at_1000_std': np.float64(-0.021448193942501127), 'nauc_map_at_1000_diff1': np.float64(0.501214979816546), 'nauc_recall_at_1_max': np.float64(0.3995722781854317), 'nauc_recall_at_1_std': np.float64(-0.047510371876157136), 'nauc_recall_at_1_diff1': np.float64(0.571295785504311), 'nauc_recall_at_3_max': np.float64(0.3192497056619929), 'nauc_recall_at_3_std': np.float64(-0.047294766135074495), 'nauc_recall_at_3_diff1': np.float64(0.4555282029326768), 'nauc_recall_at_5_max': np.float64(0.34759811105683097), 'nauc_recall_at_5_std': np.float64(0.03637843999348631), 'nauc_recall_at_5_diff1': np.float64(0.4374206155349292), 'nauc_recall_at_10_max': np.float64(0.32143854068616307), 'nauc_recall_at_10_std': np.float64(0.03891070791002631), 'nauc_recall_at_10_diff1': np.float64(0.37828556590606627), 'nauc_recall_at_20_max': np.float64(0.37737674492072587), 'nauc_recall_at_20_std': np.float64(0.10529086948223305), 'nauc_recall_at_20_diff1': np.float64(0.4252374276857466), 'nauc_recall_at_100_max': np.float64(0.38440746486156113), 'nauc_recall_at_100_std': np.float64(0.2799793165044893), 'nauc_recall_at_100_diff1': np.float64(0.3407057459377301), 'nauc_recall_at_1000_max': np.float64(0.5748179469109707), 'nauc_recall_at_1000_std': np.float64(0.5696499882546399), 'nauc_recall_at_1000_diff1': np.float64(0.433370247323736), 'nauc_precision_at_1_max': np.float64(0.3995722781854317), 'nauc_precision_at_1_std': np.float64(-0.047510371876157136), 'nauc_precision_at_1_diff1': np.float64(0.571295785504311), 'nauc_precision_at_3_max': np.float64(0.31924970566199307), 'nauc_precision_at_3_std': np.float64(-0.0472947661350743), 'nauc_precision_at_3_diff1': np.float64(0.455528202932677), 'nauc_precision_at_5_max': np.float64(0.34759811105683125), 'nauc_precision_at_5_std': np.float64(0.03637843999348661), 'nauc_precision_at_5_diff1': np.float64(0.43742061553492917), 'nauc_precision_at_10_max': np.float64(0.32143854068616307), 'nauc_precision_at_10_std': np.float64(0.038910707910026245), 'nauc_precision_at_10_diff1': np.float64(0.37828556590606627), 'nauc_precision_at_20_max': np.float64(0.37737674492072576), 'nauc_precision_at_20_std': np.float64(0.10529086948223308), 'nauc_precision_at_20_diff1': np.float64(0.4252374276857461), 'nauc_precision_at_100_max': np.float64(0.3844074648615614), 'nauc_precision_at_100_std': np.float64(0.2799793165044896), 'nauc_precision_at_100_diff1': np.float64(0.34070574593773006), 'nauc_precision_at_1000_max': np.float64(0.5748179469109707), 'nauc_precision_at_1000_std': np.float64(0.5696499882546394), 'nauc_precision_at_1000_diff1': np.float64(0.4333702473237359), 'nauc_mrr_at_1_max': np.float64(0.3995722781854317), 'nauc_mrr_at_1_std': np.float64(-0.047510371876157136), 'nauc_mrr_at_1_diff1': np.float64(0.571295785504311), 'nauc_mrr_at_3_max': np.float64(0.35968086944605004), 'nauc_mrr_at_3_std': np.float64(-0.0498704053482372), 'nauc_mrr_at_3_diff1': np.float64(0.5111653985258982), 'nauc_mrr_at_5_max': np.float64(0.3667951414120113), 'nauc_mrr_at_5_std': np.float64(-0.02957220171359919), 'nauc_mrr_at_5_diff1': np.float64(0.5074575226401661), 'nauc_mrr_at_10_max': np.float64(0.3626499124430716), 'nauc_mrr_at_10_std': np.float64(-0.02977736008364212), 'nauc_mrr_at_10_diff1': np.float64(0.49870614950079595), 'nauc_mrr_at_20_max': np.float64(0.36698074453088086), 'nauc_mrr_at_20_std': np.float64(-0.025181890209297744), 'nauc_mrr_at_20_diff1': np.float64(0.5021721838341945), 'nauc_mrr_at_100_max': np.float64(0.3674499369044366), 'nauc_mrr_at_100_std': np.float64(-0.021918713600922717), 'nauc_mrr_at_100_diff1': np.float64(0.5012333619787828), 'nauc_mrr_at_1000_max': np.float64(0.3676029509312789), 'nauc_mrr_at_1000_std': np.float64(-0.021448193942501127), 'nauc_mrr_at_1000_diff1': np.float64(0.501214979816546), 'main_score': 0.32148}}



==================================================
Running model: Snowflake/snowflake-arctic-embed-l-v2.0
--------------------------------------------------
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: Snowflake/snowflake-arctic-embed-l-v2.0
INFO:sentence_transformers.SentenceTransformer:1 prompts are loaded, with the keys: ['query']
INFO:mteb.models.sentence_transformer_wrapper:Model prompts will be overwritten with {'query': 'query: '}
WARNING:mteb.models.overview:Failed to extract metadata from model: 'SentenceTransformerWrapper' object has no attribute 'model_card_data'. Upgrading to sentence-transformers v3.0.0 or above is recommended.
INFO:mteb.evaluation.MTEB:

## Evaluating 6 tasks:
Running tasks: ['Ko-StrategyQA', 'AutoRAGRetrieval', 'PublicHealthQA', 'BelebeleRetrieval', 'XPQARetrieval', 'MultiLongDocRetrieval'] / Snowflake/snowflake-arctic-embed-l-v2.0 on GPU 0 in process Process-16
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - Ko-StrategyQA, s2p
    - AutoRAGRetrieval, s2p
    - PublicHealthQA, s2p, multilingual 1 / 8 Subsets
    - BelebeleRetrieval, s2p, multilingual 3 / 376 Subsets
    - XPQARetrieval, s2p, multilingual 3 / 36 Subsets
    - MultiLongDocRetrieval, s2p, multilingual 1 / 13 Subsets


INFO:mteb.evaluation.MTEB:

********************** Evaluating Ko-StrategyQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 9251 DEV Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '17th century-1', 'title': '17th century', 'text': '17세기는 1601년 1월 1일부터 1700년 12월 31일까지 지속된 세기입니다. 이 시기는 유럽의 근대 초기에 속하며, 바로크 문화 운동, 스페인 황금 시대의 후반부, 네덜란드 황금 시대, 루이 14세가 지배한 프랑스 왕정 시대, 과학 혁명, 세계 최초의 공기업이자 거대 기업인 네덜란드 동인도 회사, 일부 역사가에 따르면 일반 위기 등이 특징적인 시기였다. 가장 큰 군사적 분쟁은 30년 전쟁, 터키 대전쟁, 무굴-사파비 전쟁(무굴-사파비 전쟁(1622-23), 무굴-사파비 전쟁(1649-53)), 무굴-마라타 전쟁, 네덜란드-포르투갈 전쟁 등이었습니다. 또한 이 시기에는 은 매장지 개발 등 유럽의 아메리카 식민지 개척이 본격적으로 시작되어 부의 유럽 유입으로 인플레이션이 발생하기도 했습니다.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 592 DEV Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '5c27625de0e7c35be856_0', 'text': '토니 베넷의 중간 이름은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=Ko-StrategyQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 592 sentences.
Batches:   0%|          | 0/19 [00:00<?, ?it/s]Batches:   5%|▌         | 1/19 [00:00<00:05,  3.43it/s]Batches:  26%|██▋       | 5/19 [00:00<00:00, 14.17it/s]Batches:  42%|████▏     | 8/19 [00:00<00:00, 18.86it/s]Batches:  58%|█████▊    | 11/19 [00:00<00:00, 22.05it/s]Batches:  79%|███████▉  | 15/19 [00:00<00:00, 25.59it/s]Batches: 100%|██████████| 19/19 [00:00<00:00, 28.91it/s]Batches: 100%|██████████| 19/19 [00:00<00:00, 22.14it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=Ko-StrategyQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 9251 sentences.
Batches:   0%|          | 0/290 [00:00<?, ?it/s]Batches:   0%|          | 1/290 [00:00<00:35,  8.09it/s]Batches:   1%|          | 2/290 [00:07<19:51,  4.14s/it]Batches:   1%|          | 3/290 [00:08<14:56,  3.12s/it]Batches:   1%|▏         | 4/290 [00:10<11:18,  2.37s/it]Batches:   2%|▏         | 5/290 [00:11<08:47,  1.85s/it]Batches:   2%|▏         | 6/290 [00:11<07:07,  1.51s/it]Batches:   2%|▏         | 7/290 [00:12<05:58,  1.27s/it]Batches:   3%|▎         | 8/290 [00:13<05:04,  1.08s/it]Batches:   3%|▎         | 9/290 [00:14<04:28,  1.05it/s]Batches:   3%|▎         | 10/290 [00:14<03:58,  1.18it/s]Batches:   4%|▍         | 11/290 [00:15<03:39,  1.27it/s]Batches:   4%|▍         | 12/290 [00:15<03:23,  1.36it/s]Batches:   4%|▍         | 13/290 [00:16<03:14,  1.42it/s]Batches:   5%|▍         | 14/290 [00:17<03:02,  1.51it/s]Batches:   5%|▌         | 15/290 [00:17<02:53,  1.58it/s]Batches:   6%|▌         | 16/290 [00:18<02:49,  1.62it/s]Batches:   6%|▌         | 17/290 [00:18<02:43,  1.67it/s]Batches:   6%|▌         | 18/290 [00:19<02:37,  1.72it/s]Batches:   7%|▋         | 19/290 [00:19<02:30,  1.80it/s]Batches:   7%|▋         | 20/290 [00:20<02:28,  1.82it/s]Batches:   7%|▋         | 21/290 [00:20<02:22,  1.89it/s]Batches:   8%|▊         | 22/290 [00:21<02:17,  1.95it/s]Batches:   8%|▊         | 23/290 [00:21<02:20,  1.90it/s]Batches:   8%|▊         | 24/290 [00:22<02:15,  1.96it/s]Batches:   9%|▊         | 25/290 [00:22<02:11,  2.01it/s]Batches:   9%|▉         | 26/290 [00:23<02:10,  2.02it/s]Batches:   9%|▉         | 27/290 [00:23<02:06,  2.08it/s]Batches:  10%|▉         | 28/290 [00:24<02:04,  2.10it/s]Batches:  10%|█         | 29/290 [00:24<02:03,  2.11it/s]Batches:  10%|█         | 30/290 [00:25<02:00,  2.16it/s]Batches:  11%|█         | 31/290 [00:25<01:58,  2.19it/s]Batches:  11%|█         | 32/290 [00:26<01:54,  2.26it/s]Batches:  11%|█▏        | 33/290 [00:26<01:53,  2.26it/s]Batches:  12%|█▏        | 34/290 [00:26<01:53,  2.26it/s]Batches:  12%|█▏        | 35/290 [00:27<01:52,  2.26it/s]Batches:  12%|█▏        | 36/290 [00:27<01:50,  2.30it/s]Batches:  13%|█▎        | 37/290 [00:28<01:48,  2.33it/s]Batches:  13%|█▎        | 38/290 [00:28<01:46,  2.37it/s]Batches:  13%|█▎        | 39/290 [00:29<01:45,  2.39it/s]Batches:  14%|█▍        | 40/290 [00:29<01:43,  2.41it/s]Batches:  14%|█▍        | 41/290 [00:29<01:43,  2.41it/s]Batches:  14%|█▍        | 42/290 [00:30<01:42,  2.42it/s]Batches:  15%|█▍        | 43/290 [00:30<01:41,  2.44it/s]Batches:  15%|█▌        | 44/290 [00:31<01:43,  2.39it/s]Batches:  16%|█▌        | 45/290 [00:31<01:40,  2.43it/s]Batches:  16%|█▌        | 46/290 [00:31<01:38,  2.47it/s]Batches:  16%|█▌        | 47/290 [00:32<01:37,  2.49it/s]Batches:  17%|█▋        | 48/290 [00:32<01:35,  2.55it/s]Batches:  17%|█▋        | 49/290 [00:33<01:33,  2.59it/s]Batches:  17%|█▋        | 50/290 [00:33<01:32,  2.60it/s]Batches:  18%|█▊        | 51/290 [00:33<01:33,  2.57it/s]Batches:  18%|█▊        | 52/290 [00:34<01:32,  2.58it/s]Batches:  18%|█▊        | 53/290 [00:34<01:31,  2.60it/s]Batches:  19%|█▊        | 54/290 [00:34<01:30,  2.62it/s]Batches:  19%|█▉        | 55/290 [00:35<01:26,  2.71it/s]Batches:  19%|█▉        | 56/290 [00:35<01:27,  2.69it/s]Batches:  20%|█▉        | 57/290 [00:36<01:25,  2.73it/s]Batches:  20%|██        | 58/290 [00:36<01:24,  2.73it/s]Batches:  20%|██        | 59/290 [00:36<01:24,  2.74it/s]Batches:  21%|██        | 60/290 [00:37<01:23,  2.75it/s]Batches:  21%|██        | 61/290 [00:37<01:21,  2.82it/s]Batches:  21%|██▏       | 62/290 [00:37<01:21,  2.79it/s]Batches:  22%|██▏       | 63/290 [00:38<01:21,  2.80it/s]Batches:  22%|██▏       | 64/290 [00:38<01:20,  2.81it/s]Batches:  22%|██▏       | 65/290 [00:38<01:19,  2.82it/s]Batches:  23%|██▎       | 66/290 [00:39<01:20,  2.80it/s]Batches:  23%|██▎       | 67/290 [00:39<01:18,  2.84it/s]Batches:  23%|██▎       | 68/290 [00:39<01:16,  2.89it/s]Batches:  24%|██▍       | 69/290 [00:40<01:15,  2.94it/s]Batches:  24%|██▍       | 70/290 [00:40<01:14,  2.96it/s]Batches:  24%|██▍       | 71/290 [00:40<01:13,  2.98it/s]Batches:  25%|██▍       | 72/290 [00:41<01:12,  3.00it/s]Batches:  25%|██▌       | 73/290 [00:41<01:11,  3.04it/s]Batches:  26%|██▌       | 74/290 [00:41<01:11,  3.03it/s]Batches:  26%|██▌       | 75/290 [00:42<01:11,  2.99it/s]Batches:  26%|██▌       | 76/290 [00:42<01:10,  3.03it/s]Batches:  27%|██▋       | 77/290 [00:42<01:09,  3.08it/s]Batches:  27%|██▋       | 78/290 [00:43<01:08,  3.11it/s]Batches:  27%|██▋       | 79/290 [00:43<01:07,  3.14it/s]Batches:  28%|██▊       | 80/290 [00:43<01:06,  3.16it/s]Batches:  28%|██▊       | 81/290 [00:44<01:06,  3.15it/s]Batches:  28%|██▊       | 82/290 [00:44<01:05,  3.18it/s]Batches:  29%|██▊       | 83/290 [00:44<01:05,  3.18it/s]Batches:  29%|██▉       | 84/290 [00:45<01:05,  3.15it/s]Batches:  29%|██▉       | 85/290 [00:45<01:05,  3.15it/s]Batches:  30%|██▉       | 86/290 [00:45<01:03,  3.19it/s]Batches:  30%|███       | 87/290 [00:45<01:04,  3.16it/s]Batches:  30%|███       | 88/290 [00:46<01:03,  3.20it/s]Batches:  31%|███       | 89/290 [00:46<01:02,  3.22it/s]Batches:  31%|███       | 90/290 [00:46<01:01,  3.25it/s]Batches:  31%|███▏      | 91/290 [00:47<01:00,  3.30it/s]Batches:  32%|███▏      | 92/290 [00:47<00:59,  3.30it/s]Batches:  32%|███▏      | 93/290 [00:47<00:59,  3.30it/s]Batches:  32%|███▏      | 94/290 [00:48<00:59,  3.30it/s]Batches:  33%|███▎      | 95/290 [00:48<00:59,  3.29it/s]Batches:  33%|███▎      | 96/290 [00:48<00:59,  3.28it/s]Batches:  33%|███▎      | 97/290 [00:49<00:58,  3.33it/s]Batches:  34%|███▍      | 98/290 [00:49<00:56,  3.38it/s]Batches:  34%|███▍      | 99/290 [00:49<00:56,  3.41it/s]Batches:  34%|███▍      | 100/290 [00:49<00:56,  3.37it/s]Batches:  35%|███▍      | 101/290 [00:50<00:54,  3.47it/s]Batches:  35%|███▌      | 102/290 [00:50<00:55,  3.42it/s]Batches:  36%|███▌      | 103/290 [00:50<00:54,  3.40it/s]Batches:  36%|███▌      | 104/290 [00:51<00:54,  3.39it/s]Batches:  36%|███▌      | 105/290 [00:51<00:53,  3.48it/s]Batches:  37%|███▋      | 106/290 [00:51<00:52,  3.49it/s]Batches:  37%|███▋      | 107/290 [00:51<00:51,  3.55it/s]Batches:  37%|███▋      | 108/290 [00:52<00:51,  3.57it/s]Batches:  38%|███▊      | 109/290 [00:52<00:50,  3.58it/s]Batches:  38%|███▊      | 110/290 [00:52<00:49,  3.63it/s]Batches:  38%|███▊      | 111/290 [00:52<00:50,  3.55it/s]Batches:  39%|███▊      | 112/290 [00:53<00:49,  3.60it/s]Batches:  39%|███▉      | 113/290 [00:53<00:48,  3.65it/s]Batches:  39%|███▉      | 114/290 [00:53<00:46,  3.75it/s]Batches:  40%|███▉      | 115/290 [00:54<00:46,  3.74it/s]Batches:  40%|████      | 116/290 [00:54<00:46,  3.74it/s]Batches:  40%|████      | 117/290 [00:54<00:45,  3.76it/s]Batches:  41%|████      | 118/290 [00:54<00:46,  3.68it/s]Batches:  41%|████      | 119/290 [00:55<00:46,  3.69it/s]Batches:  41%|████▏     | 120/290 [00:55<00:45,  3.72it/s]Batches:  42%|████▏     | 121/290 [00:55<00:44,  3.76it/s]Batches:  42%|████▏     | 122/290 [00:55<00:44,  3.77it/s]Batches:  42%|████▏     | 123/290 [00:56<00:44,  3.79it/s]Batches:  43%|████▎     | 124/290 [00:56<00:43,  3.82it/s]Batches:  43%|████▎     | 125/290 [00:56<00:43,  3.83it/s]Batches:  43%|████▎     | 126/290 [00:56<00:41,  3.91it/s]Batches:  44%|████▍     | 127/290 [00:57<00:42,  3.88it/s]Batches:  44%|████▍     | 128/290 [00:57<00:41,  3.93it/s]Batches:  44%|████▍     | 129/290 [00:57<00:41,  3.88it/s]Batches:  45%|████▍     | 130/290 [00:57<00:41,  3.87it/s]Batches:  45%|████▌     | 131/290 [00:58<00:41,  3.87it/s]Batches:  46%|████▌     | 132/290 [00:58<00:41,  3.83it/s]Batches:  46%|████▌     | 133/290 [00:58<00:40,  3.92it/s]Batches:  46%|████▌     | 134/290 [00:58<00:39,  3.99it/s]Batches:  47%|████▋     | 135/290 [00:59<00:38,  4.04it/s]Batches:  47%|████▋     | 136/290 [00:59<00:38,  4.03it/s]Batches:  47%|████▋     | 137/290 [00:59<00:38,  3.99it/s]Batches:  48%|████▊     | 138/290 [00:59<00:37,  4.02it/s]Batches:  48%|████▊     | 139/290 [01:00<00:37,  4.02it/s]Batches:  48%|████▊     | 140/290 [01:00<00:36,  4.10it/s]Batches:  49%|████▊     | 141/290 [01:00<00:36,  4.07it/s]Batches:  49%|████▉     | 142/290 [01:00<00:35,  4.13it/s]Batches:  49%|████▉     | 143/290 [01:01<00:35,  4.18it/s]Batches:  50%|████▉     | 144/290 [01:01<00:34,  4.24it/s]Batches:  50%|█████     | 145/290 [01:01<00:33,  4.27it/s]Batches:  50%|█████     | 146/290 [01:01<00:33,  4.29it/s]Batches:  51%|█████     | 147/290 [01:02<00:33,  4.29it/s]Batches:  51%|█████     | 148/290 [01:02<00:33,  4.30it/s]Batches:  51%|█████▏    | 149/290 [01:02<00:32,  4.31it/s]Batches:  52%|█████▏    | 150/290 [01:02<00:32,  4.32it/s]Batches:  52%|█████▏    | 151/290 [01:03<00:32,  4.34it/s]Batches:  52%|█████▏    | 152/290 [01:03<00:31,  4.33it/s]Batches:  53%|█████▎    | 153/290 [01:03<00:30,  4.43it/s]Batches:  53%|█████▎    | 154/290 [01:03<00:30,  4.41it/s]Batches:  53%|█████▎    | 155/290 [01:03<00:30,  4.41it/s]Batches:  54%|█████▍    | 156/290 [01:04<00:29,  4.48it/s]Batches:  54%|█████▍    | 157/290 [01:04<00:29,  4.44it/s]Batches:  54%|█████▍    | 158/290 [01:04<00:29,  4.50it/s]Batches:  55%|█████▍    | 159/290 [01:04<00:29,  4.44it/s]Batches:  55%|█████▌    | 160/290 [01:05<00:28,  4.51it/s]Batches:  56%|█████▌    | 161/290 [01:05<00:28,  4.57it/s]Batches:  56%|█████▌    | 162/290 [01:05<00:28,  4.52it/s]Batches:  56%|█████▌    | 163/290 [01:05<00:27,  4.58it/s]Batches:  57%|█████▋    | 164/290 [01:05<00:27,  4.52it/s]Batches:  57%|█████▋    | 165/290 [01:06<00:27,  4.57it/s]Batches:  57%|█████▋    | 166/290 [01:06<00:27,  4.49it/s]Batches:  58%|█████▊    | 167/290 [01:06<00:26,  4.57it/s]Batches:  58%|█████▊    | 168/290 [01:06<00:27,  4.49it/s]Batches:  58%|█████▊    | 169/290 [01:06<00:26,  4.59it/s]Batches:  59%|█████▊    | 170/290 [01:07<00:25,  4.67it/s]Batches:  59%|█████▉    | 171/290 [01:07<00:25,  4.67it/s]Batches:  59%|█████▉    | 172/290 [01:07<00:25,  4.70it/s]Batches:  60%|█████▉    | 173/290 [01:07<00:24,  4.70it/s]Batches:  60%|██████    | 174/290 [01:08<00:24,  4.78it/s]Batches:  60%|██████    | 175/290 [01:08<00:23,  4.81it/s]Batches:  61%|██████    | 176/290 [01:08<00:23,  4.82it/s]Batches:  61%|██████    | 177/290 [01:08<00:23,  4.80it/s]Batches:  61%|██████▏   | 178/290 [01:08<00:23,  4.83it/s]Batches:  62%|██████▏   | 179/290 [01:09<00:22,  4.87it/s]Batches:  62%|██████▏   | 180/290 [01:09<00:22,  4.81it/s]Batches:  62%|██████▏   | 181/290 [01:09<00:22,  4.92it/s]Batches:  63%|██████▎   | 182/290 [01:09<00:21,  4.97it/s]Batches:  63%|██████▎   | 183/290 [01:09<00:21,  5.05it/s]Batches:  63%|██████▎   | 184/290 [01:10<00:20,  5.09it/s]Batches:  64%|██████▍   | 185/290 [01:10<00:20,  5.06it/s]Batches:  64%|██████▍   | 186/290 [01:10<00:20,  4.97it/s]Batches:  64%|██████▍   | 187/290 [01:10<00:20,  5.00it/s]Batches:  65%|██████▍   | 188/290 [01:10<00:20,  5.07it/s]Batches:  65%|██████▌   | 189/290 [01:11<00:20,  5.01it/s]Batches:  66%|██████▌   | 190/290 [01:11<00:20,  4.95it/s]Batches:  66%|██████▌   | 191/290 [01:11<00:19,  4.97it/s]Batches:  66%|██████▌   | 192/290 [01:11<00:19,  5.07it/s]Batches:  67%|██████▋   | 193/290 [01:11<00:19,  5.06it/s]Batches:  67%|██████▋   | 194/290 [01:12<00:18,  5.15it/s]Batches:  67%|██████▋   | 195/290 [01:12<00:18,  5.09it/s]Batches:  68%|██████▊   | 196/290 [01:12<00:18,  5.18it/s]Batches:  68%|██████▊   | 197/290 [01:12<00:17,  5.20it/s]Batches:  68%|██████▊   | 198/290 [01:12<00:17,  5.32it/s]Batches:  69%|██████▊   | 199/290 [01:12<00:17,  5.34it/s]Batches:  69%|██████▉   | 200/290 [01:13<00:16,  5.38it/s]Batches:  69%|██████▉   | 201/290 [01:13<00:16,  5.46it/s]Batches:  70%|██████▉   | 202/290 [01:13<00:16,  5.39it/s]Batches:  70%|███████   | 203/290 [01:13<00:16,  5.35it/s]Batches:  70%|███████   | 204/290 [01:13<00:15,  5.47it/s]Batches:  71%|███████   | 205/290 [01:14<00:15,  5.48it/s]Batches:  71%|███████   | 206/290 [01:14<00:15,  5.48it/s]Batches:  71%|███████▏  | 207/290 [01:14<00:15,  5.46it/s]Batches:  72%|███████▏  | 208/290 [01:14<00:14,  5.49it/s]Batches:  72%|███████▏  | 209/290 [01:14<00:14,  5.53it/s]Batches:  72%|███████▏  | 210/290 [01:14<00:14,  5.53it/s]Batches:  73%|███████▎  | 211/290 [01:15<00:13,  5.65it/s]Batches:  73%|███████▎  | 212/290 [01:15<00:13,  5.66it/s]Batches:  73%|███████▎  | 213/290 [01:15<00:13,  5.65it/s]Batches:  74%|███████▍  | 214/290 [01:15<00:13,  5.68it/s]Batches:  74%|███████▍  | 215/290 [01:15<00:12,  5.84it/s]Batches:  74%|███████▍  | 216/290 [01:16<00:12,  5.79it/s]Batches:  75%|███████▍  | 217/290 [01:16<00:12,  5.72it/s]Batches:  75%|███████▌  | 218/290 [01:16<00:12,  5.89it/s]Batches:  76%|███████▌  | 219/290 [01:16<00:11,  6.01it/s]Batches:  76%|███████▌  | 220/290 [01:16<00:11,  6.14it/s]Batches:  76%|███████▌  | 221/290 [01:16<00:11,  6.09it/s]Batches:  77%|███████▋  | 222/290 [01:16<00:11,  6.17it/s]Batches:  77%|███████▋  | 223/290 [01:17<00:10,  6.19it/s]Batches:  77%|███████▋  | 224/290 [01:17<00:10,  6.27it/s]Batches:  78%|███████▊  | 225/290 [01:17<00:10,  6.30it/s]Batches:  78%|███████▊  | 226/290 [01:17<00:09,  6.42it/s]Batches:  78%|███████▊  | 227/290 [01:17<00:09,  6.45it/s]Batches:  79%|███████▊  | 228/290 [01:17<00:09,  6.46it/s]Batches:  79%|███████▉  | 229/290 [01:18<00:09,  6.54it/s]Batches:  79%|███████▉  | 230/290 [01:18<00:09,  6.54it/s]Batches:  80%|███████▉  | 231/290 [01:18<00:09,  6.49it/s]Batches:  80%|████████  | 232/290 [01:18<00:08,  6.51it/s]Batches:  80%|████████  | 233/290 [01:18<00:08,  6.57it/s]Batches:  81%|████████  | 234/290 [01:18<00:08,  6.70it/s]Batches:  81%|████████  | 235/290 [01:18<00:08,  6.70it/s]Batches:  81%|████████▏ | 236/290 [01:19<00:07,  6.77it/s]Batches:  82%|████████▏ | 237/290 [01:19<00:07,  6.78it/s]Batches:  82%|████████▏ | 238/290 [01:19<00:07,  6.81it/s]Batches:  82%|████████▏ | 239/290 [01:19<00:07,  6.83it/s]Batches:  83%|████████▎ | 240/290 [01:19<00:07,  6.87it/s]Batches:  83%|████████▎ | 241/290 [01:19<00:07,  6.82it/s]Batches:  83%|████████▎ | 242/290 [01:19<00:06,  6.91it/s]Batches:  84%|████████▍ | 243/290 [01:20<00:06,  6.98it/s]Batches:  84%|████████▍ | 244/290 [01:20<00:06,  6.98it/s]Batches:  84%|████████▍ | 245/290 [01:20<00:06,  7.04it/s]Batches:  85%|████████▍ | 246/290 [01:20<00:06,  7.01it/s]Batches:  85%|████████▌ | 247/290 [01:20<00:06,  6.92it/s]Batches:  86%|████████▌ | 248/290 [01:20<00:05,  7.05it/s]Batches:  86%|████████▌ | 249/290 [01:20<00:05,  7.20it/s]Batches:  86%|████████▌ | 250/290 [01:21<00:05,  7.34it/s]Batches:  87%|████████▋ | 251/290 [01:21<00:05,  7.41it/s]Batches:  87%|████████▋ | 252/290 [01:21<00:05,  7.36it/s]Batches:  87%|████████▋ | 253/290 [01:21<00:04,  7.41it/s]Batches:  88%|████████▊ | 254/290 [01:21<00:04,  7.46it/s]Batches:  88%|████████▊ | 255/290 [01:21<00:04,  7.60it/s]Batches:  88%|████████▊ | 256/290 [01:21<00:04,  7.70it/s]Batches:  89%|████████▊ | 257/290 [01:22<00:04,  7.71it/s]Batches:  89%|████████▉ | 258/290 [01:22<00:04,  7.78it/s]Batches:  89%|████████▉ | 259/290 [01:22<00:03,  8.01it/s]Batches:  90%|████████▉ | 260/290 [01:22<00:03,  8.09it/s]Batches:  90%|█████████ | 261/290 [01:22<00:03,  8.05it/s]Batches:  90%|█████████ | 262/290 [01:22<00:03,  8.20it/s]Batches:  91%|█████████ | 263/290 [01:22<00:03,  8.43it/s]Batches:  91%|█████████ | 264/290 [01:22<00:03,  8.42it/s]Batches:  91%|█████████▏| 265/290 [01:22<00:02,  8.63it/s]Batches:  92%|█████████▏| 266/290 [01:23<00:02,  8.81it/s]Batches:  92%|█████████▏| 267/290 [01:23<00:02,  8.91it/s]Batches:  92%|█████████▏| 268/290 [01:23<00:02,  8.98it/s]Batches:  93%|█████████▎| 269/290 [01:23<00:02,  9.10it/s]Batches:  93%|█████████▎| 270/290 [01:23<00:02,  9.17it/s]Batches:  93%|█████████▎| 271/290 [01:23<00:02,  9.24it/s]Batches:  94%|█████████▍| 272/290 [01:23<00:01,  9.44it/s]Batches:  94%|█████████▍| 274/290 [01:23<00:01,  9.73it/s]Batches:  95%|█████████▌| 276/290 [01:24<00:01,  9.83it/s]Batches:  96%|█████████▌| 278/290 [01:24<00:01, 10.26it/s]Batches:  97%|█████████▋| 280/290 [01:24<00:00, 10.40it/s]Batches:  97%|█████████▋| 282/290 [01:24<00:00, 10.94it/s]Batches:  98%|█████████▊| 284/290 [01:24<00:00, 11.32it/s]Batches:  99%|█████████▊| 286/290 [01:24<00:00, 12.23it/s]Batches:  99%|█████████▉| 288/290 [01:25<00:00, 13.10it/s]Batches: 100%|██████████| 290/290 [01:25<00:00, 14.51it/s]Batches: 100%|██████████| 290/290 [01:25<00:00,  3.41it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 86.83 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for Ko-StrategyQA on dev took 87.46 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.78378, 'ndcg_at_3': 0.75718, 'ndcg_at_5': 0.78694, 'ndcg_at_10': 0.80455, 'ndcg_at_20': 0.81148, 'ndcg_at_100': 0.81914, 'ndcg_at_1000': 0.82687, 'map_at_1': 0.50886, 'map_at_3': 0.71843, 'map_at_5': 0.74839, 'map_at_10': 0.76025, 'map_at_20': 0.7634, 'map_at_100': 0.76489, 'map_at_1000': 0.76521, 'recall_at_1': 0.50886, 'recall_at_3': 0.75575, 'recall_at_5': 0.81673, 'recall_at_10': 0.85876, 'recall_at_20': 0.87945, 'recall_at_100': 0.91277, 'recall_at_1000': 0.96273, 'precision_at_1': 0.78378, 'precision_at_3': 0.44369, 'precision_at_5': 0.29662, 'precision_at_10': 0.15861, 'precision_at_20': 0.08193, 'precision_at_100': 0.01715, 'precision_at_1000': 0.00183, 'mrr_at_1': 0.7837837837837838, 'mrr_at_3': 0.8192567567567567, 'mrr_at_5': 0.8249155405405404, 'mrr_at_10': 0.827872962247962, 'mrr_at_20': 0.8283489727979858, 'mrr_at_100': 0.8288911264937635, 'mrr_at_1000': 0.829072378270852, 'nauc_ndcg_at_1_max': np.float64(0.6635098950594458), 'nauc_ndcg_at_1_std': np.float64(0.3429610770121941), 'nauc_ndcg_at_1_diff1': np.float64(0.7039782338675161), 'nauc_ndcg_at_3_max': np.float64(0.6006969271196718), 'nauc_ndcg_at_3_std': np.float64(0.24601151525952972), 'nauc_ndcg_at_3_diff1': np.float64(0.5553824868395421), 'nauc_ndcg_at_5_max': np.float64(0.6567932863280592), 'nauc_ndcg_at_5_std': np.float64(0.3102342977945531), 'nauc_ndcg_at_5_diff1': np.float64(0.564383093173911), 'nauc_ndcg_at_10_max': np.float64(0.6871098520842034), 'nauc_ndcg_at_10_std': np.float64(0.36613655689021257), 'nauc_ndcg_at_10_diff1': np.float64(0.573620477553593), 'nauc_ndcg_at_20_max': np.float64(0.6986081011851142), 'nauc_ndcg_at_20_std': np.float64(0.3884514469424697), 'nauc_ndcg_at_20_diff1': np.float64(0.5809611232086308), 'nauc_ndcg_at_100_max': np.float64(0.7017299325839507), 'nauc_ndcg_at_100_std': np.float64(0.3931337735532815), 'nauc_ndcg_at_100_diff1': np.float64(0.5951293251311348), 'nauc_ndcg_at_1000_max': np.float64(0.6893530441579121), 'nauc_ndcg_at_1000_std': np.float64(0.37992160336607234), 'nauc_ndcg_at_1000_diff1': np.float64(0.5896225113344592), 'nauc_map_at_1_max': np.float64(0.27455432180887457), 'nauc_map_at_1_std': np.float64(0.04908746167255407), 'nauc_map_at_1_diff1': np.float64(0.6036848204260679), 'nauc_map_at_3_max': np.float64(0.5520570489363213), 'nauc_map_at_3_std': np.float64(0.19297973101256116), 'nauc_map_at_3_diff1': np.float64(0.5385000330031868), 'nauc_map_at_5_max': np.float64(0.599469102192466), 'nauc_map_at_5_std': np.float64(0.24190335441363955), 'nauc_map_at_5_diff1': np.float64(0.5393656278653534), 'nauc_map_at_10_max': np.float64(0.6169145920121064), 'nauc_map_at_10_std': np.float64(0.2745621611414533), 'nauc_map_at_10_diff1': np.float64(0.5436639110590266), 'nauc_map_at_20_max': np.float64(0.6209476711990533), 'nauc_map_at_20_std': np.float64(0.2824604565534582), 'nauc_map_at_20_diff1': np.float64(0.5465351018324915), 'nauc_map_at_100_max': np.float64(0.6214872864776789), 'nauc_map_at_100_std': np.float64(0.2835101366310819), 'nauc_map_at_100_diff1': np.float64(0.5491627339626662), 'nauc_map_at_1000_max': np.float64(0.6210577609718555), 'nauc_map_at_1000_std': np.float64(0.28321542795402066), 'nauc_map_at_1000_diff1': np.float64(0.5489318218179154), 'nauc_recall_at_1_max': np.float64(0.27455432180887457), 'nauc_recall_at_1_std': np.float64(0.04908746167255407), 'nauc_recall_at_1_diff1': np.float64(0.6036848204260679), 'nauc_recall_at_3_max': np.float64(0.5863841039940547), 'nauc_recall_at_3_std': np.float64(0.2200945916068751), 'nauc_recall_at_3_diff1': np.float64(0.5098681472005341), 'nauc_recall_at_5_max': np.float64(0.6952867242934441), 'nauc_recall_at_5_std': np.float64(0.34578000450761803), 'nauc_recall_at_5_diff1': np.float64(0.5146535797571318), 'nauc_recall_at_10_max': np.float64(0.7900763809418352), 'nauc_recall_at_10_std': np.float64(0.5145499618616513), 'nauc_recall_at_10_diff1': np.float64(0.5286081497108596), 'nauc_recall_at_20_max': np.float64(0.8651038956195233), 'nauc_recall_at_20_std': np.float64(0.6404039903045148), 'nauc_recall_at_20_diff1': np.float64(0.5607915727462451), 'nauc_recall_at_100_max': np.float64(0.9531826358145166), 'nauc_recall_at_100_std': np.float64(0.7636033719487576), 'nauc_recall_at_100_diff1': np.float64(0.6710034241527233), 'nauc_recall_at_1000_max': np.float64(0.9478764080243092), 'nauc_recall_at_1000_std': np.float64(0.8617360062914394), 'nauc_recall_at_1000_diff1': np.float64(0.6221662816899628), 'nauc_precision_at_1_max': np.float64(0.6635098950594458), 'nauc_precision_at_1_std': np.float64(0.3429610770121941), 'nauc_precision_at_1_diff1': np.float64(0.7039782338675161), 'nauc_precision_at_3_max': np.float64(0.3935900804913455), 'nauc_precision_at_3_std': np.float64(0.24876520314540496), 'nauc_precision_at_3_diff1': np.float64(-0.007856671228000968), 'nauc_precision_at_5_max': np.float64(0.3286423864345503), 'nauc_precision_at_5_std': np.float64(0.26482494102747317), 'nauc_precision_at_5_diff1': np.float64(-0.09044356310025989), 'nauc_precision_at_10_max': np.float64(0.28837668524433513), 'nauc_precision_at_10_std': np.float64(0.3051512111631377), 'nauc_precision_at_10_diff1': np.float64(-0.1378495149487669), 'nauc_precision_at_20_max': np.float64(0.26129862941748194), 'nauc_precision_at_20_std': np.float64(0.31514306291879324), 'nauc_precision_at_20_diff1': np.float64(-0.1560605152827473), 'nauc_precision_at_100_max': np.float64(0.20203526260720608), 'nauc_precision_at_100_std': np.float64(0.28792879251276216), 'nauc_precision_at_100_diff1': np.float64(-0.18364009205411602), 'nauc_precision_at_1000_max': np.float64(0.0458619746506168), 'nauc_precision_at_1000_std': np.float64(0.18497742062780098), 'nauc_precision_at_1000_diff1': np.float64(-0.3096914087420698), 'nauc_mrr_at_1_max': np.float64(0.6635098950594458), 'nauc_mrr_at_1_std': np.float64(0.3429610770121941), 'nauc_mrr_at_1_diff1': np.float64(0.7039782338675161), 'nauc_mrr_at_3_max': np.float64(0.7376710071921518), 'nauc_mrr_at_3_std': np.float64(0.42405952788338447), 'nauc_mrr_at_3_diff1': np.float64(0.6834176298612757), 'nauc_mrr_at_5_max': np.float64(0.7367565345614144), 'nauc_mrr_at_5_std': np.float64(0.4369650736792798), 'nauc_mrr_at_5_diff1': np.float64(0.6849212012473278), 'nauc_mrr_at_10_max': np.float64(0.7404394035108768), 'nauc_mrr_at_10_std': np.float64(0.44252326049371493), 'nauc_mrr_at_10_diff1': np.float64(0.6866693253784778), 'nauc_mrr_at_20_max': np.float64(0.7403043990549767), 'nauc_mrr_at_20_std': np.float64(0.4422889201745312), 'nauc_mrr_at_20_diff1': np.float64(0.6865762848379476), 'nauc_mrr_at_100_max': np.float64(0.7397764597355462), 'nauc_mrr_at_100_std': np.float64(0.44171317144790206), 'nauc_mrr_at_100_diff1': np.float64(0.6871772045884535), 'nauc_mrr_at_1000_max': np.float64(0.7395039139774315), 'nauc_mrr_at_1000_std': np.float64(0.44129594326015636), 'nauc_mrr_at_1000_diff1': np.float64(0.6871327673802907), 'main_score': 0.80455}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating AutoRAGRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 720 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'commerce - B2BDigComm.pdf - 1', 'text': 'Adobe\n디지털 커머스 시대,\nB2B 비즈니스 생존 전략\nB2B 비즈니스를 e커머스에 통합해야 하는\n3가지 이유', 'title': ''}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 114 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '0_finance', 'text': '시중은행, 지방은행, 인터넷은행의 인가 요건 및 절차에 차이가 있는데 그 차이점은 무엇인가요?'}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: default
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=AutoRAGRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 114 sentences.
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  50%|█████     | 2/4 [00:00<00:00, 16.62it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 16.16it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 16.19it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=AutoRAGRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 720 sentences.
Batches:   0%|          | 0/23 [00:00<?, ?it/s]Batches:   9%|▊         | 2/23 [00:02<00:23,  1.12s/it]Batches:  13%|█▎        | 3/23 [00:03<00:24,  1.21s/it]Batches:  17%|█▋        | 4/23 [00:04<00:22,  1.20s/it]Batches:  22%|██▏       | 5/23 [00:05<00:20,  1.15s/it]Batches:  26%|██▌       | 6/23 [00:06<00:18,  1.10s/it]Batches:  30%|███       | 7/23 [00:07<00:16,  1.04s/it]Batches:  35%|███▍      | 8/23 [00:08<00:14,  1.02it/s]Batches:  39%|███▉      | 9/23 [00:09<00:13,  1.04it/s]Batches:  43%|████▎     | 10/23 [00:10<00:12,  1.07it/s]Batches:  48%|████▊     | 11/23 [00:11<00:10,  1.11it/s]Batches:  52%|█████▏    | 12/23 [00:11<00:09,  1.15it/s]Batches:  57%|█████▋    | 13/23 [00:12<00:08,  1.22it/s]Batches:  61%|██████    | 14/23 [00:13<00:07,  1.28it/s]Batches:  65%|██████▌   | 15/23 [00:14<00:05,  1.34it/s]Batches:  70%|██████▉   | 16/23 [00:14<00:04,  1.41it/s]Batches:  74%|███████▍  | 17/23 [00:15<00:03,  1.50it/s]Batches:  78%|███████▊  | 18/23 [00:15<00:03,  1.61it/s]Batches:  83%|████████▎ | 19/23 [00:16<00:02,  1.74it/s]Batches:  87%|████████▋ | 20/23 [00:16<00:01,  1.95it/s]Batches:  91%|█████████▏| 21/23 [00:16<00:00,  2.17it/s]Batches:  96%|█████████▌| 22/23 [00:17<00:00,  2.60it/s]Batches: 100%|██████████| 23/23 [00:17<00:00,  3.23it/s]Batches: 100%|██████████| 23/23 [00:17<00:00,  1.33it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 17.65 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for AutoRAGRetrieval on test took 17.78 seconds
INFO:mteb.evaluation.MTEB:Scores: {'default': {'ndcg_at_1': 0.68421, 'ndcg_at_3': 0.79354, 'ndcg_at_5': 0.83356, 'ndcg_at_10': 0.83863, 'ndcg_at_20': 0.84288, 'ndcg_at_100': 0.84288, 'ndcg_at_1000': 0.84288, 'map_at_1': 0.68421, 'map_at_3': 0.76754, 'map_at_5': 0.78991, 'map_at_10': 0.79167, 'map_at_20': 0.79273, 'map_at_100': 0.79273, 'map_at_1000': 0.79273, 'recall_at_1': 0.68421, 'recall_at_3': 0.86842, 'recall_at_5': 0.96491, 'recall_at_10': 0.98246, 'recall_at_20': 1.0, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.68421, 'precision_at_3': 0.28947, 'precision_at_5': 0.19298, 'precision_at_10': 0.09825, 'precision_at_20': 0.05, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6842105263157895, 'mrr_at_3': 0.7675438596491229, 'mrr_at_5': 0.7899122807017545, 'mrr_at_10': 0.7916666666666667, 'mrr_at_20': 0.792730908152735, 'mrr_at_100': 0.792730908152735, 'mrr_at_1000': 0.792730908152735, 'nauc_ndcg_at_1_max': np.float64(0.08937251170693959), 'nauc_ndcg_at_1_std': np.float64(-0.40944616514098364), 'nauc_ndcg_at_1_diff1': np.float64(0.7315739378887288), 'nauc_ndcg_at_3_max': np.float64(0.24842005840007533), 'nauc_ndcg_at_3_std': np.float64(-0.4310821162984832), 'nauc_ndcg_at_3_diff1': np.float64(0.7013661131573447), 'nauc_ndcg_at_5_max': np.float64(0.21515205814835708), 'nauc_ndcg_at_5_std': np.float64(-0.47674613092113943), 'nauc_ndcg_at_5_diff1': np.float64(0.7050812246939303), 'nauc_ndcg_at_10_max': np.float64(0.20652883534218802), 'nauc_ndcg_at_10_std': np.float64(-0.44185925880170035), 'nauc_ndcg_at_10_diff1': np.float64(0.7175174694626112), 'nauc_ndcg_at_20_max': np.float64(0.19402279307495116), 'nauc_ndcg_at_20_std': np.float64(-0.42996831555137355), 'nauc_ndcg_at_20_diff1': np.float64(0.7157357387931066), 'nauc_ndcg_at_100_max': np.float64(0.19402279307495116), 'nauc_ndcg_at_100_std': np.float64(-0.42996831555137355), 'nauc_ndcg_at_100_diff1': np.float64(0.7157357387931066), 'nauc_ndcg_at_1000_max': np.float64(0.19402279307495116), 'nauc_ndcg_at_1000_std': np.float64(-0.42996831555137355), 'nauc_ndcg_at_1000_diff1': np.float64(0.7157357387931066), 'nauc_map_at_1_max': np.float64(0.08937251170693959), 'nauc_map_at_1_std': np.float64(-0.40944616514098364), 'nauc_map_at_1_diff1': np.float64(0.7315739378887288), 'nauc_map_at_3_max': np.float64(0.2077439479456947), 'nauc_map_at_3_std': np.float64(-0.4210120558017581), 'nauc_map_at_3_diff1': np.float64(0.7120407684642793), 'nauc_map_at_5_max': np.float64(0.1900538786359124), 'nauc_map_at_5_std': np.float64(-0.4372445542839447), 'nauc_map_at_5_diff1': np.float64(0.7144138576597245), 'nauc_map_at_10_max': np.float64(0.18748746385796178), 'nauc_map_at_10_std': np.float64(-0.42745998982824207), 'nauc_map_at_10_diff1': np.float64(0.7178559952483783), 'nauc_map_at_20_max': np.float64(0.18502503702396267), 'nauc_map_at_20_std': np.float64(-0.4249990451938173), 'nauc_map_at_20_diff1': np.float64(0.7175453870894336), 'nauc_map_at_100_max': np.float64(0.18502503702396267), 'nauc_map_at_100_std': np.float64(-0.4249990451938173), 'nauc_map_at_100_diff1': np.float64(0.7175453870894336), 'nauc_map_at_1000_max': np.float64(0.18502503702396267), 'nauc_map_at_1000_std': np.float64(-0.4249990451938173), 'nauc_map_at_1000_diff1': np.float64(0.7175453870894336), 'nauc_recall_at_1_max': np.float64(0.08937251170693959), 'nauc_recall_at_1_std': np.float64(-0.40944616514098364), 'nauc_recall_at_1_diff1': np.float64(0.7315739378887288), 'nauc_recall_at_3_max': np.float64(0.4315055296764355), 'nauc_recall_at_3_std': np.float64(-0.48012898839184837), 'nauc_recall_at_3_diff1': np.float64(0.6509000965721542), 'nauc_recall_at_5_max': np.float64(0.5349009588020079), 'nauc_recall_at_5_std': np.float64(-1.1344371632083772), 'nauc_recall_at_5_diff1': np.float64(0.5674537857580308), 'nauc_recall_at_10_max': np.float64(0.6136582309416372), 'nauc_recall_at_10_std': np.float64(-0.8171511695270118), 'nauc_recall_at_10_diff1': np.float64(0.7773798018086994), 'nauc_recall_at_20_max': nan, 'nauc_recall_at_20_std': nan, 'nauc_recall_at_20_diff1': nan, 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.08937251170693959), 'nauc_precision_at_1_std': np.float64(-0.40944616514098364), 'nauc_precision_at_1_diff1': np.float64(0.7315739378887288), 'nauc_precision_at_3_max': np.float64(0.43150552967643396), 'nauc_precision_at_3_std': np.float64(-0.4801289883918476), 'nauc_precision_at_3_diff1': np.float64(0.6509000965721542), 'nauc_precision_at_5_max': np.float64(0.5349009588020046), 'nauc_precision_at_5_std': np.float64(-1.1344371632083743), 'nauc_precision_at_5_diff1': np.float64(0.5674537857580312), 'nauc_precision_at_10_max': np.float64(0.6136582309416158), 'nauc_precision_at_10_std': np.float64(-0.8171511695270405), 'nauc_precision_at_10_diff1': np.float64(0.7773798018086919), 'nauc_precision_at_20_max': np.float64(1.0), 'nauc_precision_at_20_std': np.float64(1.0), 'nauc_precision_at_20_diff1': np.float64(1.0), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': np.float64(1.0), 'nauc_precision_at_1000_std': np.float64(1.0), 'nauc_precision_at_1000_diff1': np.float64(1.0), 'nauc_mrr_at_1_max': np.float64(0.08937251170693959), 'nauc_mrr_at_1_std': np.float64(-0.40944616514098364), 'nauc_mrr_at_1_diff1': np.float64(0.7315739378887288), 'nauc_mrr_at_3_max': np.float64(0.2077439479456947), 'nauc_mrr_at_3_std': np.float64(-0.4210120558017581), 'nauc_mrr_at_3_diff1': np.float64(0.7120407684642793), 'nauc_mrr_at_5_max': np.float64(0.1900538786359124), 'nauc_mrr_at_5_std': np.float64(-0.4372445542839447), 'nauc_mrr_at_5_diff1': np.float64(0.7144138576597245), 'nauc_mrr_at_10_max': np.float64(0.18748746385796178), 'nauc_mrr_at_10_std': np.float64(-0.42745998982824207), 'nauc_mrr_at_10_diff1': np.float64(0.7178559952483783), 'nauc_mrr_at_20_max': np.float64(0.18502503702396267), 'nauc_mrr_at_20_std': np.float64(-0.4249990451938173), 'nauc_mrr_at_20_diff1': np.float64(0.7175453870894336), 'nauc_mrr_at_100_max': np.float64(0.18502503702396267), 'nauc_mrr_at_100_std': np.float64(-0.4249990451938173), 'nauc_mrr_at_100_diff1': np.float64(0.7175453870894336), 'nauc_mrr_at_1000_max': np.float64(0.18502503702396267), 'nauc_mrr_at_1000_std': np.float64(-0.4249990451938173), 'nauc_mrr_at_1000_diff1': np.float64(0.7175453870894336), 'main_score': 0.83863}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating PublicHealthQA **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: korean
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=PublicHealthQA prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches: 100%|██████████| 3/3 [00:00<00:00, 22.72it/s]Batches: 100%|██████████| 3/3 [00:00<00:00, 22.55it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=PublicHealthQA prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 77 sentences.
Batches:   0%|          | 0/3 [00:00<?, ?it/s]Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.99it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]Batches: 100%|██████████| 3/3 [00:01<00:00,  2.46it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.41 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for PublicHealthQA on test took 1.49 seconds
INFO:mteb.evaluation.MTEB:Scores: {'korean': {'ndcg_at_1': 0.67532, 'ndcg_at_3': 0.78324, 'ndcg_at_5': 0.79888, 'ndcg_at_10': 0.81679, 'ndcg_at_20': 0.82679, 'ndcg_at_100': 0.82963, 'ndcg_at_1000': 0.82963, 'map_at_1': 0.67532, 'map_at_3': 0.75758, 'map_at_5': 0.76602, 'map_at_10': 0.77406, 'map_at_20': 0.77689, 'map_at_100': 0.77745, 'map_at_1000': 0.77745, 'recall_at_1': 0.67532, 'recall_at_3': 0.85714, 'recall_at_5': 0.8961, 'recall_at_10': 0.94805, 'recall_at_20': 0.98701, 'recall_at_100': 1.0, 'recall_at_1000': 1.0, 'precision_at_1': 0.67532, 'precision_at_3': 0.28571, 'precision_at_5': 0.17922, 'precision_at_10': 0.09481, 'precision_at_20': 0.04935, 'precision_at_100': 0.01, 'precision_at_1000': 0.001, 'mrr_at_1': 0.6753246753246753, 'mrr_at_3': 0.7575757575757577, 'mrr_at_5': 0.7660173160173163, 'mrr_at_10': 0.7740568954854671, 'mrr_at_20': 0.7768866775360285, 'mrr_at_100': 0.7774513302745942, 'mrr_at_1000': 0.7774513302745942, 'nauc_ndcg_at_1_max': np.float64(0.2752344116017262), 'nauc_ndcg_at_1_std': np.float64(-0.02403878250515555), 'nauc_ndcg_at_1_diff1': np.float64(0.7851995165398186), 'nauc_ndcg_at_3_max': np.float64(0.23894532675598978), 'nauc_ndcg_at_3_std': np.float64(-0.12910519725348626), 'nauc_ndcg_at_3_diff1': np.float64(0.7255510914154699), 'nauc_ndcg_at_5_max': np.float64(0.2600640990272683), 'nauc_ndcg_at_5_std': np.float64(-0.1416299994729397), 'nauc_ndcg_at_5_diff1': np.float64(0.7642780739999684), 'nauc_ndcg_at_10_max': np.float64(0.2292185678814945), 'nauc_ndcg_at_10_std': np.float64(-0.1383305401007248), 'nauc_ndcg_at_10_diff1': np.float64(0.7665394522213186), 'nauc_ndcg_at_20_max': np.float64(0.22112551117322296), 'nauc_ndcg_at_20_std': np.float64(-0.10971479650074134), 'nauc_ndcg_at_20_diff1': np.float64(0.7566748738648852), 'nauc_ndcg_at_100_max': np.float64(0.2474642550077683), 'nauc_ndcg_at_100_std': np.float64(-0.10114625492689958), 'nauc_ndcg_at_100_diff1': np.float64(0.7573226007395515), 'nauc_ndcg_at_1000_max': np.float64(0.2474642550077683), 'nauc_ndcg_at_1000_std': np.float64(-0.10114625492689958), 'nauc_ndcg_at_1000_diff1': np.float64(0.7573226007395515), 'nauc_map_at_1_max': np.float64(0.2752344116017262), 'nauc_map_at_1_std': np.float64(-0.02403878250515555), 'nauc_map_at_1_diff1': np.float64(0.7851995165398186), 'nauc_map_at_3_max': np.float64(0.2537127755597208), 'nauc_map_at_3_std': np.float64(-0.09955471183608891), 'nauc_map_at_3_diff1': np.float64(0.7421587566835735), 'nauc_map_at_5_max': np.float64(0.26320166564302433), 'nauc_map_at_5_std': np.float64(-0.10458123709335891), 'nauc_map_at_5_diff1': np.float64(0.7604174039241631), 'nauc_map_at_10_max': np.float64(0.25137148334753867), 'nauc_map_at_10_std': np.float64(-0.10245596346743999), 'nauc_map_at_10_diff1': np.float64(0.7607416017588936), 'nauc_map_at_20_max': np.float64(0.24973268621226655), 'nauc_map_at_20_std': np.float64(-0.09396946143109765), 'nauc_map_at_20_diff1': np.float64(0.7583721957646316), 'nauc_map_at_100_max': np.float64(0.2538527035545413), 'nauc_map_at_100_std': np.float64(-0.09261037432487297), 'nauc_map_at_100_diff1': np.float64(0.7584764114264305), 'nauc_map_at_1000_max': np.float64(0.2538527035545413), 'nauc_map_at_1000_std': np.float64(-0.09261037432487297), 'nauc_map_at_1000_diff1': np.float64(0.7584764114264305), 'nauc_recall_at_1_max': np.float64(0.2752344116017262), 'nauc_recall_at_1_std': np.float64(-0.02403878250515555), 'nauc_recall_at_1_diff1': np.float64(0.7851995165398186), 'nauc_recall_at_3_max': np.float64(0.1709126730774714), 'nauc_recall_at_3_std': np.float64(-0.25885159978810973), 'nauc_recall_at_3_diff1': np.float64(0.6527505054073036), 'nauc_recall_at_5_max': np.float64(0.24811281473066885), 'nauc_recall_at_5_std': np.float64(-0.35376378094362426), 'nauc_recall_at_5_diff1': np.float64(0.801157388309851), 'nauc_recall_at_10_max': np.float64(-0.03149121242100211), 'nauc_recall_at_10_std': np.float64(-0.5249129783115243), 'nauc_recall_at_10_diff1': np.float64(0.8650070126227221), 'nauc_recall_at_20_max': np.float64(-1.1643653934883855), 'nauc_recall_at_20_std': np.float64(-0.5604438248609525), 'nauc_recall_at_20_diff1': np.float64(0.7226026455463075), 'nauc_recall_at_100_max': nan, 'nauc_recall_at_100_std': nan, 'nauc_recall_at_100_diff1': nan, 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.2752344116017262), 'nauc_precision_at_1_std': np.float64(-0.02403878250515555), 'nauc_precision_at_1_diff1': np.float64(0.7851995165398186), 'nauc_precision_at_3_max': np.float64(0.17091267307747307), 'nauc_precision_at_3_std': np.float64(-0.2588515997881084), 'nauc_precision_at_3_diff1': np.float64(0.6527505054073036), 'nauc_precision_at_5_max': np.float64(0.24811281473067048), 'nauc_precision_at_5_std': np.float64(-0.35376378094362076), 'nauc_precision_at_5_diff1': np.float64(0.8011573883098524), 'nauc_precision_at_10_max': np.float64(-0.03149121242099502), 'nauc_precision_at_10_std': np.float64(-0.5249129783115125), 'nauc_precision_at_10_diff1': np.float64(0.8650070126227222), 'nauc_precision_at_20_max': np.float64(-1.1643653934883855), 'nauc_precision_at_20_std': np.float64(-0.5604438248609525), 'nauc_precision_at_20_diff1': np.float64(0.7226026455462948), 'nauc_precision_at_100_max': np.float64(1.0), 'nauc_precision_at_100_std': np.float64(1.0), 'nauc_precision_at_100_diff1': np.float64(1.0), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.2752344116017262), 'nauc_mrr_at_1_std': np.float64(-0.02403878250515555), 'nauc_mrr_at_1_diff1': np.float64(0.7851995165398186), 'nauc_mrr_at_3_max': np.float64(0.2537127755597208), 'nauc_mrr_at_3_std': np.float64(-0.09955471183608891), 'nauc_mrr_at_3_diff1': np.float64(0.7421587566835735), 'nauc_mrr_at_5_max': np.float64(0.26320166564302433), 'nauc_mrr_at_5_std': np.float64(-0.10458123709335891), 'nauc_mrr_at_5_diff1': np.float64(0.7604174039241631), 'nauc_mrr_at_10_max': np.float64(0.25137148334753867), 'nauc_mrr_at_10_std': np.float64(-0.10245596346743999), 'nauc_mrr_at_10_diff1': np.float64(0.7607416017588936), 'nauc_mrr_at_20_max': np.float64(0.24973268621226655), 'nauc_mrr_at_20_std': np.float64(-0.09396946143109765), 'nauc_mrr_at_20_diff1': np.float64(0.7583721957646316), 'nauc_mrr_at_100_max': np.float64(0.2538527035545413), 'nauc_mrr_at_100_std': np.float64(-0.09261037432487297), 'nauc_mrr_at_100_diff1': np.float64(0.7584764114264305), 'nauc_mrr_at_1000_max': np.float64(0.2538527035545413), 'nauc_mrr_at_1000_std': np.float64(-0.09261037432487297), 'nauc_mrr_at_1000_diff1': np.float64(0.7584764114264305), 'main_score': 0.81679}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating BelebeleRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:01, 23.06it/s]Batches:  21%|██        | 6/29 [00:00<00:01, 21.40it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 21.58it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 22.06it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 22.82it/s]Batches:  62%|██████▏   | 18/29 [00:00<00:00, 24.10it/s]Batches:  72%|███████▏  | 21/29 [00:00<00:00, 25.27it/s]Batches:  83%|████████▎ | 24/29 [00:00<00:00, 26.03it/s]Batches:  93%|█████████▎| 27/29 [00:01<00:00, 27.09it/s]Batches: 100%|██████████| 29/29 [00:01<00:00, 25.11it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  3.95it/s]Batches:  19%|█▉        | 3/16 [00:00<00:03,  3.84it/s]Batches:  25%|██▌       | 4/16 [00:01<00:03,  3.80it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  3.96it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.08it/s]Batches:  44%|████▍     | 7/16 [00:01<00:02,  4.20it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  4.35it/s]Batches:  56%|█████▋    | 9/16 [00:02<00:01,  4.60it/s]Batches:  62%|██████▎   | 10/16 [00:02<00:01,  4.80it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.03it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  5.39it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  5.69it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  5.96it/s]Batches:  94%|█████████▍| 15/16 [00:03<00:00,  6.37it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  6.98it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.73 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor_Hang-eng_Latn
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:01, 23.94it/s]Batches:  21%|██        | 6/29 [00:00<00:01, 22.93it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 23.44it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 23.75it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 25.02it/s]Batches:  62%|██████▏   | 18/29 [00:00<00:00, 25.98it/s]Batches:  72%|███████▏  | 21/29 [00:00<00:00, 26.99it/s]Batches:  83%|████████▎ | 24/29 [00:00<00:00, 27.59it/s]Batches:  97%|█████████▋| 28/29 [00:01<00:00, 29.52it/s]Batches: 100%|██████████| 29/29 [00:01<00:00, 26.91it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  3.94it/s]Batches:  19%|█▉        | 3/16 [00:00<00:03,  3.82it/s]Batches:  25%|██▌       | 4/16 [00:01<00:03,  3.81it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  3.95it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.07it/s]Batches:  44%|████▍     | 7/16 [00:01<00:02,  4.19it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  4.36it/s]Batches:  56%|█████▋    | 9/16 [00:02<00:01,  4.59it/s]Batches:  62%|██████▎   | 10/16 [00:02<00:01,  4.78it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.02it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  5.38it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  5.70it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  5.97it/s]Batches:  94%|█████████▍| 15/16 [00:03<00:00,  6.41it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  7.02it/s]Batches: 100%|██████████| 16/16 [00:03<00:00,  5.00it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.64 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng_Latn-kor_Hang
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=BelebeleRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 900 sentences.
Batches:   0%|          | 0/29 [00:00<?, ?it/s]Batches:  10%|█         | 3/29 [00:00<00:01, 24.00it/s]Batches:  21%|██        | 6/29 [00:00<00:01, 21.72it/s]Batches:  31%|███       | 9/29 [00:00<00:00, 21.68it/s]Batches:  41%|████▏     | 12/29 [00:00<00:00, 22.15it/s]Batches:  52%|█████▏    | 15/29 [00:00<00:00, 22.89it/s]Batches:  62%|██████▏   | 18/29 [00:00<00:00, 24.16it/s]Batches:  72%|███████▏  | 21/29 [00:00<00:00, 25.33it/s]Batches:  83%|████████▎ | 24/29 [00:00<00:00, 25.97it/s]Batches:  93%|█████████▎| 27/29 [00:01<00:00, 27.06it/s]Batches: 100%|██████████| 29/29 [00:01<00:00, 25.20it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=BelebeleRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 488 sentences.
Batches:   0%|          | 0/16 [00:00<?, ?it/s]Batches:  12%|█▎        | 2/16 [00:00<00:03,  4.39it/s]Batches:  19%|█▉        | 3/16 [00:00<00:02,  4.42it/s]Batches:  25%|██▌       | 4/16 [00:00<00:02,  4.36it/s]Batches:  31%|███▏      | 5/16 [00:01<00:02,  4.47it/s]Batches:  38%|███▊      | 6/16 [00:01<00:02,  4.64it/s]Batches:  44%|████▍     | 7/16 [00:01<00:01,  4.85it/s]Batches:  50%|█████     | 8/16 [00:01<00:01,  5.09it/s]Batches:  56%|█████▋    | 9/16 [00:01<00:01,  5.24it/s]Batches:  62%|██████▎   | 10/16 [00:02<00:01,  5.52it/s]Batches:  69%|██████▉   | 11/16 [00:02<00:00,  5.73it/s]Batches:  75%|███████▌  | 12/16 [00:02<00:00,  6.02it/s]Batches:  81%|████████▏ | 13/16 [00:02<00:00,  6.38it/s]Batches:  88%|████████▊ | 14/16 [00:02<00:00,  6.65it/s]Batches:  94%|█████████▍| 15/16 [00:02<00:00,  7.24it/s]Batches: 100%|██████████| 16/16 [00:02<00:00,  7.82it/s]Batches: 100%|██████████| 16/16 [00:02<00:00,  5.68it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.28 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for BelebeleRetrieval on test took 15.06 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor_Hang-kor_Hang': {'ndcg_at_1': 0.88222, 'ndcg_at_3': 0.91395, 'ndcg_at_5': 0.92314, 'ndcg_at_10': 0.9271, 'ndcg_at_20': 0.92943, 'ndcg_at_100': 0.93212, 'ndcg_at_1000': 0.93287, 'map_at_1': 0.88222, 'map_at_3': 0.90611, 'map_at_5': 0.91122, 'map_at_10': 0.91286, 'map_at_20': 0.91355, 'map_at_100': 0.91392, 'map_at_1000': 0.91395, 'recall_at_1': 0.88222, 'recall_at_3': 0.93667, 'recall_at_5': 0.95889, 'recall_at_10': 0.97111, 'recall_at_20': 0.98, 'recall_at_100': 0.99444, 'recall_at_1000': 1.0, 'precision_at_1': 0.88222, 'precision_at_3': 0.31222, 'precision_at_5': 0.19178, 'precision_at_10': 0.09711, 'precision_at_20': 0.049, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8822222222222222, 'mrr_at_3': 0.9061111111111113, 'mrr_at_5': 0.9112222222222226, 'mrr_at_10': 0.912859788359789, 'mrr_at_20': 0.9135460737280918, 'mrr_at_100': 0.9139200792755104, 'mrr_at_1000': 0.9139533425494579, 'nauc_ndcg_at_1_max': np.float64(0.8717942957784449), 'nauc_ndcg_at_1_std': np.float64(0.08754919756303658), 'nauc_ndcg_at_1_diff1': np.float64(0.9296227737541118), 'nauc_ndcg_at_3_max': np.float64(0.8943716652553768), 'nauc_ndcg_at_3_std': np.float64(0.15547258152559723), 'nauc_ndcg_at_3_diff1': np.float64(0.9307142736830627), 'nauc_ndcg_at_5_max': np.float64(0.8975194616001423), 'nauc_ndcg_at_5_std': np.float64(0.18753693112985628), 'nauc_ndcg_at_5_diff1': np.float64(0.9312687490280459), 'nauc_ndcg_at_10_max': np.float64(0.8931854614350907), 'nauc_ndcg_at_10_std': np.float64(0.17704568176023203), 'nauc_ndcg_at_10_diff1': np.float64(0.9307900330993414), 'nauc_ndcg_at_20_max': np.float64(0.8912589054659944), 'nauc_ndcg_at_20_std': np.float64(0.1632119096506032), 'nauc_ndcg_at_20_diff1': np.float64(0.9313533299976648), 'nauc_ndcg_at_100_max': np.float64(0.8885188782375928), 'nauc_ndcg_at_100_std': np.float64(0.153497086784182), 'nauc_ndcg_at_100_diff1': np.float64(0.9298078644281649), 'nauc_ndcg_at_1000_max': np.float64(0.8875965980618693), 'nauc_ndcg_at_1000_std': np.float64(0.14744169803176757), 'nauc_ndcg_at_1000_diff1': np.float64(0.929651467839546), 'nauc_map_at_1_max': np.float64(0.8717942957784449), 'nauc_map_at_1_std': np.float64(0.08754919756303658), 'nauc_map_at_1_diff1': np.float64(0.9296227737541118), 'nauc_map_at_3_max': np.float64(0.8866182961417318), 'nauc_map_at_3_std': np.float64(0.13246139588309766), 'nauc_map_at_3_diff1': np.float64(0.9292837470187973), 'nauc_map_at_5_max': np.float64(0.887466860226232), 'nauc_map_at_5_std': np.float64(0.14534590681117465), 'nauc_map_at_5_diff1': np.float64(0.9294892971901109), 'nauc_map_at_10_max': np.float64(0.8857740031256106), 'nauc_map_at_10_std': np.float64(0.14093319846495117), 'nauc_map_at_10_diff1': np.float64(0.9292695155141295), 'nauc_map_at_20_max': np.float64(0.8851605946546521), 'nauc_map_at_20_std': np.float64(0.13700857190885474), 'nauc_map_at_20_diff1': np.float64(0.9292469552544826), 'nauc_map_at_100_max': np.float64(0.8847901634803119), 'nauc_map_at_100_std': np.float64(0.13555528328408067), 'nauc_map_at_100_diff1': np.float64(0.9290685815866618), 'nauc_map_at_1000_max': np.float64(0.8847616291616678), 'nauc_map_at_1000_std': np.float64(0.13532290242176023), 'nauc_map_at_1000_diff1': np.float64(0.9290688820516655), 'nauc_recall_at_1_max': np.float64(0.8717942957784449), 'nauc_recall_at_1_std': np.float64(0.08754919756303658), 'nauc_recall_at_1_diff1': np.float64(0.9296227737541118), 'nauc_recall_at_3_max': np.float64(0.9277196258620402), 'nauc_recall_at_3_std': np.float64(0.2542794895736067), 'nauc_recall_at_3_diff1': np.float64(0.9374252625026616), 'nauc_recall_at_5_max': np.float64(0.9617684911802569), 'nauc_recall_at_5_std': np.float64(0.46228581522699563), 'nauc_recall_at_5_diff1': np.float64(0.9433467080525928), 'nauc_recall_at_10_max': np.float64(0.955648926237161), 'nauc_recall_at_10_std': np.float64(0.4976836888601627), 'nauc_recall_at_10_diff1': np.float64(0.9451447245564897), 'nauc_recall_at_20_max': np.float64(0.9607065048241529), 'nauc_recall_at_20_std': np.float64(0.4662050005187225), 'nauc_recall_at_20_diff1': np.float64(0.9636891793754577), 'nauc_recall_at_100_max': np.float64(0.9738562091503434), 'nauc_recall_at_100_std': np.float64(0.6798319327731049), 'nauc_recall_at_100_diff1': np.float64(0.9477124183006633), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8717942957784449), 'nauc_precision_at_1_std': np.float64(0.08754919756303658), 'nauc_precision_at_1_diff1': np.float64(0.9296227737541118), 'nauc_precision_at_3_max': np.float64(0.9277196258620428), 'nauc_precision_at_3_std': np.float64(0.2542794895736049), 'nauc_precision_at_3_diff1': np.float64(0.9374252625026622), 'nauc_precision_at_5_max': np.float64(0.9617684911802544), 'nauc_precision_at_5_std': np.float64(0.4622858152269868), 'nauc_precision_at_5_diff1': np.float64(0.9433467080525879), 'nauc_precision_at_10_max': np.float64(0.9556489262371577), 'nauc_precision_at_10_std': np.float64(0.49768368886015196), 'nauc_precision_at_10_diff1': np.float64(0.9451447245564852), 'nauc_precision_at_20_max': np.float64(0.9607065048241547), 'nauc_precision_at_20_std': np.float64(0.4662050005187193), 'nauc_precision_at_20_diff1': np.float64(0.9636891793754528), 'nauc_precision_at_100_max': np.float64(0.9738562091503018), 'nauc_precision_at_100_std': np.float64(0.6798319327730821), 'nauc_precision_at_100_diff1': np.float64(0.9477124183006403), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8717942957784449), 'nauc_mrr_at_1_std': np.float64(0.08754919756303658), 'nauc_mrr_at_1_diff1': np.float64(0.9296227737541118), 'nauc_mrr_at_3_max': np.float64(0.8866182961417318), 'nauc_mrr_at_3_std': np.float64(0.13246139588309766), 'nauc_mrr_at_3_diff1': np.float64(0.9292837470187973), 'nauc_mrr_at_5_max': np.float64(0.887466860226232), 'nauc_mrr_at_5_std': np.float64(0.14534590681117465), 'nauc_mrr_at_5_diff1': np.float64(0.9294892971901109), 'nauc_mrr_at_10_max': np.float64(0.8857740031256106), 'nauc_mrr_at_10_std': np.float64(0.14093319846495117), 'nauc_mrr_at_10_diff1': np.float64(0.9292695155141295), 'nauc_mrr_at_20_max': np.float64(0.8851605946546521), 'nauc_mrr_at_20_std': np.float64(0.13700857190885474), 'nauc_mrr_at_20_diff1': np.float64(0.9292469552544826), 'nauc_mrr_at_100_max': np.float64(0.8847901634803119), 'nauc_mrr_at_100_std': np.float64(0.13555528328408067), 'nauc_mrr_at_100_diff1': np.float64(0.9290685815866618), 'nauc_mrr_at_1000_max': np.float64(0.8847616291616678), 'nauc_mrr_at_1000_std': np.float64(0.13532290242176023), 'nauc_mrr_at_1000_diff1': np.float64(0.9290688820516655), 'main_score': 0.9271}, 'kor_Hang-eng_Latn': {'ndcg_at_1': 0.82111, 'ndcg_at_3': 0.87551, 'ndcg_at_5': 0.88427, 'ndcg_at_10': 0.89361, 'ndcg_at_20': 0.89785, 'ndcg_at_100': 0.90122, 'ndcg_at_1000': 0.9015, 'map_at_1': 0.82111, 'map_at_3': 0.86241, 'map_at_5': 0.8673, 'map_at_10': 0.87116, 'map_at_20': 0.87233, 'map_at_100': 0.87283, 'map_at_1000': 0.87284, 'recall_at_1': 0.82111, 'recall_at_3': 0.91333, 'recall_at_5': 0.93444, 'recall_at_10': 0.96333, 'recall_at_20': 0.98, 'recall_at_100': 0.99778, 'recall_at_1000': 1.0, 'precision_at_1': 0.82111, 'precision_at_3': 0.30444, 'precision_at_5': 0.18689, 'precision_at_10': 0.09633, 'precision_at_20': 0.049, 'precision_at_100': 0.00998, 'precision_at_1000': 0.001, 'mrr_at_1': 0.8211111111111111, 'mrr_at_3': 0.8624074074074078, 'mrr_at_5': 0.8672962962962969, 'mrr_at_10': 0.8711556437389774, 'mrr_at_20': 0.8723318337435988, 'mrr_at_100': 0.8728269213805212, 'mrr_at_1000': 0.8728367557763205, 'nauc_ndcg_at_1_max': np.float64(0.8026690709023879), 'nauc_ndcg_at_1_std': np.float64(-0.008929725338634197), 'nauc_ndcg_at_1_diff1': np.float64(0.8847659254974121), 'nauc_ndcg_at_3_max': np.float64(0.8277550898723998), 'nauc_ndcg_at_3_std': np.float64(0.013666366202421504), 'nauc_ndcg_at_3_diff1': np.float64(0.8545545607220641), 'nauc_ndcg_at_5_max': np.float64(0.8325374753277351), 'nauc_ndcg_at_5_std': np.float64(0.045388004793190995), 'nauc_ndcg_at_5_diff1': np.float64(0.8586379403658919), 'nauc_ndcg_at_10_max': np.float64(0.8325457384802886), 'nauc_ndcg_at_10_std': np.float64(0.04935484768956332), 'nauc_ndcg_at_10_diff1': np.float64(0.8618641391656243), 'nauc_ndcg_at_20_max': np.float64(0.8283295689405594), 'nauc_ndcg_at_20_std': np.float64(0.0373936582483197), 'nauc_ndcg_at_20_diff1': np.float64(0.8647360440836114), 'nauc_ndcg_at_100_max': np.float64(0.8239819570557388), 'nauc_ndcg_at_100_std': np.float64(0.026893456100997564), 'nauc_ndcg_at_100_diff1': np.float64(0.8665918671839828), 'nauc_ndcg_at_1000_max': np.float64(0.8238458780351965), 'nauc_ndcg_at_1000_std': np.float64(0.02638731545967157), 'nauc_ndcg_at_1000_diff1': np.float64(0.8663767029892047), 'nauc_map_at_1_max': np.float64(0.8026690709023879), 'nauc_map_at_1_std': np.float64(-0.008929725338634197), 'nauc_map_at_1_diff1': np.float64(0.8847659254974121), 'nauc_map_at_3_max': np.float64(0.8203568712506853), 'nauc_map_at_3_std': np.float64(0.00799766483893894), 'nauc_map_at_3_diff1': np.float64(0.8634853587757678), 'nauc_map_at_5_max': np.float64(0.8224014562485236), 'nauc_map_at_5_std': np.float64(0.023727719476427437), 'nauc_map_at_5_diff1': np.float64(0.8657225255016116), 'nauc_map_at_10_max': np.float64(0.822177885685061), 'nauc_map_at_10_std': np.float64(0.02488887476873139), 'nauc_map_at_10_diff1': np.float64(0.8671053595478713), 'nauc_map_at_20_max': np.float64(0.8210793536623991), 'nauc_map_at_20_std': np.float64(0.02163563249331133), 'nauc_map_at_20_diff1': np.float64(0.8678593951223997), 'nauc_map_at_100_max': np.float64(0.8205501194066572), 'nauc_map_at_100_std': np.float64(0.020074098891765757), 'nauc_map_at_100_diff1': np.float64(0.8681729576451603), 'nauc_map_at_1000_max': np.float64(0.8205432324113134), 'nauc_map_at_1000_std': np.float64(0.020044750664545318), 'nauc_map_at_1000_diff1': np.float64(0.8681658869952232), 'nauc_recall_at_1_max': np.float64(0.8026690709023879), 'nauc_recall_at_1_std': np.float64(-0.008929725338634197), 'nauc_recall_at_1_diff1': np.float64(0.8847659254974121), 'nauc_recall_at_3_max': np.float64(0.8600936100936094), 'nauc_recall_at_3_std': np.float64(0.037791184850005786), 'nauc_recall_at_3_diff1': np.float64(0.8155031243266528), 'nauc_recall_at_5_max': np.float64(0.8902894491129779), 'nauc_recall_at_5_std': np.float64(0.17275158651031172), 'nauc_recall_at_5_diff1': np.float64(0.8205779486936017), 'nauc_recall_at_10_max': np.float64(0.9341453753218488), 'nauc_recall_at_10_std': np.float64(0.29833347480406125), 'nauc_recall_at_10_diff1': np.float64(0.817432023314378), 'nauc_recall_at_20_max': np.float64(0.9400871459694983), 'nauc_recall_at_20_std': np.float64(0.2897862848843228), 'nauc_recall_at_20_diff1': np.float64(0.8330999066293204), 'nauc_recall_at_100_max': np.float64(0.8611111111111373), 'nauc_recall_at_100_std': np.float64(0.15289449112976736), 'nauc_recall_at_100_diff1': np.float64(0.934640522875857), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8026690709023879), 'nauc_precision_at_1_std': np.float64(-0.008929725338634197), 'nauc_precision_at_1_diff1': np.float64(0.8847659254974121), 'nauc_precision_at_3_max': np.float64(0.8600936100936113), 'nauc_precision_at_3_std': np.float64(0.037791184850007375), 'nauc_precision_at_3_diff1': np.float64(0.8155031243266547), 'nauc_precision_at_5_max': np.float64(0.890289449112978), 'nauc_precision_at_5_std': np.float64(0.17275158651030734), 'nauc_precision_at_5_diff1': np.float64(0.820577948693603), 'nauc_precision_at_10_max': np.float64(0.9341453753218462), 'nauc_precision_at_10_std': np.float64(0.2983334748040586), 'nauc_precision_at_10_diff1': np.float64(0.817432023314378), 'nauc_precision_at_20_max': np.float64(0.9400871459694904), 'nauc_precision_at_20_std': np.float64(0.2897862848843251), 'nauc_precision_at_20_diff1': np.float64(0.8330999066293161), 'nauc_precision_at_100_max': np.float64(0.8611111111111238), 'nauc_precision_at_100_std': np.float64(0.15289449112979822), 'nauc_precision_at_100_diff1': np.float64(0.9346405228757582), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8026690709023879), 'nauc_mrr_at_1_std': np.float64(-0.008929725338634197), 'nauc_mrr_at_1_diff1': np.float64(0.8847659254974121), 'nauc_mrr_at_3_max': np.float64(0.8203568712506853), 'nauc_mrr_at_3_std': np.float64(0.00799766483893894), 'nauc_mrr_at_3_diff1': np.float64(0.8634853587757678), 'nauc_mrr_at_5_max': np.float64(0.8224014562485236), 'nauc_mrr_at_5_std': np.float64(0.023727719476427437), 'nauc_mrr_at_5_diff1': np.float64(0.8657225255016116), 'nauc_mrr_at_10_max': np.float64(0.822177885685061), 'nauc_mrr_at_10_std': np.float64(0.02488887476873139), 'nauc_mrr_at_10_diff1': np.float64(0.8671053595478713), 'nauc_mrr_at_20_max': np.float64(0.8210793536623991), 'nauc_mrr_at_20_std': np.float64(0.02163563249331133), 'nauc_mrr_at_20_diff1': np.float64(0.8678593951223997), 'nauc_mrr_at_100_max': np.float64(0.8205501194066572), 'nauc_mrr_at_100_std': np.float64(0.020074098891765757), 'nauc_mrr_at_100_diff1': np.float64(0.8681729576451603), 'nauc_mrr_at_1000_max': np.float64(0.8205432324113134), 'nauc_mrr_at_1000_std': np.float64(0.020044750664545318), 'nauc_mrr_at_1000_diff1': np.float64(0.8681658869952232), 'main_score': 0.89361}, 'eng_Latn-kor_Hang': {'ndcg_at_1': 0.79667, 'ndcg_at_3': 0.84704, 'ndcg_at_5': 0.85765, 'ndcg_at_10': 0.86663, 'ndcg_at_20': 0.87407, 'ndcg_at_100': 0.87837, 'ndcg_at_1000': 0.88035, 'map_at_1': 0.79667, 'map_at_3': 0.83519, 'map_at_5': 0.84113, 'map_at_10': 0.84483, 'map_at_20': 0.84695, 'map_at_100': 0.8476, 'map_at_1000': 0.8477, 'recall_at_1': 0.79667, 'recall_at_3': 0.88111, 'recall_at_5': 0.90667, 'recall_at_10': 0.93444, 'recall_at_20': 0.96333, 'recall_at_100': 0.98556, 'recall_at_1000': 1.0, 'precision_at_1': 0.79667, 'precision_at_3': 0.2937, 'precision_at_5': 0.18133, 'precision_at_10': 0.09344, 'precision_at_20': 0.04817, 'precision_at_100': 0.00986, 'precision_at_1000': 0.001, 'mrr_at_1': 0.7966666666666666, 'mrr_at_3': 0.8351851851851854, 'mrr_at_5': 0.84112962962963, 'mrr_at_10': 0.8448302469135806, 'mrr_at_20': 0.8469450342208344, 'mrr_at_100': 0.847602652517519, 'mrr_at_1000': 0.8476973598340662, 'nauc_ndcg_at_1_max': np.float64(0.8404908479702803), 'nauc_ndcg_at_1_std': np.float64(0.21593913441332988), 'nauc_ndcg_at_1_diff1': np.float64(0.8889866055161487), 'nauc_ndcg_at_3_max': np.float64(0.847282957249051), 'nauc_ndcg_at_3_std': np.float64(0.23785368772265184), 'nauc_ndcg_at_3_diff1': np.float64(0.8704788855958584), 'nauc_ndcg_at_5_max': np.float64(0.8464852880417384), 'nauc_ndcg_at_5_std': np.float64(0.25312207546383614), 'nauc_ndcg_at_5_diff1': np.float64(0.8649640538751412), 'nauc_ndcg_at_10_max': np.float64(0.8477420938906917), 'nauc_ndcg_at_10_std': np.float64(0.2661911743981658), 'nauc_ndcg_at_10_diff1': np.float64(0.8669405052315483), 'nauc_ndcg_at_20_max': np.float64(0.8519299505328641), 'nauc_ndcg_at_20_std': np.float64(0.2665151070100241), 'nauc_ndcg_at_20_diff1': np.float64(0.8724632969842627), 'nauc_ndcg_at_100_max': np.float64(0.8515023011122944), 'nauc_ndcg_at_100_std': np.float64(0.26146582006703034), 'nauc_ndcg_at_100_diff1': np.float64(0.8741038419953362), 'nauc_ndcg_at_1000_max': np.float64(0.8490794706219542), 'nauc_ndcg_at_1000_std': np.float64(0.25244197649015077), 'nauc_ndcg_at_1000_diff1': np.float64(0.8735503525549674), 'nauc_map_at_1_max': np.float64(0.8404908479702803), 'nauc_map_at_1_std': np.float64(0.21593913441332988), 'nauc_map_at_1_diff1': np.float64(0.8889866055161487), 'nauc_map_at_3_max': np.float64(0.8464258714127866), 'nauc_map_at_3_std': np.float64(0.2336668429753893), 'nauc_map_at_3_diff1': np.float64(0.8756536115134201), 'nauc_map_at_5_max': np.float64(0.8460027843300343), 'nauc_map_at_5_std': np.float64(0.24066510804131827), 'nauc_map_at_5_diff1': np.float64(0.8731005687254455), 'nauc_map_at_10_max': np.float64(0.8464764370604289), 'nauc_map_at_10_std': np.float64(0.24495694567233875), 'nauc_map_at_10_diff1': np.float64(0.8739530265702778), 'nauc_map_at_20_max': np.float64(0.847544236596684), 'nauc_map_at_20_std': np.float64(0.2445676989728708), 'nauc_map_at_20_diff1': np.float64(0.8754155038533379), 'nauc_map_at_100_max': np.float64(0.847432220350922), 'nauc_map_at_100_std': np.float64(0.24377939110617025), 'nauc_map_at_100_diff1': np.float64(0.8755526313063526), 'nauc_map_at_1000_max': np.float64(0.8473357258197913), 'nauc_map_at_1000_std': np.float64(0.2434152819342852), 'nauc_map_at_1000_diff1': np.float64(0.8755355763204816), 'nauc_recall_at_1_max': np.float64(0.8404908479702803), 'nauc_recall_at_1_std': np.float64(0.21593913441332988), 'nauc_recall_at_1_diff1': np.float64(0.8889866055161487), 'nauc_recall_at_3_max': np.float64(0.8499737116479688), 'nauc_recall_at_3_std': np.float64(0.2528226561038003), 'nauc_recall_at_3_diff1': np.float64(0.8505885917463488), 'nauc_recall_at_5_max': np.float64(0.8477613267529225), 'nauc_recall_at_5_std': np.float64(0.3140923035881024), 'nauc_recall_at_5_diff1': np.float64(0.8259136988128578), 'nauc_recall_at_10_max': np.float64(0.855378309515894), 'nauc_recall_at_10_std': np.float64(0.4190365411701397), 'nauc_recall_at_10_diff1': np.float64(0.8218993812214135), 'nauc_recall_at_20_max': np.float64(0.9115242056418519), 'nauc_recall_at_20_std': np.float64(0.5478029595676642), 'nauc_recall_at_20_diff1': np.float64(0.8547944430297391), 'nauc_recall_at_100_max': np.float64(0.9899446958270551), 'nauc_recall_at_100_std': np.float64(0.7759462759462875), 'nauc_recall_at_100_diff1': np.float64(0.9069884364002062), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.8404908479702803), 'nauc_precision_at_1_std': np.float64(0.21593913441332988), 'nauc_precision_at_1_diff1': np.float64(0.8889866055161487), 'nauc_precision_at_3_max': np.float64(0.8499737116479701), 'nauc_precision_at_3_std': np.float64(0.2528226561037997), 'nauc_precision_at_3_diff1': np.float64(0.8505885917463502), 'nauc_precision_at_5_max': np.float64(0.8477613267529237), 'nauc_precision_at_5_std': np.float64(0.31409230358810086), 'nauc_precision_at_5_diff1': np.float64(0.8259136988128576), 'nauc_precision_at_10_max': np.float64(0.855378309515898), 'nauc_precision_at_10_std': np.float64(0.41903654117014016), 'nauc_precision_at_10_diff1': np.float64(0.8218993812214133), 'nauc_precision_at_20_max': np.float64(0.911524205641851), 'nauc_precision_at_20_std': np.float64(0.5478029595676562), 'nauc_precision_at_20_diff1': np.float64(0.8547944430297364), 'nauc_precision_at_100_max': np.float64(0.9899446958270675), 'nauc_precision_at_100_std': np.float64(0.7759462759462854), 'nauc_precision_at_100_diff1': np.float64(0.9069884364002117), 'nauc_precision_at_1000_max': nan, 'nauc_precision_at_1000_std': nan, 'nauc_precision_at_1000_diff1': nan, 'nauc_mrr_at_1_max': np.float64(0.8404908479702803), 'nauc_mrr_at_1_std': np.float64(0.21593913441332988), 'nauc_mrr_at_1_diff1': np.float64(0.8889866055161487), 'nauc_mrr_at_3_max': np.float64(0.8464258714127866), 'nauc_mrr_at_3_std': np.float64(0.2336668429753893), 'nauc_mrr_at_3_diff1': np.float64(0.8756536115134201), 'nauc_mrr_at_5_max': np.float64(0.8460027843300343), 'nauc_mrr_at_5_std': np.float64(0.24066510804131827), 'nauc_mrr_at_5_diff1': np.float64(0.8731005687254455), 'nauc_mrr_at_10_max': np.float64(0.8464764370604289), 'nauc_mrr_at_10_std': np.float64(0.24495694567233875), 'nauc_mrr_at_10_diff1': np.float64(0.8739530265702778), 'nauc_mrr_at_20_max': np.float64(0.847544236596684), 'nauc_mrr_at_20_std': np.float64(0.2445676989728708), 'nauc_mrr_at_20_diff1': np.float64(0.8754155038533379), 'nauc_mrr_at_100_max': np.float64(0.847432220350922), 'nauc_mrr_at_100_std': np.float64(0.24377939110617025), 'nauc_mrr_at_100_diff1': np.float64(0.8755526313063526), 'nauc_mrr_at_1000_max': np.float64(0.8473357258197913), 'nauc_mrr_at_1000_std': np.float64(0.2434152819342852), 'nauc_mrr_at_1000_diff1': np.float64(0.8755355763204816), 'main_score': 0.86663}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating XPQARetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/21 [00:00<?, ?it/s]Batches:  10%|▉         | 2/21 [00:00<00:01, 18.58it/s]Batches:  24%|██▍       | 5/21 [00:00<00:00, 21.37it/s]Batches:  38%|███▊      | 8/21 [00:00<00:00, 24.64it/s]Batches:  57%|█████▋    | 12/21 [00:00<00:00, 28.63it/s]Batches:  76%|███████▌  | 16/21 [00:00<00:00, 31.40it/s]Batches:  95%|█████████▌| 20/21 [00:00<00:00, 33.51it/s]Batches: 100%|██████████| 21/21 [00:00<00:00, 30.20it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/28 [00:00<?, ?it/s]Batches:   7%|▋         | 2/28 [00:00<00:01, 13.04it/s]Batches:  18%|█▊        | 5/28 [00:00<00:01, 18.42it/s]Batches:  29%|██▊       | 8/28 [00:00<00:00, 22.21it/s]Batches:  39%|███▉      | 11/28 [00:00<00:00, 24.08it/s]Batches:  50%|█████     | 14/28 [00:00<00:00, 25.68it/s]Batches:  64%|██████▍   | 18/28 [00:00<00:00, 28.03it/s]Batches:  79%|███████▊  | 22/28 [00:00<00:00, 30.93it/s]Batches:  96%|█████████▋| 27/28 [00:00<00:00, 35.62it/s]Batches: 100%|██████████| 28/28 [00:00<00:00, 29.15it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.06 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: eng-kor
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 654 sentences.
Batches:   0%|          | 0/21 [00:00<?, ?it/s]Batches:  10%|▉         | 2/21 [00:00<00:01, 18.85it/s]Batches:  24%|██▍       | 5/21 [00:00<00:00, 21.52it/s]Batches:  38%|███▊      | 8/21 [00:00<00:00, 24.68it/s]Batches:  57%|█████▋    | 12/21 [00:00<00:00, 28.61it/s]Batches:  76%|███████▌  | 16/21 [00:00<00:00, 31.30it/s]Batches:  95%|█████████▌| 20/21 [00:00<00:00, 33.46it/s]Batches: 100%|██████████| 21/21 [00:00<00:00, 30.20it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 1169 sentences.
Batches:   0%|          | 0/37 [00:00<?, ?it/s]Batches:   5%|▌         | 2/37 [00:02<00:37,  1.08s/it]Batches:   8%|▊         | 3/37 [00:02<00:23,  1.45it/s]Batches:  11%|█         | 4/37 [00:02<00:16,  2.06it/s]Batches:  14%|█▎        | 5/37 [00:02<00:11,  2.71it/s]Batches:  16%|█▌        | 6/37 [00:02<00:09,  3.44it/s]Batches:  19%|█▉        | 7/37 [00:02<00:07,  4.22it/s]Batches:  24%|██▍       | 9/37 [00:03<00:04,  5.94it/s]Batches:  27%|██▋       | 10/37 [00:03<00:04,  6.41it/s]Batches:  32%|███▏      | 12/37 [00:03<00:03,  8.08it/s]Batches:  38%|███▊      | 14/37 [00:03<00:02,  9.53it/s]Batches:  43%|████▎     | 16/37 [00:03<00:02, 10.36it/s]Batches:  49%|████▊     | 18/37 [00:03<00:01, 11.28it/s]Batches:  54%|█████▍    | 20/37 [00:03<00:01, 12.31it/s]Batches:  59%|█████▉    | 22/37 [00:04<00:01, 13.79it/s]Batches:  65%|██████▍   | 24/37 [00:04<00:00, 15.07it/s]Batches:  73%|███████▎  | 27/37 [00:04<00:00, 16.81it/s]Batches:  81%|████████  | 30/37 [00:04<00:00, 18.52it/s]Batches:  89%|████████▉ | 33/37 [00:04<00:00, 21.03it/s]Batches: 100%|██████████| 37/37 [00:04<00:00, 24.15it/s]Batches: 100%|██████████| 37/37 [00:04<00:00,  7.99it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.77 seconds
INFO:root:

INFO:mteb.abstasks.AbsTaskRetrieval:Subset: kor-eng
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=XPQARetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 614 sentences.
Batches:   0%|          | 0/20 [00:00<?, ?it/s]Batches:  10%|█         | 2/20 [00:00<00:01, 16.94it/s]Batches:  25%|██▌       | 5/20 [00:00<00:00, 21.13it/s]Batches:  45%|████▌     | 9/20 [00:00<00:00, 25.80it/s]Batches:  65%|██████▌   | 13/20 [00:00<00:00, 29.39it/s]Batches:  85%|████████▌ | 17/20 [00:00<00:00, 31.81it/s]Batches: 100%|██████████| 20/20 [00:00<00:00, 29.99it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=XPQARetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 889 sentences.
Batches:   0%|          | 0/28 [00:00<?, ?it/s]Batches:   7%|▋         | 2/28 [00:00<00:01, 13.05it/s]Batches:  18%|█▊        | 5/28 [00:00<00:01, 18.32it/s]Batches:  29%|██▊       | 8/28 [00:00<00:00, 22.08it/s]Batches:  39%|███▉      | 11/28 [00:00<00:00, 23.98it/s]Batches:  50%|█████     | 14/28 [00:00<00:00, 25.57it/s]Batches:  64%|██████▍   | 18/28 [00:00<00:00, 27.99it/s]Batches:  79%|███████▊  | 22/28 [00:00<00:00, 30.89it/s]Batches:  96%|█████████▋| 27/28 [00:00<00:00, 35.52it/s]Batches: 100%|██████████| 28/28 [00:00<00:00, 29.06it/s]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.01 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for XPQARetrieval on test took 11.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'kor-kor': {'ndcg_at_1': 0.34098, 'ndcg_at_3': 0.36993, 'ndcg_at_5': 0.39574, 'ndcg_at_10': 0.43009, 'ndcg_at_20': 0.45708, 'ndcg_at_100': 0.49827, 'ndcg_at_1000': 0.51972, 'map_at_1': 0.24093, 'map_at_3': 0.33978, 'map_at_5': 0.36288, 'map_at_10': 0.37917, 'map_at_20': 0.38755, 'map_at_100': 0.39458, 'map_at_1000': 0.39551, 'recall_at_1': 0.24093, 'recall_at_3': 0.38856, 'recall_at_5': 0.45178, 'recall_at_10': 0.54684, 'recall_at_20': 0.64126, 'recall_at_100': 0.83856, 'recall_at_1000': 1.0, 'precision_at_1': 0.34098, 'precision_at_3': 0.20897, 'precision_at_5': 0.14893, 'precision_at_10': 0.08945, 'precision_at_20': 0.05252, 'precision_at_100': 0.01373, 'precision_at_1000': 0.00156, 'mrr_at_1': 0.3409785932721712, 'mrr_at_3': 0.39041794087665666, 'mrr_at_5': 0.4020387359836901, 'mrr_at_10': 0.41436216688510247, 'mrr_at_20': 0.4209954172095932, 'mrr_at_100': 0.4250774091477316, 'mrr_at_1000': 0.4257319515188771, 'nauc_ndcg_at_1_max': np.float64(0.37193769173547747), 'nauc_ndcg_at_1_std': np.float64(-0.22091330442205906), 'nauc_ndcg_at_1_diff1': np.float64(0.4988182950549638), 'nauc_ndcg_at_3_max': np.float64(0.3427517639425211), 'nauc_ndcg_at_3_std': np.float64(-0.22349697906774166), 'nauc_ndcg_at_3_diff1': np.float64(0.4413272548657244), 'nauc_ndcg_at_5_max': np.float64(0.32352766298755464), 'nauc_ndcg_at_5_std': np.float64(-0.23586499044627476), 'nauc_ndcg_at_5_diff1': np.float64(0.4320786993042591), 'nauc_ndcg_at_10_max': np.float64(0.3119742185605333), 'nauc_ndcg_at_10_std': np.float64(-0.23405519842228667), 'nauc_ndcg_at_10_diff1': np.float64(0.4229130058476732), 'nauc_ndcg_at_20_max': np.float64(0.3082632824325079), 'nauc_ndcg_at_20_std': np.float64(-0.23500903077640786), 'nauc_ndcg_at_20_diff1': np.float64(0.41418715110304727), 'nauc_ndcg_at_100_max': np.float64(0.32204790695505664), 'nauc_ndcg_at_100_std': np.float64(-0.2126358068944856), 'nauc_ndcg_at_100_diff1': np.float64(0.41248772782680093), 'nauc_ndcg_at_1000_max': np.float64(0.32788544399290914), 'nauc_ndcg_at_1000_std': np.float64(-0.2187435063065557), 'nauc_ndcg_at_1000_diff1': np.float64(0.42351822614620327), 'nauc_map_at_1_max': np.float64(0.286224524905145), 'nauc_map_at_1_std': np.float64(-0.21431805724563696), 'nauc_map_at_1_diff1': np.float64(0.553079568837683), 'nauc_map_at_3_max': np.float64(0.34085375945432494), 'nauc_map_at_3_std': np.float64(-0.2147009945202048), 'nauc_map_at_3_diff1': np.float64(0.45028862410820064), 'nauc_map_at_5_max': np.float64(0.3325026750118491), 'nauc_map_at_5_std': np.float64(-0.2274662384333891), 'nauc_map_at_5_diff1': np.float64(0.44214439565683855), 'nauc_map_at_10_max': np.float64(0.32675784102167427), 'nauc_map_at_10_std': np.float64(-0.22855517516902316), 'nauc_map_at_10_diff1': np.float64(0.4375622578483712), 'nauc_map_at_20_max': np.float64(0.32612406023838514), 'nauc_map_at_20_std': np.float64(-0.2289601415087353), 'nauc_map_at_20_diff1': np.float64(0.4351896294064596), 'nauc_map_at_100_max': np.float64(0.32743541554641054), 'nauc_map_at_100_std': np.float64(-0.22602145167638776), 'nauc_map_at_100_diff1': np.float64(0.4343268482488689), 'nauc_map_at_1000_max': np.float64(0.3279363310263593), 'nauc_map_at_1000_std': np.float64(-0.22593437937872046), 'nauc_map_at_1000_diff1': np.float64(0.43480909830241105), 'nauc_recall_at_1_max': np.float64(0.286224524905145), 'nauc_recall_at_1_std': np.float64(-0.21431805724563696), 'nauc_recall_at_1_diff1': np.float64(0.553079568837683), 'nauc_recall_at_3_max': np.float64(0.32072036817146826), 'nauc_recall_at_3_std': np.float64(-0.22191616043254955), 'nauc_recall_at_3_diff1': np.float64(0.4120673515361544), 'nauc_recall_at_5_max': np.float64(0.2806542134473705), 'nauc_recall_at_5_std': np.float64(-0.24618562180895076), 'nauc_recall_at_5_diff1': np.float64(0.3815383698695913), 'nauc_recall_at_10_max': np.float64(0.24462795090588246), 'nauc_recall_at_10_std': np.float64(-0.2337638319386335), 'nauc_recall_at_10_diff1': np.float64(0.35270201713244026), 'nauc_recall_at_20_max': np.float64(0.2149720153360262), 'nauc_recall_at_20_std': np.float64(-0.24012301485659718), 'nauc_recall_at_20_diff1': np.float64(0.30565039401672306), 'nauc_recall_at_100_max': np.float64(0.26094793327202975), 'nauc_recall_at_100_std': np.float64(-0.08297900906354048), 'nauc_recall_at_100_diff1': np.float64(0.24388679482975748), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.37193769173547747), 'nauc_precision_at_1_std': np.float64(-0.22091330442205906), 'nauc_precision_at_1_diff1': np.float64(0.4988182950549638), 'nauc_precision_at_3_max': np.float64(0.33740691397807143), 'nauc_precision_at_3_std': np.float64(-0.16208204487376968), 'nauc_precision_at_3_diff1': np.float64(0.21846381186872282), 'nauc_precision_at_5_max': np.float64(0.2801914416550342), 'nauc_precision_at_5_std': np.float64(-0.17478384261237984), 'nauc_precision_at_5_diff1': np.float64(0.17853249975264068), 'nauc_precision_at_10_max': np.float64(0.2255385166494696), 'nauc_precision_at_10_std': np.float64(-0.15927250296457718), 'nauc_precision_at_10_diff1': np.float64(0.1257159467629075), 'nauc_precision_at_20_max': np.float64(0.19382171395674946), 'nauc_precision_at_20_std': np.float64(-0.13902393287978332), 'nauc_precision_at_20_diff1': np.float64(0.06840561542425261), 'nauc_precision_at_100_max': np.float64(0.19440932831518787), 'nauc_precision_at_100_std': np.float64(0.02669196505869482), 'nauc_precision_at_100_diff1': np.float64(-0.049553967440838745), 'nauc_precision_at_1000_max': np.float64(0.1834451970827565), 'nauc_precision_at_1000_std': np.float64(0.07736146383254927), 'nauc_precision_at_1000_diff1': np.float64(-0.1237168615440891), 'nauc_mrr_at_1_max': np.float64(0.37193769173547747), 'nauc_mrr_at_1_std': np.float64(-0.22313208246414099), 'nauc_mrr_at_1_diff1': np.float64(0.4988182950549638), 'nauc_mrr_at_3_max': np.float64(0.35285651115700656), 'nauc_mrr_at_3_std': np.float64(-0.2336473867007424), 'nauc_mrr_at_3_diff1': np.float64(0.4667223098558777), 'nauc_mrr_at_5_max': np.float64(0.34173656871359476), 'nauc_mrr_at_5_std': np.float64(-0.2347060341014013), 'nauc_mrr_at_5_diff1': np.float64(0.4568853076114551), 'nauc_mrr_at_10_max': np.float64(0.3390799289904632), 'nauc_mrr_at_10_std': np.float64(-0.23232266206303093), 'nauc_mrr_at_10_diff1': np.float64(0.45357443210196907), 'nauc_mrr_at_20_max': np.float64(0.33903737722734), 'nauc_mrr_at_20_std': np.float64(-0.23127387932665758), 'nauc_mrr_at_20_diff1': np.float64(0.45223413484242236), 'nauc_mrr_at_100_max': np.float64(0.34055012710241456), 'nauc_mrr_at_100_std': np.float64(-0.2293767688288561), 'nauc_mrr_at_100_diff1': np.float64(0.45230939085343846), 'nauc_mrr_at_1000_max': np.float64(0.3406157865566202), 'nauc_mrr_at_1000_std': np.float64(-0.2296484612846579), 'nauc_mrr_at_1000_diff1': np.float64(0.45273379378084133), 'main_score': 0.43009}, 'eng-kor': {'ndcg_at_1': 0.3211, 'ndcg_at_3': 0.32729, 'ndcg_at_5': 0.34032, 'ndcg_at_10': 0.37783, 'ndcg_at_20': 0.40662, 'ndcg_at_100': 0.45834, 'ndcg_at_1000': 0.48616, 'map_at_1': 0.18524, 'map_at_3': 0.27607, 'map_at_5': 0.30003, 'map_at_10': 0.32097, 'map_at_20': 0.33112, 'map_at_100': 0.33984, 'map_at_1000': 0.34145, 'recall_at_1': 0.18524, 'recall_at_3': 0.32011, 'recall_at_5': 0.37513, 'recall_at_10': 0.47146, 'recall_at_20': 0.56577, 'recall_at_100': 0.80892, 'recall_at_1000': 0.99796, 'precision_at_1': 0.3211, 'precision_at_3': 0.21458, 'precision_at_5': 0.15841, 'precision_at_10': 0.09924, 'precision_at_20': 0.05917, 'precision_at_100': 0.01633, 'precision_at_1000': 0.00195, 'mrr_at_1': 0.3211009174311927, 'mrr_at_3': 0.3649337410805302, 'mrr_at_5': 0.3783129459734965, 'mrr_at_10': 0.38948837435075967, 'mrr_at_20': 0.3958084381395087, 'mrr_at_100': 0.4008542146580521, 'mrr_at_1000': 0.4015281143847229, 'nauc_ndcg_at_1_max': np.float64(0.2744152928620983), 'nauc_ndcg_at_1_std': np.float64(-0.19242930389889282), 'nauc_ndcg_at_1_diff1': np.float64(0.49866615704480877), 'nauc_ndcg_at_3_max': np.float64(0.241399855326456), 'nauc_ndcg_at_3_std': np.float64(-0.21665280827254582), 'nauc_ndcg_at_3_diff1': np.float64(0.459130556530345), 'nauc_ndcg_at_5_max': np.float64(0.2287216345330515), 'nauc_ndcg_at_5_std': np.float64(-0.22377877730944767), 'nauc_ndcg_at_5_diff1': np.float64(0.44703120810301933), 'nauc_ndcg_at_10_max': np.float64(0.21437099868078652), 'nauc_ndcg_at_10_std': np.float64(-0.23808072271397712), 'nauc_ndcg_at_10_diff1': np.float64(0.4377569417180383), 'nauc_ndcg_at_20_max': np.float64(0.20051580097571753), 'nauc_ndcg_at_20_std': np.float64(-0.24378633817294293), 'nauc_ndcg_at_20_diff1': np.float64(0.43364906151583554), 'nauc_ndcg_at_100_max': np.float64(0.219773755845085), 'nauc_ndcg_at_100_std': np.float64(-0.21115168538413312), 'nauc_ndcg_at_100_diff1': np.float64(0.44039470513802115), 'nauc_ndcg_at_1000_max': np.float64(0.23140097578516694), 'nauc_ndcg_at_1000_std': np.float64(-0.20759180179893977), 'nauc_ndcg_at_1000_diff1': np.float64(0.43976585632413223), 'nauc_map_at_1_max': np.float64(0.19490782765484738), 'nauc_map_at_1_std': np.float64(-0.20131058537586496), 'nauc_map_at_1_diff1': np.float64(0.5267465832325585), 'nauc_map_at_3_max': np.float64(0.2348643775481), 'nauc_map_at_3_std': np.float64(-0.21496873326193244), 'nauc_map_at_3_diff1': np.float64(0.4801368277178186), 'nauc_map_at_5_max': np.float64(0.2384165070606153), 'nauc_map_at_5_std': np.float64(-0.21850141349946745), 'nauc_map_at_5_diff1': np.float64(0.4597374308167914), 'nauc_map_at_10_max': np.float64(0.23465086016319753), 'nauc_map_at_10_std': np.float64(-0.22632668721798485), 'nauc_map_at_10_diff1': np.float64(0.45132513646066996), 'nauc_map_at_20_max': np.float64(0.22998518755073658), 'nauc_map_at_20_std': np.float64(-0.22849625494513465), 'nauc_map_at_20_diff1': np.float64(0.4505636787055316), 'nauc_map_at_100_max': np.float64(0.2315393698333892), 'nauc_map_at_100_std': np.float64(-0.22415299399216249), 'nauc_map_at_100_diff1': np.float64(0.4502468556483691), 'nauc_map_at_1000_max': np.float64(0.23275197399601816), 'nauc_map_at_1000_std': np.float64(-0.22303437237099213), 'nauc_map_at_1000_diff1': np.float64(0.4501597607849182), 'nauc_recall_at_1_max': np.float64(0.19490782765484738), 'nauc_recall_at_1_std': np.float64(-0.20131058537586496), 'nauc_recall_at_1_diff1': np.float64(0.5267465832325585), 'nauc_recall_at_3_max': np.float64(0.19033866104859168), 'nauc_recall_at_3_std': np.float64(-0.23047990599148557), 'nauc_recall_at_3_diff1': np.float64(0.4406437098836785), 'nauc_recall_at_5_max': np.float64(0.1850540757672552), 'nauc_recall_at_5_std': np.float64(-0.23597849006915314), 'nauc_recall_at_5_diff1': np.float64(0.39768693698817836), 'nauc_recall_at_10_max': np.float64(0.1412302458577678), 'nauc_recall_at_10_std': np.float64(-0.27133700545683576), 'nauc_recall_at_10_diff1': np.float64(0.37603050591537074), 'nauc_recall_at_20_max': np.float64(0.08516331120456642), 'nauc_recall_at_20_std': np.float64(-0.29657332433419803), 'nauc_recall_at_20_diff1': np.float64(0.3519516987965453), 'nauc_recall_at_100_max': np.float64(0.13982421882829893), 'nauc_recall_at_100_std': np.float64(-0.12966701376768694), 'nauc_recall_at_100_diff1': np.float64(0.38446075731052776), 'nauc_recall_at_1000_max': np.float64(0.7072549206096401), 'nauc_recall_at_1000_std': np.float64(0.400806734203622), 'nauc_recall_at_1000_diff1': np.float64(-0.34366622104804095), 'nauc_precision_at_1_max': np.float64(0.2744152928620983), 'nauc_precision_at_1_std': np.float64(-0.19242930389889282), 'nauc_precision_at_1_diff1': np.float64(0.49866615704480877), 'nauc_precision_at_3_max': np.float64(0.25797752075870695), 'nauc_precision_at_3_std': np.float64(-0.1707193937040658), 'nauc_precision_at_3_diff1': np.float64(0.3104972595408083), 'nauc_precision_at_5_max': np.float64(0.23279785974937944), 'nauc_precision_at_5_std': np.float64(-0.15791586900626517), 'nauc_precision_at_5_diff1': np.float64(0.24185411181963068), 'nauc_precision_at_10_max': np.float64(0.18843337861248288), 'nauc_precision_at_10_std': np.float64(-0.16357372946062101), 'nauc_precision_at_10_diff1': np.float64(0.19172801032172165), 'nauc_precision_at_20_max': np.float64(0.14261600454366413), 'nauc_precision_at_20_std': np.float64(-0.15025062080281562), 'nauc_precision_at_20_diff1': np.float64(0.15845371881957565), 'nauc_precision_at_100_max': np.float64(0.15991771852194117), 'nauc_precision_at_100_std': np.float64(0.01843741245030099), 'nauc_precision_at_100_diff1': np.float64(0.06652936985070007), 'nauc_precision_at_1000_max': np.float64(0.1700390808234916), 'nauc_precision_at_1000_std': np.float64(0.10131119924066942), 'nauc_precision_at_1000_diff1': np.float64(-0.027351959677437417), 'nauc_mrr_at_1_max': np.float64(0.2744152928620983), 'nauc_mrr_at_1_std': np.float64(-0.19242930389889282), 'nauc_mrr_at_1_diff1': np.float64(0.49866615704480877), 'nauc_mrr_at_3_max': np.float64(0.24608744263793345), 'nauc_mrr_at_3_std': np.float64(-0.2129350980220903), 'nauc_mrr_at_3_diff1': np.float64(0.47117559829579714), 'nauc_mrr_at_5_max': np.float64(0.24380806318470563), 'nauc_mrr_at_5_std': np.float64(-0.21064574990742738), 'nauc_mrr_at_5_diff1': np.float64(0.46394032738396945), 'nauc_mrr_at_10_max': np.float64(0.23803674448095652), 'nauc_mrr_at_10_std': np.float64(-0.21291362110704165), 'nauc_mrr_at_10_diff1': np.float64(0.4617447642635972), 'nauc_mrr_at_20_max': np.float64(0.2354022243418246), 'nauc_mrr_at_20_std': np.float64(-0.213817271904943), 'nauc_mrr_at_20_diff1': np.float64(0.46093476252778337), 'nauc_mrr_at_100_max': np.float64(0.238775993873158), 'nauc_mrr_at_100_std': np.float64(-0.209919275955211), 'nauc_mrr_at_100_diff1': np.float64(0.46236831420956687), 'nauc_mrr_at_1000_max': np.float64(0.23904828911088472), 'nauc_mrr_at_1000_std': np.float64(-0.20997048702461174), 'nauc_mrr_at_1000_diff1': np.float64(0.46242278322134905), 'main_score': 0.37783}, 'kor-eng': {'ndcg_at_1': 0.30945, 'ndcg_at_3': 0.33596, 'ndcg_at_5': 0.36497, 'ndcg_at_10': 0.39109, 'ndcg_at_20': 0.42067, 'ndcg_at_100': 0.46815, 'ndcg_at_1000': 0.49409, 'map_at_1': 0.21551, 'map_at_3': 0.30412, 'map_at_5': 0.3287, 'map_at_10': 0.3432, 'map_at_20': 0.35301, 'map_at_100': 0.36127, 'map_at_1000': 0.36252, 'recall_at_1': 0.21551, 'recall_at_3': 0.34737, 'recall_at_5': 0.41921, 'recall_at_10': 0.48758, 'recall_at_20': 0.59012, 'recall_at_100': 0.8113, 'recall_at_1000': 1.0, 'precision_at_1': 0.30945, 'precision_at_3': 0.19598, 'precision_at_5': 0.14332, 'precision_at_10': 0.0855, 'precision_at_20': 0.05147, 'precision_at_100': 0.01417, 'precision_at_1000': 0.00167, 'mrr_at_1': 0.31107491856677527, 'mrr_at_3': 0.36020629750271455, 'mrr_at_5': 0.3756786102062975, 'mrr_at_10': 0.3844604725712216, 'mrr_at_20': 0.39097541035090816, 'mrr_at_100': 0.3960552146624982, 'mrr_at_1000': 0.3968448844639659, 'nauc_ndcg_at_1_max': np.float64(0.23866129328964528), 'nauc_ndcg_at_1_std': np.float64(-0.24340702832669642), 'nauc_ndcg_at_1_diff1': np.float64(0.5267262337881523), 'nauc_ndcg_at_3_max': np.float64(0.20971496522207547), 'nauc_ndcg_at_3_std': np.float64(-0.2377510506944891), 'nauc_ndcg_at_3_diff1': np.float64(0.46793420267160435), 'nauc_ndcg_at_5_max': np.float64(0.19914113864657929), 'nauc_ndcg_at_5_std': np.float64(-0.24307022401939474), 'nauc_ndcg_at_5_diff1': np.float64(0.4541433980050947), 'nauc_ndcg_at_10_max': np.float64(0.19949106797978167), 'nauc_ndcg_at_10_std': np.float64(-0.24517004561521907), 'nauc_ndcg_at_10_diff1': np.float64(0.4354361974904552), 'nauc_ndcg_at_20_max': np.float64(0.18096798803168987), 'nauc_ndcg_at_20_std': np.float64(-0.250280617167327), 'nauc_ndcg_at_20_diff1': np.float64(0.42603530704040254), 'nauc_ndcg_at_100_max': np.float64(0.2040053428600786), 'nauc_ndcg_at_100_std': np.float64(-0.21676085807383963), 'nauc_ndcg_at_100_diff1': np.float64(0.43453667641644034), 'nauc_ndcg_at_1000_max': np.float64(0.20819962028802516), 'nauc_ndcg_at_1000_std': np.float64(-0.22887179688325687), 'nauc_ndcg_at_1000_diff1': np.float64(0.4455663154720834), 'nauc_map_at_1_max': np.float64(0.18286329496829418), 'nauc_map_at_1_std': np.float64(-0.20708664895395715), 'nauc_map_at_1_diff1': np.float64(0.5779386853894177), 'nauc_map_at_3_max': np.float64(0.21374768303001832), 'nauc_map_at_3_std': np.float64(-0.22473504103987182), 'nauc_map_at_3_diff1': np.float64(0.4827724715123031), 'nauc_map_at_5_max': np.float64(0.20452149810859), 'nauc_map_at_5_std': np.float64(-0.23632025739821672), 'nauc_map_at_5_diff1': np.float64(0.4682145205357387), 'nauc_map_at_10_max': np.float64(0.200668446379563), 'nauc_map_at_10_std': np.float64(-0.24374143314527924), 'nauc_map_at_10_diff1': np.float64(0.4563113995819711), 'nauc_map_at_20_max': np.float64(0.19508872863540536), 'nauc_map_at_20_std': np.float64(-0.24433529902613751), 'nauc_map_at_20_diff1': np.float64(0.45251618295726986), 'nauc_map_at_100_max': np.float64(0.19873894571168801), 'nauc_map_at_100_std': np.float64(-0.23945939677429573), 'nauc_map_at_100_diff1': np.float64(0.45444897833749226), 'nauc_map_at_1000_max': np.float64(0.19931141015432094), 'nauc_map_at_1000_std': np.float64(-0.2395474454941214), 'nauc_map_at_1000_diff1': np.float64(0.4548958964766957), 'nauc_recall_at_1_max': np.float64(0.18286329496829418), 'nauc_recall_at_1_std': np.float64(-0.20708664895395715), 'nauc_recall_at_1_diff1': np.float64(0.5779386853894177), 'nauc_recall_at_3_max': np.float64(0.20032119773337181), 'nauc_recall_at_3_std': np.float64(-0.21747080231896787), 'nauc_recall_at_3_diff1': np.float64(0.4408164666227879), 'nauc_recall_at_5_max': np.float64(0.1725453157801843), 'nauc_recall_at_5_std': np.float64(-0.23074996262983022), 'nauc_recall_at_5_diff1': np.float64(0.3946980792796597), 'nauc_recall_at_10_max': np.float64(0.17380174290259812), 'nauc_recall_at_10_std': np.float64(-0.23083308572578656), 'nauc_recall_at_10_diff1': np.float64(0.3428784439269361), 'nauc_recall_at_20_max': np.float64(0.0933382713149298), 'nauc_recall_at_20_std': np.float64(-0.2556646482459679), 'nauc_recall_at_20_diff1': np.float64(0.29516049564863056), 'nauc_recall_at_100_max': np.float64(0.17984057458845398), 'nauc_recall_at_100_std': np.float64(-0.023650986403760597), 'nauc_recall_at_100_diff1': np.float64(0.27331771683785144), 'nauc_recall_at_1000_max': nan, 'nauc_recall_at_1000_std': nan, 'nauc_recall_at_1000_diff1': nan, 'nauc_precision_at_1_max': np.float64(0.23866129328964528), 'nauc_precision_at_1_std': np.float64(-0.24340702832669642), 'nauc_precision_at_1_diff1': np.float64(0.5267262337881523), 'nauc_precision_at_3_max': np.float64(0.19541954983773932), 'nauc_precision_at_3_std': np.float64(-0.2115866935867554), 'nauc_precision_at_3_diff1': np.float64(0.248416852451941), 'nauc_precision_at_5_max': np.float64(0.14445211015921075), 'nauc_precision_at_5_std': np.float64(-0.2297600151053609), 'nauc_precision_at_5_diff1': np.float64(0.19269755745899614), 'nauc_precision_at_10_max': np.float64(0.12235436428946195), 'nauc_precision_at_10_std': np.float64(-0.21794163532860025), 'nauc_precision_at_10_diff1': np.float64(0.13445719806685344), 'nauc_precision_at_20_max': np.float64(0.07613968754489926), 'nauc_precision_at_20_std': np.float64(-0.19295008925677776), 'nauc_precision_at_20_diff1': np.float64(0.08472184472828873), 'nauc_precision_at_100_max': np.float64(0.14683891434414773), 'nauc_precision_at_100_std': np.float64(0.00980347233198947), 'nauc_precision_at_100_diff1': np.float64(0.006767748506611152), 'nauc_precision_at_1000_max': np.float64(0.15341997500895743), 'nauc_precision_at_1000_std': np.float64(0.044926991535131085), 'nauc_precision_at_1000_diff1': np.float64(-0.06873750540272515), 'nauc_mrr_at_1_max': np.float64(0.23508291252382657), 'nauc_mrr_at_1_std': np.float64(-0.2479014148162675), 'nauc_mrr_at_1_diff1': np.float64(0.5216144246032884), 'nauc_mrr_at_3_max': np.float64(0.2235918989193775), 'nauc_mrr_at_3_std': np.float64(-0.2509956018197716), 'nauc_mrr_at_3_diff1': np.float64(0.48789010383009696), 'nauc_mrr_at_5_max': np.float64(0.21703824401606106), 'nauc_mrr_at_5_std': np.float64(-0.25277193790188085), 'nauc_mrr_at_5_diff1': np.float64(0.4814046246191893), 'nauc_mrr_at_10_max': np.float64(0.2213185230641255), 'nauc_mrr_at_10_std': np.float64(-0.24699892936185902), 'nauc_mrr_at_10_diff1': np.float64(0.4769538177746792), 'nauc_mrr_at_20_max': np.float64(0.21765289559125464), 'nauc_mrr_at_20_std': np.float64(-0.2493718994450294), 'nauc_mrr_at_20_diff1': np.float64(0.4763242221393896), 'nauc_mrr_at_100_max': np.float64(0.21897704178257765), 'nauc_mrr_at_100_std': np.float64(-0.24688459056119716), 'nauc_mrr_at_100_diff1': np.float64(0.4769610203525847), 'nauc_mrr_at_1000_max': np.float64(0.21893893730516018), 'nauc_mrr_at_1000_std': np.float64(-0.24729261779254305), 'nauc_mrr_at_1000_diff1': np.float64(0.4772701728011638), 'main_score': 0.39109}}
INFO:mteb.evaluation.MTEB:

********************** Evaluating MultiLongDocRetrieval **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/7 [00:00<?, ?it/s]Batches:  29%|██▊       | 2/7 [00:00<00:01,  4.03it/s]Batches:  57%|█████▋    | 4/7 [00:00<00:00,  7.10it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 11.72it/s]Batches: 100%|██████████| 7/7 [00:00<00:00,  9.30it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/193 [00:00<?, ?it/s]Batches:   1%|          | 1/193 [00:01<03:57,  1.24s/it]Batches:   1%|          | 2/193 [00:38<1:12:09, 22.67s/it]Batches:   2%|▏         | 3/193 [01:17<1:34:10, 29.74s/it]Batches:   2%|▏         | 4/193 [01:55<1:44:17, 33.11s/it]Batches:   3%|▎         | 5/193 [02:33<1:49:34, 34.97s/it]Batches:   3%|▎         | 6/193 [03:11<1:52:29, 36.09s/it]Batches:   4%|▎         | 7/193 [03:50<1:54:06, 36.81s/it]Batches:   4%|▍         | 8/193 [04:28<1:54:57, 37.28s/it]Batches:   5%|▍         | 9/193 [05:06<1:55:19, 37.60s/it]Batches:   5%|▌         | 10/193 [05:45<1:55:20, 37.82s/it]Batches:   6%|▌         | 11/193 [06:23<1:55:09, 37.96s/it]Batches:   6%|▌         | 12/193 [07:01<1:54:50, 38.07s/it]Batches:   7%|▋         | 13/193 [07:39<1:54:24, 38.14s/it]Batches:   7%|▋         | 14/193 [08:18<1:53:54, 38.18s/it]Batches:   8%|▊         | 15/193 [08:56<1:53:22, 38.21s/it]Batches:   8%|▊         | 16/193 [09:34<1:52:48, 38.24s/it]Batches:   9%|▉         | 17/193 [10:13<1:52:13, 38.26s/it]Batches:   9%|▉         | 18/193 [10:51<1:51:39, 38.28s/it]Batches:  10%|▉         | 19/193 [11:29<1:51:04, 38.30s/it]Batches:  10%|█         | 20/193 [12:08<1:50:27, 38.31s/it]Batches:  11%|█         | 21/193 [12:46<1:49:50, 38.32s/it]Batches:  11%|█▏        | 22/193 [13:24<1:49:18, 38.35s/it]Batches:  12%|█▏        | 23/193 [14:11<1:55:40, 40.83s/it]Batches:  12%|█▏        | 24/193 [14:49<1:52:53, 40.08s/it]Batches:  13%|█▎        | 25/193 [15:28<1:50:45, 39.56s/it]Batches:  13%|█▎        | 26/193 [16:06<1:49:04, 39.19s/it]Batches:  14%|█▍        | 27/193 [16:44<1:47:42, 38.93s/it]Batches:  15%|█▍        | 28/193 [17:23<1:46:33, 38.75s/it]Batches:  15%|█▌        | 29/193 [18:01<1:45:34, 38.63s/it]Batches:  16%|█▌        | 30/193 [18:39<1:44:41, 38.54s/it]Batches:  16%|█▌        | 31/193 [19:18<1:43:53, 38.48s/it]Batches:  17%|█▋        | 32/193 [19:56<1:43:07, 38.43s/it]Batches:  17%|█▋        | 33/193 [20:34<1:42:24, 38.40s/it]Batches:  18%|█▊        | 34/193 [21:13<1:41:42, 38.38s/it]Batches:  18%|█▊        | 35/193 [21:51<1:41:01, 38.36s/it]Batches:  19%|█▊        | 36/193 [22:29<1:40:21, 38.35s/it]Batches:  19%|█▉        | 37/193 [23:08<1:39:42, 38.35s/it]Batches:  20%|█▉        | 38/193 [23:46<1:39:03, 38.34s/it]Batches:  20%|██        | 39/193 [24:33<1:44:48, 40.83s/it]Batches:  21%|██        | 40/193 [25:11<1:42:13, 40.09s/it]Batches:  21%|██        | 41/193 [25:49<1:40:12, 39.56s/it]Batches:  22%|██▏       | 42/193 [26:28<1:38:37, 39.19s/it]Batches:  22%|██▏       | 43/193 [27:06<1:37:20, 38.94s/it]Batches:  23%|██▎       | 44/193 [27:53<1:42:26, 41.25s/it]Batches:  23%|██▎       | 45/193 [28:31<1:39:34, 40.37s/it]Batches:  24%|██▍       | 46/193 [29:18<1:43:30, 42.25s/it]Batches:  24%|██▍       | 47/193 [30:04<1:46:00, 43.57s/it]Batches:  25%|██▍       | 48/193 [30:43<1:41:29, 42.00s/it]Batches:  25%|██▌       | 49/193 [31:21<1:38:09, 40.90s/it]Batches:  26%|██▌       | 50/193 [31:59<1:35:38, 40.13s/it]Batches:  26%|██▋       | 51/193 [32:46<1:39:35, 42.08s/it]Batches:  27%|██▋       | 52/193 [33:24<1:36:14, 40.95s/it]Batches:  27%|██▋       | 53/193 [34:11<1:39:31, 42.66s/it]Batches:  28%|██▊       | 54/193 [34:57<1:41:34, 43.85s/it]Batches:  28%|██▊       | 55/193 [35:44<1:42:46, 44.68s/it]Batches:  29%|██▉       | 56/193 [36:31<1:43:21, 45.27s/it]Batches:  30%|██▉       | 57/193 [37:17<1:43:31, 45.68s/it]Batches:  30%|███       | 58/193 [38:04<1:43:24, 45.96s/it]Batches:  31%|███       | 59/193 [38:51<1:43:05, 46.16s/it]Batches:  31%|███       | 60/193 [39:37<1:42:38, 46.30s/it]Batches:  32%|███▏      | 61/193 [40:24<1:42:05, 46.40s/it]Batches:  32%|███▏      | 62/193 [41:11<1:41:27, 46.47s/it]Batches:  33%|███▎      | 63/193 [41:57<1:40:48, 46.53s/it]Batches:  33%|███▎      | 64/193 [42:44<1:40:05, 46.56s/it]Batches:  34%|███▎      | 65/193 [43:30<1:39:22, 46.58s/it]Batches:  34%|███▍      | 66/193 [44:17<1:38:38, 46.60s/it]Batches:  35%|███▍      | 67/193 [45:04<1:37:53, 46.62s/it]Batches:  35%|███▌      | 68/193 [45:50<1:37:07, 46.62s/it]Batches:  36%|███▌      | 69/193 [46:37<1:36:21, 46.63s/it]Batches:  36%|███▋      | 70/193 [47:24<1:35:35, 46.63s/it]Batches:  37%|███▋      | 71/193 [48:10<1:34:50, 46.64s/it]Batches:  37%|███▋      | 72/193 [48:57<1:34:03, 46.64s/it]Batches:  38%|███▊      | 73/193 [49:44<1:33:16, 46.64s/it]Batches:  38%|███▊      | 74/193 [50:30<1:32:30, 46.64s/it]Batches:  39%|███▉      | 75/193 [51:17<1:31:43, 46.64s/it]Batches:  39%|███▉      | 76/193 [52:04<1:30:57, 46.65s/it]Batches:  40%|███▉      | 77/193 [52:50<1:30:10, 46.65s/it]Batches:  40%|████      | 78/193 [53:37<1:29:23, 46.64s/it]Batches:  41%|████      | 79/193 [54:23<1:28:37, 46.64s/it]Batches:  41%|████▏     | 80/193 [55:10<1:27:50, 46.64s/it]Batches:  42%|████▏     | 81/193 [55:57<1:27:03, 46.64s/it]Batches:  42%|████▏     | 82/193 [56:43<1:26:15, 46.63s/it]Batches:  43%|████▎     | 83/193 [57:30<1:25:29, 46.63s/it]Batches:  44%|████▎     | 84/193 [58:17<1:24:42, 46.63s/it]Batches:  44%|████▍     | 85/193 [59:03<1:23:56, 46.63s/it]Batches:  45%|████▍     | 86/193 [59:50<1:23:09, 46.63s/it]Batches:  45%|████▌     | 87/193 [1:00:36<1:22:22, 46.63s/it]Batches:  46%|████▌     | 88/193 [1:01:23<1:21:36, 46.63s/it]Batches:  46%|████▌     | 89/193 [1:02:10<1:20:49, 46.63s/it]Batches:  47%|████▋     | 90/193 [1:02:56<1:20:03, 46.63s/it]Batches:  47%|████▋     | 91/193 [1:03:43<1:19:16, 46.63s/it]Batches:  48%|████▊     | 92/193 [1:04:30<1:18:29, 46.63s/it]Batches:  48%|████▊     | 93/193 [1:05:16<1:17:42, 46.62s/it]Batches:  49%|████▊     | 94/193 [1:06:03<1:16:55, 46.62s/it]Batches:  49%|████▉     | 95/193 [1:06:49<1:16:08, 46.62s/it]Batches:  50%|████▉     | 96/193 [1:07:36<1:15:21, 46.62s/it]Batches:  50%|█████     | 97/193 [1:08:23<1:14:34, 46.61s/it]Batches:  51%|█████     | 98/193 [1:09:09<1:13:48, 46.61s/it]Batches:  51%|█████▏    | 99/193 [1:09:56<1:13:01, 46.61s/it]Batches:  52%|█████▏    | 100/193 [1:10:43<1:12:15, 46.62s/it]Batches:  52%|█████▏    | 101/193 [1:11:29<1:11:28, 46.61s/it]Batches:  53%|█████▎    | 102/193 [1:12:16<1:10:41, 46.61s/it]Batches:  53%|█████▎    | 103/193 [1:13:02<1:09:55, 46.61s/it]Batches:  54%|█████▍    | 104/193 [1:13:49<1:09:08, 46.61s/it]Batches:  54%|█████▍    | 105/193 [1:14:38<1:09:32, 47.42s/it]Batches:  55%|█████▍    | 106/193 [1:15:25<1:08:23, 47.17s/it]Batches:  55%|█████▌    | 107/193 [1:16:13<1:08:01, 47.45s/it]Batches:  56%|█████▌    | 108/193 [1:17:00<1:06:52, 47.20s/it]Batches:  56%|█████▋    | 109/193 [1:17:46<1:05:49, 47.02s/it]Batches:  57%|█████▋    | 110/193 [1:18:30<1:03:37, 46.00s/it]Batches:  58%|█████▊    | 111/193 [1:19:14<1:01:55, 45.32s/it]Batches:  58%|█████▊    | 112/193 [1:20:00<1:01:40, 45.68s/it]Batches:  59%|█████▊    | 113/193 [1:20:47<1:01:34, 46.18s/it]Batches:  59%|█████▉    | 114/193 [1:21:31<59:50, 45.45s/it]  Batches:  60%|█████▉    | 115/193 [1:22:13<57:50, 44.49s/it]Batches:  60%|██████    | 116/193 [1:23:00<57:53, 45.11s/it]Batches:  61%|██████    | 117/193 [1:23:49<58:35, 46.26s/it]Batches:  61%|██████    | 118/193 [1:24:38<58:53, 47.11s/it]Batches:  62%|██████▏   | 119/193 [1:25:09<52:02, 42.20s/it]Batches:  62%|██████▏   | 120/193 [1:25:41<47:41, 39.19s/it]Batches:  63%|██████▎   | 121/193 [1:26:08<42:29, 35.41s/it]Batches:  63%|██████▎   | 122/193 [1:26:30<37:27, 31.65s/it]Batches:  64%|██████▎   | 123/193 [1:26:50<32:52, 28.18s/it]Batches:  64%|██████▍   | 124/193 [1:27:09<29:04, 25.28s/it]Batches:  65%|██████▍   | 125/193 [1:27:28<26:21, 23.26s/it]Batches:  65%|██████▌   | 126/193 [1:27:45<23:54, 21.40s/it]Batches:  66%|██████▌   | 127/193 [1:27:59<21:22, 19.43s/it]Batches:  66%|██████▋   | 128/193 [1:28:13<19:07, 17.65s/it]Batches:  67%|██████▋   | 129/193 [1:28:28<17:51, 16.75s/it]Batches:  67%|██████▋   | 130/193 [1:28:42<16:57, 16.14s/it]Batches:  68%|██████▊   | 131/193 [1:28:55<15:33, 15.05s/it]Batches:  68%|██████▊   | 132/193 [1:29:06<14:16, 14.04s/it]Batches:  69%|██████▉   | 133/193 [1:29:19<13:33, 13.56s/it]Batches:  69%|██████▉   | 134/193 [1:29:30<12:40, 12.89s/it]Batches:  70%|██████▉   | 135/193 [1:29:40<11:38, 12.04s/it]Batches:  70%|███████   | 136/193 [1:29:49<10:32, 11.10s/it]Batches:  71%|███████   | 137/193 [1:30:00<10:13, 10.95s/it]Batches:  72%|███████▏  | 138/193 [1:30:08<09:17, 10.14s/it]Batches:  72%|███████▏  | 139/193 [1:30:16<08:29,  9.44s/it]Batches:  73%|███████▎  | 140/193 [1:30:25<08:07,  9.20s/it]Batches:  73%|███████▎  | 141/193 [1:30:31<07:17,  8.41s/it]Batches:  74%|███████▎  | 142/193 [1:30:37<06:38,  7.81s/it]Batches:  74%|███████▍  | 143/193 [1:30:44<06:16,  7.53s/it]Batches:  75%|███████▍  | 144/193 [1:30:51<06:02,  7.39s/it]Batches:  75%|███████▌  | 145/193 [1:30:58<05:47,  7.24s/it]Batches:  76%|███████▌  | 146/193 [1:31:04<05:24,  6.91s/it]Batches:  76%|███████▌  | 147/193 [1:31:10<05:01,  6.56s/it]Batches:  77%|███████▋  | 148/193 [1:31:16<04:38,  6.20s/it]Batches:  77%|███████▋  | 149/193 [1:31:21<04:27,  6.07s/it]Batches:  78%|███████▊  | 150/193 [1:31:27<04:11,  5.85s/it]Batches:  78%|███████▊  | 151/193 [1:31:32<03:56,  5.63s/it]Batches:  79%|███████▉  | 152/193 [1:31:37<03:43,  5.45s/it]Batches:  79%|███████▉  | 153/193 [1:31:42<03:32,  5.32s/it]Batches:  80%|███████▉  | 154/193 [1:31:47<03:29,  5.37s/it]Batches:  80%|████████  | 155/193 [1:31:52<03:12,  5.07s/it]Batches:  81%|████████  | 156/193 [1:31:57<03:14,  5.27s/it]Batches:  81%|████████▏ | 157/193 [1:32:02<02:59,  4.98s/it]Batches:  82%|████████▏ | 158/193 [1:32:06<02:44,  4.69s/it]Batches:  82%|████████▏ | 159/193 [1:32:10<02:39,  4.68s/it]Batches:  83%|████████▎ | 160/193 [1:32:15<02:29,  4.52s/it]Batches:  83%|████████▎ | 161/193 [1:32:19<02:26,  4.58s/it]Batches:  84%|████████▍ | 162/193 [1:32:23<02:11,  4.23s/it]Batches:  84%|████████▍ | 163/193 [1:32:27<02:05,  4.18s/it]Batches:  85%|████████▍ | 164/193 [1:32:31<01:57,  4.05s/it]Batches:  85%|████████▌ | 165/193 [1:32:34<01:47,  3.85s/it]Batches:  86%|████████▌ | 166/193 [1:32:37<01:41,  3.74s/it]Batches:  87%|████████▋ | 167/193 [1:32:41<01:33,  3.60s/it]Batches:  87%|████████▋ | 168/193 [1:32:44<01:28,  3.53s/it]Batches:  88%|████████▊ | 169/193 [1:32:48<01:24,  3.52s/it]Batches:  88%|████████▊ | 170/193 [1:32:51<01:18,  3.41s/it]Batches:  89%|████████▊ | 171/193 [1:32:54<01:15,  3.45s/it]Batches:  89%|████████▉ | 172/193 [1:32:57<01:10,  3.34s/it]Batches:  90%|████████▉ | 173/193 [1:33:01<01:07,  3.37s/it]Batches:  90%|█████████ | 174/193 [1:33:04<01:01,  3.21s/it]Batches:  91%|█████████ | 175/193 [1:33:06<00:55,  3.09s/it]Batches:  91%|█████████ | 176/193 [1:33:10<00:54,  3.20s/it]Batches:  92%|█████████▏| 177/193 [1:33:12<00:47,  3.00s/it]Batches:  92%|█████████▏| 178/193 [1:33:15<00:43,  2.92s/it]Batches:  93%|█████████▎| 179/193 [1:33:18<00:39,  2.84s/it]Batches:  93%|█████████▎| 180/193 [1:33:20<00:35,  2.75s/it]Batches:  94%|█████████▍| 181/193 [1:33:23<00:32,  2.69s/it]Batches:  94%|█████████▍| 182/193 [1:33:26<00:30,  2.78s/it]Batches:  95%|█████████▍| 183/193 [1:33:28<00:27,  2.71s/it]Batches:  95%|█████████▌| 184/193 [1:33:31<00:24,  2.69s/it]Batches:  96%|█████████▌| 185/193 [1:33:33<00:20,  2.60s/it]Batches:  96%|█████████▋| 186/193 [1:33:36<00:18,  2.59s/it]Batches:  97%|█████████▋| 187/193 [1:33:38<00:15,  2.52s/it]Batches:  97%|█████████▋| 188/193 [1:33:40<00:11,  2.40s/it]Batches:  98%|█████████▊| 189/193 [1:33:42<00:09,  2.30s/it]Batches:  98%|█████████▊| 190/193 [1:33:45<00:07,  2.41s/it]Batches:  99%|█████████▉| 191/193 [1:33:48<00:04,  2.39s/it]Batches:  99%|█████████▉| 192/193 [1:33:50<00:02,  2.28s/it]Batches: 100%|██████████| 193/193 [1:33:52<00:00,  2.23s/it]Batches: 100%|██████████| 193/193 [1:33:52<00:00, 29.18s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5639.62 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on dev took 5639.91 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.29, 'ndcg_at_3': 0.35917, 'ndcg_at_5': 0.38176, 'ndcg_at_10': 0.40401, 'ndcg_at_20': 0.42135, 'ndcg_at_100': 0.4465, 'ndcg_at_1000': 0.4683, 'map_at_1': 0.29, 'map_at_3': 0.34167, 'map_at_5': 0.35417, 'map_at_10': 0.3631, 'map_at_20': 0.36767, 'map_at_100': 0.37114, 'map_at_1000': 0.3719, 'recall_at_1': 0.29, 'recall_at_3': 0.41, 'recall_at_5': 0.465, 'recall_at_10': 0.535, 'recall_at_20': 0.605, 'recall_at_100': 0.74, 'recall_at_1000': 0.915, 'precision_at_1': 0.29, 'precision_at_3': 0.13667, 'precision_at_5': 0.093, 'precision_at_10': 0.0535, 'precision_at_20': 0.03025, 'precision_at_100': 0.0074, 'precision_at_1000': 0.00092, 'mrr_at_1': 0.29, 'mrr_at_3': 0.3416666666666666, 'mrr_at_5': 0.35416666666666674, 'mrr_at_10': 0.3630992063492065, 'mrr_at_20': 0.36766753078363, 'mrr_at_100': 0.3711384633457173, 'mrr_at_1000': 0.37189738331580946, 'nauc_ndcg_at_1_max': np.float64(0.39917997884702555), 'nauc_ndcg_at_1_std': np.float64(0.027622488084282235), 'nauc_ndcg_at_1_diff1': np.float64(0.4828166421713391), 'nauc_ndcg_at_3_max': np.float64(0.4198405042078001), 'nauc_ndcg_at_3_std': np.float64(0.06509499992051403), 'nauc_ndcg_at_3_diff1': np.float64(0.4545766592925812), 'nauc_ndcg_at_5_max': np.float64(0.43372843547167483), 'nauc_ndcg_at_5_std': np.float64(0.08556913036057888), 'nauc_ndcg_at_5_diff1': np.float64(0.4564134710353235), 'nauc_ndcg_at_10_max': np.float64(0.4359896102482136), 'nauc_ndcg_at_10_std': np.float64(0.08614540313566939), 'nauc_ndcg_at_10_diff1': np.float64(0.44646248518349163), 'nauc_ndcg_at_20_max': np.float64(0.4478875466397034), 'nauc_ndcg_at_20_std': np.float64(0.11118427838611118), 'nauc_ndcg_at_20_diff1': np.float64(0.4369234063362664), 'nauc_ndcg_at_100_max': np.float64(0.4454290362973049), 'nauc_ndcg_at_100_std': np.float64(0.12580780403668493), 'nauc_ndcg_at_100_diff1': np.float64(0.4285848863786797), 'nauc_ndcg_at_1000_max': np.float64(0.44940087831479314), 'nauc_ndcg_at_1000_std': np.float64(0.12392203253167734), 'nauc_ndcg_at_1000_diff1': np.float64(0.43408501974393143), 'nauc_map_at_1_max': np.float64(0.39917997884702555), 'nauc_map_at_1_std': np.float64(0.027622488084282235), 'nauc_map_at_1_diff1': np.float64(0.4828166421713391), 'nauc_map_at_3_max': np.float64(0.419223281529853), 'nauc_map_at_3_std': np.float64(0.05882346397303398), 'nauc_map_at_3_diff1': np.float64(0.46405313101422846), 'nauc_map_at_5_max': np.float64(0.4261875045392837), 'nauc_map_at_5_std': np.float64(0.06944372126284282), 'nauc_map_at_5_diff1': np.float64(0.46516712944081634), 'nauc_map_at_10_max': np.float64(0.4270268587993162), 'nauc_map_at_10_std': np.float64(0.06924906791385384), 'nauc_map_at_10_diff1': np.float64(0.46108134854997723), 'nauc_map_at_20_max': np.float64(0.4300363726855353), 'nauc_map_at_20_std': np.float64(0.0757982536181022), 'nauc_map_at_20_diff1': np.float64(0.4583864939230525), 'nauc_map_at_100_max': np.float64(0.42981378374129936), 'nauc_map_at_100_std': np.float64(0.07745346867638817), 'nauc_map_at_100_diff1': np.float64(0.45746546765685037), 'nauc_map_at_1000_max': np.float64(0.429917182615959), 'nauc_map_at_1000_std': np.float64(0.07729332504983516), 'nauc_map_at_1000_diff1': np.float64(0.45767919139476493), 'nauc_recall_at_1_max': np.float64(0.39917997884702555), 'nauc_recall_at_1_std': np.float64(0.027622488084282235), 'nauc_recall_at_1_diff1': np.float64(0.4828166421713391), 'nauc_recall_at_3_max': np.float64(0.41987547954583626), 'nauc_recall_at_3_std': np.float64(0.08160352377384805), 'nauc_recall_at_3_diff1': np.float64(0.42697340377436493), 'nauc_recall_at_5_max': np.float64(0.4563152802732639), 'nauc_recall_at_5_std': np.float64(0.13410468537129527), 'nauc_recall_at_5_diff1': np.float64(0.43065400385675995), 'nauc_recall_at_10_max': np.float64(0.4648209436817266), 'nauc_recall_at_10_std': np.float64(0.14030166308531014), 'nauc_recall_at_10_diff1': np.float64(0.3982698938029865), 'nauc_recall_at_20_max': np.float64(0.5194462952842263), 'nauc_recall_at_20_std': np.float64(0.2532547745427594), 'nauc_recall_at_20_diff1': np.float64(0.3548995680264725), 'nauc_recall_at_100_max': np.float64(0.5211974372490977), 'nauc_recall_at_100_std': np.float64(0.4133956449454604), 'nauc_recall_at_100_diff1': np.float64(0.2614147844775151), 'nauc_recall_at_1000_max': np.float64(0.7666007579502387), 'nauc_recall_at_1000_std': np.float64(0.8437414181358818), 'nauc_recall_at_1000_diff1': np.float64(0.13750205964738907), 'nauc_precision_at_1_max': np.float64(0.39917997884702555), 'nauc_precision_at_1_std': np.float64(0.027622488084282235), 'nauc_precision_at_1_diff1': np.float64(0.4828166421713391), 'nauc_precision_at_3_max': np.float64(0.4198754795458362), 'nauc_precision_at_3_std': np.float64(0.08160352377384772), 'nauc_precision_at_3_diff1': np.float64(0.4269734037743647), 'nauc_precision_at_5_max': np.float64(0.45631528027326396), 'nauc_precision_at_5_std': np.float64(0.13410468537129516), 'nauc_precision_at_5_diff1': np.float64(0.43065400385676006), 'nauc_precision_at_10_max': np.float64(0.46482094368172655), 'nauc_precision_at_10_std': np.float64(0.1403016630853097), 'nauc_precision_at_10_diff1': np.float64(0.3982698938029859), 'nauc_precision_at_20_max': np.float64(0.5194462952842266), 'nauc_precision_at_20_std': np.float64(0.25325477454275946), 'nauc_precision_at_20_diff1': np.float64(0.3548995680264723), 'nauc_precision_at_100_max': np.float64(0.5211974372490971), 'nauc_precision_at_100_std': np.float64(0.41339564494546), 'nauc_precision_at_100_diff1': np.float64(0.26141478447751504), 'nauc_precision_at_1000_max': np.float64(0.7666007579502365), 'nauc_precision_at_1000_std': np.float64(0.843741418135881), 'nauc_precision_at_1000_diff1': np.float64(0.13750205964738865), 'nauc_mrr_at_1_max': np.float64(0.39917997884702555), 'nauc_mrr_at_1_std': np.float64(0.027622488084282235), 'nauc_mrr_at_1_diff1': np.float64(0.4828166421713391), 'nauc_mrr_at_3_max': np.float64(0.419223281529853), 'nauc_mrr_at_3_std': np.float64(0.05882346397303398), 'nauc_mrr_at_3_diff1': np.float64(0.46405313101422846), 'nauc_mrr_at_5_max': np.float64(0.4261875045392837), 'nauc_mrr_at_5_std': np.float64(0.06944372126284282), 'nauc_mrr_at_5_diff1': np.float64(0.46516712944081634), 'nauc_mrr_at_10_max': np.float64(0.4270268587993162), 'nauc_mrr_at_10_std': np.float64(0.06924906791385384), 'nauc_mrr_at_10_diff1': np.float64(0.46108134854997723), 'nauc_mrr_at_20_max': np.float64(0.4300363726855353), 'nauc_mrr_at_20_std': np.float64(0.0757982536181022), 'nauc_mrr_at_20_diff1': np.float64(0.4583864939230525), 'nauc_mrr_at_100_max': np.float64(0.42981378374129936), 'nauc_mrr_at_100_std': np.float64(0.07745346867638817), 'nauc_mrr_at_100_diff1': np.float64(0.45746546765685037), 'nauc_mrr_at_1000_max': np.float64(0.429917182615959), 'nauc_mrr_at_1000_std': np.float64(0.07729332504983516), 'nauc_mrr_at_1000_diff1': np.float64(0.45767919139476493), 'main_score': 0.40401}}
INFO:mteb.abstasks.AbsTaskRetrieval:Subset: ko
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries.
INFO:mteb.models.sentence_transformer_wrapper:Using prompt_name=query for task=MultiLongDocRetrieval prompt_type=query
INFO:mteb.models.sentence_transformer_wrapper:Encoding 200 sentences.
Batches:   0%|          | 0/7 [00:00<?, ?it/s]Batches:  29%|██▊       | 2/7 [00:00<00:00,  8.13it/s]Batches:  57%|█████▋    | 4/7 [00:00<00:00, 11.18it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 16.04it/s]Batches: 100%|██████████| 7/7 [00:00<00:00, 13.97it/s]
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.models.wrapper:No combination of task name and prompt type was found in model prompts.
INFO:mteb.models.sentence_transformer_wrapper:No model prompts found for task=MultiLongDocRetrieval prompt_type=passage
INFO:mteb.models.sentence_transformer_wrapper:Encoding 6176 sentences.
Batches:   0%|          | 0/193 [00:00<?, ?it/s]Batches:   1%|          | 1/193 [00:00<02:59,  1.07it/s]Batches:   1%|          | 2/193 [00:39<1:12:57, 22.92s/it]Batches:   2%|▏         | 3/193 [01:17<1:34:52, 29.96s/it]Batches:   2%|▏         | 4/193 [01:55<1:44:50, 33.28s/it]Batches:   3%|▎         | 5/193 [02:34<1:50:03, 35.12s/it]Batches:   3%|▎         | 6/193 [03:12<1:52:53, 36.22s/it]Batches:   4%|▎         | 7/193 [03:51<1:54:26, 36.91s/it]Batches:   4%|▍         | 8/193 [04:29<1:55:14, 37.38s/it]Batches:   5%|▍         | 9/193 [05:07<1:55:33, 37.68s/it]Batches:   5%|▌         | 10/193 [05:46<1:55:33, 37.89s/it]Batches:   6%|▌         | 11/193 [06:24<1:55:21, 38.03s/it]Batches:   6%|▌         | 12/193 [07:02<1:55:02, 38.13s/it]Batches:   7%|▋         | 13/193 [07:41<1:54:36, 38.20s/it]Batches:   7%|▋         | 14/193 [08:19<1:54:06, 38.25s/it]Batches:   8%|▊         | 15/193 [08:57<1:53:34, 38.28s/it]Batches:   8%|▊         | 16/193 [09:36<1:52:59, 38.30s/it]Batches:   9%|▉         | 17/193 [10:14<1:52:23, 38.31s/it]Batches:   9%|▉         | 18/193 [10:52<1:51:46, 38.32s/it]Batches:  10%|▉         | 19/193 [11:31<1:51:09, 38.33s/it]Batches:  10%|█         | 20/193 [12:09<1:50:31, 38.33s/it]Batches:  11%|█         | 21/193 [12:47<1:49:54, 38.34s/it]Batches:  11%|█▏        | 22/193 [13:26<1:49:16, 38.34s/it]Batches:  12%|█▏        | 23/193 [14:12<1:55:42, 40.84s/it]Batches:  12%|█▏        | 24/193 [14:51<1:52:55, 40.09s/it]Batches:  13%|█▎        | 25/193 [15:29<1:50:47, 39.57s/it]Batches:  13%|█▎        | 26/193 [16:08<1:49:07, 39.21s/it]Batches:  14%|█▍        | 27/193 [16:46<1:47:46, 38.95s/it]Batches:  15%|█▍        | 28/193 [17:24<1:46:38, 38.78s/it]Batches:  15%|█▌        | 29/193 [18:03<1:45:39, 38.66s/it]Batches:  16%|█▌        | 30/193 [18:41<1:44:45, 38.56s/it]Batches:  16%|█▌        | 31/193 [19:19<1:43:57, 38.50s/it]Batches:  17%|█▋        | 32/193 [19:58<1:43:10, 38.45s/it]Batches:  17%|█▋        | 33/193 [20:36<1:42:27, 38.42s/it]Batches:  18%|█▊        | 34/193 [21:14<1:41:45, 38.40s/it]Batches:  18%|█▊        | 35/193 [21:53<1:41:04, 38.38s/it]Batches:  19%|█▊        | 36/193 [22:31<1:40:24, 38.37s/it]Batches:  19%|█▉        | 37/193 [23:09<1:39:44, 38.36s/it]Batches:  20%|█▉        | 38/193 [23:48<1:39:05, 38.36s/it]Batches:  20%|██        | 39/193 [24:34<1:44:49, 40.84s/it]Batches:  21%|██        | 40/193 [25:13<1:42:14, 40.10s/it]Batches:  21%|██        | 41/193 [25:51<1:40:15, 39.58s/it]Batches:  22%|██▏       | 42/193 [26:29<1:38:40, 39.21s/it]Batches:  22%|██▏       | 43/193 [27:08<1:37:21, 38.95s/it]Batches:  23%|██▎       | 44/193 [27:54<1:42:27, 41.26s/it]Batches:  23%|██▎       | 45/193 [28:33<1:39:36, 40.38s/it]Batches:  24%|██▍       | 46/193 [29:19<1:43:32, 42.26s/it]Batches:  24%|██▍       | 47/193 [30:06<1:46:03, 43.58s/it]Batches:  25%|██▍       | 48/193 [30:44<1:41:32, 42.02s/it]Batches:  25%|██▌       | 49/193 [31:23<1:38:12, 40.92s/it]Batches:  26%|██▌       | 50/193 [32:01<1:35:40, 40.15s/it]Batches:  26%|██▋       | 51/193 [32:48<1:39:37, 42.10s/it]Batches:  27%|██▋       | 52/193 [33:26<1:36:17, 40.98s/it]Batches:  27%|██▋       | 53/193 [34:13<1:39:36, 42.69s/it]Batches:  28%|██▊       | 54/193 [35:00<1:41:40, 43.89s/it]Batches:  28%|██▊       | 55/193 [35:46<1:42:51, 44.72s/it]Batches:  29%|██▉       | 56/193 [36:33<1:43:26, 45.30s/it]Batches:  30%|██▉       | 57/193 [37:20<1:43:37, 45.72s/it]Batches:  30%|███       | 58/193 [38:06<1:43:30, 46.00s/it]Batches:  31%|███       | 59/193 [38:53<1:43:12, 46.21s/it]Batches:  31%|███       | 60/193 [39:40<1:42:44, 46.35s/it]Batches:  32%|███▏      | 61/193 [40:26<1:42:11, 46.45s/it]Batches:  32%|███▏      | 62/193 [41:13<1:41:33, 46.52s/it]Batches:  33%|███▎      | 63/193 [42:00<1:40:53, 46.57s/it]Batches:  33%|███▎      | 64/193 [42:46<1:40:10, 46.59s/it]Batches:  34%|███▎      | 65/193 [43:33<1:39:27, 46.62s/it]Batches:  34%|███▍      | 66/193 [44:20<1:38:42, 46.63s/it]Batches:  35%|███▍      | 67/193 [45:06<1:37:57, 46.65s/it]Batches:  35%|███▌      | 68/193 [45:53<1:37:11, 46.65s/it]Batches:  36%|███▌      | 69/193 [46:40<1:36:25, 46.66s/it]Batches:  36%|███▋      | 70/193 [47:26<1:35:39, 46.66s/it]Batches:  37%|███▋      | 71/193 [48:13<1:34:53, 46.66s/it]Batches:  37%|███▋      | 72/193 [49:00<1:34:06, 46.67s/it]Batches:  38%|███▊      | 73/193 [49:46<1:33:19, 46.66s/it]Batches:  38%|███▊      | 74/193 [50:33<1:32:32, 46.66s/it]Batches:  39%|███▉      | 75/193 [51:20<1:31:46, 46.66s/it]Batches:  39%|███▉      | 76/193 [52:06<1:30:59, 46.66s/it]Batches:  40%|███▉      | 77/193 [52:53<1:30:12, 46.66s/it]Batches:  40%|████      | 78/193 [53:40<1:29:25, 46.66s/it]Batches:  41%|████      | 79/193 [54:26<1:28:39, 46.66s/it]Batches:  41%|████▏     | 80/193 [55:13<1:27:53, 46.66s/it]Batches:  42%|████▏     | 81/193 [56:00<1:27:06, 46.66s/it]Batches:  42%|████▏     | 82/193 [56:46<1:26:19, 46.67s/it]Batches:  43%|████▎     | 83/193 [57:33<1:25:33, 46.66s/it]Batches:  44%|████▎     | 84/193 [58:20<1:24:45, 46.66s/it]Batches:  44%|████▍     | 85/193 [59:06<1:23:59, 46.66s/it]Batches:  45%|████▍     | 86/193 [59:53<1:23:12, 46.66s/it]Batches:  45%|████▌     | 87/193 [1:00:40<1:22:25, 46.66s/it]Batches:  46%|████▌     | 88/193 [1:01:26<1:21:38, 46.65s/it]Batches:  46%|████▌     | 89/193 [1:02:13<1:20:51, 46.65s/it]Batches:  47%|████▋     | 90/193 [1:02:59<1:20:04, 46.65s/it]Batches:  47%|████▋     | 91/193 [1:03:46<1:19:17, 46.65s/it]Batches:  48%|████▊     | 92/193 [1:04:33<1:18:31, 46.64s/it]Batches:  48%|████▊     | 93/193 [1:05:19<1:17:43, 46.64s/it]Batches:  49%|████▊     | 94/193 [1:06:06<1:16:57, 46.64s/it]Batches:  49%|████▉     | 95/193 [1:06:53<1:16:10, 46.63s/it]Batches:  50%|████▉     | 96/193 [1:07:39<1:15:24, 46.64s/it]Batches:  50%|█████     | 97/193 [1:08:26<1:14:36, 46.64s/it]Batches:  51%|█████     | 98/193 [1:09:13<1:13:50, 46.64s/it]Batches:  51%|█████▏    | 99/193 [1:09:59<1:13:03, 46.64s/it]Batches:  52%|█████▏    | 100/193 [1:10:46<1:12:16, 46.63s/it]Batches:  52%|█████▏    | 101/193 [1:11:32<1:11:29, 46.63s/it]Batches:  53%|█████▎    | 102/193 [1:12:19<1:10:42, 46.62s/it]Batches:  53%|█████▎    | 103/193 [1:13:06<1:09:55, 46.61s/it]Batches:  54%|█████▍    | 104/193 [1:13:52<1:09:08, 46.61s/it]Batches:  54%|█████▍    | 105/193 [1:14:42<1:09:33, 47.42s/it]Batches:  55%|█████▍    | 106/193 [1:15:28<1:08:24, 47.18s/it]Batches:  55%|█████▌    | 107/193 [1:16:16<1:08:01, 47.46s/it]Batches:  56%|█████▌    | 108/193 [1:17:03<1:06:53, 47.22s/it]Batches:  56%|█████▋    | 109/193 [1:17:50<1:05:50, 47.03s/it]Batches:  57%|█████▋    | 110/193 [1:18:33<1:03:38, 46.01s/it]Batches:  58%|█████▊    | 111/193 [1:19:17<1:01:56, 45.33s/it]Batches:  58%|█████▊    | 112/193 [1:20:03<1:01:41, 45.70s/it]Batches:  59%|█████▊    | 113/193 [1:20:51<1:01:35, 46.20s/it]Batches:  59%|█████▉    | 114/193 [1:21:35<59:51, 45.46s/it]  Batches:  60%|█████▉    | 115/193 [1:22:17<57:51, 44.51s/it]Batches:  60%|██████    | 116/193 [1:23:03<57:54, 45.13s/it]Batches:  61%|██████    | 117/193 [1:23:52<58:37, 46.29s/it]Batches:  61%|██████    | 118/193 [1:24:42<58:55, 47.13s/it]Batches:  62%|██████▏   | 119/193 [1:25:12<52:04, 42.22s/it]Batches:  62%|██████▏   | 120/193 [1:25:44<47:41, 39.20s/it]Batches:  63%|██████▎   | 121/193 [1:26:11<42:28, 35.40s/it]Batches:  63%|██████▎   | 122/193 [1:26:34<37:26, 31.63s/it]Batches:  64%|██████▎   | 123/193 [1:26:54<32:51, 28.17s/it]Batches:  64%|██████▍   | 124/193 [1:27:12<29:03, 25.27s/it]Batches:  65%|██████▍   | 125/193 [1:27:31<26:21, 23.25s/it]Batches:  65%|██████▌   | 126/193 [1:27:48<23:53, 21.39s/it]Batches:  66%|██████▌   | 127/193 [1:28:03<21:21, 19.42s/it]Batches:  66%|██████▋   | 128/193 [1:28:16<19:06, 17.64s/it]Batches:  67%|██████▋   | 129/193 [1:28:31<17:50, 16.73s/it]Batches:  67%|██████▋   | 130/193 [1:28:46<16:56, 16.13s/it]Batches:  68%|██████▊   | 131/193 [1:28:58<15:32, 15.04s/it]Batches:  68%|██████▊   | 132/193 [1:29:10<14:16, 14.03s/it]Batches:  69%|██████▉   | 133/193 [1:29:22<13:32, 13.55s/it]Batches:  69%|██████▉   | 134/193 [1:29:34<12:40, 12.89s/it]Batches:  70%|██████▉   | 135/193 [1:29:44<11:38, 12.04s/it]Batches:  70%|███████   | 136/193 [1:29:53<10:32, 11.10s/it]Batches:  71%|███████   | 137/193 [1:30:03<10:13, 10.95s/it]Batches:  72%|███████▏  | 138/193 [1:30:11<09:17, 10.14s/it]Batches:  72%|███████▏  | 139/193 [1:30:19<08:29,  9.44s/it]Batches:  73%|███████▎  | 140/193 [1:30:28<08:07,  9.19s/it]Batches:  73%|███████▎  | 141/193 [1:30:34<07:16,  8.40s/it]Batches:  74%|███████▎  | 142/193 [1:30:41<06:38,  7.81s/it]Batches:  74%|███████▍  | 143/193 [1:30:48<06:16,  7.53s/it]Batches:  75%|███████▍  | 144/193 [1:30:55<06:01,  7.39s/it]Batches:  75%|███████▌  | 145/193 [1:31:02<05:47,  7.23s/it]Batches:  76%|███████▌  | 146/193 [1:31:08<05:24,  6.90s/it]Batches:  76%|███████▌  | 147/193 [1:31:13<05:01,  6.56s/it]Batches:  77%|███████▋  | 148/193 [1:31:19<04:38,  6.19s/it]Batches:  77%|███████▋  | 149/193 [1:31:25<04:27,  6.07s/it]Batches:  78%|███████▊  | 150/193 [1:31:30<04:11,  5.85s/it]Batches:  78%|███████▊  | 151/193 [1:31:35<03:56,  5.62s/it]Batches:  79%|███████▉  | 152/193 [1:31:40<03:43,  5.45s/it]Batches:  79%|███████▉  | 153/193 [1:31:45<03:32,  5.32s/it]Batches:  80%|███████▉  | 154/193 [1:31:51<03:29,  5.37s/it]Batches:  80%|████████  | 155/193 [1:31:55<03:12,  5.07s/it]Batches:  81%|████████  | 156/193 [1:32:01<03:14,  5.27s/it]Batches:  81%|████████▏ | 157/193 [1:32:05<02:59,  4.97s/it]Batches:  82%|████████▏ | 158/193 [1:32:09<02:44,  4.69s/it]Batches:  82%|████████▏ | 159/193 [1:32:14<02:39,  4.68s/it]Batches:  83%|████████▎ | 160/193 [1:32:18<02:29,  4.52s/it]Batches:  83%|████████▎ | 161/193 [1:32:23<02:26,  4.58s/it]Batches:  84%|████████▍ | 162/193 [1:32:26<02:11,  4.23s/it]Batches:  84%|████████▍ | 163/193 [1:32:30<02:05,  4.18s/it]Batches:  85%|████████▍ | 164/193 [1:32:34<01:57,  4.05s/it]Batches:  85%|████████▌ | 165/193 [1:32:37<01:47,  3.85s/it]Batches:  86%|████████▌ | 166/193 [1:32:41<01:41,  3.74s/it]Batches:  87%|████████▋ | 167/193 [1:32:44<01:33,  3.60s/it]Batches:  87%|████████▋ | 168/193 [1:32:47<01:28,  3.53s/it]Batches:  88%|████████▊ | 169/193 [1:32:51<01:24,  3.52s/it]Batches:  88%|████████▊ | 170/193 [1:32:54<01:18,  3.41s/it]Batches:  89%|████████▊ | 171/193 [1:32:57<01:15,  3.45s/it]Batches:  89%|████████▉ | 172/193 [1:33:01<01:10,  3.34s/it]Batches:  90%|████████▉ | 173/193 [1:33:04<01:07,  3.37s/it]Batches:  90%|█████████ | 174/193 [1:33:07<01:01,  3.21s/it]Batches:  91%|█████████ | 175/193 [1:33:10<00:55,  3.09s/it]Batches:  91%|█████████ | 176/193 [1:33:13<00:54,  3.19s/it]Batches:  92%|█████████▏| 177/193 [1:33:16<00:47,  3.00s/it]Batches:  92%|█████████▏| 178/193 [1:33:18<00:43,  2.92s/it]Batches:  93%|█████████▎| 179/193 [1:33:21<00:39,  2.84s/it]Batches:  93%|█████████▎| 180/193 [1:33:24<00:35,  2.75s/it]Batches:  94%|█████████▍| 181/193 [1:33:26<00:32,  2.69s/it]Batches:  94%|█████████▍| 182/193 [1:33:29<00:30,  2.77s/it]Batches:  95%|█████████▍| 183/193 [1:33:32<00:27,  2.71s/it]Batches:  95%|█████████▌| 184/193 [1:33:34<00:24,  2.68s/it]Batches:  96%|█████████▌| 185/193 [1:33:37<00:20,  2.60s/it]Batches:  96%|█████████▋| 186/193 [1:33:39<00:18,  2.59s/it]Batches:  97%|█████████▋| 187/193 [1:33:42<00:15,  2.52s/it]Batches:  97%|█████████▋| 188/193 [1:33:44<00:11,  2.40s/it]Batches:  98%|█████████▊| 189/193 [1:33:46<00:09,  2.30s/it]Batches:  98%|█████████▊| 190/193 [1:33:48<00:07,  2.41s/it]Batches:  99%|█████████▉| 191/193 [1:33:51<00:04,  2.39s/it]Batches:  99%|█████████▉| 192/193 [1:33:53<00:02,  2.28s/it]Batches: 100%|██████████| 193/193 [1:33:55<00:00,  2.22s/it]Batches: 100%|██████████| 193/193 [1:33:55<00:00, 29.20s/it]
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5642.30 seconds
INFO:root:

INFO:mteb.evaluation.MTEB:Evaluation for MultiLongDocRetrieval on test took 5642.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ko': {'ndcg_at_1': 0.275, 'ndcg_at_3': 0.31958, 'ndcg_at_5': 0.34024, 'ndcg_at_10': 0.36877, 'ndcg_at_20': 0.38634, 'ndcg_at_100': 0.41038, 'ndcg_at_1000': 0.43478, 'map_at_1': 0.275, 'map_at_3': 0.3075, 'map_at_5': 0.319, 'map_at_10': 0.33044, 'map_at_20': 0.33519, 'map_at_100': 0.33817, 'map_at_1000': 0.33902, 'recall_at_1': 0.275, 'recall_at_3': 0.355, 'recall_at_5': 0.405, 'recall_at_10': 0.495, 'recall_at_20': 0.565, 'recall_at_100': 0.7, 'recall_at_1000': 0.895, 'precision_at_1': 0.275, 'precision_at_3': 0.11833, 'precision_at_5': 0.081, 'precision_at_10': 0.0495, 'precision_at_20': 0.02825, 'precision_at_100': 0.007, 'precision_at_1000': 0.0009, 'mrr_at_1': 0.275, 'mrr_at_3': 0.30750000000000005, 'mrr_at_5': 0.31900000000000006, 'mrr_at_10': 0.33043849206349213, 'mrr_at_20': 0.33519194335506275, 'mrr_at_100': 0.33816825300207165, 'mrr_at_1000': 0.33901539954417975, 'nauc_ndcg_at_1_max': np.float64(0.5918301229003063), 'nauc_ndcg_at_1_std': np.float64(0.1476423565869634), 'nauc_ndcg_at_1_diff1': np.float64(0.5993027432475263), 'nauc_ndcg_at_3_max': np.float64(0.5980753454423011), 'nauc_ndcg_at_3_std': np.float64(0.1512167068029201), 'nauc_ndcg_at_3_diff1': np.float64(0.5553727984656028), 'nauc_ndcg_at_5_max': np.float64(0.6037297227789772), 'nauc_ndcg_at_5_std': np.float64(0.15652922893975202), 'nauc_ndcg_at_5_diff1': np.float64(0.575234192186373), 'nauc_ndcg_at_10_max': np.float64(0.6100563705986363), 'nauc_ndcg_at_10_std': np.float64(0.17917460646822164), 'nauc_ndcg_at_10_diff1': np.float64(0.542187109829058), 'nauc_ndcg_at_20_max': np.float64(0.6170702941599755), 'nauc_ndcg_at_20_std': np.float64(0.20123467915484194), 'nauc_ndcg_at_20_diff1': np.float64(0.5420734547320807), 'nauc_ndcg_at_100_max': np.float64(0.6220186576985072), 'nauc_ndcg_at_100_std': np.float64(0.20435822830310854), 'nauc_ndcg_at_100_diff1': np.float64(0.5421939099650478), 'nauc_ndcg_at_1000_max': np.float64(0.619198701111182), 'nauc_ndcg_at_1000_std': np.float64(0.20110282032635932), 'nauc_ndcg_at_1000_diff1': np.float64(0.5477073388422267), 'nauc_map_at_1_max': np.float64(0.5918301229003063), 'nauc_map_at_1_std': np.float64(0.1476423565869634), 'nauc_map_at_1_diff1': np.float64(0.5993027432475263), 'nauc_map_at_3_max': np.float64(0.5959254593928469), 'nauc_map_at_3_std': np.float64(0.15003703817492253), 'nauc_map_at_3_diff1': np.float64(0.566574839302112), 'nauc_map_at_5_max': np.float64(0.599378620355109), 'nauc_map_at_5_std': np.float64(0.15299758269322475), 'nauc_map_at_5_diff1': np.float64(0.5778609892342207), 'nauc_map_at_10_max': np.float64(0.6022376715359256), 'nauc_map_at_10_std': np.float64(0.16167125398637616), 'nauc_map_at_10_diff1': np.float64(0.5645702303690379), 'nauc_map_at_20_max': np.float64(0.6038820896596527), 'nauc_map_at_20_std': np.float64(0.1669276747626766), 'nauc_map_at_20_diff1': np.float64(0.564489451140831), 'nauc_map_at_100_max': np.float64(0.6036924068469054), 'nauc_map_at_100_std': np.float64(0.1670951142446419), 'nauc_map_at_100_diff1': np.float64(0.5645560958995411), 'nauc_map_at_1000_max': np.float64(0.6035113395906951), 'nauc_map_at_1000_std': np.float64(0.16704012516217587), 'nauc_map_at_1000_diff1': np.float64(0.564660700523618), 'nauc_recall_at_1_max': np.float64(0.5918301229003063), 'nauc_recall_at_1_std': np.float64(0.1476423565869634), 'nauc_recall_at_1_diff1': np.float64(0.5993027432475263), 'nauc_recall_at_3_max': np.float64(0.6043260093254503), 'nauc_recall_at_3_std': np.float64(0.15463280217286934), 'nauc_recall_at_3_diff1': np.float64(0.5238627619905692), 'nauc_recall_at_5_max': np.float64(0.6163755585214413), 'nauc_recall_at_5_std': np.float64(0.16710187817946184), 'nauc_recall_at_5_diff1': np.float64(0.5701915575414095), 'nauc_recall_at_10_max': np.float64(0.6346441611300646), 'nauc_recall_at_10_std': np.float64(0.23983958819656429), 'nauc_recall_at_10_diff1': np.float64(0.4672825096599563), 'nauc_recall_at_20_max': np.float64(0.6667499232849731), 'nauc_recall_at_20_std': np.float64(0.33993677254529747), 'nauc_recall_at_20_diff1': np.float64(0.4623382740189398), 'nauc_recall_at_100_max': np.float64(0.7301657359034409), 'nauc_recall_at_100_std': np.float64(0.4011709601873531), 'nauc_recall_at_100_diff1': np.float64(0.4443883984867592), 'nauc_recall_at_1000_max': np.float64(0.8341461232159645), 'nauc_recall_at_1000_std': np.float64(0.5913829358865373), 'nauc_recall_at_1000_diff1': np.float64(0.44742964520603123), 'nauc_precision_at_1_max': np.float64(0.5918301229003063), 'nauc_precision_at_1_std': np.float64(0.1476423565869634), 'nauc_precision_at_1_diff1': np.float64(0.5993027432475263), 'nauc_precision_at_3_max': np.float64(0.6043260093254502), 'nauc_precision_at_3_std': np.float64(0.1546328021728694), 'nauc_precision_at_3_diff1': np.float64(0.5238627619905692), 'nauc_precision_at_5_max': np.float64(0.6163755585214417), 'nauc_precision_at_5_std': np.float64(0.1671018781794618), 'nauc_precision_at_5_diff1': np.float64(0.5701915575414094), 'nauc_precision_at_10_max': np.float64(0.6346441611300654), 'nauc_precision_at_10_std': np.float64(0.2398395881965642), 'nauc_precision_at_10_diff1': np.float64(0.46728250965995627), 'nauc_precision_at_20_max': np.float64(0.6667499232849733), 'nauc_precision_at_20_std': np.float64(0.3399367725452974), 'nauc_precision_at_20_diff1': np.float64(0.46233827401893934), 'nauc_precision_at_100_max': np.float64(0.7301657359034404), 'nauc_precision_at_100_std': np.float64(0.40117096018735326), 'nauc_precision_at_100_diff1': np.float64(0.44438839848675893), 'nauc_precision_at_1000_max': np.float64(0.834146123215964), 'nauc_precision_at_1000_std': np.float64(0.591382935886539), 'nauc_precision_at_1000_diff1': np.float64(0.4474296452060312), 'nauc_mrr_at_1_max': np.float64(0.5918301229003063), 'nauc_mrr_at_1_std': np.float64(0.1476423565869634), 'nauc_mrr_at_1_diff1': np.float64(0.5993027432475263), 'nauc_mrr_at_3_max': np.float64(0.5959254593928469), 'nauc_mrr_at_3_std': np.float64(0.15003703817492253), 'nauc_mrr_at_3_diff1': np.float64(0.566574839302112), 'nauc_mrr_at_5_max': np.float64(0.599378620355109), 'nauc_mrr_at_5_std': np.float64(0.15299758269322475), 'nauc_mrr_at_5_diff1': np.float64(0.5778609892342207), 'nauc_mrr_at_10_max': np.float64(0.6022376715359256), 'nauc_mrr_at_10_std': np.float64(0.16167125398637616), 'nauc_mrr_at_10_diff1': np.float64(0.5645702303690379), 'nauc_mrr_at_20_max': np.float64(0.6038820896596527), 'nauc_mrr_at_20_std': np.float64(0.1669276747626766), 'nauc_mrr_at_20_diff1': np.float64(0.564489451140831), 'nauc_mrr_at_100_max': np.float64(0.6036924068469054), 'nauc_mrr_at_100_std': np.float64(0.1670951142446419), 'nauc_mrr_at_100_diff1': np.float64(0.5645560958995411), 'nauc_mrr_at_1000_max': np.float64(0.6035113395906951), 'nauc_mrr_at_1000_std': np.float64(0.16704012516217587), 'nauc_mrr_at_1000_diff1': np.float64(0.564660700523618), 'main_score': 0.36877}}
